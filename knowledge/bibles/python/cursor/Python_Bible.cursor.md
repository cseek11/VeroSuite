# Python Bible ‚Äì Cursor Edition

> Auto-generated from SSM Bible via V3 compiler + pipeline.
> This file contains the COMPLETE content from the SSM Bible.

**Last Updated:** 2025-11-30

## Chapter 1 ‚Äî INTRODUCTION TO PYTHON

_Difficulty: Beginner_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch01-start" --> üìò CHAPTER 1 ‚Äî INTRODUCTION TO PYTHON üü¢ Beginner.

<!-- SSM:CHUNK_BOUNDARY id="ch01-start" --> üìò CHAPTER 1 ‚Äî INTRODUCTION TO PYTHON üü¢ Beginner

#### ## How to Use This Bible.

## How to Use This Bible

#### üéØ "I'm building data pipelines" 1.

**üéØ "I'm building data pipelines"** 1. Chapter 21 (Data Engineering) ‚Üí 6 hours 2. Chapter 12 (Performance) ‚Üí 3 hours 3. Chapter 17 (Concurrency) ‚Üí 4 hours 4. Chapter 22 (Packaging) ‚Üí 2 hours **Total: ~15 hours**

#### Depth Level: 3 (Comprehensive) Python Versions Covered: 3.8‚Äì3.14+.

Depth Level: 3 (Comprehensive) Python Versions Covered: 3.8‚Äì3.14+

#### üìö Python Bible Learning Roadmap.

üìö Python Bible Learning Roadmap

#### Quick Start: Want code immediately? Jump to Ch.

Quick Start: Want code immediately? Jump to Ch. 2.2.3 for your first working example, then return here for context.

#### 1.1 What Python Is (and Is Not).

1.1 What Python Is (and Is Not)

#### Python is a high-level, general-purpose programming language emphasizing:.

Python is a high-level, general-purpose programming language emphasizing:

#### Huge ecosystem support.

huge ecosystem support

#### Interoperability with C, Rust, and other runtimes.

interoperability with C, Rust, and other runtimes

#### Batteries-included standard library.

batteries-included standard library

#### Dynamic + optionally statically-typed workflow.

dynamic + optionally statically-typed workflow

#### Python is designed so developers can think about ideas rather than ceremony, making it one of the most effective languages for:.

Python is designed so developers can think about ideas rather than ceremony, making it one of the most effective languages for:

#### Infrastructure tooling.

infrastructure tooling

#### But Python also powers: operating system components, distributed systems, servers, compilers, and even embedded devices.

But Python also powers: operating system components, distributed systems, servers, compilers, and even embedded devices.

#### 1.2 Why Python Matters (2025+).

1.2 Why Python Matters (2025+)

#### Python continues to dominate because:.

Python continues to dominate because:

#### ‚úî AI & ML ecosystem is unmatched.

‚úî AI & ML ecosystem is unmatched

#### NumPy, PyTorch, TensorFlow, JAX, Polars, Pandas, etc.

NumPy, PyTorch, TensorFlow, JAX, Polars, Pandas, etc.

#### ‚úî Data engineering & analytics.

‚úî Data engineering & analytics

#### Polars, Pandas, DuckDB, PySpark, Apache Arrow.

Polars, Pandas, DuckDB, PySpark, Apache Arrow.

#### ‚úî Web frameworks are world-class.

‚úî Web frameworks are world-class

#### FastAPI, Django, Starlette.

FastAPI, Django, Starlette.

#### ‚úî High-performance via extensions.

‚úî High-performance via extensions

#### CPython 3.11+ specialization.

CPython 3.11+ specialization

#### 3.14+ free-threading mode.

3.14+ free-threading mode

#### ‚úî Excellent for automation.

‚úî Excellent for automation

#### Scripting, DevOps, CI/CD, infra-as-code.

Scripting, DevOps, CI/CD, infra-as-code.

#### ‚úî Strong typing story.

‚úî Strong typing story

#### Python 3.10‚Äì3.14 introduced:.

Python 3.10‚Äì3.14 introduced:

#### New generic syntax (PEP 695).

new generic syntax (PEP 695)

#### Broad editor + LSP support.

broad editor + LSP support

#### 1.3 Python‚Äôs Design Philosophy (The Zen of Python).

1.3 Python‚Äôs Design Philosophy (The Zen of Python)

#### Simple is better than complex.

Simple is better than complex.

#### Explicit is better than implicit.

Explicit is better than implicit.

#### If the implementation is hard to explain, it‚Äôs a bad idea.

If the implementation is hard to explain, it‚Äôs a bad idea.

#### Throughout this book, these principles guide best practices.

Throughout this book, these principles guide best practices.

#### 1.4 How Python Runs Your Code.

1.4 How Python Runs Your Code

#### Interpreted (executed by the CPython interpreter).

interpreted (executed by the CPython interpreter)

#### Bytecode compiled (source ‚Üí bytecode ‚Üí executed).

bytecode compiled (source ‚Üí bytecode ‚Üí executed)

#### Dynamically typed (type checks at runtime).

dynamically typed (type checks at runtime)

#### Hybrid binding model: early binding for locals (compile-time via LOAD_FAST), late binding for globals and closures (runtime via LOAD_GLOBAL/LOAD_DE...

hybrid binding model: early binding for locals (compile-time via LOAD_FAST), late binding for globals and closures (runtime via LOAD_GLOBAL/LOAD_DEREF)

#### Object-oriented (everything is an object).

object-oriented (everything is an object)

#### Python Execution Pipeline:.

**Python Execution Pipeline:**

#### Tokenization: Character stream ‚Üí Token stream - Parsing (PEG parser): Token stream ‚Üí AST (Abstract Syntax Tree) - AST generation: Tree structure re...

- **Tokenization**: Character stream ‚Üí Token stream - **Parsing (PEG parser)**: Token stream ‚Üí AST (Abstract Syntax Tree) - **AST generation**: Tree structure representing code structure - **Bytecode compilation**: AST ‚Üí Bytecode instructions - **Execution by CPython VM**: Interpreter executes bytecode (or JIT compiles it) - **Optional JIT tiers (3.13+ experimental)**: Hot code paths compiled to native code

#### *See Appendix G ‚Üí G.2.1 for additional details and memory layout diagrams.*.

*See Appendix G ‚Üí G.2.1 for additional details and memory layout diagrams.*

#### 1.5 Python Implementations 1.5.1 CPython (default, reference implementation).

1.5 Python Implementations 1.5.1 CPython (default, reference implementation)

#### 3.11+: huge speed jumps (PEP 659).

3.11+: huge speed jumps (PEP 659)

#### 3.14+: optional free-threading.

3.14+: optional free-threading

#### Great for long-running, pure-Python workloads.

Great for long-running, pure-Python workloads

#### Sometimes incompatible with CPython C-extensions.

Sometimes incompatible with CPython C-extensions

#### 1.5.3 MicroPython & CircuitPython.

1.5.3 MicroPython & CircuitPython

#### Designed for embedded devices.

Designed for embedded devices

#### 1.5.4 Jython, IronPython, GraalPython.

1.5.4 Jython, IronPython, GraalPython

#### Jython ‚Üí Java ecosystem.

Jython ‚Üí Java ecosystem

#### GraalPython ‚Üí Polyglot on GraalVM, extremely fast for some workloads.

GraalPython ‚Üí Polyglot on GraalVM, extremely fast for some workloads

#### 1.6.0 Quick Start: Your First Python Program.

1.6.0 Quick Start: Your First Python Program

#### Before diving into theory, let's write working code:.

Before diving into theory, let's write working code:

#### Try This: Modify the function to accept an optional title parameter.

Try This: Modify the function to accept an optional title parameter.

#### Now you've written Python code! The rest of this chapter provides context for why Python works this way.

Now you've written Python code! The rest of this chapter provides context for why Python works this way.

#### ‚úî Excellent Use Cases.

‚úî Excellent Use Cases

#### Scripting & automation.

Scripting & automation

#### API services (FastAPI, Django).

API services (FastAPI, Django)

#### Data engineering pipelines.

Data engineering pipelines

#### Prototyping / rapid iteration.

Prototyping / rapid iteration

#### Infrastructure scripting.

Infrastructure scripting

#### Low-latency systems (C++/Rust preferred).

Low-latency systems (C++/Rust preferred)

#### Real-time embedded control.

Real-time embedded control

#### Extremely high-throughput microservices where GC and interpreter overhead matter.

Extremely high-throughput microservices where GC and interpreter overhead matter

#### GPU kernels (use Python wrappers but write kernels in CUDA/Numba).

GPU kernels (use Python wrappers but write kernels in CUDA/Numba)

#### 1.7 Setting Up Your Python Environment (2025+) 1.7.1 Choose Your Python Version.

1.7 Setting Up Your Python Environment (2025+) 1.7.1 Choose Your Python Version

#### Python 3.12 or 3.13 (3.14 optional-runtime for free-threading).

Python 3.12 or 3.13 (3.14 optional-runtime for free-threading)

#### Install via pyenv, asdf, or the official installer.

Install via pyenv, asdf, or the official installer.

#### 1.7.2 Create a Virtual Environment python3 -m venv .venv source .venv/bin/activate # Unix .\.venv\Scripts\activate # Windows.

1.7.2 Create a Virtual Environment python3 -m venv .venv source .venv/bin/activate # Unix .\.venv\Scripts\activate # Windows

#### Or modern alternatives:.

or modern alternatives:

#### Uv (Rust-based, extremely fast).

uv (Rust-based, extremely fast)

#### Pipx for global tool isolation.

pipx for global tool isolation

#### 1.7.3 Install Core Tools pip install \ black \ ruff \ mypy \ pytest \ httpx \ rich.

1.7.3 Install Core Tools pip install \ black \ ruff \ mypy \ pytest \ httpx \ rich

#### 1.8 A Tour of Python via Examples.

1.8 A Tour of Python via Examples

#### This section gives newcomers a taste of the syntax.

This section gives newcomers a taste of the syntax.

#### 1.8.1 Micro Example ‚Äî Variables & Expressions name = "Alice" age = 30 message = f"{name} is {age} years old." print(message).

1.8.1 Micro Example ‚Äî Variables & Expressions name = "Alice" age = 30 message = f"{name} is {age} years old." print(message)

#### 1.8.2 Mini Example ‚Äî Working with Collections users = [ {"id": 1, "active": True}, {"id": 2, "active": False}, ].

1.8.2 Mini Example ‚Äî Working with Collections users = [ {"id": 1, "active": True}, {"id": 2, "active": False}, ]

#### Active_users = [u for u in users if u["active"]].

active_users = [u for u in users if u["active"]]

#### 1.8.3 Mini Example ‚Äî Functions & Decorators from functools import lru_cache.

1.8.3 Mini Example ‚Äî Functions & Decorators from functools import lru_cache

#### @lru_cache(maxsize=256) def fib(n: int) -> int: if n < 2: return n return fib(n-1) + fib(n-2).

@lru_cache(maxsize=256) def fib(n: int) -> int: if n < 2: return n return fib(n-1) + fib(n-2)

#### 1.8.4 Macro Example ‚Äî Simple CLI App #!/usr/bin/env python3 """ Simple Task Manager CLI """.

1.8.4 Macro Example ‚Äî Simple CLI App #!/usr/bin/env python3 """ Simple Task Manager CLI """

#### From __future__ import annotations from pathlib import Path import json import sys.

from __future__ import annotations from pathlib import Path import json import sys

#### TASKS_FILE = Path("tasks.json").

TASKS_FILE = Path("tasks.json")

#### Def load_tasks() -> list[str]: if TASKS_FILE.exists(): return json.loads(TASKS_FILE.read_text()) return [].

def load_tasks() -> list[str]: if TASKS_FILE.exists(): return json.loads(TASKS_FILE.read_text()) return []

#### Def save_tasks(tasks: list[str]) -> None: TASKS_FILE.write_text(json.dumps(tasks, indent=2)).

def save_tasks(tasks: list[str]) -> None: TASKS_FILE.write_text(json.dumps(tasks, indent=2))

#### Def main() -> int: tasks = load_tasks().

def main() -> int: tasks = load_tasks()

#### If len(sys.argv) < 2: print("Usage: task add <name> | task list") return 1.

if len(sys.argv) < 2: print("Usage: task add <name> | task list") return 1

#### Command = sys.argv[1].

command = sys.argv[1]

#### If command == "add": name = " ".join(sys.argv[2:]) tasks.append(name) save_tasks(tasks) print("Added:", name).

if command == "add": name = " ".join(sys.argv[2:]) tasks.append(name) save_tasks(tasks) print("Added:", name)

#### Elif command == "list": for i, t in enumerate(tasks, start=1): print(f"{i}.

elif command == "list": for i, t in enumerate(tasks, start=1): print(f"{i}. {t}")

#### If __name__ == "__main__": raise SystemExit(main()).

if __name__ == "__main__": raise SystemExit(main())

#### Clean project structure.

Clean project structure

#### Teaser for Modules (Chapter 8).

Teaser for Modules (Chapter 8)

#### (Some later covered in Appendix D).

(Some later covered in Appendix D)

#### Mutable default arguments 2.

1. Mutable default arguments 2. Closing files improperly 3. Misusing is vs == 4. Modifying lists while iterating 5. Shadowing built-in names 6. Forgetting virtual environments 7. Using Python lists for heavy numerical workloads

#### Each will have deeper treatment later.

Each will have deeper treatment later.

#### 1.10 Python Version Compatibility (3.8 ‚Üí 3.14).

1.10 Python Version Compatibility (3.8 ‚Üí 3.14)

#### Python 3.10‚Äì3.14 introduced profound enhancements:.

Python 3.10‚Äì3.14 introduced profound enhancements:

#### Structural pattern matching.

structural pattern matching

#### Self, ParamSpec, TypeVarTuple.

Self, ParamSpec, TypeVarTuple

#### Immortal objects / free-threading groundwork.

immortal objects / free-threading groundwork

#### Optional GIL removal (3.14+).

optional GIL removal (3.14+)

#### 1.11 Summary & Key Takeaways.

1.11 Summary & Key Takeaways

#### Python is a readable, expressive, versatile language.

Python is a readable, expressive, versatile language.

#### CPython is the reference implementation.

CPython is the reference implementation.

#### Execution = tokenization ‚Üí AST ‚Üí bytecode ‚Üí interpreter.

Execution = tokenization ‚Üí AST ‚Üí bytecode ‚Üí interpreter.

#### Everything is an object.

Everything is an object.

#### Python is dynamic but now strongly supports optional static typing.

Python is dynamic but now strongly supports optional static typing.

#### Python 3.11+ brought radical performance gains.

Python 3.11+ brought radical performance gains.

#### Virtual environments are essential.

Virtual environments are essential.

#### You‚Äôve now seen enough to be productive.

You‚Äôve now seen enough to be productive.

#### Proceed to Chapter 2 ‚Äî Syntax & Semantics, where we dive into:.

Proceed to Chapter 2 ‚Äî Syntax & Semantics, where we dive into:

#### String formatting evolution.

string formatting evolution

#### This is where Python‚Äôs deeper semantics begin to matter.

This is where Python‚Äôs deeper semantics begin to matter.

#### <!-- SSM:PART id="part2" title="Part II: Language Core" -->.

<!-- SSM:PART id="part2" title="Part II: Language Core" -->

#### # Part II: Language Core.

# Part II: Language Core


---

## Chapter 2 ‚Äî SYNTAX & SEMANTICS

_Difficulty: Beginner_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch02-start" --> üìò CHAPTER 2 ‚Äî SYNTAX & SEMANTICS üü¢ Beginner.

<!-- SSM:CHUNK_BOUNDARY id="ch02-start" --> üìò CHAPTER 2 ‚Äî SYNTAX & SEMANTICS üü¢ Beginner

#### Depth Level: 3 (Comprehensive) Python Versions Covered: 3.8‚Äì3.14+ Prerequisites: Chapter 1.

Depth Level: 3 (Comprehensive) Python Versions Covered: 3.8‚Äì3.14+ Prerequisites: Chapter 1

#### Chapter 2 establishes the full formal grammar and operational semantics of Python‚Äôs everyday constructs.

Chapter 2 establishes the full formal grammar and operational semantics of Python‚Äôs everyday constructs.

#### What counts as a valid token.

What counts as a valid token

#### How whitespace controls program structure.

How whitespace controls program structure

#### How names bind to objects.

How names bind to objects

#### Everything about strings, slice notation, unpacking, and expressions.

Everything about strings, slice notation, unpacking, and expressions

#### The evolution of string formatting (%, .format(), f-strings).

The evolution of string formatting (%, .format(), f-strings)

#### Raw strings & escaping.

Raw strings & escaping

#### Line continuation patterns.

Line continuation patterns

#### Indexing + slicing semantics.

Indexing + slicing semantics

#### Unpacking semantics (*, **).

Unpacking semantics (*, **)

#### This chapter forms the mental model that your entire understanding of Python will build upon.

This chapter forms the mental model that your entire understanding of Python will build upon.

#### 2.1 Lexical Structure (Tokens, Keywords, Names) 2.1.1 Tokens.

2.1 Lexical Structure (Tokens, Keywords, Names) 2.1.1 Tokens

#### Python's lexical components include:.

Python's lexical components include:

#### Identifiers (variable names).

Identifiers (variable names)

#### Keywords (if, for, class, etc.).

Keywords (if, for, class, etc.)

#### Literals (42, "hello", 3.14, True).

Literals (42, "hello", 3.14, True)

#### Operators (+, -, *, //, %, ==, etc.).

Operators (+, -, *, //, %, ==, etc.)

#### Delimiters ((), [], {}, ,, :).

Delimiters ((), [], {}, ,, :)

#### 2.1.2 Keywords (3.10‚Äì3.14).

2.1.2 Keywords (3.10‚Äì3.14)

#### False, None, True, and, as, assert, async, await, break, class, continue, def, del, elif, else, except, finally, for, from, global, if, import, in,...

False, None, True, and, as, assert, async, await, break, class, continue, def, del, elif, else, except, finally, for, from, global, if, import, in, is, lambda, nonlocal, not, or, pass, raise, return, try, while, with, yield, match, case # 3.10+

#### 2.1.3 Identifiers (Names).

2.1.3 Identifiers (Names)

#### Start with letter or underscore.

Start with letter or underscore

#### Followed by letters, numbers, underscores.

Followed by letters, numbers, underscores

#### Unicode allowed (but discouraged for public APIs).

Unicode allowed (but discouraged for public APIs)

#### _valid_name = 10 œÄ = 3.14 # Allowed, but avoid in production user_id = 42.

_valid_name = 10 œÄ = 3.14 # Allowed, but avoid in production user_id = 42

#### 2.2 Significance of Whitespace.

2.2 Significance of Whitespace

#### Python uses indentation to define blocks instead of {}.

Python uses indentation to define blocks instead of {}.

#### 1 indentation level = 4 spaces (PEP 8).

1 indentation level = 4 spaces (PEP 8)

#### Tabs are discouraged.

Tabs are discouraged

#### If x: print("bad indent") # 3 spaces print("mixed") # 4 spaces.

if x: print("bad indent") # 3 spaces print("mixed") # 4 spaces

#### If x: print("good") print("consistent").

if x: print("good") print("consistent")

#### 2.3 Expressions and Operators.

2.3 Expressions and Operators

#### Expressions follow a strict precedence order.

Expressions follow a strict precedence order. The most common:

#### ** exponentiation *, /, //, % multiplication/division +, - addition/subtraction <<, >> bitwise shifts & bitwise and ^ xor | or <, >, <=, >= compari...

** exponentiation *, /, //, % multiplication/division +, - addition/subtraction <<, >> bitwise shifts & bitwise and ^ xor | or <, >, <=, >= comparisons ==, != equality not logical not and logical and or logical or

#### # and stops early x is not None and x > 0.

# and stops early x is not None and x > 0

#### # or stops early username or "guest".

# or stops early username or "guest"

#### 2.4 Strings (The Complete Treatment).

2.4 Strings (The Complete Treatment)

#### Sequences of code points.

sequences of code points

#### "double quotes" 'single quotes' """triple quoted""" r"raw\nstring" # raw literal f"{expression}" # formatted.

"double quotes" 'single quotes' """triple quoted""" r"raw\nstring" # raw literal f"{expression}" # formatted

#### 2.4.1 String Formatting Evolution.

2.4.1 String Formatting Evolution

#### Code Evolution: Simple ‚Üí Production-Ready.

Code Evolution: Simple ‚Üí Production-Ready

#### Stage 1: Basic % formatting (legacy).

Stage 1: Basic % formatting (legacy)

#### Stage 2: .format() method (Python 2.7+, 3.0+).

Stage 2: .format() method (Python 2.7+, 3.0+)

#### Stage 3: f-strings (Python 3.6+, recommended).

Stage 3: f-strings (Python 3.6+, recommended)

#### Stage 4: Production-ready with validation.

Stage 4: Production-ready with validation

#### 2.4.1 String Formatting Evolution 1.

2.4.1 String Formatting Evolution 1. Percent-style (%) "%s is %d years old" % ("Alice", 30)

#### Str.format() (2008) "{name} is {age}".format(name="Alice", age=30).

2. str.format() (2008) "{name} is {age}".format(name="Alice", age=30)

#### Avoids ordering confusion Cons:.

avoids ordering confusion Cons:

#### F-Strings (3.6+) ‚Äî Use these everywhere name = "Alice" age = 30 f"{name} is {age} years old".

3. F-Strings (3.6+) ‚Äî Use these everywhere name = "Alice" age = 30 f"{name} is {age} years old"

#### Advanced f-strings (3.12+ PEP 701):.

Advanced f-strings (3.12+ PEP 701):

#### X = 10 print(f"{x = }") # prints: x = 10 print(f"{x+5 = }") # prints: x+5 = 15.

x = 10 print(f"{x = }") # prints: x = 10 print(f"{x+5 = }") # prints: x+5 = 15

#### f"{user.name.upper():>20}"

f"{user.name.upper():>20}"

#### Raw strings disable escape interpretation.

Raw strings disable escape interpretation.

#### ‚ö†Ô∏è Raw strings cannot end with an odd number of backslashes.

‚ö†Ô∏è Raw strings cannot end with an odd number of backslashes.

#### R"C:\newfolder\" # invalid.

r"C:\newfolder\" # invalid

#### Python converts values to boolean using:.

Python converts values to boolean using:

#### __len__() (non-zero means True).

__len__() (non-zero means True)

#### 0 0.0 0j '' [] {} set() None False.

0 0.0 0j '' [] {} set() None False

#### Everything else is truthy.

Everything else is truthy.

#### 2.7 Indexing & Slice Semantics (Critical Topic) Syntax: obj[start:stop:step].

2.7 Indexing & Slice Semantics (Critical Topic) Syntax: obj[start:stop:step]

#### S[0] # 'a' s[-1] # 'f'.

s[0] # 'a' s[-1] # 'f'

#### S[2:5] # 'cde' s[:3] # 'abc' s[3:] # 'def' s[::2] # 'ace' s[::-1] # reverse string.

s[2:5] # 'cde' s[:3] # 'abc' s[3:] # 'def' s[::2] # 'ace' s[::-1] # reverse string

#### Negative indices count from the right.

Negative indices count from the right

#### Omitted start/stop default to entire range.

Omitted start/stop default to entire range

#### 2.8 Unpacking (* and **).

2.8 Unpacking (* and **)

#### Assignment unpacking a, b = [1, 2].

Assignment unpacking a, b = [1, 2]

#### A, *middle, b = [1, 2, 3, 4, 5].

a, *middle, b = [1, 2, 3, 4, 5]

#### # a=1, middle=[2,3,4], b=5.

# a=1, middle=[2,3,4], b=5

#### Function arguments def add(a, b, c): return a + b + c.

Function arguments def add(a, b, c): return a + b + c

#### Nums = [1, 2, 3] add(*nums).

nums = [1, 2, 3] add(*nums)

#### Dict merging a = {"x": 1} b = {"y": 2} c = {a, b}.

Dict merging a = {"x": 1} b = {"y": 2} c = {**a, **b}

#### 2.9 Line Continuation.

2.9 Line Continuation

#### Three valid approaches:.

Three valid approaches:

#### Implicit (best) total = ( price + tax + discount ).

1. Implicit (best) total = ( price + tax + discount )

#### Explicit (rarely used) result = price + \ tax + \ discount.

2. Explicit (rarely used) result = price + \ tax + \ discount

#### Inside list/dict literals.

3. Inside list/dict literals

#### 2.10 Binding Semantics (Names ‚Üí Objects).

2.10 Binding Semantics (Names ‚Üí Objects)

#### Python variables are just names pointing to objects.

Python variables are just names pointing to objects.

#### Example: a = [1, 2, 3] b = a # same list b.append(4).

Example: a = [1, 2, 3] b = a # same list b.append(4)

#### Print(a) # [1,2,3,4].

print(a) # [1,2,3,4]

#### Identity vs equality.

identity vs equality

#### 2.11 Identity: is vs == x == y # value equality x is y # same object identity.

2.11 Identity: is vs == x == y # value equality x is y # same object identity

#### X = 256 y = 256 x is y # True (interning).

x = 256 y = 256 x is y # True (interning)

#### X = 1000 y = 1000 x is y # False.

x = 1000 y = 1000 x is y # False

#### Custom objects (if designed mutable).

custom objects (if designed mutable)

#### 2.13 Expression Evaluation Order.

2.13 Expression Evaluation Order

#### X = f1() + f2() * f3().

x = f1() + f2() * f3()

#### Even though multiplication binds tighter.

Even though multiplication binds tighter.

#### 2.14 Preview: How These Semantics Affect Real Programs.

2.14 Preview: How These Semantics Affect Real Programs

#### These semantics will directly impact:

These semantics will directly impact:

#### Chapter 4 (Type System).

Chapter 4 (Type System)

#### Chapter 5 (Control Flow).

Chapter 5 (Control Flow)

#### Chapter 6 (Functions).

Chapter 6 (Functions)

#### Chapter 17 (Concurrency).

Chapter 17 (Concurrency)

#### Chapter 21 (Data Engineering).

Chapter 21 (Data Engineering)

#### Python's simplicity masks deep semantics.

Python's simplicity masks deep semantics.

#### 2.15 Mini Example ‚Äî Slicing + Unpacking + f-strings def summarize(sequence: list[int]) -> str: first, *middle, last = sequence return f"{first=} {l...

2.15 Mini Example ‚Äî Slicing + Unpacking + f-strings def summarize(sequence: list[int]) -> str: first, *middle, last = sequence return f"{first=} {last=} {len(middle)} items in between"

#### Print(summarize([10, 20, 30, 40, 50])).

print(summarize([10, 20, 30, 40, 50]))

#### 2.16 Macro Example ‚Äî Log Parser from pathlib import Path.

2.16 Macro Example ‚Äî Log Parser from pathlib import Path

#### Def analyze_log(path: str): lines = Path(path).read_text().splitlines().

def analyze_log(path: str): lines = Path(path).read_text().splitlines()

#### Error_lines = [ line for line in lines if "ERROR" in line ].

error_lines = [ line for line in lines if "ERROR" in line ]

#### Timestamps = [ line.split(" ", 1)[0] for line in error_lines ].

timestamps = [ line.split(" ", 1)[0] for line in error_lines ]

#### Return { "errors": len(error_lines), "first": timestamps[0] if timestamps else None, "last": timestamps[-1] if timestamps else None, }.

return { "errors": len(error_lines), "first": timestamps[0] if timestamps else None, "last": timestamps[-1] if timestamps else None, }

#### Stats = analyze_log("server.log") print(stats).

stats = analyze_log("server.log") print(stats)

#### ‚ö†Ô∏è Mutable default arguments ‚ö†Ô∏è is vs == ‚ö†Ô∏è Modifying sequences during iteration ‚ö†Ô∏è Late binding in closures ‚ö†Ô∏è Raw string edge cases ‚ö†Ô∏è Line-conti...

‚ö†Ô∏è Mutable default arguments ‚ö†Ô∏è is vs == ‚ö†Ô∏è Modifying sequences during iteration ‚ö†Ô∏è Late binding in closures ‚ö†Ô∏è Raw string edge cases ‚ö†Ô∏è Line-continuation bugs ‚ö†Ô∏è Copying vs aliasing

#### 2.18 Summary & Takeaways.

2.18 Summary & Takeaways

#### Python‚Äôs syntax is clean but deeply semantic.

Python‚Äôs syntax is clean but deeply semantic

#### Indentation = structure.

Indentation = structure

#### Strings: use f-strings.

Strings: use f-strings

#### Slicing and unpacking are powerful.

Slicing and unpacking are powerful

#### Raw strings essential for regex.

Raw strings essential for regex

#### Semantics around identity and mutability are critical.

Semantics around identity and mutability are critical

#### Evaluation order is predictable (left-to-right).

Evaluation order is predictable (left-to-right)

#### üëâ Chapter 3 ‚Äî Core Execution Model.

üëâ Chapter 3 ‚Äî Core Execution Model

#### Where we deeply analyze:.

Where we deeply analyze:

#### Import system caching (sys.modules).

Import system caching (sys.modules)

#### __pycache__ mechanics.

__pycache__ mechanics


---

## Chapter 3 ‚Äî CORE EXECUTION MODEL

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch03-start" --> üìò CHAPTER 3 ‚Äî CORE EXECUTION MODEL üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch03-start" --> üìò CHAPTER 3 ‚Äî CORE EXECUTION MODEL üü° Intermediate

#### Depth Level: 3 (Comprehensive) Python Versions Covered: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì2.

Depth Level: 3 (Comprehensive) Python Versions Covered: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì2

#### This chapter provides a deep, formal understanding of:

This chapter provides a deep, formal understanding of:

#### How Python processes, compiles, and executes code.

How Python processes, compiles, and executes code

#### The token ‚Üí AST ‚Üí bytecode ‚Üí execution cycle.

The token ‚Üí AST ‚Üí bytecode ‚Üí execution cycle

#### Frames, namespaces, and scope resolution mechanics.

Frames, namespaces, and scope resolution mechanics

#### How functions, classes, modules, and scripts load.

How functions, classes, modules, and scripts load

#### The role of the CPython virtual machine.

The role of the CPython virtual machine

#### The import system (including caching via sys.modules).

The import system (including caching via sys.modules)

#### __pycache__ and .pyc bytecode files.

__pycache__ and .pyc bytecode files

#### Optimization flags and effects.

Optimization flags and effects

#### Execution contexts, globals, locals.

Execution contexts, globals, locals

#### How Python finds modules via sys.path.

How Python finds modules via sys.path

#### How __name__ == "__main__" actually works.

How __name__ == "__main__" actually works

#### Evaluation order and stack frames.

Evaluation order and stack frames

#### 3.13+ JIT tiers and 3.14+ free-threading impact.

3.13+ JIT tiers and 3.14+ free-threading impact

#### Understanding this chapter is essential before learning:.

Understanding this chapter is essential before learning:

#### Performance optimization.

performance optimization

#### Debugging and profiling.

debugging and profiling

#### 3.1 From Source File to Running Program.

3.1 From Source File to Running Program

#### Python executes code in a multi-stage pipeline, not line-by-line.

Python executes code in a multi-stage pipeline, not line-by-line.

#### Complete Execution Pipeline:.

**Complete Execution Pipeline:**

#### Read source file (.py): Python reads the source file from disk 2.

1. **Read source file (.py)**: Python reads the source file from disk 2. **Tokenize**: Convert character stream to token stream 3. **Parse (PEG parser)**: Convert tokens to Abstract Syntax Tree (AST) 4. **AST construction**: Build tree structure representing code semantics 5. **Bytecode compilation**: Convert AST to bytecode instructions 6. **Write .pyc file to __pycache__**: Cache compiled bytecode for faster subsequent runs 7. **Interpreter executes bytecode**: CPython VM executes bytecode instructions 8. **Optionally JIT-optimized (3.13+)**: Hot code paths compiled to native machine code

#### *See Appendix G ‚Üí G.2.1 for additional memory layout and frame structure diagrams.*.

*See Appendix G ‚Üí G.2.1 for additional memory layout and frame structure diagrams.*

#### Example: Complete Transformation Pipeline.

**Example: Complete Transformation Pipeline**

#### 1. Tokenization:

**1. Tokenization:**

#### AST (Abstract Syntax Tree):.

**2. AST (Abstract Syntax Tree):**

#### Bytecode (Actual CPython Output):.

**3. Bytecode (Actual CPython Output):**

#### Bytecode Explanation:.

**Bytecode Explanation:**

#### LOAD_FAST 0 (a): Load local variable a (index 0 in fast locals array) - LOAD_FAST 1 (b): Load local variable b (index 1 in fast locals array) - BIN...

- `LOAD_FAST 0 (a)`: Load local variable `a` (index 0 in fast locals array) - `LOAD_FAST 1 (b)`: Load local variable `b` (index 1 in fast locals array) - `BINARY_ADD`: Pop two values from stack, add them, push result - `RETURN_VALUE`: Pop value from stack and return it

#### Try This: Inspect bytecode for different operations:.

**Try This:** Inspect bytecode for different operations:

#### The tokenizer converts raw characters to tokens.

The tokenizer converts raw characters to tokens.

#### Import tokenize from io import BytesIO.

import tokenize from io import BytesIO

#### Code = b"1 + 2 * 3" print(list(tokenize.tokenize(BytesIO(code).readline))).

code = b"1 + 2 * 3" print(list(tokenize.tokenize(BytesIO(code).readline)))

#### This is the basis for syntax errors.

This is the basis for syntax errors.

#### 3.3 Parsing (PEG Parser).

3.3 Parsing (PEG Parser)

#### Python 3.9+ replaced the LL(1) parser with a PEG parser:.

Python 3.9+ replaced the LL(1) parser with a PEG parser:

#### Fewer parsing restrictions.

fewer parsing restrictions

#### Allows new syntax like pattern matching.

allows new syntax like pattern matching

#### Fewer ‚Äúambiguous grammar‚Äù errors.

fewer ‚Äúambiguous grammar‚Äù errors

#### The PEG parser constructs a tree of AST nodes.

The PEG parser constructs a tree of AST nodes.

#### 3.4 Abstract Syntax Tree (AST).

3.4 Abstract Syntax Tree (AST)

#### AST represents the syntactic structure.

AST represents the syntactic structure.

#### Import ast print(ast.dump(ast.parse("x = 1 + 2"), indent=4)).

import ast print(ast.dump(ast.parse("x = 1 + 2"), indent=4))

#### Module( body=[ Assign( targets=[Name(id='x')], value=BinOp( left=Constant(1), op=Add(), right=Constant(2) ) ) ] ).

Module( body=[ Assign( targets=[Name(id='x')], value=BinOp( left=Constant(1), op=Add(), right=Constant(2) ) ) ] )

#### Static analysis tools.

static analysis tools

#### 3.5 Bytecode Compilation.

3.5 Bytecode Compilation

#### The AST is compiled to bytecode, a list of VM instructions.

The AST is compiled to bytecode, a list of VM instructions.

#### Def add(a, b): return a + b.

def add(a, b): return a + b

#### CALL / CALL_FUNCTION (3.11 has new CALL opcodes).

CALL / CALL_FUNCTION (3.11 has new CALL opcodes)

#### 3.6 The CPython Execution Loop (Interpreter).

3.6 The CPython Execution Loop (Interpreter)

#### CPython is a stack-based virtual machine.

CPython is a stack-based virtual machine.

#### Execution logic (simplified):.

Execution logic (simplified):

#### While True: instruction = next_bytecode execute instruction manipulate stack.

while True: instruction = next_bytecode execute instruction manipulate stack

#### Stack-based example:.

Stack-based example:

#### LOAD_FAST a LOAD_FAST b BINARY_ADD RETURN_VALUE.

LOAD_FAST a LOAD_FAST b BINARY_ADD RETURN_VALUE

#### Values pushed/popped from the VM stack.

values pushed/popped from the VM stack

#### Locals stored in frame objects.

locals stored in frame objects

#### Execution context preserved in a stack of frames.

execution context preserved in a stack of frames

#### 3.7 Frame Objects & Namespaces.

3.7 Frame Objects & Namespaces

#### Each function call creates a frame:.

Each function call creates a frame:

#### Def f(a): frame = inspect.currentframe() print(frame.f_locals).

def f(a): frame = inspect.currentframe() print(frame.f_locals)

#### Builtins (f_builtins).

builtins (f_builtins)

#### Bytecode instruction pointer.

bytecode instruction pointer

#### Closure cell references.

closure cell references

#### Understanding frames is essential for:.

Understanding frames is essential for:

#### Tail recursion limits.

tail recursion limits

#### Async/await internals.

async/await internals

#### 3.8 The Import System (Critical Topic).

3.8 The Import System (Critical Topic)

#### Python‚Äôs module loader is one of its most misunderstood subsystems.

Python‚Äôs module loader is one of its most misunderstood subsystems.

#### Check sys.modules cache.

Check sys.modules cache

#### Find module (via sys.meta_path).

Find module (via sys.meta_path)

#### Load and execute module.

Load and execute module

#### Store module object in sys.modules.

Store module object in sys.modules

#### Import returns the module object.

Import returns the module object

#### Import Machinery Flow:.

**Import Machinery Flow:**

#### ‚ñº Return module object.

‚ñº Return module object

#### Sys.modules acts as a cache (prevents re-importing) - sys.meta_path contains finders (BuiltinImporter, FrozenImporter, PathFinder) - ModuleSpec con...

- `sys.modules` acts as a cache (prevents re-importing) - `sys.meta_path` contains finders (BuiltinImporter, FrozenImporter, PathFinder) - `ModuleSpec` contains all metadata about a module - Loaders execute the module code - Module is stored in `sys.modules` before execution completes

#### *See Appendix G ‚Üí G.4.1 for additional details.*.

*See Appendix G ‚Üí G.4.1 for additional details.*

#### 3.8.1 Module Search Path (sys.path).

3.8.1 Module Search Path (sys.path)

#### Python looks for modules in:.

Python looks for modules in:

#### Directory of running script.

Directory of running script

#### Import sys print(sys.path).

import sys print(sys.path)

#### 3.8.2 sys.modules: The Global Module Cache.

3.8.2 sys.modules: The Global Module Cache

#### A module is executed once.

A module is executed once. All future imports return the cached object.

#### Import sys print(sys.modules["sys"]).

import sys print(sys.modules["sys"])

#### Circular import debugging.

circular import debugging

#### 3.9 __pycache__ and .pyc Files.

3.9 __pycache__ and .pyc Files

#### When Python imports a module:.

When Python imports a module:

#### It compiles bytecode.

It compiles bytecode

#### Writes .pyc to __pycache__.

Writes .pyc to __pycache__

#### example.cpython-311.pyc

example.cpython-311.pyc

#### To disable bytecode generation:.

To disable bytecode generation:

#### PYTHONDONTWRITEBYTECODE=1 python app.py.

PYTHONDONTWRITEBYTECODE=1 python app.py

#### 3.10 Execution Modes 3.10.1 Running as script.

3.10 Execution Modes 3.10.1 Running as script

#### Python script.py Executes file as __main__.

python script.py Executes file as __main__.

#### 3.10.2 Running as module.

3.10.2 Running as module

#### Python -m package.module.

python -m package.module

#### 3.10.3 Running in REPL/interactive.

3.10.3 Running in REPL/interactive

#### IPython, Jupyter, Python Shell.

IPython, Jupyter, Python Shell.

#### 3.11 __name__ == "__main__" Explained.

3.11 __name__ == "__main__" Explained

#### This idiom controls whether code runs during:

This idiom controls whether code runs during:

#### Def main(): print("running").

def main(): print("running")

#### If __name__ == "__main__": main().

if __name__ == "__main__": main()

#### __name__ = "__main__".

__name__ = "__main__"

#### __name__ = "<module_name>".

__name__ = "<module_name>"

#### Prevent code from running unintentionally.

Prevent code from running unintentionally

#### Testing reusable modules.

Testing reusable modules

#### 3.12 Optimization Levels.

3.12 Optimization Levels

#### Run Python optimized:.

Run Python optimized:

#### Python -O script.py python -OO script.py.

python -O script.py python -OO script.py

#### Removes assert statements.

removes assert statements

#### Creates .opt-1.pyc / .opt-2.pyc.

creates .opt-1.pyc / .opt-2.pyc

#### ‚ö†Ô∏è Do not rely on assert for production validation.

‚ö†Ô∏è Do not rely on assert for production validation.

#### 3.13 CPython 3.11+ Performance Model.

3.13 CPython 3.11+ Performance Model

#### Adaptive specializing interpreter.

adaptive specializing interpreter

#### Zero-cost exception handling.

zero-cost exception handling

#### Faster function calls.

faster function calls

#### Drastically faster async execution.

drastically faster async execution

#### Performance gain: 10%‚Äì60% faster without changing code.

Performance gain: 10%‚Äì60% faster without changing code.

#### See also: - Chapter 8 (Modules & Imports) for how modules are loaded and cached during execution - Chapter 12 (Performance) for optimization techni...

**See also:** - Chapter 8 (Modules & Imports) for how modules are loaded and cached during execution - Chapter 12 (Performance) for optimization techniques that leverage Python's execution model - Chapter 27 (CPython Internals) for deep dive into bytecode and the evaluation loop

#### 3.14 CPython 3.13‚Äì3.14+ JIT & Free-Threading.

3.14 CPython 3.13‚Äì3.14+ JIT & Free-Threading

#### 3.13: Tier 2 JIT (Copy-and-Patch, Experimental).

3.13: Tier 2 JIT (Copy-and-Patch, Experimental)

#### ‚ö†Ô∏è Important: Python 3.13 introduces an optional, experimental JIT compiler enabled at build time (--enable-experimental-jit).

‚ö†Ô∏è Important: Python 3.13 introduces an optional, experimental JIT compiler enabled at build time (`--enable-experimental-jit`). The implementation is a copy-and-patch JIT (PEP 744), not LLVM-based.

#### Tier 0: Baseline interpreter (standard bytecode execution).

Tier 0: Baseline interpreter (standard bytecode execution)

#### Tier 1: Adaptive interpreter (specialized opcodes based on runtime types).

Tier 1: Adaptive interpreter (specialized opcodes based on runtime types)

#### Tier 2: Copy-and-patch JIT (experimental, 3.13+).

Tier 2: Copy-and-patch JIT (experimental, 3.13+)

#### How Copy-and-Patch Works:.

How Copy-and-Patch Works:

#### CPython still uses the regular bytecode interpreter as tier 0.

CPython still uses the regular bytecode interpreter as tier 0.

#### "Hot" regions of bytecode are compiled by stitching together pre-generated machine code templates.

"Hot" regions of bytecode are compiled by stitching together pre-generated machine code templates.

#### The JIT patches constants, jump targets, and metadata at runtime.

The JIT patches constants, jump targets, and metadata at runtime.

#### This design minimizes compile overhead and complexity, in exchange for more modest optimization...

This design minimizes compile overhead and complexity, in exchange for more modest optimization compared with full SSA/LLVM-style JITs.

#### No IR ‚Üí machine code pipeline like LLVM; instead, templates are copied and patched.

No IR ‚Üí machine code pipeline like LLVM; instead, templates are copied and patched.

#### Adaptive thresholds determine when to promote code to JIT tier.

Adaptive thresholds determine when to promote code to JIT tier.

#### Performance: Real-world benchmarks show 5‚Äì15% speedups on pyperformance, with larger gains on tight numeric/control-flow heavy code and negligible ...

Performance: Real-world benchmarks show 5‚Äì15% speedups on pyperformance, with larger gains on tight numeric/control-flow heavy code and negligible benefits for I/O-bound or extension-heavy workloads.

#### Enable with: PYTHON_JIT=1 python script.py.

Enable with: `PYTHON_JIT=1 python script.py`

#### 3.14: Free-threading Mode.

3.14: Free-threading Mode

#### ‚ö†Ô∏è Experimental: Free-threading is a build-time optional feature in 3.13+ (e.g., python3.13t, or --disable-gil when building from source).

‚ö†Ô∏è Experimental: Free-threading is a build-time optional feature in 3.13+ (e.g., `python3.13t`, or `--disable-gil` when building from source).

#### Python3.13t script.py # or python3.13 --disable-gil script.py.

python3.13t script.py # or python3.13 --disable-gil script.py

#### True parallelism for Python threads, but:.

True parallelism for Python threads, but:

#### Higher per-object synchronization cost; single-threaded code may slow down.

Higher per-object synchronization cost; single-threaded code may slow down.

#### In 3.14+, PEP 779 moves free-threading toward "supported but not default" status.

In 3.14+, PEP 779 moves free-threading toward "supported but not default" status.

#### Compatibility issues:.

Compatibility issues:

#### C-extension libraries may not be thread-safe without GIL.

C-extension libraries may not be thread-safe without GIL

#### Performance degradation possible for CPU-bound single-threaded code.

Performance degradation possible for CPU-bound single-threaded code

#### Immortal objects stabilization not complete.

Immortal objects stabilization not complete

#### Frame semantics changes.

Frame semantics changes

#### Reality Check: Free-Threading in Production.

Reality Check: Free-Threading in Production

#### Safe to experiment in CPU-bound, thread-friendly workloads you control.

Safe to experiment in CPU-bound, thread-friendly workloads you control

#### Don't assume drop-in gains; measure with pyperformance & your own load tests.

Don't assume drop-in gains; measure with pyperformance & your own load tests

#### This will eventually reshape Python's performance landscape.

This will eventually reshape Python's performance landscape.

#### 3.15 Mini Example ‚Äî Inspecting Execution import dis.

3.15 Mini Example ‚Äî Inspecting Execution import dis

#### Def compute(x): return x * 2 + 3.

def compute(x): return x * 2 + 3

#### print(dis.dis(compute))

print(dis.dis(compute))

#### How to read bytecode.

how to read bytecode

#### What optimizations Python performs.

what optimizations Python performs

#### 3.16 Mini Example ‚Äî Import Behavior.

3.16 Mini Example ‚Äî Import Behavior

#### App/ main.py util.py.

app/ main.py util.py

#### Example: Import Caching via sys.modules.

**Example: Import Caching via sys.modules**

#### First import: Module code executes, module object created and stored in sys.modules 2.

1. **First import:** Module code executes, module object created and stored in `sys.modules` 2. **Subsequent imports:** Python checks `sys.modules` first, returns cached module without re-execution 3. **Same object:** All import statements return the same module object (singleton behavior) 4. **Direct access:** Can access cached modules via `sys.modules['module_name']`

#### Try This: Experiment with import caching:.

**Try This:** Experiment with import caching:

#### See also: - Chapter 3.1 (Execution Model) for how Python loads and executes modules - Chapter 3.17 (Module Loader) for custom module loading exampl...

**See also:** - Chapter 3.1 (Execution Model) for how Python loads and executes modules - Chapter 3.17 (Module Loader) for custom module loading examples - Chapter 11.12 (Circular Imports) for architectural solutions

#### 3.17 Macro Example ‚Äî Simple Module Loader import importlib import sys from pathlib import Path.

3.17 Macro Example ‚Äî Simple Module Loader import importlib import sys from pathlib import Path

#### Def load_module(path: str, name: str): spec = importlib.util.spec_from_file_location(name, path) module = importlib.util.module_from_spec(spec) sys...

def load_module(path: str, name: str): spec = importlib.util.spec_from_file_location(name, path) module = importlib.util.module_from_spec(spec) sys.modules[name] = module spec.loader.exec_module(module) return module

#### # usage m = load_module("config.py", "config") print(m).

# usage m = load_module("config.py", "config") print(m)

#### Custom loading workflow.

custom loading workflow

#### This is how plugin systems work.

This is how plugin systems work.

#### ‚ö†Ô∏è Circular imports ‚ö†Ô∏è Mutable module-level state ‚ö†Ô∏è Overusing import * ‚ö†Ô∏è Confusing script vs module execution ‚ö†Ô∏è Using assert for runtime checks ...

‚ö†Ô∏è Circular imports ‚ö†Ô∏è Mutable module-level state ‚ö†Ô∏è Overusing import * ‚ö†Ô∏è Confusing script vs module execution ‚ö†Ô∏è Using assert for runtime checks ‚ö†Ô∏è Modifying sys.path directly ‚ö†Ô∏è Relying on bytecode-only releases

#### Full treatment in Appendix D.

Full treatment in Appendix D.

#### 3.19 Summary & Takeaways.

3.19 Summary & Takeaways

#### Python compiles source to bytecode before running.

Python compiles source to bytecode before running

#### The interpreter is a stack machine.

The interpreter is a stack machine

#### Frames model execution state.

Frames model execution state

#### Imports are cached in sys.modules.

Imports are cached in sys.modules

#### .pyc files improve startup speed.

.pyc files improve startup speed

#### JIT and free-threading are transforming performance.

JIT and free-threading are transforming performance

#### Understanding execution model leads to better debugging, testing, and performance tuning.

Understanding execution model leads to better debugging, testing, and performance tuning

#### üëâ Chapter 4 ‚Äî Types & Type System.

üëâ Chapter 4 ‚Äî Types & Type System

#### The entire Python type lattice.

the entire Python type lattice

#### Depth Level: 3 (Comprehensive) Length Equivalent: 10‚Äì15 pages Versions Covered: 3.8 ‚Üí 3.14+.

Depth Level: 3 (Comprehensive) Length Equivalent: 10‚Äì15 pages Versions Covered: 3.8 ‚Üí 3.14+


---

## Chapter 4 ‚Äî TYPES & TYPE SYSTEM

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch04-start" --> üìò CHAPTER 4 ‚Äî TYPES & TYPE SYSTEM üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch04-start" --> üìò CHAPTER 4 ‚Äî TYPES & TYPE SYSTEM üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8‚Äì3.14+.

Depth Level: 3 Python Versions: 3.8‚Äì3.14+

#### <!-- SSM:CONCEPT id="type-system" level="intermediate" prereqs="syntax,functions" --> 4.0 Overview <!-- /SSM:CONCEPT -->.

<!-- SSM:CONCEPT id="type-system" level="intermediate" prereqs="syntax,functions" --> 4.0 Overview <!-- /SSM:CONCEPT -->

#### Python‚Äôs type system is:.

Python‚Äôs type system is:

#### Gradually typed via optional static typing.

Gradually typed via optional static typing

#### Structural for protocols.

Structural for protocols

#### Richly extensible through the Data Model.

Richly extensible through the Data Model

#### Strongly typed (no silent coercions like JS).

Strongly typed (no silent coercions like JS)

#### Runtime introspectable.

Runtime introspectable

#### This chapter covers:

This chapter covers:

#### The entire Data Model (dunder methods).

The entire Data Model (dunder methods)

#### Abstract Base Classes.

Abstract Base Classes

#### Typing: generics, TypeVar, ParamSpec, Self, TypeAlias, TypedDict, Protocol.

typing: generics, TypeVar, ParamSpec, Self, TypeAlias, TypedDict, Protocol

#### Type narrowing & guards.

Type narrowing & guards

#### Python‚Äôs conceptual type lattice.

Python‚Äôs conceptual type lattice

#### Practical examples for real-world engineering.

Practical examples for real-world engineering

#### 4.1 Everything Is an Object (Formal Statement).

4.1 Everything Is an Object (Formal Statement)

#### Every value is an object.

Every value is an object. Every object has a type. The type determines the object‚Äôs behavior.

#### Type(10) is int type("hello") is str type([1,2,3]) is list.

type(10) is int type("hello") is str type([1,2,3]) is list

#### Even functions and classes are objects:.

Even functions and classes are objects:

#### Def f(): pass class C: pass.

def f(): pass class C: pass

#### Type(f) # function type(C) # type.

type(f) # function type(C) # type

#### 4.2 Built-In Types (Full Inventory).

4.2 Built-In Types (Full Inventory)

#### Python‚Äôs built-in types fall into categories:.

Python‚Äôs built-in types fall into categories:

#### User-defined classes.

user-defined classes

#### Type-checking helpers:.

Type-checking helpers:

#### 4.3 Identity, Equality, and Mutability 4.3.1 Identity a is b.

4.3 Identity, Equality, and Mutability 4.3.1 Identity a is b

#### True only if they reference the same object.

True only if they reference the same object.

#### 4.3.2 Equality a == b.

4.3.2 Equality a == b

#### True if values compare equal.

True if values compare equal.

#### Def f(x=None): if x is None: x = [].

def f(x=None): if x is None: x = []

#### 4.4 The Type Hierarchy & Lattice.

4.4 The Type Hierarchy & Lattice

#### Python Type Hierarchy:.

**Python Type Hierarchy:**

#### Type Relationships:.

**Type Relationships:**

#### All types inherit from object - type is the metaclass for all classes (classes are instances of type) - Built-in types are implemented in C (PyObje...

- All types inherit from `object` - `type` is the metaclass for all classes (classes are instances of `type`) - Built-in types are implemented in C (PyObject structures) - User-defined classes are instances of `type` - Special types: `NoneType` (singleton), `NotImplementedType`, `EllipsisType`

#### Python's type model is:.

Python's type model is:

#### Not a single inheritance hierarchy.

not a single inheritance hierarchy

#### Driven by protocols and behavior.

driven by protocols and behavior

#### Integrated with abstract base classes.

integrated with abstract base classes

#### Supports structural typing via Protocol.

supports structural typing via Protocol

#### The true type system is closer to a behavioral lattice than a classical tree.

The true type system is closer to a behavioral lattice than a classical tree.

#### 4.5 Static Typing with typing.

4.5 Static Typing with typing

#### Python supports optional static typing:.

Python supports optional static typing:

#### Def add(a: int, b: int) -> int: return a + b.

def add(a: int, b: int) -> int: return a + b

#### Pyright (recommended).

pyright (recommended)

#### Pylance (VS Code plugin).

pylance (VS Code plugin)

#### Ruff (with type-checking mode coming).

ruff (with type-checking mode coming)

#### 4.5.1 Basic types x: int = 10 y: str = "hello" z: list[int] = [1, 2, 3].

4.5.1 Basic types x: int = 10 y: str = "hello" z: list[int] = [1, 2, 3]

#### (3.9+ syntax allows built-in generics.).

(3.9+ syntax allows built-in generics.)

#### Def maybe(x: int | None) -> int | None: return x.

def maybe(x: int | None) -> int | None: return x

#### Equivalent to typing.Union[int, None].

Equivalent to typing.Union[int, None].

#### 4.5.3 Optional def greet(name: str | None) -> str: if name is None: return "Hello!" return f"Hello, {name}!".

4.5.3 Optional def greet(name: str | None) -> str: if name is None: return "Hello!" return f"Hello, {name}!"

#### Optional means ‚Äúvalue may be None‚Äù.

Optional means ‚Äúvalue may be None‚Äù.

#### 4.5.4 Literal Types def move(direction: Literal["up", "down"]): ...

4.5.4 Literal Types def move(direction: Literal["up", "down"]): ...

#### 4.5.5 Type Aliases (3.10+) UserId: TypeAlias = int.

4.5.5 Type Aliases (3.10+) UserId: TypeAlias = int

#### 4.5.6 NewType UserId = NewType("UserId", int).

4.5.6 NewType UserId = NewType("UserId", int)

#### Adds semantic distinction.

Adds semantic distinction.

#### 4.5.7 TypeVar, ParamSpec, TypeVarTuple TypeVar: T = TypeVar("T").

4.5.7 TypeVar, ParamSpec, TypeVarTuple TypeVar: T = TypeVar("T")

#### Def identity(x: T) -> T: return x.

def identity(x: T) -> T: return x

#### ParamSpec (for decorators): P = ParamSpec("P").

ParamSpec (for decorators): P = ParamSpec("P")

#### TypeVarTuple (variadic generics): Ts = TypeVarTuple("Ts").

TypeVarTuple (variadic generics): Ts = TypeVarTuple("Ts")

#### Used with tuple types.

Used with tuple types.

#### 4.5.8 Self Type (3.11+) class Builder: def set_x(self, value) -> Self: self.x = value return self.

4.5.8 Self Type (3.11+) class Builder: def set_x(self, value) -> Self: self.x = value return self

#### Supports fluent interfaces.

Supports fluent interfaces.

#### 4.5.9 override Decorator (3.12+) class Base: def f(self): ...

4.5.9 override Decorator (3.12+) class Base: def f(self): ...

#### Class Child(Base): @override def f(self): ...

class Child(Base): @override def f(self): ...

#### 4.6 The Data Model (Dunder Methods).

4.6 The Data Model (Dunder Methods)

#### This is the heart of Python.

This is the heart of Python.

#### Python's entire behavior model is defined through special methods.

Python's entire behavior model is defined through special methods.

#### Categories: 4.6.1 Object Lifecycle __new__(cls, ...) __init__(self, ...) __del__(self).

Categories: 4.6.1 Object Lifecycle __new__(cls, ...) __init__(self, ...) __del__(self)

#### 4.6.2 Representation __repr__(self) __str__(self) __format__(self, spec).

4.6.2 Representation __repr__(self) __str__(self) __format__(self, spec)

#### 4.6.3 Comparison & Ordering __eq__, __ne__ __lt__, __le__, __gt__, __ge__.

4.6.3 Comparison & Ordering __eq__, __ne__ __lt__, __le__, __gt__, __ge__

#### 4.6.4 Numeric Operators __add__, __sub__, __mul__, __truediv__ __floordiv__, __mod__ __pow__, __neg__.

4.6.4 Numeric Operators __add__, __sub__, __mul__, __truediv__ __floordiv__, __mod__ __pow__, __neg__

#### 4.6.5 Container Protocols __len__ __getitem__ __setitem__ __delitem__ __contains__ __iter__ __next__.

4.6.5 Container Protocols __len__ __getitem__ __setitem__ __delitem__ __contains__ __iter__ __next__

#### 4.6.6 Callable Objects __call__(self, *args, **kwargs).

4.6.6 Callable Objects __call__(self, *args, **kwargs)

#### Lets objects behave like functions.

Lets objects behave like functions.

#### 4.6.7 Attribute Access __getattr__ __setattr__ __delattr__ __getattribute__.

4.6.7 Attribute Access __getattr__ __setattr__ __delattr__ __getattribute__

#### Powerful but dangerous.

Powerful but dangerous.

#### 4.6.8 Context Managers __enter__ __exit__.

4.6.8 Context Managers __enter__ __exit__

#### 4.7 Abstract Base Classes (ABCs).

4.7 Abstract Base Classes (ABCs)

#### Collections.abc defines behavioral categories:.

collections.abc defines behavioral categories:

#### Use to define expected interfaces:.

Use to define expected interfaces:

#### From collections.abc import Iterable.

from collections.abc import Iterable

#### Def flatten(items: Iterable): ...

def flatten(items: Iterable): ...

#### 4.8 Protocols (Structural Typing).

4.8 Protocols (Structural Typing)

#### Protocols describe behavior, not inheritance.

Protocols describe behavior, not inheritance.

#### From typing import Protocol.

from typing import Protocol

#### Class SupportsClose(Protocol): def close(self) -> None: ...

class SupportsClose(Protocol): def close(self) -> None: ...

#### Any object with a .close() method qualifies, regardless of class hierarchy.

Any object with a .close() method qualifies, regardless of class hierarchy.

#### This is duck typing with static checks.

This is duck typing with static checks.

#### 4.9 Type Narrowing & Type Guards.

4.9 Type Narrowing & Type Guards

#### Use isinstance() + match-case.

Use isinstance() + match-case.

#### Def f(x: int | str): if isinstance(x, int): # narrowed to int return x + 1 else: return x.upper().

def f(x: int | str): if isinstance(x, int): # narrowed to int return x + 1 else: return x.upper()

#### From typing import TypeGuard.

from typing import TypeGuard

#### Def is_int_list(v: list[object]) -> TypeGuard[list[int]]: return all(isinstance(x, int) for x in v).

def is_int_list(v: list[object]) -> TypeGuard[list[int]]: return all(isinstance(x, int) for x in v)

#### 4.10 Real-World Mini Example ‚Äî Typed Repository from typing import Protocol, TypeVar, Generic.

4.10 Real-World Mini Example ‚Äî Typed Repository from typing import Protocol, TypeVar, Generic

#### Class Repo(Protocol[T]): def add(self, item: T) -> None: ..

class Repo(Protocol[T]): def add(self, item: T) -> None: ... def get_all(self) -> list[T]: ...

#### Class MemoryRepo(Generic[T]): def __init__(self): self._items: list[T] = [].

class MemoryRepo(Generic[T]): def __init__(self): self._items: list[T] = []

#### Def add(self, item: T) -> None: self._items.append(item).

def add(self, item: T) -> None: self._items.append(item)

#### Def get_all(self) -> list[T]: return list(self._items).

def get_all(self) -> list[T]: return list(self._items)

#### Repo: Repo[int] = MemoryRepo() repo.add(1) print(repo.get_all()).

repo: Repo[int] = MemoryRepo() repo.add(1) print(repo.get_all())

#### 4.11 Macro Example ‚Äî Fluent Builder with Self + Protocols from __future__ import annotations from typing import Self, Protocol.

4.11 Macro Example ‚Äî Fluent Builder with Self + Protocols from __future__ import annotations from typing import Self, Protocol

#### Class Buildable(Protocol): def build(self) -> dict: ...

class Buildable(Protocol): def build(self) -> dict: ...

#### Class ConfigBuilder: def __init__(self): self._cfg = {}.

class ConfigBuilder: def __init__(self): self._cfg = {}

#### Def set(self, key: str, value) -> Self: self._cfg[key] = value return self.

def set(self, key: str, value) -> Self: self._cfg[key] = value return self

#### Def build(self) -> dict: return dict(self._cfg).

def build(self) -> dict: return dict(self._cfg)

#### Cfg = ( ConfigBuilder() .set("user", "alice") .set("debug", True) .build() ).

cfg = ( ConfigBuilder() .set("user", "alice") .set("debug", True) .build() )

#### ‚ö†Ô∏è List[Any] allows anything ‚ö†Ô∏è Optional[T] ‚â† nullable by default ‚ö†Ô∏è dict is not ordered in older Python (<3.7) ‚ö†Ô∏è misuse of Protocol can lead to f...

‚ö†Ô∏è List[Any] allows anything ‚ö†Ô∏è Optional[T] ‚â† nullable by default ‚ö†Ô∏è dict is not ordered in older Python (<3.7) ‚ö†Ô∏è misuse of Protocol can lead to false positives ‚ö†Ô∏è forgetting deep immutability (tuple with list inside) ‚ö†Ô∏è mixing mutable + immutable types in hash keys

#### 4.13 Summary & Takeaways.

4.13 Summary & Takeaways

#### - üéØ The Data Model (dunder methods) allows customizing object behavior for operators, iteration, and more.

- üéØ **Everything is an object** in Python, each with a type determining its behavior. - üéØ Python has a **rich set of built-in types** (numeric, sequence, mapping, set, boolean, None). - üéØ Understand **mutability** (lists, dicts are mutable; tuples, strings are immutable) to avoid unexpected side effects. - üéØ Differentiate **identity (`is`) from equality (`==`)**. `is` checks if two variables refer to the *exact same object* in memory. - üéØ The **Data Model (dunder methods)** allows customizing object behavior for operators, iteration, and more. - üéØ **Type hints** (`typing` module, `int | str` syntax) enable static analysis for better code quality, but don't enforce types at runtime. - üéØ Use **`typing.Protocol`** for structural typing (duck typing with static checks) and `abc.ABC` for nominal interfaces. - üéØ **Generics + TypeVar** enable reusable, typed APIs with Self, ParamSpec, and new generic syntax.

#### Medium: Implement a custom class Vector that supports addition (+), subtraction (-), and string representation (str()).

1. **Easy:** Create a `dataclass` for a `Point` with `x` and `y` coordinates. Add a method `distance_from_origin`. 2. **Medium:** Implement a custom class `Vector` that supports addition (`+`), subtraction (`-`), and string representation (`str()`). 3. **Hard:** Create a `typing.Protocol` for a `Logger` with a `log(message: str)` method. Then create two concrete implementations: `ConsoleLogger` and `FileLogger`. Write a function that accepts any `Logger` and uses it.

#### 4.14 Coming From Other Languages.

4.14 Coming From Other Languages

#### This section helps developers from other languages map familiar concepts to Python.

This section helps developers from other languages map familiar concepts to Python.

#### Key Mindset Shift: Python favors "duck typing" - if it walks like a duck and quacks like a duck, it's a duck.

**Key Mindset Shift:** Python favors "duck typing" - if it walks like a duck and quacks like a duck, it's a duck. Focus on what an object *does*, not what it *is*.

#### Key Mindset Shift: Python has no implicit type coercion.

**Key Mindset Shift:** Python has no implicit type coercion. `1 + "1"` raises `TypeError`, not `"11"`.

#### üëâ Chapter 5 ‚Äî Control Flow.

üëâ Chapter 5 ‚Äî Control Flow

#### Advanced pattern matching.

advanced pattern matching

#### Real-world flows in production code.

real-world flows in production code


---

## Chapter 5 ‚Äî CONTROL FLOW

_Difficulty: Beginner_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch05-start" --> üìò CHAPTER 5 ‚Äî CONTROL FLOW üü¢ Beginner.

<!-- SSM:CHUNK_BOUNDARY id="ch05-start" --> üìò CHAPTER 5 ‚Äî CONTROL FLOW üü¢ Beginner

#### Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì4.

Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì4

#### Control flow defines how your program decides what to do and when to do it.

Control flow defines how your program decides what to do and when to do it.

#### Structural pattern matching (3.10+).

Structural pattern matching (3.10+)

#### Loop control keywords (break, continue, else).

Loop control keywords (break, continue, else)

#### Exception chaining (raise ..

Exception chaining (raise ... from)

#### Context managers (with).

Context managers (with)

#### Real-world examples (mini + macro).

Real-world examples (mini + macro)

#### 5.1 Boolean Logic & Conditionals.

5.1 Boolean Logic & Conditionals

#### 5.1.1 if / elif / else if x > 10: print("large") elif x > 5: print("medium") else: print("small").

5.1.1 if / elif / else if x > 10: print("large") elif x > 5: print("medium") else: print("small")

#### 5.1.2 Truthiness Reminders.

5.1.2 Truthiness Reminders

#### Empty sequences are false.

Empty sequences are false

#### Non-empty sequences are true.

Non-empty sequences are true

#### Numbers: 0 ‚Üí False, otherwise True.

Numbers: 0 ‚Üí False, otherwise True

#### 5.1.3 Ternary Expression result = "yes" if flag else "no".

5.1.3 Ternary Expression result = "yes" if flag else "no"

#### 5.1.4 Comparisons Are Chainable 0 < x < 10.

5.1.4 Comparisons Are Chainable 0 < x < 10

#### Python has two loop types:.

Python has two loop types:

#### For (iteration-based).

for (iteration-based)

#### While (condition-based).

while (condition-based)

#### 5.2.1 for loops for item in items: print(item).

5.2.1 for loops for item in items: print(item)

#### Python‚Äôs for loops are iterator-based, not C-style counter loops.

Python‚Äôs for loops are iterator-based, not C-style counter loops.

#### Iter_obj = iter(items) while True: try: item = next(iter_obj) except StopIteration: break.

iter_obj = iter(items) while True: try: item = next(iter_obj) except StopIteration: break

#### 5.2.2 while loops while n > 0: n -= 1.

5.2.2 while loops while n > 0: n -= 1

#### Waiting for conditions.

waiting for conditions

#### 5.2.3 Loop Control Keywords Keyword Meaning break exit loop immediately continue skip to next iteration else runs only if loop completed without br...

5.2.3 Loop Control Keywords Keyword Meaning break exit loop immediately continue skip to next iteration else runs only if loop completed without break 5.2.4 Loop else

#### For user in users: if user.id == target: print("Found!") break else: print("Not found").

for user in users: if user.id == target: print("Found!") break else: print("Not found")

#### The else triggers only if break did not run.

The else triggers only if break did not run.

#### 5.3 Comprehensions 5.3.1 List comprehensions squares = [x*x for x in range(10)].

5.3 Comprehensions 5.3.1 List comprehensions squares = [x*x for x in range(10)]

#### 5.3.2 Dict comprehensions d = {user.id: user for user in users}.

5.3.2 Dict comprehensions d = {user.id: user for user in users}

#### 5.3.3 Set comprehensions unique = {item.lower() for item in items}.

5.3.3 Set comprehensions unique = {item.lower() for item in items}

#### 5.3.4 Generator expressions gen = (x*x for x in range(1_000_000)).

5.3.4 Generator expressions gen = (x*x for x in range(1_000_000))

#### Lazy and memory-efficient.

Lazy and memory-efficient.

#### 5.3.5 When NOT to use comprehensions.

5.3.5 When NOT to use comprehensions

#### When nesting exceeds ~2 levels.

When nesting exceeds ~2 levels

#### When readability suffers.

When readability suffers

#### When side effects occur.

When side effects occur

#### 5.4 Pattern Matching (match / case) ‚Äî Python 3.10+.

5.4 Pattern Matching (match / case) ‚Äî Python 3.10+

#### Introduced in PEP 634‚Äì636.

Introduced in PEP 634‚Äì636.

#### Pattern matching is not a switch-case.

Pattern matching is not a switch-case. It is a mini declarative matching language inside Python.

#### 5.4.1 Basic Example match command: case "start": ..

5.4.1 Basic Example match command: case "start": ... case "stop": ... case _: ...

#### 5.4.2 Literal Patterns case 0: case "yes":.

5.4.2 Literal Patterns case 0: case "yes":

#### 5.4.3 Sequence Patterns match x: case [a, b]: ..

5.4.3 Sequence Patterns match x: case [a, b]: ... case [a, b, c, *rest]: ...

#### 5.4.4 Mapping Patterns match obj: case {"type": "user", "id": user_id}: ...

5.4.4 Mapping Patterns match obj: case {"type": "user", "id": user_id}: ...

#### 5.4.5 Class Patterns class Point: def __init__(self, x, y): self.x, self.y = x, y.

5.4.5 Class Patterns class Point: def __init__(self, x, y): self.x, self.y = x, y

#### Match p: case Point(x, y): ...

match p: case Point(x, y): ...

#### 5.4.6 OR Patterns case "y" | "yes" | "true":.

5.4.6 OR Patterns case "y" | "yes" | "true":

#### 5.4.7 AS Patterns case {"user": u} as obj: print(obj).

5.4.7 AS Patterns case {"user": u} as obj: print(obj)

#### 5.4.8 Guards match age: case x if x < 13: print("child") case x if x < 20: print("teen").

5.4.8 Guards match age: case x if x < 13: print("child") case x if x < 20: print("teen")

#### Guards allow arbitrary boolean conditions.

Guards allow arbitrary boolean conditions.

#### 5.5 Exception Handling 5.5.1 Basic try-except try: risky() except ValueError: recover().

5.5 Exception Handling 5.5.1 Basic try-except try: risky() except ValueError: recover()

#### 5.5.2 Catching multiple exceptions except (ValueError, TypeError):.

5.5.2 Catching multiple exceptions except (ValueError, TypeError):

#### Try: ..

try: ... finally: cleanup()

#### Runs only if no exception occurred:.

Runs only if no exception occurred:

#### Try: value = int(x) except ValueError: ..

try: value = int(x) except ValueError: ... else: print("parsed ok")

#### 5.5.1 Exception Chaining (Critical Topic) Why chaining?.

5.5.1 Exception Chaining (Critical Topic) Why chaining?

#### Helps preserve root cause.

Helps preserve root cause.

#### Implicit chaining try: open("missing.txt") except Exception as e: raise RuntimeError("fail").

Implicit chaining try: open("missing.txt") except Exception as e: raise RuntimeError("fail")

#### During handling of the above exception, another exception occurred:.

During handling of the above exception, another exception occurred:

#### Explicit chaining try: open("missing.txt") except OSError as e: raise RuntimeError("fail") from e.

Explicit chaining try: open("missing.txt") except OSError as e: raise RuntimeError("fail") from e

#### Preserves cause cleanly.

Preserves cause cleanly.

#### 5.6 Context Managers (with).

5.6 Context Managers (with)

#### Handles setup/teardown logic.

Handles setup/teardown logic.

#### 5.6.1 Basic Example with open("data.txt") as f: data = f.read().

5.6.1 Basic Example with open("data.txt") as f: data = f.read()

#### 5.6.2 Custom Context Manager class Timer: def __enter__(self): self.start = time.perf_counter() return self def __exit__(self, exc_type, exc, tb): ...

5.6.2 Custom Context Manager class Timer: def __enter__(self): self.start = time.perf_counter() return self def __exit__(self, exc_type, exc, tb): self.end = time.perf_counter()

#### With Timer() as t: heavy().

with Timer() as t: heavy()

#### 5.7 Putting It All Together ‚Äî Mini Example.

5.7 Putting It All Together ‚Äî Mini Example

#### (loops + comprehensions + pattern matching).

(loops + comprehensions + pattern matching)

#### Def process(records): for r in records: match r: case {"type": "user", "id": id}: print(f"user={id}") case ["log", ts, msg]: print(f"{ts}: {msg}") ...

def process(records): for r in records: match r: case {"type": "user", "id": id}: print(f"user={id}") case ["log", ts, msg]: print(f"{ts}: {msg}") case _: print("unknown")

#### 5.8 Macro Example ‚Äî Log Routing System from datetime import datetime.

5.8 Macro Example ‚Äî Log Routing System from datetime import datetime

#### Def route(record): match record: case {"level": "error", "msg": msg}: return f"[ERROR] {msg}" case {"level": "warn", "msg": msg}: return f"[WARN] {...

def route(record): match record: case {"level": "error", "msg": msg}: return f"[ERROR] {msg}" case {"level": "warn", "msg": msg}: return f"[WARN] {msg}" case {"level": "info", "msg": msg}: return f"[INFO] {msg}" case ["metric", name, value]: return f"[METRIC] {name}={value}" case _: return "[UNKNOWN]"

#### Lines = [ "{'level': 'info', 'msg': 'started'}", "['metric', 'latency', 32]", "{'level': 'error', 'msg': 'failure'}", ].

lines = [ "{'level': 'info', 'msg': 'started'}", "['metric', 'latency', 32]", "{'level': 'error', 'msg': 'failure'}", ]

#### print(process_log(lines))

print(process_log(lines))

#### (A safer example would parse JSON; this is intentionally short-form.).

(A safer example would parse JSON; this is intentionally short-form.)

#### 5.10 Summary & Takeaways.

5.10 Summary & Takeaways

#### Control flow is clean and expressive.

Control flow is clean and expressive

#### Iteration is central to Python.

Iteration is central to Python

#### Pattern matching is a huge addition (Python 3.10+).

Pattern matching is a huge addition (Python 3.10+)

#### Exception chaining helps debugging.

Exception chaining helps debugging

#### Context managers simplify resource handling.

Context managers simplify resource handling

#### Best engineers write small, clear, predictable control-flow blocks.

Best engineers write small, clear, predictable control-flow blocks

#### üëâ Chapter 6 ‚Äî Functions & Functional Concepts.

üëâ Chapter 6 ‚Äî Functions & Functional Concepts

#### Iterators and generators.

iterators and generators

#### Functools & itertools.

functools & itertools

#### Iteration protocol (__iter__, __next__).

iteration protocol (__iter__, __next__)

#### Advanced decorator typing with ParamSpec.

advanced decorator typing with ParamSpec


---

## Chapter 6 ‚Äî FUNCTIONS & FUNCTIONAL CONCEPTS

_Difficulty: Beginner_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch06-start" --> üìò CHAPTER 6 ‚Äî FUNCTIONS & FUNCTIONAL CONCEPTS üü¢ Beginner.

<!-- SSM:CHUNK_BOUNDARY id="ch06-start" --> üìò CHAPTER 6 ‚Äî FUNCTIONS & FUNCTIONAL CONCEPTS üü¢ Beginner

#### Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì5.

Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì5

#### Functions are the core building block of Python programs.

Functions are the core building block of Python programs. In Python, functions are:

#### Storable in variables.

storable in variables

#### Passable as arguments.

passable as arguments

#### Returnable as values.

returnable as values

#### Can act as decorators.

can act as decorators

#### Can yield (generators).

can yield (generators)

#### Can be async (coroutines).

can be async (coroutines)

#### This chapter provides a formal and practical understanding of:

This chapter provides a formal and practical understanding of:

#### Function definitions.

Function definitions

#### Parameter kinds & signatures.

Parameter kinds & signatures

#### Iterators & iterable protocol.

Iterators & iterable protocol

#### Generators & coroutines.

Generators & coroutines

#### Decorators (simple ‚Üí advanced).

Decorators (simple ‚Üí advanced)

#### Functools (lru_cache, partial, singledispatch).

functools (lru_cache, partial, singledispatch)

#### Itertools (infinite iterators, combinatorics).

itertools (infinite iterators, combinatorics)

#### Tail-call limitations.

Tail-call limitations

#### Type annotations for functions.

Type annotations for functions

#### 6.1 Function Definitions.

6.1 Function Definitions

#### Def greet(name: str) -> str: return f"Hello, {name}!".

def greet(name: str) -> str: return f"Hello, {name}!"

#### Functions consist of:.

Functions consist of:

#### Optional return annotation.

optional return annotation

#### Optional docstring (see Chapter 30 for comprehensive docstring conventions).

optional docstring (see Chapter 30 for comprehensive docstring conventions)

#### 6.2 Functions Are First-Class Objects.

6.2 Functions Are First-Class Objects

#### Store them in variables.

store them in variables

#### Pass them to other functions.

pass them to other functions

#### Store them in data structures.

store them in data structures

#### Def add(a, b): return a + b def mul(a, b): return a * b.

def add(a, b): return a + b def mul(a, b): return a * b

#### Ops = { "add": add, "mul": mul, }.

ops = { "add": add, "mul": mul, }

#### Print(ops["mul"](3, 4)).

print(ops["mul"](3, 4))

#### This property underpins decorators, callbacks, strategies, and functional patterns.

This property underpins decorators, callbacks, strategies, and functional patterns.

#### 6.3 Parameter Kinds (The 5 Types).

6.3 Parameter Kinds (The 5 Types)

#### Python has five categories of parameters.

Python has five categories of parameters.

#### Def f(a, b, /, c, d=4, *args, e, f=6, **kwargs): pass.

def f(a, b, /, c, d=4, *args, e, f=6, **kwargs): pass

#### 6.3.1 Positional-only (/).

6.3.1 Positional-only (/)

#### Def add(a, b, /): return a + b.

def add(a, b, /): return a + b

#### 6.3.2 Positional-or-keyword (normal) def f(x, y): ...

6.3.2 Positional-or-keyword (normal) def f(x, y): ...

#### 6.3.3 Keyword-only (*) def config(*, debug=False): return debug.

6.3.3 Keyword-only (*) def config(*, debug=False): return debug

#### 6.3.4 Variadic positional (*args) def total(*nums): return sum(nums).

6.3.4 Variadic positional (*args) def total(*nums): return sum(nums)

#### 6.3.5 Variadic keyword (kwargs) def print_info(data): print(data).

6.3.5 Variadic keyword (**kwargs) def print_info(**data): print(data)

#### 6.4 Return Semantics.

6.4 Return Semantics

#### A function without return returns:.

A function without return returns:

#### Multi-return using tuples:.

Multi-return using tuples:

#### Def pair(): return (1, 2).

def pair(): return (1, 2)

#### Python resolves names in:.

Python resolves names in:

#### Scope Example Local inside function Enclosing outer function Global module Built-in len, range.

Scope Example Local inside function Enclosing outer function Global module Built-in len, range

#### *See Appendix G ‚Üí G.3.1 for additional examples and edge cases.*.

*See Appendix G ‚Üí G.3.1 for additional examples and edge cases.*

#### 6.5.1 global count = 0.

6.5.1 global count = 0

#### Def inc(): global count count += 1.

def inc(): global count count += 1

#### Captures enclosing variables (not global):.

Captures enclosing variables (not global):

#### Def outer(): x = 0 def inner(): nonlocal x x += 1 inner() return x.

def outer(): x = 0 def inner(): nonlocal x x += 1 inner() return x

#### Functions capture free variables from enclosing scopes.

Functions capture free variables from enclosing scopes.

#### Def make_adder(n): def adder(x): return x + n return adder.

def make_adder(n): def adder(x): return x + n return adder

#### Plus_10 = make_adder(10) print(plus_10(5)) # 15.

plus_10 = make_adder(10) print(plus_10(5)) # 15

#### Closures capture references, not copies.

Closures capture references, not copies.

#### 6.7 Iterators & The Iteration Protocol (New Chapter Section).

6.7 Iterators & The Iteration Protocol (New Chapter Section)

#### Python iteration is built on two methods:.

Python iteration is built on two methods:

#### __iter__(self) -> iterator __next__(self) -> next_value.

__iter__(self) -> iterator __next__(self) -> next_value

#### 6.7.1 Iterable vs Iterator Concept Has Example Iterable __iter__ list, dict, set, str Iterator __iter__, __next__ generators, iterators 6.7.2 Creat...

6.7.1 Iterable vs Iterator Concept Has Example Iterable __iter__ list, dict, set, str Iterator __iter__, __next__ generators, iterators 6.7.2 Creating custom iterators class Count: def __init__(self, start): self.value = start

#### Def __iter__(self): return self.

def __iter__(self): return self

#### Def __next__(self): v = self.value self.value += 1 return v.

def __next__(self): v = self.value self.value += 1 return v

#### 6.7.3 Sentinel iteration for chunk in iter(lambda: f.read(1024), b""): process(chunk).

6.7.3 Sentinel iteration for chunk in iter(lambda: f.read(1024), b""): process(chunk)

#### 6.7.4 Infinite iterators.

6.7.4 Infinite iterators

#### Import itertools for x in itertools.count(10, 2): ...

import itertools for x in itertools.count(10, 2): ...

#### 6.8 Generators & yield.

6.8 Generators & yield

#### Generators are lightweight, resumable functions.

Generators are lightweight, resumable functions.

#### Def countdown(n): while n > 0: yield n n -= 1.

def countdown(n): while n > 0: yield n n -= 1

#### 6.8.1 yield from for delegation def chain(a, b): yield from a yield from b.

6.8.1 yield from for delegation def chain(a, b): yield from a yield from b

#### 6.8.2 Why generators matter.

6.8.2 Why generators matter

#### Coroutines (before async/await).

coroutines (before async/await)

#### 6.9 Decorators (Deep Dive) üü° Intermediate.

6.9 Decorators (Deep Dive) üü° Intermediate

#### Prerequisites: Chapter 6.5 (Closures), Chapter 6.2 (First-class functions) Estimated time: 1-2 hours When you need this: Logging, timing, caching, ...

**Prerequisites:** Chapter 6.5 (Closures), Chapter 6.2 (First-class functions) **Estimated time:** 1-2 hours **When you need this:** Logging, timing, caching, access control, input validation

#### Decorators transform callables.

Decorators transform callables.

#### 6.9.1 Basic decorator def log(fn): def wrapper(*a, **k): print("calling", fn.__name__) return fn(*a, **k) return wrapper.

6.9.1 Basic decorator def log(fn): def wrapper(*a, **k): print("calling", fn.__name__) return fn(*a, **k) return wrapper

#### @log def greet(): print("hi").

@log def greet(): print("hi")

#### 6.9.2 Decorators with arguments def tagged(tag): def deco(fn): def wrapper(*a, **k): print(f"[{tag}] calling {fn.__name__}") return fn(*a, **k) ret...

6.9.2 Decorators with arguments def tagged(tag): def deco(fn): def wrapper(*a, **k): print(f"[{tag}] calling {fn.__name__}") return fn(*a, **k) return wrapper return deco

#### @tagged("INFO") def f(): ...

@tagged("INFO") def f(): ...

#### 6.9.3 Using functools.wraps.

6.9.3 Using functools.wraps

#### From functools import wraps.

from functools import wraps

#### Def log(fn): @wraps(fn) def wrapper(*a, **k): ...

def log(fn): @wraps(fn) def wrapper(*a, **k): ...

#### 6.9.4 Classmethod, Staticmethod, Property classmethod class C: count = 0.

6.9.4 Classmethod, Staticmethod, Property classmethod class C: count = 0

#### @classmethod def inc(cls): cls.count += 1.

@classmethod def inc(cls): cls.count += 1

#### Staticmethod class C: @staticmethod def add(a, b): return a + b.

staticmethod class C: @staticmethod def add(a, b): return a + b

#### Property class User: def __init__(self, name): self._name = name.

property class User: def __init__(self, name): self._name = name

#### @property def name(self): return self._name.

@property def name(self): return self._name

#### 6.10 functools Essentials 6.10.1 partial from functools import partial.

6.10 functools Essentials 6.10.1 partial from functools import partial

#### Add5 = partial(lambda x, y: x+y, 5) add5(10) # 15.

add5 = partial(lambda x, y: x+y, 5) add5(10) # 15

#### 6.10.2 lru_cache @lru_cache(maxsize=256) def fib(n): ...

6.10.2 lru_cache @lru_cache(maxsize=256) def fib(n): ...

#### 6.10.3 singledispatch from functools import singledispatch.

6.10.3 singledispatch from functools import singledispatch

#### @singledispatch def handle(x): ...

@singledispatch def handle(x): ...

#### @handle.register def _(x: int): ...

@handle.register def _(x: int): ...

#### @handle.register def _(x: list): ...

@handle.register def _(x: list): ...

#### 6.11 itertools Essentials 6.11.1 Infinite iterators itertools.count() itertools.cycle().

6.11 itertools Essentials 6.11.1 Infinite iterators itertools.count() itertools.cycle()

#### 6.11.2 Combinatorics itertools.permutations() itertools.combinations().

6.11.2 Combinatorics itertools.permutations() itertools.combinations()

#### 6.11.3 Chaining itertools.chain(a, b).

6.11.3 Chaining itertools.chain(a, b)

#### 6.11.4 Grouping itertools.groupby(...).

6.11.4 Grouping itertools.groupby(...)

#### 6.12 operator Module.

6.12 operator Module

#### Used for functional composition & speed.

Used for functional composition & speed.

#### From operator import itemgetter, attrgetter.

from operator import itemgetter, attrgetter

#### Sorted(users, key=attrgetter("age")).

sorted(users, key=attrgetter("age"))

#### Python recursion is limited by call stack:.

Python recursion is limited by call stack:

#### Import sys sys.getrecursionlimit().

import sys sys.getrecursionlimit()

#### 6.13.1 Tail-call optimization.

6.13.1 Tail-call optimization

#### Python does not perform TCO.

Python does not perform TCO.

#### 6.14 Mini Example ‚Äî Pipeline Generator def read_lines(path): with open(path) as f: for line in f: yield line.strip().

6.14 Mini Example ‚Äî Pipeline Generator def read_lines(path): with open(path) as f: for line in f: yield line.strip()

#### Def filter_errors(lines): for line in lines: if "ERROR" in line: yield line.

def filter_errors(lines): for line in lines: if "ERROR" in line: yield line

#### Pipeline = filter_errors(read_lines("app.log")).

pipeline = filter_errors(read_lines("app.log"))

#### For line in pipeline: print(line).

for line in pipeline: print(line)

#### 6.15 Macro Example ‚Äî Decorator + Cache + Iterators from functools import lru_cache, wraps import itertools.

6.15 Macro Example ‚Äî Decorator + Cache + Iterators from functools import lru_cache, wraps import itertools

#### Def logged(fn): @wraps(fn) def wrapper(*a, **k): print("calling", fn.__name__) return fn(*a, **k) return wrapper.

def logged(fn): @wraps(fn) def wrapper(*a, **k): print("calling", fn.__name__) return fn(*a, **k) return wrapper

#### @logged @lru_cache(maxsize=128) def prime(n: int) -> int: # Fisher‚ÄìYates prime generator demo count = 0 for x in itertools.count(2): if all(x % p f...

@logged @lru_cache(maxsize=128) def prime(n: int) -> int: # Fisher‚ÄìYates prime generator demo count = 0 for x in itertools.count(2): if all(x % p for p in range(2, int(x**0.5) + 1)): count += 1 if count == n: return x

#### Print(prime(10)) # calls logged print(prime(10)) # hits cache.

print(prime(10)) # calls logged print(prime(10)) # hits cache

#### Prime computation pipeline.

prime computation pipeline

#### 6.17 Summary & Takeaways.

6.17 Summary & Takeaways

#### [ ] Can you explain the difference between *args and **kwargs? 2.

1. [ ] Can you explain the difference between `*args` and `**kwargs`? 2. [ ] Can you write a decorator that logs function execution time? 3. [ ] Can you explain why mutable default arguments are dangerous? 4. [ ] Can you describe what a closure captures and when it does so? 5. [ ] What's the difference between a generator function and a generator expression? 6. [ ] How does `@functools.lru_cache` work and when would you use it?

#### Easy: Write a decorator that prints "Calling {func_name}" before each call and "Finished {func_name}" after 2.

1. **Easy:** Write a decorator that prints "Calling {func_name}" before each call and "Finished {func_name}" after 2. **Medium:** Write a memoization decorator from scratch (without using `@lru_cache`) 3. **Medium:** Create a generator that yields the Fibonacci sequence indefinitely 4. **Hard:** Write a decorator that retries failed functions with exponential backoff (max 3 retries) 5. **Hard:** Implement a `@validate_types` decorator that checks function arguments against type hints at runtime

#### üëâ Chapter 7 ‚Äî Classes & Object-Oriented Programming.

üëâ Chapter 7 ‚Äî Classes & Object-Oriented Programming

#### This is one of the largest chapters in the entire book and covers:

This is one of the largest chapters in the entire book and covers:

#### Data model deep integration.

data model deep integration


---

## Chapter 7 ‚Äî CLASSES & OBJECT-ORIENTED PROGRAMMING

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch07-start" --> üìò CHAPTER 7 ‚Äî CLASSES & OBJECT-ORIENTED PROGRAMMING üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch07-start" --> üìò CHAPTER 7 ‚Äî CLASSES & OBJECT-ORIENTED PROGRAMMING üü° Intermediate

#### Prerequisites: Chapters 1-6 (especially functions and closures) Estimated time: 4-6 hours When you need this: Structuring complex applications, dat...

**Prerequisites:** Chapters 1-6 (especially functions and closures) **Estimated time:** 4-6 hours **When you need this:** Structuring complex applications, data modeling, framework design

#### Python OOP sits on three pillars:.

Python OOP sits on three pillars:

#### ‚úî Everything is an object.

‚úî Everything is an object

#### Classes are objects.

Classes are objects. Instances are objects. Functions, methods, modules: all objects.

#### Procedural programming.

procedural programming

#### Functional programming.

functional programming

#### Data-centric structural design.

data-centric structural design

#### Protocol-based design.

protocol-based design

#### ‚úî Deep integration with the Data Model.

‚úî Deep integration with the Data Model

#### The Data Model (from Chapter 4) determines how:.

The Data Model (from Chapter 4) determines how:

#### Attribute lookup works.

attribute lookup works

#### Context managers work.

context managers work

#### Numeric operations work.

numeric operations work

#### This chapter provides a complete, rigorous guide to:

This chapter provides a complete, rigorous guide to:

#### Self, initialization.

self, initialization

#### Special methods (all major categories).

special methods (all major categories)

#### Properties & descriptors.

properties & descriptors

#### Use cases in modern Python.

use cases in modern Python

#### 7.1 Class Definition Fundamentals 7.1.1 Basic Class class User: pass.

7.1 Class Definition Fundamentals 7.1.1 Basic Class class User: pass

#### Note: For comprehensive class docstring conventions (including Attributes, Args, Returns sections),...

**Note:** For comprehensive class docstring conventions (including Attributes, Args, Returns sections), see Chapter 30.

#### 7.1.2 Creating instances u = User() print(type(u)).

7.1.2 Creating instances u = User() print(type(u))

#### 7.1.3 The __init__ initializer class User: def __init__(self, name): self.name = name.

7.1.3 The __init__ initializer class User: def __init__(self, name): self.name = name

#### Self is the instance being constructed.

self is the instance being constructed.

#### 7.1.4 Instance attributes.

7.1.4 Instance attributes

#### Class Counter: def __init__(self): self.value = 0.

class Counter: def __init__(self): self.value = 0

#### Backing storage is the instance‚Äôs __dict__.

Backing storage is the instance‚Äôs __dict__.

#### 7.1.5 Class attributes.

7.1.5 Class attributes

#### Shared across all instances:.

Shared across all instances:

#### Class User: def __init__(self, name: str): self.name = name.

class User: def __init__(self, name: str): self.name = name

#### Def greet(self): return f"Hi, I'm {self.name}".

def greet(self): return f"Hi, I'm {self.name}"

#### User = User("Alice") print(user.greet()).

user = User("Alice") print(user.greet())

#### # Output: Hi, I'm Alice.

# Output: Hi, I'm Alice

#### User.greet(user) # Python inserts self automatically.

User.greet(user) # Python inserts self automatically

#### Helpful mental model.

Helpful mental model.

#### Try This: Experiment with method binding:.

Try This: Experiment with method binding:

#### 7.2 Class, Instance, and Static Methods 7.2.1 Instance Methods.

7.2 Class, Instance, and Static Methods 7.2.1 Instance Methods

#### First parameter is the instance (self).

First parameter is the instance (self).

#### First parameter is class (cls).

First parameter is class (cls).

#### Class App: version = "1.0".

class App: version = "1.0"

#### @classmethod def get_version(cls): return cls.version.

@classmethod def get_version(cls): return cls.version

#### 7.2.3 Static Methods.

7.2.3 Static Methods

#### No automatic self/cls.

No automatic self/cls.

#### Class Math: @staticmethod def add(a, b): return a + b.

class Math: @staticmethod def add(a, b): return a + b

#### 7.3 Object Lifecycle.

7.3 Object Lifecycle

#### __del__(self) (rarely use).

__del__(self) (rarely use)

#### __new__ constructs the object; __init__ initializes it.

__new__ constructs the object; __init__ initializes it.

#### 7.4 Attribute Lookup (Critical Mechanism).

7.4 Attribute Lookup (Critical Mechanism)

#### Order of attribute resolution:.

Order of attribute resolution:

#### Descriptors override all.

descriptors override all

#### This process is governed by:

This process is governed by:

#### Later sections dive deep.

Later sections dive deep.

#### 7.5 Inheritance 7.5.1 Single Inheritance class Animal: ..

7.5 Inheritance 7.5.1 Single Inheritance class Animal: ... class Dog(Animal): ...

#### 7.5.2 Multiple Inheritance class A: ..

7.5.2 Multiple Inheritance class A: ... class B: ... class C(A, B): ...

#### Python uses C3 linearization for ordering.

Python uses C3 linearization for ordering.

#### 7.5.3 Memory Optimization with __slots__.

7.5.3 Memory Optimization with __slots__

#### __slots__ is a powerful memory optimization that restricts instance attributes to a predefined set, eliminating the __dict__ overhead.

**__slots__** is a powerful memory optimization that restricts instance attributes to a predefined set, eliminating the `__dict__` overhead.

#### Without __slots__ (default behavior):.

**Without __slots__ (default behavior):**

#### Memory Savings Example:.

**Memory Savings Example:**

#### When to Use __slots__:.

**When to Use __slots__:**

#### Performance Benefits:.

**Performance Benefits:**

#### Memory: 4-5√ó reduction in instance size - Speed: Faster attribute access (no dict lookup) - Trade-off: Less flexibility (no dynamic attributes).

- **Memory:** 4-5√ó reduction in instance size - **Speed:** Faster attribute access (no dict lookup) - **Trade-off:** Less flexibility (no dynamic attributes)

#### Try This: Compare memory usage:.

**Try This:** Compare memory usage:

#### See also: Chapter 12 (Performance) for more memory optimization techniques.

**See also:** Chapter 12 (Performance) for more memory optimization techniques.

#### 7.6 Method Resolution Order (MRO).

7.6 Method Resolution Order (MRO)

#### Example: class A: ..

Example: class A: ... class B: ... class C(A, B): ...

#### 7.6.1 MRO Resolution Algorithm Visualization.

7.6.1 MRO Resolution Algorithm Visualization

#### C3 Linearization Algorithm:.

C3 Linearization Algorithm:

#### Try This: Explore MRO with multiple inheritance:.

Try This: Explore MRO with multiple inheritance:

#### Method Resolution Order (MRO) Visualization:.

**Method Resolution Order (MRO) Visualization:**

#### Method Lookup Flow:.

**Method Lookup Flow:**

#### MRO follows C3 linearization algorithm - Search order: left to right in MRO list - First match wins (stops searching) - super() uses MRO to find ne...

- MRO follows C3 linearization algorithm - Search order: left to right in MRO list - First match wins (stops searching) - `super()` uses MRO to find next class in chain - MRO ensures monotonicity (no cycles, consistent ordering)

#### *See Appendix G ‚Üí G.6.2 for additional examples and complex inheritance scenarios.*.

*See Appendix G ‚Üí G.6.2 for additional examples and complex inheritance scenarios.*

#### 7.7 super() (How It Really Works).

7.7 super() (How It Really Works)

#### Super() is not ‚Äúparent class‚Äù.

super() is not ‚Äúparent class‚Äù. It is a dynamic MRO-aware forwarder.

#### Super(CurrentClass, instance).

super(CurrentClass, instance)

#### It returns the next class after CurrentClass in the MRO.

It returns the next class after CurrentClass in the MRO.

#### 7.7.1 Cooperative multiple inheritance.

7.7.1 Cooperative multiple inheritance

#### Class A: def f(self): super().f().

class A: def f(self): super().f()

#### Class B: def f(self): super().f().

class B: def f(self): super().f()

#### Class C(A, B): def f(self): super().f().

class C(A, B): def f(self): super().f()

#### MRO ensures each gets called once.

MRO ensures each gets called once.

#### 7.8 Composition Over Inheritance.

7.8 Composition Over Inheritance

#### You want a pipeline of responsibilities.

you want a pipeline of responsibilities

#### You avoid diamond inheritance.

you avoid diamond inheritance

#### Class Engine: ..

class Engine: ... class Car: def __init__(self): self.engine = Engine()

#### Composition promotes:.

Composition promotes:

#### 7.9 The Data Model (Dunder Methods) in Detail.

7.9 The Data Model (Dunder Methods) in Detail

#### Extends Chapter 4‚Äôs overview ‚Äî now with deeper examples.

Extends Chapter 4‚Äôs overview ‚Äî now with deeper examples.

#### 7.9.1 Representation Methods __repr__ __str__ __format__.

7.9.1 Representation Methods __repr__ __str__ __format__

#### Best Practice: def __repr__(self): return f"{self.__class__.__name__}(x={self.x}, y={self.y})".

Best Practice: def __repr__(self): return f"{self.__class__.__name__}(x={self.x}, y={self.y})"

#### 7.9.2 Numeric Methods.

7.9.2 Numeric Methods

#### Implement vector arithmetic:.

Implement vector arithmetic:

#### Class Vector: def __init__(self, x, y): self.x, self.y = x, y.

class Vector: def __init__(self, x, y): self.x, self.y = x, y

#### Def __add__(self, other): return Vector(self.x + other.x, self.y + other.y).

def __add__(self, other): return Vector(self.x + other.x, self.y + other.y)

#### Def __mul__(self, scalar): return Vector(self.x * scalar, self.y * scalar).

def __mul__(self, scalar): return Vector(self.x * scalar, self.y * scalar)

#### 7.9.3 Comparison Methods __eq__ __lt__ __le__ ...

7.9.3 Comparison Methods __eq__ __lt__ __le__ ...

#### Support sorting by implementing:.

Support sorting by implementing:

#### Def __lt__(self, other): ...

def __lt__(self, other): ...

#### 7.9.4 Container Protocol __len__ __getitem__ __setitem__ __contains__.

7.9.4 Container Protocol __len__ __getitem__ __setitem__ __contains__

#### Class Bag: def __init__(self, items): self.items = items.

class Bag: def __init__(self, items): self.items = items

#### Def __len__(self): return len(self.items).

def __len__(self): return len(self.items)

#### Def __getitem__(self, idx): return self.items[idx].

def __getitem__(self, idx): return self.items[idx]

#### 7.9.5 Callable Objects __call__.

7.9.5 Callable Objects __call__

#### Class Adder: def __init__(self, n): self.n = n.

class Adder: def __init__(self, n): self.n = n

#### Def __call__(self, x): return x + self.n.

def __call__(self, x): return x + self.n

#### 7.9.6 Attribute Access Protocol __getattr__.

7.9.6 Attribute Access Protocol __getattr__

#### Called when attribute not found.

Called when attribute not found.

#### Intercepts all attribute lookups.

Intercepts all attribute lookups. Dangerous but powerful.

#### 7.9.7 Context Manager Protocol __enter__ __exit__.

7.9.7 Context Manager Protocol __enter__ __exit__

#### 7.9.8 Iterator Protocol __iter__ __next__.

7.9.8 Iterator Protocol __iter__ __next__

#### Usually implemented via generators.

Usually implemented via generators.

#### 7.10 Properties & Descriptors.

7.10 Properties & Descriptors

#### Descriptors are Python‚Äôs deepest mechanism.

Descriptors are Python‚Äôs deepest mechanism.

#### A descriptor is any object implementing:.

A descriptor is any object implementing:

#### __get__ __set__ __delete__.

__get__ __set__ __delete__

#### Properties are descriptors:.

Properties are descriptors:

#### Class User: @property def name(self): ...

class User: @property def name(self): ...

#### 7.11 Dataclasses (Python 3.7+).

7.11 Dataclasses (Python 3.7+)

#### Fastest way to create classes with fields.

Fastest way to create classes with fields.

#### From dataclasses import dataclass.

from dataclasses import dataclass

#### @dataclass class Point: x: int y: int.

@dataclass class Point: x: int y: int

#### Auto comparison methods.

auto comparison methods

#### Frozen=True for immutability.

frozen=True for immutability

#### Slots=True (Python 3.10+) reduces memory.

slots=True (Python 3.10+) reduces memory

#### 7.11.1 Post-init processing @dataclass class User: name: str def __post_init__(self): self.name = self.name.title().

7.11.1 Post-init processing @dataclass class User: name: str def __post_init__(self): self.name = self.name.title()

#### 7.11.2 slots=True @dataclass(slots=True) class Point: ...

7.11.2 slots=True @dataclass(slots=True) class Point: ...

#### Improves memory and speed.

Improves memory and speed.

#### 7.12 attrs ‚Äî A More Powerful dataclass Alternative import attr.

7.12 attrs ‚Äî A More Powerful dataclass Alternative import attr

#### @attr.define class User: name: str age: int.

@attr.define class User: name: str age: int

#### 7.13 Pydantic Models (FastAPI Standard) from pydantic import BaseModel.

7.13 Pydantic Models (FastAPI Standard) from pydantic import BaseModel

#### Class User(BaseModel): id: int name: str.

class User(BaseModel): id: int name: str

#### HTTPS APIs integration.

HTTPS APIs integration

#### 7.14 Metaclasses (Deep Topic).

7.14 Metaclasses (Deep Topic)

#### Metaclasses control:.

Metaclasses control:

#### Interface enforcement.

interface enforcement

#### ORM table construction.

ORM table construction

#### 7.14.1 What is a metaclass?.

7.14.1 What is a metaclass?

#### A class whose instances are classes.

A class whose instances are classes.

#### 7.14.2 Custom metaclass class Meta(type): def __new__(cls, name, bases, attrs): if "run" not in attrs: raise TypeError("need run() method") return ...

7.14.2 Custom metaclass class Meta(type): def __new__(cls, name, bases, attrs): if "run" not in attrs: raise TypeError("need run() method") return super().__new__(cls, name, bases, attrs)

#### Class Task(metaclass=Meta): def run(self): pass.

class Task(metaclass=Meta): def run(self): pass

#### 7.14.3 Common use cases.

7.14.3 Common use cases

#### Frameworks (Django models).

frameworks (Django models)

#### Interfaces/protocol validation.

interfaces/protocol validation

#### Automatic registration systems.

automatic registration systems

#### See also: Chapter 12.5.1 (Memory Optimization) for __slots__ performance benefits, and Chapter 4 (Type System) for type hints with classes.

**See also:** Chapter 12.5.1 (Memory Optimization) for __slots__ performance benefits, and Chapter 4 (Type System) for type hints with classes.

#### 7.15 Mini Example ‚Äî Vector Class @dataclass class Vec: x: int y: int.

7.15 Mini Example ‚Äî Vector Class @dataclass class Vec: x: int y: int

#### Def __add__(self, o): return Vec(self.x + o.x, self.y + o.y).

def __add__(self, o): return Vec(self.x + o.x, self.y + o.y)

#### V1 = Vec(1, 2) v2 = Vec(3, 4) print(v1 + v2).

v1 = Vec(1, 2) v2 = Vec(3, 4) print(v1 + v2)

#### 7.16 Macro Example ‚Äî Plugin System with Metaclass + Registry class PluginMeta(type): registry = {}.

7.16 Macro Example ‚Äî Plugin System with Metaclass + Registry class PluginMeta(type): registry = {}

#### Def __new__(cls, name, bases, attrs): new_cls = super().__new__(cls, name, bases, attrs) if name != "Plugin": cls.registry[name] = new_cls return n...

def __new__(cls, name, bases, attrs): new_cls = super().__new__(cls, name, bases, attrs) if name != "Plugin": cls.registry[name] = new_cls return new_cls

#### Class Plugin(metaclass=PluginMeta): def run(self): raise NotImplementedError.

class Plugin(metaclass=PluginMeta): def run(self): raise NotImplementedError

#### Class Logger(Plugin): def run(self): print("logging").

class Logger(Plugin): def run(self): print("logging")

#### Class Notifier(Plugin): def run(self): print("notifying").

class Notifier(Plugin): def run(self): print("notifying")

#### For name, cls in PluginMeta.registry.items(): print(name, "‚Üí", cls().run()).

for name, cls in PluginMeta.registry.items(): print(name, "‚Üí", cls().run())

#### Class creation hooks.

class creation hooks

#### ‚ö† misunderstanding self ‚ö† confusing class vs instance attributes ‚ö† overriding __getattribute__ without care ‚ö† multiple inheritance diamonds ‚ö† descr...

‚ö† misunderstanding self ‚ö† confusing class vs instance attributes ‚ö† overriding __getattribute__ without care ‚ö† multiple inheritance diamonds ‚ö† descriptor mistakes ‚ö† misuse of metaclasses (overkill) ‚ö† dataclass mutable default fields ‚ö† mismatched type annotations

#### 7.18 Summary & Takeaways.

7.18 Summary & Takeaways

#### üéØ Everything is an object ‚Äî classes, instances, functions, modules - üéØ MRO (Method Resolution Order) enables safe multiple inheritance - üéØ super() ...

- üéØ **Everything is an object** ‚Äî classes, instances, functions, modules - üéØ **MRO (Method Resolution Order)** enables safe multiple inheritance - üéØ **`super()` is MRO-aware**, not simply "parent class" - üéØ **Data Model (dunder methods)** powers operators, iteration, context managers - üéØ **`@dataclass` (3.7+)** eliminates boilerplate for data containers - üéØ **Prefer composition over inheritance** for flexible designs - üéØ **Descriptors** (`@property`, custom) control attribute access - üéØ **Metaclasses** are powerful but rarely needed ‚Äî prefer simpler patterns

#### üëâ Chapter 8 ‚Äî Modules, Packages & Project Structure Where we cover:.

üëâ Chapter 8 ‚Äî Modules, Packages & Project Structure Where we cover:

#### Reusable package structure.

reusable package structure

#### Best practices for libraries.

best practices for libraries

#### Layout for modern Python projects.

layout for modern Python projects

#### <!-- SSM:PART id="part3" title="Part III: Applied Python" -->.

<!-- SSM:PART id="part3" title="Part III: Applied Python" -->

#### # Part III: Applied Python.

# Part III: Applied Python


---

## Chapter 8 ‚Äî MODULES, PACKAGES & PROJECT STRUCTURE

_Difficulty: Beginner_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch08-start" --> üìò CHAPTER 8 ‚Äî MODULES, PACKAGES & PROJECT STRUCTURE üü¢ Beginner.

<!-- SSM:CHUNK_BOUNDARY id="ch08-start" --> üìò CHAPTER 8 ‚Äî MODULES, PACKAGES & PROJECT STRUCTURE üü¢ Beginner

#### Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì7.

Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì7

#### Modules and packages provide organizational structure, encapsulation, reusability, and deployment for Python projects.

Modules and packages provide organizational structure, encapsulation, reusability, and deployment for Python projects.

#### This chapter explains:

This chapter explains:

#### How Python resolves names.

How Python resolves names

#### Sys.path and import search paths.

sys.path and import search paths

#### Namespace packages (PEP 420).

Namespace packages (PEP 420)

#### Modern build systems.

Modern build systems

#### Versioning & distribution.

Versioning & distribution

#### Best practices for structuring real-world applications.

Best practices for structuring real-world applications

#### Intra-package imports.

intra-package imports

#### Absolute vs relative imports.

absolute vs relative imports

#### Top-level vs local imports.

top-level vs local imports

#### Circular import avoidance.

circular import avoidance

#### 8.1 What Is a Module?.

8.1 What Is a Module?

#### A module is any .py file.

A module is any .py file.

#### App/ main.py utils.py.

app/ main.py utils.py

#### Everything in utils.py becomes namespaced under utils.

Everything in utils.py becomes namespaced under utils.

#### 8.2 Import Mechanics (Critical Topic).

8.2 Import Mechanics (Critical Topic)

#### 8.2.0 Import System Flow Diagram.

8.2.0 Import System Flow Diagram

#### Try This: Explore the import system interactively:.

Try This: Explore the import system interactively:

#### Python imports follow this lifecycle:.

Python imports follow this lifecycle:

#### Check sys.modules (import cache).

Check sys.modules (import cache)

#### Find module on sys.path.

Find module on sys.path

#### Load module (source ‚Üí bytecode).

Load module (source ‚Üí bytecode)

#### Execute module top-to-bottom.

Execute module top-to-bottom

#### Store module in sys.modules.

Store module in sys.modules

#### A dict of all already imported modules:.

A dict of all already imported modules:

#### Import sys print(sys.modules["os"]).

import sys print(sys.modules["os"])

#### Importing the same module twice does not re-run it.

Importing the same module twice does not re-run it.

#### Python searches for modules in:.

Python searches for modules in:

#### 8.2.3 Import caching.

8.2.3 Import caching

#### Python stores compiled bytecode in:.

Python stores compiled bytecode in:

#### utils.cpython-312.pyc

utils.cpython-312.pyc

#### This speeds up imports.

This speeds up imports.

#### 8.3 Absolute vs Relative Imports 8.3.1 Absolute Import from project.module import func.

8.3 Absolute vs Relative Imports 8.3.1 Absolute Import from project.module import func

#### 8.3.2 Relative Import.

8.3.2 Relative Import

#### From .helpers import util from ..core.base import BaseClass.

from .helpers import util from ..core.base import BaseClass

#### Relative imports depend on package structure.

Relative imports depend on package structure.

#### A package is a directory with Python modules.

A package is a directory with Python modules.

#### Modern Python does not require __init__.py for a namespace package, but does require it for a regular package.

Modern Python does not require __init__.py for a namespace package, but does require it for a regular package.

#### Myapp/ __init__.py models/ __init__.py user.py.

myapp/ __init__.py models/ __init__.py user.py

#### 8.4.1 Regular packages.

8.4.1 Regular packages

#### Directory + __init__.py.

Directory + __init__.py.

#### __init__.py runs on import.

__init__.py runs on import.

#### 8.4.2 Namespace packages (PEP 420).

8.4.2 Namespace packages (PEP 420)

#### Directory without __init__.py.

Directory without __init__.py.

#### Large vendors (Google, AWS).

large vendors (Google, AWS)

#### Google/ cloud/ storage/ cloud/ compute/.

google/ cloud/ storage/ cloud/ compute/

#### These directories merge into one namespace.

These directories merge into one namespace.

#### 8.5 init.py: What It Really Does.

8.5 init.py: What It Really Does

#### __init__.py controls:.

__init__.py controls:

#### # myapp/models/__init__.py from .user import User from .invoice import Invoice.

# myapp/models/__init__.py from .user import User from .invoice import Invoice

#### __all__ = ["User", "Invoice"].

__all__ = ["User", "Invoice"]

#### 8.6 Handling Circular Imports.

8.6 Handling Circular Imports

#### Circular imports occur when:.

Circular imports occur when:

#### A imports b b imports a.

a imports b b imports a

#### Solution strategies:.

Solution strategies:

#### ‚úî Move imports inside functions def use_db(): from .db import connect.

‚úî Move imports inside functions def use_db(): from .db import connect

#### ‚úî Refactor into common module (common.py) ‚úî Use type-check‚Äìonly imports from __future__ import annotations.

‚úî Refactor into common module (common.py) ‚úî Use type-check‚Äìonly imports from __future__ import annotations

#### If typing.TYPE_CHECKING: from .models import User.

if typing.TYPE_CHECKING: from .models import User

#### 8.7 Project Layout Patterns.

8.7 Project Layout Patterns

#### Three main patterns.

Three main patterns.

#### 8.7.1 Flat Script Layout (small scripts) script.py.

8.7.1 Flat Script Layout (small scripts) script.py

#### 8.7.2 Basic Package Layout (small libraries) myproj/ myproj/ __init__.py main.py pyproject.toml.

8.7.2 Basic Package Layout (small libraries) myproj/ myproj/ __init__.py main.py pyproject.toml

#### 8.7.3 Professional Application Layout (recommended) myapp/ myapp/ __init__.py core/ __init__.py config.py logging.py api/ __init__.py routes.py ser...

8.7.3 Professional Application Layout (recommended) myapp/ myapp/ __init__.py core/ __init__.py config.py logging.py api/ __init__.py routes.py services/ __init__.py users.py payments.py tests/ pyproject.toml README.md

#### 8.8 pyproject.toml (PEP 518+).

8.8 pyproject.toml (PEP 518+)

#### Modern Python builds use this file.

Modern Python builds use this file.

#### [project] name = "myapp" version = "0.1.0" description = "Example project" dependencies = [ "requests", "pydantic>=2.0", ].

[project] name = "myapp" version = "0.1.0" description = "Example project" dependencies = [ "requests", "pydantic>=2.0", ]

#### [build-system] requires = ["setuptools>=61.0"] build-backend = "setuptools.build_meta".

[build-system] requires = ["setuptools>=61.0"] build-backend = "setuptools.build_meta"

#### 8.9 Virtual Environments 8.9.1 venv.

8.9 Virtual Environments 8.9.1 venv

#### Python -m venv .venv source .venv/bin/activate.

python -m venv .venv source .venv/bin/activate

#### 8.9.2 pyenv (Python version manager).

8.9.2 pyenv (Python version manager)

#### Install & switch versions:.

Install & switch versions:

#### Pyenv install 3.12.0 pyenv global 3.12.0.

pyenv install 3.12.0 pyenv global 3.12.0

#### Install isolated CLI tools:.

Install isolated CLI tools:

#### 8.10 Packaging & Distribution.

8.10 Packaging & Distribution

#### Write pyproject.toml.

write pyproject.toml

#### 8.11 Import Style Guide & Best Practices ‚úî Use absolute imports ‚úî Prefer explicit exports via __all__ ‚úî Do not put top-level code in modules ‚úî Keep...

8.11 Import Style Guide & Best Practices ‚úî Use absolute imports ‚úî Prefer explicit exports via __all__ ‚úî Do not put top-level code in modules ‚úî Keep packages small and focused ‚úî Avoid circular imports by design ‚úî Group related modules into subpackages 8.12 Mini Example ‚Äî Utilities Package myproj/ utils/ __init__.py math.py strings.py main.py

#### From utils.math import add from utils.strings import slugify.

from utils.math import add from utils.strings import slugify

#### 8.13 Macro Example ‚Äî Production-Ready Package myservice/ myservice/ __init__.py config.py http/ __init__.py client.py db/ __init__.py models.py rep...

8.13 Macro Example ‚Äî Production-Ready Package myservice/ myservice/ __init__.py config.py http/ __init__.py client.py db/ __init__.py models.py repository.py scripts/ seed_db.py tests/ pyproject.toml

#### # myservice/__main__.py from .http.client import HttpClient from .config import load_config.

# myservice/__main__.py from .http.client import HttpClient from .config import load_config

#### Def main(): config = load_config() client = HttpClient(config.api_url) print(client.get_status()).

def main(): config = load_config() client = HttpClient(config.api_url) print(client.get_status())

#### ‚ö† Circular imports ‚ö† Name shadowing (json.py shadowing stdlib json) ‚ö† Multiple namespace packages conflicting ‚ö† Accidental re-execution via relativ...

‚ö† Circular imports ‚ö† Name shadowing (json.py shadowing stdlib json) ‚ö† Multiple namespace packages conflicting ‚ö† Accidental re-execution via relative paths ‚ö† Adding directories to sys.path (avoid) ‚ö† Having both src/ and root code (use src layout)

#### 8.15 Summary & Takeaways.

8.15 Summary & Takeaways

#### Modules are single Python files.

Modules are single Python files

#### Packages are module directories.

Packages are module directories

#### Namespace packages allow multi-repo organization.

Namespace packages allow multi-repo organization

#### Imports follow sys.modules ‚Üí sys.path ‚Üí file loading.

Imports follow sys.modules ‚Üí sys.path ‚Üí file loading

#### Pyproject.toml is the modern packaging standard.

pyproject.toml is the modern packaging standard

#### Recommended project layout improves maintainability.

Recommended project layout improves maintainability

#### Proper import strategy prevents circular dependencies.

Proper import strategy prevents circular dependencies

#### üëâ Chapter 9 ‚Äî Standard Library Essentials Covers:.

üëâ Chapter 9 ‚Äî Standard Library Essentials Covers:

#### Collections, heapq, bisect.

collections, heapq, bisect

#### Json, csv, configparser.

json, csv, configparser


---

## Chapter 9 ‚Äî STANDARD LIBRARY ESSENTIALS

_Difficulty: Beginner_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch09-start" --> üìò CHAPTER 9 ‚Äî STANDARD LIBRARY ESSENTIALS üü¢ Beginner.

<!-- SSM:CHUNK_BOUNDARY id="ch09-start" --> üìò CHAPTER 9 ‚Äî STANDARD LIBRARY ESSENTIALS üü¢ Beginner

#### Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì8.

Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì8

#### Python‚Äôs standard library is enormous and often referred to as:.

Python‚Äôs standard library is enormous and often referred to as:

#### ‚ÄúBatteries Included.‚Äù.

‚ÄúBatteries Included.‚Äù

#### This chapter covers the most essential 80% of modules used in:

This chapter covers the most essential 80% of modules used in:

#### We do not cover concurrency libraries here (threading, multiprocessing, asyncio), because those have their own dedicated chapters.

We do not cover concurrency libraries here (threading, multiprocessing, asyncio), because those have their own dedicated chapters.

#### 9.1 Filesystem & OS Interaction.

9.1 Filesystem & OS Interaction

#### This section covers:

This section covers:

#### 9.1.1 pathlib: Modern Path Handling (Preferred) from pathlib import Path.

9.1.1 pathlib: Modern Path Handling (Preferred) from pathlib import Path

#### P = Path("data") / "input.txt".

p = Path("data") / "input.txt"

#### If p.exists(): text = p.read_text().

if p.exists(): text = p.read_text()

#### Path.read_text(), .read_bytes().

Path.read_text(), .read_bytes()

#### .mkdir(), .unlink(), .rename().

.mkdir(), .unlink(), .rename()

#### 9.1.2 os & os.path: Legacy but Common.

9.1.2 os & os.path: Legacy but Common

#### Useful for lower-level control.

Useful for lower-level control.

#### Files = os.listdir(".") os.makedirs("tmp", exist_ok=True).

files = os.listdir(".") os.makedirs("tmp", exist_ok=True)

#### 9.1.3 shutil: File Operations.

9.1.3 shutil: File Operations

#### The shutil module provides high-level file operations for copying, moving, and archiving files and directories.

The `shutil` module provides high-level file operations for copying, moving, and archiving files and directories.

#### Removing Directories:.

**Removing Directories:**

#### Creating Archives:.

**Creating Archives:**

#### Extracting Archives:.

**Extracting Archives:**

#### Finding Executables:.

**Finding Executables:**

#### Copy(), copy2() ‚Äî Copy files (copy2 preserves metadata) - copytree() ‚Äî Recursive directory copy - move() ‚Äî Move/rename files or directories - rmtre...

- `copy()`, `copy2()` ‚Äî Copy files (copy2 preserves metadata) - `copytree()` ‚Äî Recursive directory copy - `move()` ‚Äî Move/rename files or directories - `rmtree()` ‚Äî Remove directory tree - `make_archive()` ‚Äî Create archives (zip, tar, gztar, bztar, xztar) - `unpack_archive()` ‚Äî Extract archives - `disk_usage()` ‚Äî Get disk space statistics - `which()` ‚Äî Find executable in PATH

#### ‚ö† shutil.rmtree() is destructive ‚Äî no undo ‚ö† copytree() fails if destination exists (use dirs_exist_ok=True in 3.8+) ‚ö† move() may copy then delete ...

‚ö† `shutil.rmtree()` is destructive ‚Äî no undo ‚ö† `copytree()` fails if destination exists (use `dirs_exist_ok=True` in 3.8+) ‚ö† `move()` may copy then delete on different filesystems ‚ö† `move()` across filesystems can be slow for large files

#### Try This: Create a backup script using shutil.make_archive():.

**Try This:** Create a backup script using `shutil.make_archive()`:

#### 9.1.4 tempfile: Secure Temporary Files.

9.1.4 tempfile: Secure Temporary Files

#### The tempfile module provides secure temporary file and directory creation with automatic cleanup.

The `tempfile` module provides secure temporary file and directory creation with automatic cleanup.

#### Temporary Files:.

**Temporary Files:**

#### Temporary Directories:.

**Temporary Directories:**

#### Low-Level Functions:.

**Low-Level Functions:**

#### Secure Temporary Files (Best Practice):.

**Secure Temporary Files (Best Practice):**

#### Temporary Files with Specific Permissions:.

**Temporary Files with Specific Permissions:**

#### TemporaryFile() ‚Äî Temporary file (auto-deleted) - NamedTemporaryFile() ‚Äî Named temporary file (visible in filesystem) - TemporaryDirectory() ‚Äî Temp...

- `TemporaryFile()` ‚Äî Temporary file (auto-deleted) - `NamedTemporaryFile()` ‚Äî Named temporary file (visible in filesystem) - `TemporaryDirectory()` ‚Äî Temporary directory (auto-deleted) - `mkstemp()` ‚Äî Low-level secure file creation (returns file descriptor) - `mkdtemp()` ‚Äî Low-level secure directory creation - `gettempdir()` ‚Äî Get system temp directory - `gettempprefix()` ‚Äî Get temp file prefix

#### ‚ö† mktemp() is deprecated ‚Äî use NamedTemporaryFile() instead ‚ö† Temporary files may persist if process crashes ‚Äî use context managers ‚ö† On Windows, f...

‚ö† `mktemp()` is deprecated ‚Äî use `NamedTemporaryFile()` instead ‚ö† Temporary files may persist if process crashes ‚Äî use context managers ‚ö† On Windows, files in use cannot be deleted ‚Äî ensure files are closed ‚ö† Race conditions possible with `mktemp()` ‚Äî use `mkstemp()` for security

#### Try This: Create a secure temporary file processor:.

**Try This:** Create a secure temporary file processor:

#### Python's datetime handling is comprehensive but requires careful attention to timezones and formatting.

Python's datetime handling is comprehensive but requires careful attention to timezones and formatting.

#### Datetime (core) ‚Äî Main datetime classes - zoneinfo (3.9+, timezone) ‚Äî Timezone support (replaces pytz) - time (system time) ‚Äî Low-level time functi...

- `datetime` (core) ‚Äî Main datetime classes - `zoneinfo` (3.9+, timezone) ‚Äî Timezone support (replaces pytz) - `time` (system time) ‚Äî Low-level time functions - `dateutil` (3rd-party, recommended) ‚Äî Advanced parsing and timezone handling

#### 9.2.1 datetime: Core Date/Time Classes.

9.2.1 datetime: Core Date/Time Classes

#### The datetime module provides classes for working with dates and times.

The `datetime` module provides classes for working with dates and times.

#### Date and Time Components:.

**Date and Time Components:**

#### Date and Time Objects:.

**Date and Time Objects:**

#### Timedelta Operations:.

**Timedelta Operations:**

#### 9.2.2 timezone handling (critical).

9.2.2 timezone handling (critical)

#### Using zoneinfo (Python 3.9+):.

**Using zoneinfo (Python 3.9+):**

#### Creating Timezone-Aware Datetimes:.

**Creating Timezone-Aware Datetimes:**

#### Common Timezones:.

**Common Timezones:**

#### Timezone Conversion:.

**Timezone Conversion:**

#### Try This: Create a timezone-aware event scheduler:.

**Try This:** Create a timezone-aware event scheduler:

#### 9.2.3 Parsing and Formatting.

9.2.3 Parsing and Formatting

#### Parsing Strings to Datetime:.

**Parsing Strings to Datetime:**

#### Formatting Datetime to String:.

**Formatting Datetime to String:**

#### Human-Readable Formatting:.

**Human-Readable Formatting:**

#### Try This: Create a date range generator:.

**Try This:** Create a date range generator:

#### 9.3 Data Structures (collections module).

9.3 Data Structures (collections module)

#### The collections module provides specialized data structures that are more efficient or convenient than built-in types for specific use cases.

The `collections` module provides specialized data structures that are more efficient or convenient than built-in types for specific use cases. These are essential productivity boosters.

#### 9.3.1 Counter: Counting Hashable Objects.

9.3.1 Counter: Counting Hashable Objects

#### Counter is a dictionary subclass for counting hashable objects.

`Counter` is a dictionary subclass for counting hashable objects. It's perfect for frequency analysis.

#### Common Operations:.

**Common Operations:**

#### Practical Examples:.

**Practical Examples:**

#### Try This: Analyze log file for most common error types:.

**Try This:** Analyze log file for most common error types:

#### 9.3.2 defaultdict: Dictionary with Default Factory.

9.3.2 defaultdict: Dictionary with Default Factory

#### Defaultdict automatically creates default values for missing keys, eliminating the need for if key in dict checks.

`defaultdict` automatically creates default values for missing keys, eliminating the need for `if key in dict` checks.

#### Common Factory Functions:.

**Common Factory Functions:**

#### Try This: Group users by department:.

**Try This:** Group users by department:

#### 9.3.3 deque: Fast Queues and Stacks.

9.3.3 deque: Fast Queues and Stacks

#### Deque (double-ended queue) provides O(1) append/pop operations from both ends, making it ideal for queues and stacks.

`deque` (double-ended queue) provides O(1) append/pop operations from both ends, making it ideal for queues and stacks.

#### Queue Operations (FIFO):.

**Queue Operations (FIFO):**

#### Stack Operations (LIFO):.

**Stack Operations (LIFO):**

#### Performance Comparison:.

**Performance Comparison:**

#### Try This: Implement a sliding window using bounded deque:.

**Try This:** Implement a sliding window using bounded deque:

#### 9.3.4 OrderedDict: Dict with Insertion Order.

9.3.4 OrderedDict: Dict with Insertion Order

#### Since Python 3.7, regular dict maintains insertion order.

Since Python 3.7, regular `dict` maintains insertion order. `OrderedDict` is still useful for:

#### Explicit ordering guarantees (backward compatibility) - move_to_end() and popitem(last=False) methods - Equality comparisons that consider order.

- Explicit ordering guarantees (backward compatibility) - `move_to_end()` and `popitem(last=False)` methods - Equality comparisons that consider order

#### 9.3.5 ChainMap: Multiple Dicts as Single Mapping.

9.3.5 ChainMap: Multiple Dicts as Single Mapping

#### ChainMap groups multiple dictionaries into a single mapping, searching each dict in order until a key is found.

`ChainMap` groups multiple dictionaries into a single mapping, searching each dict in order until a key is found.

#### Practical Example:.

**Practical Example:**

#### Try This: Create a configuration system:.

**Try This:** Create a configuration system:

#### 9.3.6 namedtuple / dataclass.

9.3.6 namedtuple / dataclass

#### Namedtuple (Legacy, but still useful):.

**namedtuple (Legacy, but still useful):**

#### Dataclass (Modern, Preferred):.

**dataclass (Modern, Preferred):**

#### Try This: Compare namedtuple vs dataclass:.

**Try This:** Compare namedtuple vs dataclass:

#### 9.4 Algorithms: heapq & bisect 9.4.1 heapq import heapq.

9.4 Algorithms: heapq & bisect 9.4.1 heapq import heapq

#### H = [] heapq.heappush(h, 5) heapq.heappush(h, 1) print(heapq.heappop(h)).

h = [] heapq.heappush(h, 5) heapq.heappush(h, 1) print(heapq.heappop(h))

#### 9.4.2 bisect (binary search) import bisect.

9.4.2 bisect (binary search) import bisect

#### Bisect.bisect([1,2,3,10], 5) # 3.

bisect.bisect([1,2,3,10], 5) # 3

#### Useful for sorted lists.

Useful for sorted lists.

#### Python provides powerful tools for text manipulation, pattern matching, and formatting.

Python provides powerful tools for text manipulation, pattern matching, and formatting.

#### Re (regex) ‚Äî Regular expressions for pattern matching - string ‚Äî String constants and utilities - textwrap ‚Äî Text wrapping and formatting - difflib...

- `re` (regex) ‚Äî Regular expressions for pattern matching - `string` ‚Äî String constants and utilities - `textwrap` ‚Äî Text wrapping and formatting - `difflib` ‚Äî Text diffing and comparison

#### 9.5.1 regex (re module): Pattern Matching.

9.5.1 regex (re module): Pattern Matching

#### The re module provides regular expression operations for pattern matching and text manipulation.

The `re` module provides regular expression operations for pattern matching and text manipulation.

#### Basic Pattern Matching:.

**Basic Pattern Matching:**

#### Groups and Capturing:.

**Groups and Capturing:**

#### Common Patterns:.

**Common Patterns:**

#### 9.5.2 Precompiled regex: Performance Optimization.

9.5.2 Precompiled regex: Performance Optimization

#### 9.5.3 Key features: Advanced Regex.

9.5.3 Key features: Advanced Regex

#### Lookaheads and Lookbehinds:.

**Lookaheads and Lookbehinds:**

#### Non-capturing Groups:.

**Non-capturing Groups:**

#### Greedy vs Non-greedy:.

**Greedy vs Non-greedy:**

#### Try This: Extract structured data from log lines:.

**Try This:** Extract structured data from log lines:

#### 9.5.4 string module: Constants and Utilities.

9.5.4 string module: Constants and Utilities

#### The string module provides useful constants and string manipulation utilities.

The `string` module provides useful constants and string manipulation utilities.

#### Template Strings:.

**Template Strings:**

#### Formatter (Advanced):.

**Formatter (Advanced):**

#### Try This: Generate random password:.

**Try This:** Generate random password:

#### 9.5.5 textwrap: Text Wrapping and Formatting.

9.5.5 textwrap: Text Wrapping and Formatting

#### The textwrap module provides text wrapping, filling, and indentation utilities.

The `textwrap` module provides text wrapping, filling, and indentation utilities.

#### Advanced Options:.

**Advanced Options:**

#### Dedent (Remove Common Indentation):.

**Dedent (Remove Common Indentation):**

#### Try This: Format code comments:.

**Try This:** Format code comments:

#### 9.5.6 difflib: Text Diffing and Comparison.

9.5.6 difflib: Text Diffing and Comparison

#### The difflib module provides tools for comparing sequences and generating diffs.

The `difflib` module provides tools for comparing sequences and generating diffs.

#### Sequence Matching:.

**Sequence Matching:**

#### Finding Close Matches:.

**Finding Close Matches:**

#### Try This: Create a simple diff viewer:.

**Try This:** Create a simple diff viewer:

#### Python's standard library provides robust support for common file formats used in data exchange and configuration.

Python's standard library provides robust support for common file formats used in data exchange and configuration.

#### 9.6.1 JSON: JavaScript Object Notation.

9.6.1 JSON: JavaScript Object Notation

#### JSON is the de facto standard for data exchange in web APIs and configuration files.

JSON is the de facto standard for data exchange in web APIs and configuration files.

#### File Operations:.

**File Operations:**

#### Try This: Create a JSON configuration manager:.

**Try This:** Create a JSON configuration manager:

#### 9.6.2 CSV: Comma-Separated Values.

9.6.2 CSV: Comma-Separated Values

#### The csv module provides robust CSV reading and writing with proper handling of edge cases.

The `csv` module provides robust CSV reading and writing with proper handling of edge cases.

#### Try This: Process CSV with data validation:.

**Try This:** Process CSV with data validation:

#### 9.6.3 configparser: INI File Parsing.

9.6.3 configparser: INI File Parsing

#### The configparser module reads and writes INI-style configuration files.

The `configparser` module reads and writes INI-style configuration files.

#### INI File Format:.

**INI File Format:**

#### Advanced Features:.

**Advanced Features:**

#### Try This: Create a configuration loader with validation:.

**Try This:** Create a configuration loader with validation:

#### 9.6.4 XML: Extensible Markup Language.

9.6.4 XML: Extensible Markup Language

#### The xml.etree.ElementTree module provides a simple and efficient API for parsing and creating XML.

The `xml.etree.ElementTree` module provides a simple and efficient API for parsing and creating XML.

#### XPath-like Searching:.

**XPath-like Searching:**

#### Try This: Parse and transform XML:.

**Try This:** Parse and transform XML:

#### 9.6.5 pickle: Python Object Serialization (‚ö† dangerous).

9.6.5 pickle: Python Object Serialization (‚ö† dangerous)

#### Protocol Versions:.

**Protocol Versions:**

#### Secure Alternatives:.

**Secure Alternatives:**

#### Try This: Safe object serialization wrapper:.

**Try This:** Safe object serialization wrapper:

#### 9.7 System Interaction.

9.7 System Interaction

#### Python provides comprehensive tools for interacting with the operating system, running external programs, and managing system resources.

Python provides comprehensive tools for interacting with the operating system, running external programs, and managing system resources.

#### Subprocess ‚Äî Run external programs and commands - sys ‚Äî System-specific parameters and functions - os ‚Äî Operating system interface - signal ‚Äî Signa...

- `subprocess` ‚Äî Run external programs and commands - `sys` ‚Äî System-specific parameters and functions - `os` ‚Äî Operating system interface - `signal` ‚Äî Signal handling for Unix systems

#### 9.7.1 subprocess: Running External Programs.

9.7.1 subprocess: Running External Programs

#### Popen for Advanced Control:.

**Popen for Advanced Control:**

#### ‚ö†Ô∏è CRITICAL: Security Best Practices:.

**‚ö†Ô∏è CRITICAL: Security Best Practices:**

#### Try This: Create a safe command runner:.

**Try This:** Create a safe command runner:

#### 9.7.2 sys module: System-Specific Parameters.

9.7.2 sys module: System-Specific Parameters

#### The sys module provides access to system-specific parameters and functions.

The `sys` module provides access to system-specific parameters and functions.

#### Command-Line Arguments:.

**Command-Line Arguments:**

#### System Information:.

**System Information:**

#### Memory and Performance:.

**Memory and Performance:**

#### Standard Streams:.

**Standard Streams:**

#### Try This: Create a CLI argument parser:.

**Try This:** Create a CLI argument parser:

#### 9.7.3 os module: Operating System Interface.

9.7.3 os module: Operating System Interface

#### The os module provides a portable way to use operating system functionality.

The `os` module provides a portable way to use operating system functionality.

#### Environment Variables:.

**Environment Variables:**

#### File and Directory Operations:.

**File and Directory Operations:**

#### Path Operations (Prefer pathlib, but os.path still common):.

**Path Operations (Prefer pathlib, but os.path still common):**

#### Process Information:.

**Process Information:**

#### Permissions (Unix):.

**Permissions (Unix):**

#### Try This: Create a file system utility:.

**Try This:** Create a file system utility:

#### 9.7.4 signal handling: Unix Signal Management.

9.7.4 signal handling: Unix Signal Management

#### The signal module allows programs to handle Unix signals (not available on Windows).

The `signal` module allows programs to handle Unix signals (not available on Windows).

#### Basic Signal Handling:.

**Basic Signal Handling:**

#### Timeout with Signals:.

**Timeout with Signals:**

#### ‚ö†Ô∏è Windows Limitation:.

**‚ö†Ô∏è Windows Limitation:**

#### Signal handling is Unix-specific.

Signal handling is Unix-specific. On Windows, only `SIGINT` and `SIGTERM` are available, and behavior differs.

#### Try This: Graceful shutdown handler:.

**Try This:** Graceful shutdown handler:

#### Python's standard library provides networking capabilities, though third-party libraries like requests and httpx are preferred for HTTP.

Python's standard library provides networking capabilities, though third-party libraries like `requests` and `httpx` are preferred for HTTP.

#### Urllib ‚Äî URL handling and HTTP client (stdlib) - requests (third-party) ‚Äî Preferred for HTTP (not in stdlib) - socket ‚Äî Low-level networking interf...

- `urllib` ‚Äî URL handling and HTTP client (stdlib) - `requests` (third-party) ‚Äî Preferred for HTTP (not in stdlib) - `socket` ‚Äî Low-level networking interface - `ssl` ‚Äî SSL/TLS support

#### 9.8.1 urllib: URL Handling and HTTP Client.

9.8.1 urllib: URL Handling and HTTP Client

#### The urllib module provides URL handling and basic HTTP client functionality.

The `urllib` module provides URL handling and basic HTTP client functionality.

#### Basic HTTP Requests:.

**Basic HTTP Requests:**

#### URL Parsing and Encoding:.

**URL Parsing and Encoding:**

#### No connection pooling - No automatic retries - Verbose API - Limited authentication options.

- No connection pooling - No automatic retries - Verbose API - Limited authentication options

#### Recommendation: Use requests or httpx for production HTTP clients.

**Recommendation:** Use `requests` or `httpx` for production HTTP clients.

#### Try This: Simple HTTP client wrapper:.

**Try This:** Simple HTTP client wrapper:

#### 9.8.2 low-level sockets: Raw Network Programming.

9.8.2 low-level sockets: Raw Network Programming

#### The socket module provides low-level network interface (rarely needed for most applications).

The `socket` module provides low-level network interface (rarely needed for most applications).

#### Basic TCP Client:.

**Basic TCP Client:**

#### Basic TCP Server:.

**Basic TCP Server:**

#### Try This: Simple echo server:.

**Try This:** Simple echo server:

#### 9.8.3 ssl: Secure Socket Layer.

9.8.3 ssl: Secure Socket Layer

#### The ssl module provides SSL/TLS support for secure connections.

The `ssl` module provides SSL/TLS support for secure connections.

#### Certificate Verification:.

**Certificate Verification:**

#### Custom Certificates:.

**Custom Certificates:**

#### ‚ö†Ô∏è Security Best Practices:.

**‚ö†Ô∏è Security Best Practices:**

#### Try This: Secure HTTPS client:.

**Try This:** Secure HTTPS client:

#### 9.9 Compression & Archives.

9.9 Compression & Archives

#### Python provides comprehensive support for compression and archive formats.

Python provides comprehensive support for compression and archive formats.

#### 9.9.1 zipfile: ZIP Archive Handling.

9.9.1 zipfile: ZIP Archive Handling

#### The zipfile module handles ZIP archives (the most common archive format).

The `zipfile` module handles ZIP archives (the most common archive format).

#### Reading ZIP Files:.

**Reading ZIP Files:**

#### Creating ZIP Files:.

**Creating ZIP Files:**

#### Password-Protected ZIPs:.

**Password-Protected ZIPs:**

#### Try This: Create a backup utility:.

**Try This:** Create a backup utility:

#### 9.9.2 tarfile: TAR Archive Handling.

9.9.2 tarfile: TAR Archive Handling

#### The tarfile module handles TAR archives (common on Unix systems).

The `tarfile` module handles TAR archives (common on Unix systems).

#### Reading TAR Files:.

**Reading TAR Files:**

#### Creating TAR Files:.

**Creating TAR Files:**

#### Try This: Archive with filtering:.

**Try This:** Archive with filtering:

#### 9.9.3 gzip/bz2/lzma: Compression Modules.

9.9.3 gzip/bz2/lzma: Compression Modules

#### These modules provide compression for individual files.

These modules provide compression for individual files.

#### Compression Comparison:.

**Compression Comparison:**

#### Try This: Compress log files:.

**Try This:** Compress log files:

#### 9.10 Debugging & Introspection Tools.

9.10 Debugging & Introspection Tools

#### Python provides powerful tools for debugging and code introspection.

Python provides powerful tools for debugging and code introspection.

#### 9.10.1 logging: Structured Logging.

9.10.1 logging: Structured Logging

#### The logging module is essential for production applications.

The `logging` module is essential for production applications.

#### Advanced Configuration:.

**Advanced Configuration:**

#### Structured Logging (with context):.

**Structured Logging (with context):**

#### Try This: Create a logging utility:.

**Try This:** Create a logging utility:

#### 9.10.2 pprint: Pretty Printing.

9.10.2 pprint: Pretty Printing

#### The pprint module provides improved printing for data structures.

The `pprint` module provides improved printing for data structures.

#### Try This: Debug data structures:.

**Try This:** Debug data structures:

#### 9.10.3 traceback: Exception Tracebacks.

9.10.3 traceback: Exception Tracebacks

#### The traceback module provides detailed exception information.

The `traceback` module provides detailed exception information.

#### Printing Tracebacks:.

**Printing Tracebacks:**

#### Custom Exception Formatting:.

**Custom Exception Formatting:**

#### Try This: Exception logger:.

**Try This:** Exception logger:

#### 9.10.4 inspect: Code Introspection.

9.10.4 inspect: Code Introspection

#### The inspect module provides powerful introspection capabilities.

The `inspect` module provides powerful introspection capabilities.

#### Function Signatures:.

**Function Signatures:**

#### Class and Object Inspection:.

**Class and Object Inspection:**

#### Frame Inspection (Debugging):.

**Frame Inspection (Debugging):**

#### Try This: Create a function inspector:.

**Try This:** Create a function inspector:

#### 9.11 Mini Example ‚Äî CSV ‚Üí JSON Converter import csv, json from pathlib import Path.

9.11 Mini Example ‚Äî CSV ‚Üí JSON Converter import csv, json from pathlib import Path

#### Def csv_to_json(path): rows = [] with open(path) as f: reader = csv.DictReader(f) rows = list(reader) Path(path).with_suffix(".json").write_text(js...

def csv_to_json(path): rows = [] with open(path) as f: reader = csv.DictReader(f) rows = list(reader) Path(path).with_suffix(".json").write_text(json.dumps(rows, indent=2))

#### csv_to_json("input.csv")

csv_to_json("input.csv")

#### 9.12 Macro Example ‚Äî Log Monitoring Utility.

9.12 Macro Example ‚Äî Log Monitoring Utility

#### Import re import gzip from pathlib import Path from datetime import datetime, timezone.

import re import gzip from pathlib import Path from datetime import datetime, timezone

#### Pattern = re.compile(r"\[(?P<ts>.*?)\] (?P<level>\w+): (?P<msg>.*)").

pattern = re.compile(r"\[(?P<ts>.*?)\] (?P<level>\w+): (?P<msg>.*)")

#### Def parse_log(path): opener = gzip.open if path.suffix == ".gz" else open.

def parse_log(path): opener = gzip.open if path.suffix == ".gz" else open

#### With opener(path, "rt") as f: for line in f: m = pattern.search(line) if not m: continue ts = datetime.fromisoformat(m["ts"]).replace(tzinfo=timezo...

with opener(path, "rt") as f: for line in f: m = pattern.search(line) if not m: continue ts = datetime.fromisoformat(m["ts"]).replace(tzinfo=timezone.utc) yield ts, m["level"], m["msg"]

#### For ts, lvl, msg in parse_log(Path("logs/app.log.gz")): print(ts, lvl, msg).

for ts, lvl, msg in parse_log(Path("logs/app.log.gz")): print(ts, lvl, msg)

#### 9.14 Summary & Takeaways.

9.14 Summary & Takeaways

#### Standard library covers huge amounts of functionality.

Standard library covers huge amounts of functionality

#### Collections and itertools are essential to performance.

collections and itertools are essential to performance

#### Datetime + zoneinfo enable complete timezone-safe operations.

datetime + zoneinfo enable complete timezone-safe operations

#### Regex is powerful but requires caution.

regex is powerful but requires caution

#### Subprocess.run() is safest modern API.

subprocess.run() is safest modern API

#### For HTTP, use requests or httpx, not urllib.

For HTTP, use requests or httpx, not urllib

#### Compression modules allow processing large archives.

Compression modules allow processing large archives

#### Debugging tools (traceback, inspect) are essential.

Debugging tools (traceback, inspect) are essential


---

## Chapter 10 ‚Äî ERROR HANDLING & EXCEPTIONS

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch10-start" --> üìò CHAPTER 10 ‚Äî ERROR HANDLING & EXCEPTIONS üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch10-start" --> üìò CHAPTER 10 ‚Äî ERROR HANDLING & EXCEPTIONS üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì9.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì9

#### Estimated time: 2-3 hours When you need this: Robust application development, API design, production systems.

**Estimated time:** 2-3 hours **When you need this:** Robust application development, API design, production systems

#### Python treats errors as exceptions, part of a rich, flexible, and powerful system.

Python treats errors as exceptions, part of a rich, flexible, and powerful system.

#### Hierarchical exception types.

hierarchical exception types

#### Catching specific or generic errors.

catching specific or generic errors

#### Raising new exceptions.

raising new exceptions

#### Suppressing exceptions.

suppressing exceptions

#### Exception groups (3.11+).

exception groups (3.11+)

#### Debugger integration.

debugger integration

#### Robust error semantics for async.

robust error semantics for async

#### 10.1 The Exception Hierarchy.

10.1 The Exception Hierarchy

#### All exceptions derive from:.

All exceptions derive from:

#### BaseException ‚îú‚îÄ‚îÄ Exception ‚îÇ ‚îú‚îÄ‚îÄ ArithmeticError ‚îÇ ‚îú‚îÄ‚îÄ LookupError ‚îÇ ‚îú‚îÄ‚îÄ ValueError ‚îÇ ‚îú‚îÄ‚îÄ TypeError ‚îÇ ‚îú‚îÄ‚îÄ RuntimeError ‚îÇ ‚îî‚îÄ‚îÄ ..

BaseException ‚îú‚îÄ‚îÄ Exception ‚îÇ ‚îú‚îÄ‚îÄ ArithmeticError ‚îÇ ‚îú‚îÄ‚îÄ LookupError ‚îÇ ‚îú‚îÄ‚îÄ ValueError ‚îÇ ‚îú‚îÄ‚îÄ TypeError ‚îÇ ‚îú‚îÄ‚îÄ RuntimeError ‚îÇ ‚îî‚îÄ‚îÄ ... ‚îú‚îÄ‚îÄ SystemExit ‚îú‚îÄ‚îÄ KeyboardInterrupt ‚îî‚îÄ‚îÄ GeneratorExit

#### Only catch subclasses of Exception unless you have a very good reason not to.

Only catch subclasses of Exception unless you have a very good reason not to.

#### 10.2 try / except / else / finally.

10.2 try / except / else / finally

#### 10.2.1 try/except try: x = int(raw) except ValueError: x = 0.

10.2.1 try/except try: x = int(raw) except ValueError: x = 0

#### Runs only when no exception was raised.

Runs only when no exception was raised.

#### Useful to separate success path from failure path.

Useful to separate success path from failure path.

#### 10.3 Raising Exceptions.

10.3 Raising Exceptions

#### Raise ValueError("Invalid").

raise ValueError("Invalid")

#### Except Exception: raise.

except Exception: raise

#### 10.4 Exception Chaining (Critical Knowledge).

10.4 Exception Chaining (Critical Knowledge)

#### Python preserves the root cause of an error.

Python preserves the root cause of an error.

#### 10.4.1 Implicit chaining try: read_config() except OSError as e: raise RuntimeError("config load failed").

10.4.1 Implicit chaining try: read_config() except OSError as e: raise RuntimeError("config load failed")

#### 10.4.2 Explicit chaining (best practice) try: read_config() except OSError as e: raise RuntimeError("config load failed") from e.

10.4.2 Explicit chaining (best practice) try: read_config() except OSError as e: raise RuntimeError("config load failed") from e

#### Use this in enterprise systems to maintain traceability.

Use this in enterprise systems to maintain traceability.

#### 10.5 Built-In Exception Types & When to Use Them.

10.5 Built-In Exception Types & When to Use Them

#### Class AppError(Exception): pass.

class AppError(Exception): pass

#### Class ConfigError(AppError): pass.

class ConfigError(AppError): pass

#### Class DatabaseError(AppError): pass.

class DatabaseError(AppError): pass

#### Catch-all for system errors.

catch-all for system errors

#### 10.7 Error Codes vs Exceptions ‚úî Prefer exceptions inside Python code ‚úî Convert to error codes only at boundaries:.

10.7 Error Codes vs Exceptions ‚úî Prefer exceptions inside Python code ‚úî Convert to error codes only at boundaries:

#### Integrations with non-Python systems.

integrations with non-Python systems

#### Try: run() except AppError: sys.exit(1).

try: run() except AppError: sys.exit(1)

#### Logger = logging.getLogger(__name__).

logger = logging.getLogger(__name__)

#### Try: do_work() except Exception as e: logger.exception("Work failed").

try: do_work() except Exception as e: logger.exception("Work failed")

#### Automatically prints:.

Automatically prints:

#### 10.9 Warnings System (Underused & Important) import warnings.

10.9 Warnings System (Underused & Important) import warnings

#### Warnings.warn("deprecated", DeprecationWarning).

warnings.warn("deprecated", DeprecationWarning)

#### Unexpected but not fatal conditions.

unexpected but not fatal conditions

#### ‚ö† Catching Exception blindly.

‚ö† Catching Exception blindly

#### Except Exception: ...

try: ... except Exception: ...

#### ‚ö† Swallowing errors silently.

‚ö† Swallowing errors silently

#### Try: ..

try: ... except: pass

#### ‚ö† Using exceptions for flow control (Except in iterator stop semantics).

‚ö† Using exceptions for flow control (Except in iterator stop semantics)

#### ‚ö† Ignoring chained exceptions.

‚ö† Ignoring chained exceptions

#### 10.11 Retry Patterns & Backoff.

10.11 Retry Patterns & Backoff

#### Enterprise systems need retries.

Enterprise systems need retries.

#### 10.11.1 Manual retry loop for attempt in range(3): try: return api_call() except TimeoutError: sleep(2).

10.11.1 Manual retry loop for attempt in range(3): try: return api_call() except TimeoutError: sleep(2)

#### 10.11.2 Exponential backoff import time, random.

10.11.2 Exponential backoff import time, random

#### Def retry_with_backoff(fn, attempts=5): delay = 0.5 for i in range(attempts): try: return fn() except Exception: time.sleep(delay) delay *= 2 * (1 ...

def retry_with_backoff(fn, attempts=5): delay = 0.5 for i in range(attempts): try: return fn() except Exception: time.sleep(delay) delay *= 2 * (1 + random.random())

#### Tenacity (most flexible).

tenacity (most flexible)

#### Backoff (simpler syntax).

backoff (simpler syntax)

#### 10.12 Circuit Breaker Pattern.

10.12 Circuit Breaker Pattern

#### Used to avoid hammering unhealthy dependencies.

Used to avoid hammering unhealthy dependencies.

#### Closed ‚Üí open ‚Üí half-open ‚Üí closed.

closed ‚Üí open ‚Üí half-open ‚Üí closed

#### Generic implementation:.

Generic implementation:

#### Class CircuitBreaker: def __init__(self): self.failures = 0 self.threshold = 5 self.open_until = None.

class CircuitBreaker: def __init__(self): self.failures = 0 self.threshold = 5 self.open_until = None

#### Def call(self, fn): ...

def call(self, fn): ...

#### Used extensively in microservices.

Used extensively in microservices.

#### 10.13 Exception Groups (Python 3.11+).

10.13 Exception Groups (Python 3.11+)

#### Allows raising multiple errors simultaneously.

Allows raising multiple errors simultaneously.

#### 10.13.1 Basic Example raise ExceptionGroup("multiple", [ValueError(), TypeError()]).

10.13.1 Basic Example raise ExceptionGroup("multiple", [ValueError(), TypeError()])

#### 10.13.2 try/except syntax* try: task_group() except* ValueError as e: handle_value_errors(e) except* TypeError as e: handle_type_errors(e).

10.13.2 try/except syntax* try: task_group() except* ValueError as e: handle_value_errors(e) except* TypeError as e: handle_type_errors(e)

#### This is essential in async and parallel programs.

This is essential in async and parallel programs.

#### 10.14 Error Handling in Async Code.

10.14 Error Handling in Async Code

#### Asyncio.gather groups exceptions.

asyncio.gather groups exceptions

#### 10.14.1 catching task errors async def worker(): raise ValueError().

10.14.1 catching task errors async def worker(): raise ValueError()

#### Async def main(): task = asyncio.create_task(worker()) try: await task except Exception as e: print("error:", e).

async def main(): task = asyncio.create_task(worker()) try: await task except Exception as e: print("error:", e)

#### 10.14.2 asyncio.gather with return_exceptions=True results = await asyncio.gather(*tasks, return_exceptions=True).

10.14.2 asyncio.gather with return_exceptions=True results = await asyncio.gather(*tasks, return_exceptions=True)

#### 10.15 Mini Example ‚Äî Robust File Loader from pathlib import Path.

10.15 Mini Example ‚Äî Robust File Loader from pathlib import Path

#### Def load_file(path): if not Path(path).exists(): raise FileNotFoundError(path).

def load_file(path): if not Path(path).exists(): raise FileNotFoundError(path)

#### Try: return Path(path).read_text() except UnicodeDecodeError as e: raise ValueError(f"invalid encoding: {path}") from e.

try: return Path(path).read_text() except UnicodeDecodeError as e: raise ValueError(f"invalid encoding: {path}") from e

#### 10.16 Macro Example ‚Äî API Client with Retry + Logging + Chaining import logging import time import requests.

10.16 Macro Example ‚Äî API Client with Retry + Logging + Chaining import logging import time import requests

#### Log = logging.getLogger("api").

log = logging.getLogger("api")

#### Class ApiError(Exception): pass.

class ApiError(Exception): pass

#### Def request_with_backoff(url, retries=3): delay = 1 for attempt in range(retries): try: r = requests.get(url, timeout=3) r.raise_for_status() retur...

def request_with_backoff(url, retries=3): delay = 1 for attempt in range(retries): try: r = requests.get(url, timeout=3) r.raise_for_status() return r.json() except Exception as e: log.warning("attempt %s failed: %s", attempt+1, e) if attempt == retries - 1: raise ApiError("API permanently failed") from e time.sleep(delay) delay *= 2

#### print(request_with_backoff("https://api.example.com/data"))

print(request_with_backoff("https://api.example.com/data"))

#### 10.18 Summary & Takeaways.

10.18 Summary & Takeaways

#### Exceptions provide clean error modeling.

exceptions provide clean error modeling

#### Chain exceptions explicitly for clarity.

chain exceptions explicitly for clarity

#### Use custom exception hierarchies.

use custom exception hierarchies

#### Integrate with logging for observability.

integrate with logging for observability

#### Warnings for non-fatal issues.

warnings for non-fatal issues

#### Async exceptions require careful handling.

async exceptions require careful handling

#### Exception groups (3.11+) simplify parallel error aggregation.

exception groups (3.11+) simplify parallel error aggregation


---

## Chapter 11 ‚Äî ARCHITECTURE & APPLICATION DESIGN

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch11-start" --> üìò CHAPTER 11 ‚Äî ARCHITECTURE & APPLICATION DESIGN üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch11-start" --> üìò CHAPTER 11 ‚Äî ARCHITECTURE & APPLICATION DESIGN üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì10.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì10

#### Architecture is the art of determining:.

Architecture is the art of determining:

#### Module responsibilities.

module responsibilities

#### The shape of your system.

the shape of your system

#### Python‚Äôs flexibility enables multiple architectural styles:.

Python‚Äôs flexibility enables multiple architectural styles:

#### FP-inspired pipelines.

FP-inspired pipelines

#### Plugin-driven designs.

plugin-driven designs

#### This chapter focuses on modern, enterprise-grade approaches:

This chapter focuses on modern, enterprise-grade approaches:

#### Hexagonal Architecture.

Hexagonal Architecture

#### Layered Architecture.

Layered Architecture

#### Building modular Python services.

Building modular Python services

#### Dependency Injection.

Dependency Injection

#### Configuration management.

Configuration management

#### Packaging and feature boundaries.

Packaging and feature boundaries

#### 11.1 Why Architecture Matters in Python.

11.1 Why Architecture Matters in Python

#### Python‚Äôs dynamic nature creates both benefits and risks:.

Python‚Äôs dynamic nature creates both benefits and risks:

#### Runtime injection possible.

runtime injection possible

#### Decorators, descriptors, metaclasses allow flexible patterns.

decorators, descriptors, metaclasses allow flexible patterns

#### Clean dependency inversion through simple function references.

clean dependency inversion through simple function references

#### Untyped or weakly typed flows.

untyped or weakly typed flows

#### Ad-hoc folder structures.

ad-hoc folder structures

#### Unbounded complexity.

unbounded complexity

#### Architecture mitigates these risks by enforcing structure and discipline.

Architecture mitigates these risks by enforcing structure and discipline.

#### 11.2 Layered Architecture.

11.2 Layered Architecture

#### Classic 3‚Äì4 layer structure:.

Classic 3‚Äì4 layer structure:

#### Presentation layer is a thin adapter.

Presentation layer is a thin adapter

#### Example folder layout:.

Example folder layout:

#### App/ domain/ services/ adapters/ infrastructure/.

app/ domain/ services/ adapters/ infrastructure/

#### 11.3 Clean Architecture (Robert Martin).

11.3 Clean Architecture (Robert Martin)

#### Dependencies point inward.

Dependencies point inward.

#### Flowchart LR UI --> UseCases UseCases --> Entities Adapters --> UseCases Infra --> Adapters.

flowchart LR UI --> UseCases UseCases --> Entities Adapters --> UseCases Infra --> Adapters

#### Entities (pure domain objects).

Entities (pure domain objects)

#### Interface Adapters (controllers, presenters, gateways).

Interface Adapters (controllers, presenters, gateways)

#### Frameworks & Drivers (ORM, HTTP frameworks, DB, logging).

Frameworks & Drivers (ORM, HTTP frameworks, DB, logging)

#### Replaceable infrastructure.

Replaceable infrastructure

#### Long-term maintainability.

Long-term maintainability

#### 11.4 Hexagonal Architecture (Ports & Adapters).

11.4 Hexagonal Architecture (Ports & Adapters)

#### Hexagonal architecture extends Clean Architecture.

Hexagonal architecture extends Clean Architecture.

#### Ports = abstract interfaces.

Ports = abstract interfaces

#### Adapters = concrete implementations.

Adapters = concrete implementations

#### Flowchart TB subgraph Application Ports Domain end Adapters --> Ports Ports --> Adapters.

flowchart TB subgraph Application Ports Domain end Adapters --> Ports Ports --> Adapters

#### # ports class UserRepo: def get_user(self, id): raise NotImplementedError.

# ports class UserRepo: def get_user(self, id): raise NotImplementedError

#### # adapter class SqlUserRepo(UserRepo): def get_user(self, id): ...

# adapter class SqlUserRepo(UserRepo): def get_user(self, id): ...

#### 11.5 Dependency Inversion in Python.

11.5 Dependency Inversion in Python

#### Python enables DI without special frameworks.

Python enables DI without special frameworks.

#### 3 common patterns: 11.5.1 Constructor Injection class Service: def __init__(self, repo): self.repo = repo.

3 common patterns: 11.5.1 Constructor Injection class Service: def __init__(self, repo): self.repo = repo

#### 11.5.2 Function Injection def process(fetch_user): user = fetch_user().

11.5.2 Function Injection def process(fetch_user): user = fetch_user()

#### 11.5.3 Provider Pattern class Container: db = Database() users = UserRepository(db).

11.5.3 Provider Pattern class Container: db = Database() users = UserRepository(db)

#### 11.6 DI Frameworks (Optional).

11.6 DI Frameworks (Optional)

#### FastAPI‚Äôs dependency system.

FastAPI‚Äôs dependency system

#### Injector (Guice-like).

Injector (Guice-like)

#### Most Python shops use manual DI for clarity and speed.

Most Python shops use manual DI for clarity and speed.

#### 11.7 Configuration Management.

11.7 Configuration Management

#### Python has multiple patterns for config:.

Python has multiple patterns for config:

#### ‚úî Environment variables ‚úî configparser / JSON / YAML ‚úî pydantic models ‚úî dynaconf ‚úî python-decouple.

‚úî Environment variables ‚úî configparser / JSON / YAML ‚úî pydantic models ‚úî dynaconf ‚úî python-decouple

#### Example using pydantic:.

Example using pydantic:

#### From pydantic import BaseSettings.

from pydantic import BaseSettings

#### Class Settings(BaseSettings): db_url: str debug: bool = False.

class Settings(BaseSettings): db_url: str debug: bool = False

#### Settings = Settings().

settings = Settings()

#### 11.8 Monorepo vs Multirepo for Python 11.8.1 Monorepo Pros.

11.8 Monorepo vs Multirepo for Python 11.8.1 Monorepo Pros

#### Single dependency graph.

single dependency graph

#### 11.8.2 Multirepo Pros.

11.8.2 Multirepo Pros

#### Cross-repo versioning.

cross-repo versioning

#### For Python microservices ‚Üí multirepo For large libraries/frameworks ‚Üí monorepo.

For Python microservices ‚Üí multirepo For large libraries/frameworks ‚Üí monorepo

#### 11.9 Plugin Architectures.

11.9 Plugin Architectures

#### Python excels at plugin systems:.

Python excels at plugin systems:

#### Entry points (setuptools).

entry points (setuptools)

#### Dynamic module loading.

dynamic module loading

#### Def plugin(fn): PLUGINS[fn.__name__] = fn return fn.

def plugin(fn): PLUGINS[fn.__name__] = fn return fn

#### 11.10 Event-Driven Architecture in Python.

11.10 Event-Driven Architecture in Python

#### Message queues (Kafka, RabbitMQ, Redis Streams).

message queues (Kafka, RabbitMQ, Redis Streams)

#### FastAPI background tasks.

FastAPI background tasks

#### Publisher ‚Üí Broker ‚Üí Consumers.

Publisher ‚Üí Broker ‚Üí Consumers

#### Event loop + tasks integration covered in Chapter 17 (Concurrency).

Event loop + tasks integration covered in Chapter 17 (Concurrency).

#### 11.11 Clean Folder Structure for Python Apps.

11.11 Clean Folder Structure for Python Apps

#### Recommended structure:.

Recommended structure:

#### Project/ src/ project/ __init__.py domain/ services/ adapters/ infra/ api/ tests/ pyproject.toml README.md.

project/ src/ project/ __init__.py domain/ services/ adapters/ infra/ api/ tests/ pyproject.toml README.md

#### Dumping everything into root.

dumping everything into root

#### Mixing infrastructure with domain logic.

mixing infrastructure with domain logic

#### Circular imports from bad folder design.

circular imports from bad folder design

#### 11.12 Avoiding Circular Imports (Architecture-Specific).

11.12 Avoiding Circular Imports (Architecture-Specific)

#### Architectural fixes:.

Architectural fixes:

#### ‚úî Move shared interfaces to domain/ports ‚úî Move DTOs to domain layer ‚úî Use dependency inversion ‚úî Use local imports only when appropriate.

‚úî Move shared interfaces to domain/ports ‚úî Move DTOs to domain layer ‚úî Use dependency inversion ‚úî Use local imports only when appropriate

#### 11.13 Testing Architecture (Forward Reference).

11.13 Testing Architecture (Forward Reference)

#### Domain layer unit tests.

domain layer unit tests

#### Service layer integration tests.

service layer integration tests

#### Adapter tests use mocks.

adapter tests use mocks

#### End-to-end tests validate system.

end-to-end tests validate system

#### Avoid testing private helpers.

avoid testing private helpers

#### 11.14 Observability in Architecture.

11.14 Observability in Architecture

#### OpenTelemetry integration.

OpenTelemetry integration

#### Handled in more detail in Chapters 12, 13, 16.

Handled in more detail in Chapters 12, 13, 16.

#### 11.15 Mini Example ‚Äî Hexagonal Task Service class TaskRepo: def save(self, task): raise NotImplementedError.

11.15 Mini Example ‚Äî Hexagonal Task Service class TaskRepo: def save(self, task): raise NotImplementedError

#### Class MemoryTaskRepo(TaskRepo): def __init__(self): self.data = [] def save(self, task): self.data.append(task).

class MemoryTaskRepo(TaskRepo): def __init__(self): self.data = [] def save(self, task): self.data.append(task)

#### Class TaskService: def __init__(self, repo: TaskRepo): self.repo = repo def create(self, title): task = {"title": title} self.repo.save(task).

class TaskService: def __init__(self, repo: TaskRepo): self.repo = repo def create(self, title): task = {"title": title} self.repo.save(task)

#### Repo = MemoryTaskRepo() service = TaskService(repo) service.create("Ship product").

repo = MemoryTaskRepo() service = TaskService(repo) service.create("Ship product")

#### 11.16 Macro Example ‚Äî Clean Architecture Web Service.

11.16 Macro Example ‚Äî Clean Architecture Web Service

#### Todo/ domain/ task.py ports.py services/ task_service.py adapters/ repo_memory.py api/ http.py.

todo/ domain/ task.py ports.py services/ task_service.py adapters/ repo_memory.py api/ http.py

#### # domain/task.py @dataclass class Task: id: int title: str.

# domain/task.py @dataclass class Task: id: int title: str

#### # domain/ports.py class TaskRepo: def add(self, task): ..

# domain/ports.py class TaskRepo: def add(self, task): ... def list(self): ...

#### # services/task_service.py class TaskService: def __init__(self, repo: TaskRepo): self.repo = repo def create(self, title): task = Task(id=int(time...

# services/task_service.py class TaskService: def __init__(self, repo: TaskRepo): self.repo = repo def create(self, title): task = Task(id=int(time.time()), title=title) self.repo.add(task)

#### # adapters/repo_memory.py class MemoryTaskRepo(TaskRepo): def __init__(self): self.tasks = [] def add(self, task): self.tasks.append(task) def list...

# adapters/repo_memory.py class MemoryTaskRepo(TaskRepo): def __init__(self): self.tasks = [] def add(self, task): self.tasks.append(task) def list(self): return self.tasks

#### HTTP Layer (FastAPI):.

HTTP Layer (FastAPI):

#### # api/http.py from fastapi import FastAPI.

# api/http.py from fastapi import FastAPI

#### App = FastAPI() repo = MemoryTaskRepo() service = TaskService(repo).

app = FastAPI() repo = MemoryTaskRepo() service = TaskService(repo)

#### @app.post("/task") def create_task(title: str): service.create(title) return {"status": "ok"}.

@app.post("/task") def create_task(title: str): service.create(title) return {"status": "ok"}

#### 11.18 Summary & Takeaways.

11.18 Summary & Takeaways

#### Architecture exists to support change.

Architecture exists to support change

#### Clean/hexagonal architectures provide longevity.

Clean/hexagonal architectures provide longevity

#### Dependency inversion keeps domains pure.

Dependency inversion keeps domains pure

#### Python makes DI simple and explicit.

Python makes DI simple and explicit

#### Folder structure matters more than frameworks.

Folder structure matters more than frameworks

#### Event-driven design is increasingly common.

Event-driven design is increasingly common

#### Avoid circular imports through inversion & structure.

Avoid circular imports through inversion & structure

#### üëâ Chapter 12 ‚Äî Performance & Optimization.

üëâ Chapter 12 ‚Äî Performance & Optimization

#### This chapter includes:

This chapter includes:

#### Computational complexity.

computational complexity

#### Optimizing async workloads.

optimizing async workloads

#### Optimizing IO-bound workloads.

optimizing IO-bound workloads

#### <!-- SSM:PART id="part4" title="Part IV: Enterprise & Production" -->.

<!-- SSM:PART id="part4" title="Part IV: Enterprise & Production" -->

#### # Part IV: Enterprise & Production.

# Part IV: Enterprise & Production


---

## Chapter 12 ‚Äî PERFORMANCE & OPTIMIZATION

_Difficulty: Advanced_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch12-start" --> üìò CHAPTER 12 ‚Äî PERFORMANCE & OPTIMIZATION üî¥ Advanced.

<!-- SSM:CHUNK_BOUNDARY id="ch12-start" --> üìò CHAPTER 12 ‚Äî PERFORMANCE & OPTIMIZATION üî¥ Advanced

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì11.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì11

#### Estimated time: 4-6 hours When you need this: Production optimization, data processing, bottleneck analysis.

**Estimated time:** 4-6 hours **When you need this:** Production optimization, data processing, bottleneck analysis

#### Prerequisites: Understanding Python's execution model (Chapter 3) and object model (Chapter 7) is essential for effective optimization.

**Prerequisites:** Understanding Python's execution model (Chapter 3) and object model (Chapter 7) is essential for effective optimization. Review bytecode compilation (Chapter 3.5) to understand how Python executes code, and __slots__ (Chapter 7.5.3) for memory optimization.

#### Python performance involves three major bottleneck areas:.

Python performance involves three major bottleneck areas:

#### Python is not fast at raw loops.

Python is not fast at raw loops

#### GIL limits multi-threaded speed (see Chapter 17 for concurrency strategies).

GIL limits multi-threaded speed (see Chapter 17 for concurrency strategies)

#### Use vectorization / C-extension escape hatches.

Use vectorization / C-extension escape hatches

#### Understanding bytecode (Chapter 3.5) helps identify optimization opportunities.

**Understanding bytecode (Chapter 3.5) helps identify optimization opportunities.**

#### 2Ô∏è‚É£ IO-bound workloads.

2Ô∏è‚É£ IO-bound workloads

#### Python is exceptionally good here.

Python is exceptionally good here

#### Async/await, threading, multiprocessing, TaskGroups (covered in Chapter 17).

async/await, threading, multiprocessing, TaskGroups (covered in Chapter 17)

#### 3Ô∏è‚É£ Memory-bound workloads.

3Ô∏è‚É£ Memory-bound workloads

#### Garbage collection (see Chapter 27 for internals).

garbage collection (see Chapter 27 for internals)

#### Memory optimization techniques: __slots__ (Chapter 7.5.3), arrays, generators (Chapter 6.10).

**Memory optimization techniques:** __slots__ (Chapter 7.5.3), arrays, generators (Chapter 6.10)

#### Large data structures.

large data structures

#### This chapter presents a complete performance engineering toolkit.

This chapter presents a complete performance engineering toolkit.

#### 12.1 Understanding Python Performance Model.

12.1 Understanding Python Performance Model

#### Python performance is shaped by:.

Python performance is shaped by:

#### ‚úî CPython interpreter ‚úî GIL (3.12 and earlier) ‚úî Tiered LLVM JIT (3.13+) ‚úî Optional free-threading mode (3.14+) ‚úî Huge object overhead (~48‚Äì72 byte...

‚úî CPython interpreter ‚úî GIL (3.12 and earlier) ‚úî Tiered LLVM JIT (3.13+) ‚úî Optional free-threading mode (3.14+) ‚úî Huge object overhead (~48‚Äì72 bytes per Python object) ‚úî Dynamic dispatch on attribute access ‚úî Dictionaries powering everything (classes, objects, scopes)

#### How Python executes loops.

how Python executes loops

#### When to escape to C/Rust/NumPy.

when to escape to C/Rust/NumPy

#### 12.2 Big-O Complexity (Python-Specific).

12.2 Big-O Complexity (Python-Specific)

#### 12.2.1 Built-in Operations Complexity Table.

12.2.1 Built-in Operations Complexity Table

#### 12.2.2 Collection Operation Benchmarks (Python 3.12, M2 Mac).

12.2.2 Collection Operation Benchmarks (Python 3.12, M2 Mac)

#### Takeaway: Use deque for queue operations, set for membership tests.

**Takeaway:** Use `deque` for queue operations, `set` for membership tests.

#### 12.2.3 War Story: The Midnight Memory Leak.

12.2.3 War Story: The Midnight Memory Leak

#### Situation: Production service memory grew from 2GB to 16GB over 3 days.

**Situation:** Production service memory grew from 2GB to 16GB over 3 days.

#### Used tracemalloc snapshots at 1-hour intervals 2.

**Investigation:** 1. Used `tracemalloc` snapshots at 1-hour intervals 2. Discovered `@lru_cache` on method with `self` ‚Üí infinite cache growth 3. Every unique object instance created new cache entries

#### Profiling is step #1 in all optimization work.

Profiling is step #1 in all optimization work.

#### 12.3.1 CPU Profiling with cProfile import cProfile cProfile.run("main()").

12.3.1 CPU Profiling with cProfile import cProfile cProfile.run("main()")

#### Python -m cProfile -o out.prof main.py snakeviz out.prof.

python -m cProfile -o out.prof main.py snakeviz out.prof

#### 12.3.2 line_profiler (line-by-line CPU) pip install line_profiler.

12.3.2 line_profiler (line-by-line CPU) pip install line_profiler

#### @profile def foo(): ...

@profile def foo(): ...

#### Kernprof -l script.py.

kernprof -l script.py

#### 12.3.3 Memory Profiling memory_profiler pip install memory_profiler.

12.3.3 Memory Profiling memory_profiler pip install memory_profiler

#### @profile def f(): ...

@profile def f(): ...

#### Python -m memory_profiler script.py.

python -m memory_profiler script.py

#### 12.3.4 tracemalloc (stdlib).

12.3.4 tracemalloc (stdlib)

#### Tracemalloc is Python's built-in memory profiler (Python 3.4+).

`tracemalloc` is Python's built-in memory profiler (Python 3.4+). It tracks memory allocations and can identify memory leaks and hotspots.

#### Complete Example: Finding Memory Hotspots.

**Complete Example: Finding Memory Hotspots**

#### Comparing Snapshots (Memory Leak Detection):.

**Comparing Snapshots (Memory Leak Detection):**

#### Filtering by Filename:.

**Filtering by Filename:**

#### Memory Profiling Context Manager:.

**Memory Profiling Context Manager:**

#### Try This: Profile your own function:.

**Try This:** Profile your own function:

#### See also: Chapter 12.5 (Memory Optimization) for more memory techniques.

**See also:** Chapter 12.5 (Memory Optimization) for more memory techniques.

#### Comprehensions execute in C, faster than Python loops.

Comprehensions execute in C, faster than Python loops.

#### Global/name resolution is slower (LOAD_GLOBAL vs LOAD_FAST).

Global/name resolution is slower (LOAD_GLOBAL vs LOAD_FAST).

#### See Chapter 3.5 (Bytecode Compilation) for details on LOAD_FAST vs LOAD_GLOBAL opcodes.

**See Chapter 3.5 (Bytecode Compilation) for details on LOAD_FAST vs LOAD_GLOBAL opcodes.**

#### Function calls are slow vs inlined operations.

Function calls are slow vs inlined operations.

#### 12.5 Memory Optimization (Critical Section).

12.5 Memory Optimization (Critical Section)

#### Python objects are heavy.

Python objects are heavy.

#### 12.5.1 Use slots to reduce memory.

12.5.1 Use slots to reduce memory

#### See Chapter 7.5.3 for complete __slots__ coverage including memory savings examples and inheritance considerations.

**See Chapter 7.5.3 for complete __slots__ coverage including memory savings examples and inheritance considerations.**

#### 12.5.2 Use arrays for numeric data from array import array x = array("d", [1.0, 2.0, 3.0]).

12.5.2 Use arrays for numeric data from array import array x = array("d", [1.0, 2.0, 3.0])

#### Much smaller than list of floats.

Much smaller than list of floats.

#### 12.5.3 Use deque for queues.

12.5.3 Use deque for queues

#### Lower memory overhead than list shifting.

Lower memory overhead than list shifting.

#### 12.5.4 Use generators for streams.

12.5.4 Use generators for streams

#### Avoid loading full data:.

Avoid loading full data:

#### For chunk in read_chunks(path): ...

for chunk in read_chunks(path): ...

#### 12.5.5 Avoid large dicts / objects when possible.

12.5.5 Avoid large dicts / objects when possible

#### A Python dict entry costs ~72‚Äì140 bytes.

A Python dict entry costs ~72‚Äì140 bytes.

#### dataclass(slots=True)

dataclass(slots=True)

#### 12.6 Garbage Collection & Reference Counting.

12.6 Garbage Collection & Reference Counting

#### ‚úî Reference counting ‚úî Generational GC (for cycles) ‚úî Immortal objects (3.12+) ‚úî Free-threading support (3.14+).

‚úî Reference counting ‚úî Generational GC (for cycles) ‚úî Immortal objects (3.12+) ‚úî Free-threading support (3.14+)

#### Disable GC in high-performance numeric code:.

Disable GC in high-performance numeric code:

#### Import gc gc.disable().

import gc gc.disable()

#### (but understand the risks).

(but understand the risks)

#### 12.7 Caching Strategies (Critical) 12.7.1 LRU Cache from functools import lru_cache.

12.7 Caching Strategies (Critical) 12.7.1 LRU Cache from functools import lru_cache

#### @lru_cache(maxsize=128) def heavy(x): ...

@lru_cache(maxsize=128) def heavy(x): ...

#### Cache = {} def f(x): if x in cache: return cache[x] ...

cache = {} def f(x): if x in cache: return cache[x] ...

#### 12.7.3 Disk-based caching.

12.7.3 Disk-based caching

#### 12.7.4 Cache invalidation patterns.

12.7.4 Cache invalidation patterns

#### 12.8 Optimizing IO-bound Workloads.

12.8 Optimizing IO-bound Workloads

#### IO-bound optimization patterns:.

IO-bound optimization patterns:

#### ‚úî use asyncio ‚úî use buffered IO ‚úî use multiprocessing for parallel IO ‚úî use mmap for large files ‚úî use aiofiles (file IO) ‚úî use httpx/asynchttpx fo...

‚úî use asyncio ‚úî use buffered IO ‚úî use multiprocessing for parallel IO ‚úî use mmap for large files ‚úî use aiofiles (file IO) ‚úî use httpx/asynchttpx for async HTTP ‚úî batch operations

#### Async with httpx.AsyncClient() as client: r = await client.get(url).

async with httpx.AsyncClient() as client: r = await client.get(url)

#### 12.9 CPU-bound Optimization.

12.9 CPU-bound Optimization

#### CPU-bound Python = slow Python.

CPU-bound Python = slow Python. Use one of these strategies:

#### 12.9.1 NumPy Vectorization (MOST IMPORTANT) import numpy as np x = np.arange(1_000_000) y = x * 2.

12.9.1 NumPy Vectorization (MOST IMPORTANT) import numpy as np x = np.arange(1_000_000) y = x * 2

#### # Output: array([0, 2, 4, ..., 1999998]).

# Output: array([0, 2, 4, ..., 1999998])

#### # Compare with Python loop result = [i * 2 for i in range(1_000_000)].

# Compare with Python loop result = [i * 2 for i in range(1_000_000)]

#### # NumPy is much faster for large arrays.

# NumPy is much faster for large arrays

#### Performance by Array Size:.

Performance by Array Size:

#### For large, numeric workloads, vectorized NumPy operations are typically 10‚Äì100√ó faster than equivalent pure-Python loops, because the heavy lifting...

For large, numeric workloads, vectorized NumPy operations are typically 10‚Äì100√ó faster than equivalent pure-Python loops, because the heavy lifting happens in optimized C code and uses contiguous, typed memory.

#### Small N (‚â§1e3): Python list comps often comparable or faster.

small N (‚â§1e3): Python list comps often comparable or faster

#### Medium N (1e4‚Äì1e6): NumPy ~10‚Äì50√ó.

medium N (1e4‚Äì1e6): NumPy ~10‚Äì50√ó

#### Huge N (‚â•1e7): NumPy often 50‚Äì100√ó, constrained by memory bandwidth.

huge N (‚â•1e7): NumPy often 50‚Äì100√ó, constrained by memory bandwidth

#### Actual Performance Benchmarks:.

**Actual Performance Benchmarks:**

#### Key Observations:.

**Key Observations:**

#### Small arrays (‚â§1,000): Python may be faster due to NumPy overhead - Medium arrays (10,000‚Äì100,000): NumPy provides 10‚Äì100√ó speedup - Large arrays (...

- **Small arrays (‚â§1,000)**: Python may be faster due to NumPy overhead - **Medium arrays (10,000‚Äì100,000)**: NumPy provides 10‚Äì100√ó speedup - **Large arrays (‚â•1,000,000)**: NumPy provides 100‚Äì200√ó speedup - **In-place operations**: Fastest (no conversion overhead)

#### Try This: Benchmark NumPy vs Python for your array sizes:.

**Try This:** Benchmark NumPy vs Python for your array sizes:

#### Advanced Benchmarking: Matrix Operations.

**Advanced Benchmarking: Matrix Operations**

#### 12.9.2 Numba (JIT compiler).

12.9.2 Numba (JIT compiler)

#### Numba compiles Python functions to machine code using LLVM, providing near-C performance for numerical code.

Numba compiles Python functions to machine code using LLVM, providing near-C performance for numerical code.

#### Performance Benchmarks:.

**Performance Benchmarks:**

#### When to Use Numba:.

**When to Use Numba:**

#### Try This: Optimize a custom algorithm with Numba:.

**Try This:** Optimize a custom algorithm with Numba:

#### Cython compiles Python-like code to C extensions, providing C-level performance.

Cython compiles Python-like code to C extensions, providing C-level performance.

#### When to Use Cython:.

**When to Use Cython:**

#### 12.9.4 Rust Extensions (PyO3).

12.9.4 Rust Extensions (PyO3)

#### Rust extensions provide the best balance of performance, safety, and modern tooling.

Rust extensions provide the best balance of performance, safety, and modern tooling.

#### Advantages of Rust:.

**Advantages of Rust:**

#### Try This: Create a simple Rust extension:.

**Try This:** Create a simple Rust extension:

#### 12.9.5 multiprocessing: Parallel CPU Work.

12.9.5 multiprocessing: Parallel CPU Work

#### Multiprocessing bypasses the GIL by using separate processes.

Multiprocessing bypasses the GIL by using separate processes.

#### 12.10 Python 3.13: Tiered LLVM JIT.

12.10 Python 3.13: Tiered LLVM JIT

#### Python 3.13 introduces:.

Python 3.13 introduces:

#### 20‚Äì50% faster for many workloads.

20‚Äì50% faster for many workloads

#### PYTHON_JIT=1 python script.py.

PYTHON_JIT=1 python script.py

#### 12.11 Python 3.14+: Free-Threading Mode.

12.11 Python 3.14+: Free-Threading Mode

#### The GIL can be disabled via:.

The GIL can be disabled via:

#### Slower for single-thread.

slower for single-thread

#### Faster for parallel workloads.

faster for parallel workloads

#### Requires thread-safe libraries.

requires thread-safe libraries

#### 12.12 Lazy Evaluation Patterns 12.12.1 Generators values = (x*x for x in range(10_000_000)).

12.12 Lazy Evaluation Patterns 12.12.1 Generators values = (x*x for x in range(10_000_000))

#### Itertools.islice(iterable, 0, 1000).

itertools.islice(iterable, 0, 1000)

#### 12.12.3 Lazy loading objects.

12.12.3 Lazy loading objects

#### Class Lazy: @property def data(self): if not hasattr(self, "_data"): self._data = load_data() return self._data.

class Lazy: @property def data(self): if not hasattr(self, "_data"): self._data = load_data() return self._data

#### 12.13 Extreme Optimization Patterns ‚úî avoid attribute lookups in hot loops.

12.13 Extreme Optimization Patterns ‚úî avoid attribute lookups in hot loops

#### Append = list.append for x in data: append(x).

append = list.append for x in data: append(x)

#### Significant speedup.

Significant speedup.

#### ‚úî avoid try/except inside hot loops.

‚úî avoid try/except inside hot loops

#### Move exception handling outside loop.

Move exception handling outside loop.

#### Long-running computations.

long-running computations

#### 12.14 Mini Example ‚Äî Fast Numeric Pipeline import numpy as np.

12.14 Mini Example ‚Äî Fast Numeric Pipeline import numpy as np

#### Def pipeline(): x = np.random.rand(1_000_000) y = np.sin(x) z = (x + y) * 2 return z.mean().

def pipeline(): x = np.random.rand(1_000_000) y = np.sin(x) z = (x + y) * 2 return z.mean()

#### 12.15 Macro Example ‚Äî Log Analyzer (Optimized).

12.15 Macro Example ‚Äî Log Analyzer (Optimized)

#### Regex precompilation.

regex precompilation

#### Import re, mmap from pathlib import Path.

import re, mmap from pathlib import Path

#### Pattern = re.compile(rb"\[(?P<ts>.*?)\] (?P<lvl>\w+): (?P<msg>.*)").

pattern = re.compile(rb"\[(?P<ts>.*?)\] (?P<lvl>\w+): (?P<msg>.*)")

#### Def read_large(path): with open(path, "rb") as f, mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm: for m in pattern.finditer(mm): yield m.g...

def read_large(path): with open(path, "rb") as f, mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm: for m in pattern.finditer(mm): yield m.group("ts"), m.group("lvl"), m.group("msg")

#### For ts, lvl, msg in read_large("logs.bin"): ...

for ts, lvl, msg in read_large("logs.bin"): ...

#### ‚ö† Python loops are slow ‚ö† dicts are expensive memory-wise ‚ö† exception-heavy code becomes slow ‚ö† premature optimization is harmful ‚ö† pickle may degr...

‚ö† Python loops are slow ‚ö† dicts are expensive memory-wise ‚ö† exception-heavy code becomes slow ‚ö† premature optimization is harmful ‚ö† pickle may degrade performance & adds security risks ‚ö† GIL prevents parallel CPU-bound threads (‚â§3.12) ‚ö† free-threading is not a magic bullet

#### 12.17 Summary & Takeaways.

12.17 Summary & Takeaways

#### Profile before optimizing.

Profile before optimizing

#### Use NumPy / Numba / Rust for CPU-bound code.

Use NumPy / Numba / Rust for CPU-bound code

#### Use asyncio for IO-bound code.

Use asyncio for IO-bound code

#### Use mmap, buffered IO, batching for file work.

Use mmap, buffered IO, batching for file work

#### Use caching effectively.

Use caching effectively

#### Understand Python objects and memory overhead.

Understand Python objects and memory overhead

#### Use slots, dataclasses, tuples for low memory.

Use slots, dataclasses, tuples for low memory

#### Effective performance requires architecture + tooling.

Effective performance requires architecture + tooling

#### üëâ Chapter 13 ‚Äî Security Including:.

üëâ Chapter 13 ‚Äî Security Including:

#### OWASP Top 10 for Python.

OWASP Top 10 for Python

#### Secure coding patterns.

secure coding patterns

#### Secure serialization.

secure serialization

#### Common vulnerabilities.

common vulnerabilities


---

## Chapter 13 ‚Äî SECURITY üîí Critical.

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch13-start" --> üìò CHAPTER 13 ‚Äî SECURITY üîí Critical.

<!-- SSM:CHUNK_BOUNDARY id="ch13-start" --> üìò CHAPTER 13 ‚Äî SECURITY üîí Critical

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì12.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì12

#### Estimated time: 3-4 hours When you need this: Production applications, APIs, handling user data.

**Estimated time:** 3-4 hours **When you need this:** Production applications, APIs, handling user data

#### Security in Python requires understanding:.

Security in Python requires understanding:

#### Python‚Äôs dynamic nature.

Python‚Äôs dynamic nature

#### Insecure standard library APIs (pickle, eval, input).

insecure standard library APIs (pickle, eval, input)

#### Dependency vulnerabilities.

dependency vulnerabilities

#### Network attack surfaces.

network attack surfaces

#### Sandboxing limitations.

sandboxing limitations

#### Runtime code execution risks.

runtime code execution risks

#### Secure configuration patterns.

secure configuration patterns

#### OWASP Top 10 applied to Python.

OWASP Top 10 applied to Python

#### This chapter provides a practical, battle-tested guide.

This chapter provides a practical, battle-tested guide.

#### 13.1 The Python Security Model.

13.1 The Python Security Model

#### Python has no built-in sandboxing.

Python has no built-in sandboxing.

#### Python can execute arbitrary code (via eval, exec, importlib).

Python can execute arbitrary code (via eval, exec, importlib)

#### Python can load arbitrary bytecode (.pyc).

Python can load arbitrary bytecode (.pyc)

#### Python can access the entire filesystem.

Python can access the entire filesystem

#### Python can open network sockets.

Python can open network sockets

#### Python can spawn system processes.

Python can spawn system processes

#### Do NOT run untrusted Python code.

Do NOT run untrusted Python code.

#### 13.2 OWASP Top 10 Applied to Python.

13.2 OWASP Top 10 Applied to Python

#### We map each category to Python-specific risks.

We map each category to Python-specific risks.

#### 13.2.1 Injection Attacks.

13.2.1 Injection Attacks

#### Python-specific injection vectors:.

Python-specific injection vectors:

#### SQL injection (unsafe string concatenation).

SQL injection (unsafe string concatenation)

#### Command injection (os.system(), subprocess(shell=True)).

command injection (os.system(), subprocess(shell=True))

#### Template injection (Jinja2 misconfiguration).

template injection (Jinja2 misconfiguration)

#### SQL Injection Prevention:.

**SQL Injection Prevention:**

#### SQLAlchemy Safe Patterns:.

**SQLAlchemy Safe Patterns:**

#### Command Injection Prevention:.

**Command Injection Prevention:**

#### Template Injection Prevention:.

**Template Injection Prevention:**

#### YAML Injection Prevention:.

**YAML Injection Prevention:**

#### 13.2.2 Broken Authentication.

13.2.2 Broken Authentication

#### Common Python mistakes:.

Common Python mistakes:

#### Storing passwords in plain text.

storing passwords in plain text

#### Rolling your own auth.

rolling your own auth

#### Weak password hashing (MD5, SHA1).

weak password hashing (MD5, SHA1)

#### Insecure session cookies.

insecure session cookies

#### Flask secret_key committed to repo.

Flask secret_key committed to repo

#### Django/fastapi auth frameworks.

django/fastapi auth frameworks

#### 13.2.3 Sensitive Data Exposure.

13.2.3 Sensitive Data Exposure

#### Storing access tokens in config files.

storing access tokens in config files

#### 13.2.4 XML External Entity (XXE).

13.2.4 XML External Entity (XXE)

#### Instead of xml.etree.

instead of xml.etree.

#### 13.2.5 Broken Access Control.

13.2.5 Broken Access Control

#### Authorizing via client-side logic.

authorizing via client-side logic

#### Trusting user-supplied IDs.

trusting user-supplied IDs

#### Direct object reference vulnerability (IDOR).

direct object reference vulnerability (IDOR)

#### 13.2.6 Security Misconfiguration.

13.2.6 Security Misconfiguration

#### Unbounded file uploads.

unbounded file uploads

#### 13.2.7 Cross-Site Scripting (XSS).

13.2.7 Cross-Site Scripting (XSS)

#### Jinja2 autoescape off.

Jinja2 autoescape off

#### Unsafe rendering of HTML.

unsafe rendering of HTML

#### 13.2.8 Insecure Deserialization.

13.2.8 Insecure Deserialization

#### Critical Python risk:.

Critical Python risk:

#### Do NOT use pickle on untrusted data.

Do NOT use pickle on untrusted data. pickle.loads(b"...") # arbitrary code execution

#### 13.2.9 Vulnerable Dependencies.

13.2.9 Vulnerable Dependencies

#### 13.2.10 Insufficient Logging & Monitoring.

13.2.10 Insufficient Logging & Monitoring

#### 13.3 Input Validation.

13.3 Input Validation

#### Python needs explicit validation to avoid:.

Python needs explicit validation to avoid:

#### 13.3.1 Pydantic (recommended) from pydantic import BaseModel, Field.

13.3.1 Pydantic (recommended) from pydantic import BaseModel, Field

#### Class User(BaseModel): name: str = Field(min_length=1) age: int = Field(gt=0).

class User(BaseModel): name: str = Field(min_length=1) age: int = Field(gt=0)

#### 13.3.2 Marshmallow from marshmallow import Schema, fields.

13.3.2 Marshmallow from marshmallow import Schema, fields

#### 13.3.3 cerberus / voluptuous.

13.3.3 cerberus / voluptuous

#### Useful for config validation.

Useful for config validation.

#### 13.4 Secrets Management.

13.4 Secrets Management

#### Stored in environment variables in plaintext logs.

stored in environment variables in plaintext logs

#### 13.4.1 Secret Rotation Patterns.

13.4.1 Secret Rotation Patterns

#### Zero-downtime rotation.

zero-downtime rotation

#### .env files are useful but:.

.env files are useful but:

#### 13.5 Secure Serialization Avoid:.

13.5 Secure Serialization Avoid:

#### ‚úî JSON ‚úî ormsgpack ‚úî msgpack ‚úî protobuf ‚úî pydantic JSON models.

‚úî JSON ‚úî ormsgpack ‚úî msgpack ‚úî protobuf ‚úî pydantic JSON models

#### 13.6 Secure Filesystem & Path Handling 13.6.1 Use pathlib to prevent path traversal def safe_join(base: Path, user_path: str) -> Path: resolved = (...

13.6 Secure Filesystem & Path Handling 13.6.1 Use pathlib to prevent path traversal def safe_join(base: Path, user_path: str) -> Path: resolved = (base / user_path).resolve() if base not in resolved.parents: raise ValueError("Traversal attempt") return resolved

#### 13.6.2 Avoid using user input in file paths directly 13.7 Rate Limiting & Abuse Prevention.

13.6.2 Avoid using user input in file paths directly 13.7 Rate Limiting & Abuse Prevention

#### Token bucket algorithms.

token bucket algorithms

#### FastAPI dependencies.

FastAPI dependencies

#### Nginx-level rate limits.

Nginx-level rate limits

#### Example token bucket:.

Example token bucket:

#### Class TokenBucket: def __init__(self, rate, capacity): self.rate = rate self.capacity = capacity self.tokens = capacity.

class TokenBucket: def __init__(self, rate, capacity): self.rate = rate self.capacity = capacity self.tokens = capacity

#### 13.8 Dependency Scanning & Supply Chain Security.

13.8 Dependency Scanning & Supply Chain Security

#### ‚úî pip-audit ‚úî safety ‚úî npm audit for frontend ‚úî osv-scanner ‚úî pipdeptree.

‚úî pip-audit ‚úî safety ‚úî npm audit for frontend ‚úî osv-scanner ‚úî pipdeptree

#### 13.9 Cryptography Basics in Python.

13.9 Cryptography Basics in Python

#### From cryptography.fernet import Fernet.

from cryptography.fernet import Fernet

#### 13.9.1 Password Hashing.

13.9.1 Password Hashing

#### Pip install argon2-cffi.

pip install argon2-cffi

#### From argon2 import PasswordHasher ph = PasswordHasher() hash = ph.hash("password").

from argon2 import PasswordHasher ph = PasswordHasher() hash = ph.hash("password")

#### Use secure defaults:.

Use secure defaults:

#### Import ssl ctx = ssl.create_default_context().

import ssl ctx = ssl.create_default_context()

#### Python cannot be sandboxed reliably.

Python cannot be sandboxed reliably.

#### Eval() untrusted code.

eval() untrusted code

#### Exec() untrusted modules.

exec() untrusted modules

#### Unpickle unknown objects.

unpickle unknown objects

#### 13.11 Threat Modeling for Python Systems.

13.11 Threat Modeling for Python Systems

#### Identify entry points.

Identify entry points

#### Identify trust boundaries.

Identify trust boundaries

#### Consider attack vectors.

Consider attack vectors

#### Identify sensitive data.

Identify sensitive data

#### 13.14 Mini Example ‚Äî Safe Config Loader from pydantic import BaseModel, ValidationError from pathlib import Path import json.

13.14 Mini Example ‚Äî Safe Config Loader from pydantic import BaseModel, ValidationError from pathlib import Path import json

#### Class Config(BaseModel): db_url: str max_workers: int.

class Config(BaseModel): db_url: str max_workers: int

#### Def load_config(path): data = json.loads(Path(path).read_text()) try: return Config(**data) except ValidationError as e: raise RuntimeError("Invali...

def load_config(path): data = json.loads(Path(path).read_text()) try: return Config(**data) except ValidationError as e: raise RuntimeError("Invalid config") from e

#### 13.15 Macro Example ‚Äî Secure FastAPI App.

13.15 Macro Example ‚Äî Secure FastAPI App

#### From fastapi import FastAPI, Depends from fastapi.security import OAuth2PasswordBearer from pydantic import BaseModel import time.

from fastapi import FastAPI, Depends from fastapi.security import OAuth2PasswordBearer from pydantic import BaseModel import time

#### Oauth2 = OAuth2PasswordBearer(tokenUrl="token").

oauth2 = OAuth2PasswordBearer(tokenUrl="token")

#### Class Item(BaseModel): name: str quantity: int.

class Item(BaseModel): name: str quantity: int

#### RATE = {} def rate_limit(ip): now = time.time() if ip not in RATE: RATE[ip] = [] RATE[ip] = [t for t in RATE[ip] if now - t < 1] if len(RATE[ip]) >...

RATE = {} def rate_limit(ip): now = time.time() if ip not in RATE: RATE[ip] = [] RATE[ip] = [t for t in RATE[ip] if now - t < 1] if len(RATE[ip]) > 5: raise RuntimeError("rate limit exceeded") RATE[ip].append(now)

#### @app.post("/items") def create_item(item: Item, token: str = Depends(oauth2)): return {"msg": "ok", "item": item}.

@app.post("/items") def create_item(item: Item, token: str = Depends(oauth2)): return {"msg": "ok", "item": item}

#### ‚ö† pickle is unsafe ‚ö† eval/exec are unsafe ‚ö† PyYAML load() is unsafe ‚ö† secrets in logs ‚ö† debug mode enabled in production ‚ö† weak password hashing ‚ö† ...

‚ö† pickle is unsafe ‚ö† eval/exec are unsafe ‚ö† PyYAML load() is unsafe ‚ö† secrets in logs ‚ö† debug mode enabled in production ‚ö† weak password hashing ‚ö† bare exceptions hide vulnerabilities ‚ö† unsanitized user input in file paths ‚ö† insecure subprocess usage ‚ö† relying solely on client-side validation

#### 13.17 Summary & Takeaways.

13.17 Summary & Takeaways

#### Python has no built-in sandbox ‚Üí avoid untrusted code.

Python has no built-in sandbox ‚Üí avoid untrusted code

#### Use pydantic for data validation.

Use pydantic for data validation

#### Avoid pickle; prefer JSON or msgpack.

Avoid pickle; prefer JSON or msgpack

#### Use pip-audit/safety for dependency scanning.

Use pip-audit/safety for dependency scanning

#### Apply OWASP Top 10 to Python frameworks.

Apply OWASP Top 10 to Python frameworks

#### Use secure TLS defaults.

Use secure TLS defaults

#### Implement rate limiting.

Implement rate limiting

#### Secrets belong in secret managers.

Secrets belong in secret managers

#### üëâ Chapter 14 ‚Äî Testing & Quality Engineering Includes:.

üëâ Chapter 14 ‚Äî Testing & Quality Engineering Includes:

#### Mocking (unittest.mock, pytest-mock).

mocking (unittest.mock, pytest-mock)

#### Test doubles (mocks, stubs, fakes, spies).

test doubles (mocks, stubs, fakes, spies)

#### Test organization patterns.

test organization patterns


---

## Chapter 14 ‚Äî TESTING & QUALITY ENGINEERING

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch14-start" --> üìò CHAPTER 14 ‚Äî TESTING & QUALITY ENGINEERING üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch14-start" --> üìò CHAPTER 14 ‚Äî TESTING & QUALITY ENGINEERING üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì13.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì13

#### Runtime-bound behavior.

runtime-bound behavior

#### Dependency injection patterns.

dependency injection patterns

#### External systems (DB, APIs, file I/O).

external systems (DB, APIs, file I/O)

#### This chapter establishes a complete testing discipline using:

This chapter establishes a complete testing discipline using:

#### Pytest as the primary framework.

pytest as the primary framework

#### Unittest for legacy/testing deep internals.

unittest for legacy/testing deep internals

#### Fixtures for maintainable tests.

fixtures for maintainable tests

#### Property-based testing.

property-based testing

#### Integration/E2E patterns.

integration/E2E patterns

#### Architecture-aligned test layers.

architecture-aligned test layers

#### 14.1 The Python Testing Landscape 14.1.1 pytest (recommended).

14.1 The Python Testing Landscape 14.1.1 pytest (recommended)

#### Simple assert statements.

simple assert statements

#### 14.1.2 unittest (stdlib).

14.1.2 unittest (stdlib)

#### Property-based test generation.

Property-based test generation.

#### Examples embedded in docstrings.

Examples embedded in docstrings.

#### 14.2 Testing Philosophy ‚úî Write tests close to the behavior, not implementation ‚úî Test the contract, not private details ‚úî Use fixtures for shared ...

14.2 Testing Philosophy ‚úî Write tests close to the behavior, not implementation ‚úî Test the contract, not private details ‚úî Use fixtures for shared setup ‚úî Use mocks only when needed ‚úî Integration > unit tests for Python ‚úî Prioritize readability and maintainability 14.3 Test Organization & Folder Structure

#### Project/ src/ package/ ..

project/ src/ package/ ... tests/ unit/ integration/ e2e/ conftest.py

#### 14.4 Unit Testing with pytest 14.4.1 Basic Test def test_add(): assert add(1, 2) == 3.

14.4 Unit Testing with pytest 14.4.1 Basic Test def test_add(): assert add(1, 2) == 3

#### 14.4.2 Parametrized Tests @pytest.mark.parametrize("a,b,res", [ (1, 2, 3), (0, 5, 5), (-1, 1, 0) ]) def test_add(a, b, res): assert add(a, b) == res.

14.4.2 Parametrized Tests @pytest.mark.parametrize("a,b,res", [ (1, 2, 3), (0, 5, 5), (-1, 1, 0) ]) def test_add(a, b, res): assert add(a, b) == res

#### 14.4.3 Testing Exceptions def test_zero_division(): with pytest.raises(ZeroDivisionError): divide(1, 0).

14.4.3 Testing Exceptions def test_zero_division(): with pytest.raises(ZeroDivisionError): divide(1, 0)

#### 14.5 unittest for Legacy Code.

14.5 unittest for Legacy Code

#### Class TestMath(unittest.TestCase): def test_add(self): self.assertEqual(add(1,2), 3).

class TestMath(unittest.TestCase): def test_add(self): self.assertEqual(add(1,2), 3)

#### If __name__ == "__main__": unittest.main().

if __name__ == "__main__": unittest.main()

#### 14.6 Mocking & Test Doubles.

14.6 Mocking & Test Doubles

#### (The Most Critical Section).

(The Most Critical Section)

#### Python supports the following doubles:.

Python supports the following doubles:

#### ‚úî Mock ‚Äî tracks calls, faked behavior ‚úî Stub ‚Äî provides fixed behavior ‚úî Fake ‚Äî working simplified implementation ‚úî Spy ‚Äî wrapper around real logic...

‚úî Mock ‚Äî tracks calls, faked behavior ‚úî Stub ‚Äî provides fixed behavior ‚úî Fake ‚Äî working simplified implementation ‚úî Spy ‚Äî wrapper around real logic ‚úî Dummy ‚Äî unused placeholder argument 14.6.1 unittest.mock from unittest.mock import Mock

#### Repo = Mock() repo.get_user.return_value = {"id": 1}.

repo = Mock() repo.get_user.return_value = {"id": 1}

#### Assert repo.get_user(1) == {"id": 1} assert repo.get_user.called.

assert repo.get_user(1) == {"id": 1} assert repo.get_user.called

#### 14.6.2 monkeypatch (pytest) def test_api(monkeypatch): monkeypatch.setattr("module.fetch_data", lambda: 42) assert module.get_processed() == 43.

14.6.2 monkeypatch (pytest) def test_api(monkeypatch): monkeypatch.setattr("module.fetch_data", lambda: 42) assert module.get_processed() == 43

#### 14.6.3 patch decorator from unittest.mock import patch.

14.6.3 patch decorator from unittest.mock import patch

#### @patch("module.Database") def test_service(MockDB): MockDB.return_value.fetch.return_value = 10 s = Service() assert s.compute() == 20.

@patch("module.Database") def test_service(MockDB): MockDB.return_value.fetch.return_value = 10 s = Service() assert s.compute() == 20

#### 14.6.4 Async mocking from unittest.mock import AsyncMock.

14.6.4 Async mocking from unittest.mock import AsyncMock

#### Client = AsyncMock() client.fetch.return_value = {"msg": "ok"}.

client = AsyncMock() client.fetch.return_value = {"msg": "ok"}

#### 14.7 Fixtures (pytest).

14.7 Fixtures (pytest)

#### Fixtures make tests clean and reusable.

Fixtures make tests clean and reusable.

#### 14.7.1 Basic Fixture @pytest.fixture def numbers(): return [1, 2, 3].

14.7.1 Basic Fixture @pytest.fixture def numbers(): return [1, 2, 3]

#### Def test_sum(numbers): assert sum(numbers) == 6.

def test_sum(numbers): assert sum(numbers) == 6

#### 14.7.2 Fixture Scopes.

14.7.2 Fixture Scopes

#### 14.7.3 Fixture Parametrization.

14.7.3 Fixture Parametrization

#### 14.7.4 Fixture Dependencies.

14.7.4 Fixture Dependencies

#### 14.7.5 Autouse Fixtures.

14.7.5 Autouse Fixtures

#### 14.8 Advanced pytest Features.

14.8 Advanced pytest Features

#### Custom Markers (pytest.ini):.

**Custom Markers (pytest.ini):**

#### 14.8.2 Parametrization Deep-Dive.

14.8.2 Parametrization Deep-Dive

#### 14.8.3 pytest.raises for Exception Testing.

14.8.3 pytest.raises for Exception Testing

#### 14.9 Mocking Patterns Deep-Dive.

14.9 Mocking Patterns Deep-Dive

#### 14.9.1 unittest.mock.Mock.

14.9.1 unittest.mock.Mock

#### 14.9.2 unittest.mock.patch.

14.9.2 unittest.mock.patch

#### 14.9.4 Mocking Async Functions.

14.9.4 Mocking Async Functions

#### 14.10 Property-Based Testing with hypothesis.

14.10 Property-Based Testing with hypothesis

#### 14.10.1 Basic Property-Based Testing.

14.10.1 Basic Property-Based Testing

#### 14.10.2 Custom Strategies.

14.10.2 Custom Strategies

#### 14.11 Coverage Analysis.

14.11 Coverage Analysis

#### Running Coverage:.

**Running Coverage:**

#### 14.11.2 Coverage Configuration (.coveragerc).

14.11.2 Coverage Configuration (.coveragerc)

#### 14.11.3 Coverage Thresholds.

14.11.3 Coverage Thresholds

#### 14.12 Integration Testing Patterns.

14.12 Integration Testing Patterns

#### 14.12.1 Testing with Real Databases.

14.12.1 Testing with Real Databases

#### 14.12.2 Testing HTTP APIs.

14.12.2 Testing HTTP APIs

#### 14.13 Test Organization Best Practices.

14.13 Test Organization Best Practices

#### 14.13.1 Test Structure.

14.13.1 Test Structure

#### 14.13.2 conftest.py for Shared Fixtures.

14.13.2 conftest.py for Shared Fixtures

#### 14.14 Summary & Takeaways.

14.14 Summary & Takeaways

#### Pytest is the recommended testing framework - Fixtures provide clean, reusable test setup - Mocking is essential for isolating units - Property-bas...

- pytest is the recommended testing framework - Fixtures provide clean, reusable test setup - Mocking is essential for isolating units - Property-based testing finds edge cases - Coverage analysis ensures test completeness - Integration tests verify system behavior - Organize tests by type (unit/integration/e2e)

#### Proceed to: üëâ Chapter 15 (Debugging) for debugging techniques üëâ Chapter 16 (Tooling) for development workflows.

Proceed to: üëâ Chapter 15 (Debugging) for debugging techniques üëâ Chapter 16 (Tooling) for development workflows

#### 14.7.3 Autouse Fixtures @pytest.fixture(autouse=True) def env(): os.environ["MODE"] = "test".

14.7.3 Autouse Fixtures @pytest.fixture(autouse=True) def env(): os.environ["MODE"] = "test"

#### 14.7.4 Parameterized Fixtures @pytest.fixture(params=[1,2,3]) def value(request): return request.param.

14.7.4 Parameterized Fixtures @pytest.fixture(params=[1,2,3]) def value(request): return request.param

#### 14.8 Testing Async Code @pytest.mark.asyncio async def test_async(): assert await async_add(1,2) == 3.

14.8 Testing Async Code @pytest.mark.asyncio async def test_async(): assert await async_add(1,2) == 3

#### Or use pytest-asyncio auto mode.

Or use pytest-asyncio auto mode.

#### 14.9 Property-Based Testing (hypothesis) from hypothesis import given, strategies as st.

14.9 Property-Based Testing (hypothesis) from hypothesis import given, strategies as st

#### @given(st.integers(), st.integers()) def test_add(a, b): assert add(a, b) == add(b, a).

@given(st.integers(), st.integers()) def test_add(a, b): assert add(a, b) == add(b, a)

#### Hypothesis finds edge cases automatically.

Hypothesis finds edge cases automatically.

#### 14.10 Integration Testing.

14.10 Integration Testing

#### Integration tests validate:.

Integration tests validate:

#### Multiple modules working together.

multiple modules working together

#### 14.10.1 Database Integration Tests.

14.10.1 Database Integration Tests

#### Testcontainers (for real DBs).

testcontainers (for real DBs)

#### @pytest.fixture def db(tmp_path): path = tmp_path / "test.db" return connect(path).

@pytest.fixture def db(tmp_path): path = tmp_path / "test.db" return connect(path)

#### 14.10.2 FastAPI Integration Test.

14.10.2 FastAPI Integration Test

#### FastAPI built-in test client:.

FastAPI built-in test client:

#### From fastapi.testclient import TestClient.

from fastapi.testclient import TestClient

#### Client = TestClient(app).

client = TestClient(app)

#### Def test_create(): r = client.post("/items", json={"name": "x"}) assert r.status_code == 200.

def test_create(): r = client.post("/items", json={"name": "x"}) assert r.status_code == 200

#### 14.11 End-to-End (E2E) Testing.

14.11 End-to-End (E2E) Testing

#### Playwright (browser).

Playwright (browser)

#### 14.12 Coverage Analysis (coverage.py).

14.12 Coverage Analysis (coverage.py)

#### Pip install coverage.

pip install coverage

#### Coverage run -m pytest coverage html.

coverage run -m pytest coverage html

#### Target Coverage Levels Component Recommended domain layer 90%+ services 80% adapters 60% API 50‚Äì80% E2E behavior-based.

Target Coverage Levels Component Recommended domain layer 90%+ services 80% adapters 60% API 50‚Äì80% E2E behavior-based

#### 14.13 Mocking External Services.

14.13 Mocking External Services

#### HTTP import httpx import respx.

HTTP import httpx import respx

#### @respx.mock def test_http(): respx.get("https://a.com").mock(return_value=httpx.Response(200)) r = httpx.get("https://a.com") assert r.status_code ...

@respx.mock def test_http(): respx.get("https://a.com").mock(return_value=httpx.Response(200)) r = httpx.get("https://a.com") assert r.status_code == 200

#### Used to validate examples in docstrings:.

Used to validate examples in docstrings:

#### Def add(x, y): """ >>> add(1, 2) 3 """ return x + y.

def add(x, y): """ >>> add(1, 2) 3 """ return x + y

#### Python -m doctest file.py.

python -m doctest file.py

#### See also: Chapter 30 (Docstrings) for comprehensive docstring conventions and doctest integration patterns.

**See also:** Chapter 30 (Docstrings) for comprehensive docstring conventions and doctest integration patterns.

#### 14.15 Mini Example ‚Äî Testing a Service with Mocks def test_service_calls_repo(): repo = Mock() repo.save.return_value = True.

14.15 Mini Example ‚Äî Testing a Service with Mocks def test_service_calls_repo(): repo = Mock() repo.save.return_value = True

#### S = Service(repo) s.create("task").

s = Service(repo) s.create("task")

#### repo.save.assert_called_once()

repo.save.assert_called_once()

#### 14.16 Macro Example ‚Äî Full Test Suite.

14.16 Macro Example ‚Äî Full Test Suite

#### Tests/ unit/ integration/ e2e/ conftest.py.

tests/ unit/ integration/ e2e/ conftest.py

#### @pytest.fixture def memory_repo(): return MemoryRepo().

@pytest.fixture def memory_repo(): return MemoryRepo()

#### Def test_create(memory_repo): s = TaskService(memory_repo) s.create("X") assert memory_repo.list() == ["X"].

def test_create(memory_repo): s = TaskService(memory_repo) s.create("X") assert memory_repo.list() == ["X"]

#### 14.18 Summary & Takeaways.

14.18 Summary & Takeaways

#### Pytest is the best tool for modern testing.

pytest is the best tool for modern testing

#### Fixtures make tests clean and maintainable.

fixtures make tests clean and maintainable

#### Integration tests catch most real issues.

integration tests catch most real issues

#### Coverage is a measure, not a goal.

coverage is a measure, not a goal

#### Async testing is easy with pytest.

async testing is easy with pytest

#### Property-based testing uncovers edge cases automatically.

property-based testing uncovers edge cases automatically

#### üëâ Chapter 15 ‚Äî Tooling & Development Workflow including:.

üëâ Chapter 15 ‚Äî Tooling & Development Workflow including:

#### Modern build systems: hatch, pdm.

modern build systems: hatch, pdm

#### Virtual environments: pyenv, venv, poetry.

virtual environments: pyenv, venv, poetry

#### Formatting & linting.

formatting & linting

#### Code quality automation.

code quality automation

#### GitHub Actions / CI/CD patterns.

GitHub Actions / CI/CD patterns

#### Documentation generation (Sphinx, MkDocs).

documentation generation (Sphinx, MkDocs)


---

## Chapter 15 ‚Äî DEBUGGING & TROUBLESHOOTING

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch15-start" --> üìò CHAPTER 15 ‚Äî DEBUGGING & TROUBLESHOOTING üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch15-start" --> üìò CHAPTER 15 ‚Äî DEBUGGING & TROUBLESHOOTING üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì14.

Depth Level: 3 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì14

#### Debugging is the art of systematically finding and fixing bugs.

Debugging is the art of systematically finding and fixing bugs. This chapter covers:

#### Interactive debugging with pdb and ipdb - IDE debugging (VS Code, PyCharm) - Remote debugging - Structured logging for debugging - Production debug...

- Interactive debugging with `pdb` and `ipdb` - IDE debugging (VS Code, PyCharm) - Remote debugging - Structured logging for debugging - Production debugging techniques - Crash analysis and core dumps - Performance debugging - Memory debugging

#### 15.1 Interactive Debugging with pdb.

15.1 Interactive Debugging with pdb

#### Python's built-in debugger pdb is essential for debugging Python code.

Python's built-in debugger `pdb` is essential for debugging Python code.

#### 15.1.1 Basic pdb Usage.

15.1.1 Basic pdb Usage

#### Common pdb Commands:.

**Common pdb Commands:**

#### 15.1.2 breakpoint() Built-in (Python 3.7+).

15.1.2 breakpoint() Built-in (Python 3.7+)

#### Environment Variable Control:.

**Environment Variable Control:**

#### 15.2 ipdb: Enhanced Interactive Debugger.

15.2 ipdb: Enhanced Interactive Debugger

#### Ipdb provides IPython-enhanced debugging with syntax highlighting and better UX.

`ipdb` provides IPython-enhanced debugging with syntax highlighting and better UX.

#### Features: - Syntax highlighting - Tab completion - Better error messages - IPython integration.

**Features:** - Syntax highlighting - Tab completion - Better error messages - IPython integration

#### 15.3.1 VS Code Debugging.

15.3.1 VS Code Debugging

#### Launch Configuration (.vscode/launch.json):.

**Launch Configuration (`.vscode/launch.json`):**

#### Key Features: - Breakpoints (click left margin) - Variable inspection - Watch expressions - Call stack navigation - Step through code.

**Key Features:** - Breakpoints (click left margin) - Variable inspection - Watch expressions - Call stack navigation - Step through code

#### 15.3.2 PyCharm Debugging.

15.3.2 PyCharm Debugging

#### PyCharm provides advanced debugging features:.

PyCharm provides advanced debugging features:

#### Breakpoints: Click left margin or Ctrl+F8 - Conditional Breakpoints: Right-click breakpoint ‚Üí Add condition - Evaluate Expression: Alt+F8 to evalua...

- **Breakpoints:** Click left margin or `Ctrl+F8` - **Conditional Breakpoints:** Right-click breakpoint ‚Üí Add condition - **Evaluate Expression:** `Alt+F8` to evaluate expressions - **Attach to Process:** Debug ‚Üí Attach to Process

#### 15.4 Remote Debugging.

15.4 Remote Debugging

#### For debugging production or remote servers:.

For debugging production or remote servers:

#### 15.4.1 debugpy (VS Code Remote Debugging).

15.4.1 debugpy (VS Code Remote Debugging)

#### VS Code Configuration:.

**VS Code Configuration:**

#### 15.5 Structured Logging for Debugging.

15.5 Structured Logging for Debugging

#### Structured logging helps debug production issues.

Structured logging helps debug production issues.

#### 15.5.1 Basic Structured Logging.

15.5.1 Basic Structured Logging

#### 15.5.2 Using structlog.

15.5.2 Using structlog

#### 15.6 Production Debugging Techniques.

15.6 Production Debugging Techniques

#### 15.6.1 Logging Levels.

15.6.1 Logging Levels

#### 15.6.2 Correlation IDs.

15.6.2 Correlation IDs

#### 15.7 Performance Debugging.

15.7 Performance Debugging

#### 15.7.1 cProfile for Performance.

15.7.1 cProfile for Performance

#### 15.7.2 line_profiler for Line-by-Line.

15.7.2 line_profiler for Line-by-Line

#### 15.8 Memory Debugging.

15.8 Memory Debugging

#### 15.8.1 tracemalloc for Memory Leaks.

15.8.1 tracemalloc for Memory Leaks

#### 15.8.2 memory_profiler.

15.8.2 memory_profiler

#### 15.9 Common Debugging Patterns.

15.9 Common Debugging Patterns

#### 15.9.1 Print Debugging (Quick & Dirty).

15.9.1 Print Debugging (Quick & Dirty)

#### 15.9.2 Assertion-Based Debugging.

15.9.2 Assertion-Based Debugging

#### 15.10 Debugging Checklist.

15.10 Debugging Checklist

#### [ ] Reproduce the bug consistently - [ ] Add logging at key points - [ ] Use breakpoints to inspect state - [ ] Check variable types and values - [...

- [ ] Reproduce the bug consistently - [ ] Add logging at key points - [ ] Use breakpoints to inspect state - [ ] Check variable types and values - [ ] Verify assumptions with assertions - [ ] Test edge cases - [ ] Review recent changes (git blame) - [ ] Check for race conditions (if concurrent) - [ ] Verify environment (Python version, dependencies)

#### 15.11 Summary & Takeaways.

15.11 Summary & Takeaways

#### Proceed to: üëâ Chapter 16 ‚Äî Tooling & Development Workflow.

Proceed to: üëâ Chapter 16 ‚Äî Tooling & Development Workflow


---

## Chapter 16 ‚Äî TOOLING & DEVELOPMENT WORKFLOW

_Difficulty: Beginner_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch16-start" --> üìò CHAPTER 16 ‚Äî TOOLING & DEVELOPMENT WORKFLOW üü¢ Beginner.

<!-- SSM:CHUNK_BOUNDARY id="ch16-start" --> üìò CHAPTER 16 ‚Äî TOOLING & DEVELOPMENT WORKFLOW üü¢ Beginner

#### While we cover NumPy, Pandas, and Polars basics, we do not provide deep-dive workflows for:.

‚ö†Ô∏è Scope Note: This Bible focuses on backend/systems Python development. While we cover NumPy, Pandas, and Polars basics, we do not provide deep-dive workflows for:

#### Machine Learning (scikit-learn, PyTorch, TensorFlow workflows).

Machine Learning (scikit-learn, PyTorch, TensorFlow workflows)

#### Data Science (Jupyter notebooks, statistical analysis).

Data Science (Jupyter notebooks, statistical analysis)

#### Frontend development (though we cover FastAPI/Django APIs).

Frontend development (though we cover FastAPI/Django APIs)

#### For ML/DS workflows, see specialized resources.

For ML/DS workflows, see specialized resources. This Bible excels at:

#### Production backend systems.

Production backend systems

#### Concurrency and performance.

Concurrency and performance

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì14.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì14

#### Modern Python development requires:.

Modern Python development requires:

#### Proper dependency management.

proper dependency management

#### Clean virtual environment handling.

clean virtual environment handling

#### Consistent formatting and linting.

consistent formatting and linting

#### Static typing enforcement.

static typing enforcement

#### Automated testing and CI.

automated testing and CI

#### Documentation that stays up-to-date.

documentation that stays up-to-date

#### Docker for deployment.

Docker for deployment

#### Automated package publishing.

automated package publishing

#### This chapter consolidates all workflows into a unified industry-standard approach.

This chapter consolidates all workflows into a unified industry-standard approach.

#### 16.1 Python Environments & Version Management.

16.1 Python Environments & Version Management

#### Python environments ensure isolation and reproducibility.

Python environments ensure isolation and reproducibility.

#### 16.1.1 pyenv (Recommended for version control).

16.1.1 pyenv (Recommended for version control)

#### Install multiple Python versions:.

Install multiple Python versions:

#### Pyenv install 3.12.2 pyenv local 3.12.2.

pyenv install 3.12.2 pyenv local 3.12.2

#### 16.1.2 venv (Standard Library) python -m venv .venv source .venv/bin/activate.

16.1.2 venv (Standard Library) python -m venv .venv source .venv/bin/activate

#### 16.1.3 python -m venv vs virtualenv.

16.1.3 python -m venv vs virtualenv

#### Virtualenv offers faster creation & extended features.

virtualenv offers faster creation & extended features

#### 16.1.4 pip-tools for locked dependencies pip-compile pip-sync.

16.1.4 pip-tools for locked dependencies pip-compile pip-sync

#### Ensures fully reproducible builds.

Ensures fully reproducible builds.

#### 16.2 Modern Build Systems.

16.2 Modern Build Systems

#### Python‚Äôs packaging ecosystem evolved dramatically:.

Python‚Äôs packaging ecosystem evolved dramatically:

#### Setuptools (still widely used).

setuptools (still widely used)

#### 16.2.1 Hatch (Highly recommended).

16.2.1 Hatch (Highly recommended)

#### Environment management.

environment management

#### Versioning automation.

versioning automation

#### Pyproject.toml first.

pyproject.toml first

#### Hatch new myproject hatch run dev hatch build hatch publish.

hatch new myproject hatch run dev hatch build hatch publish

#### PEP 582 support (‚Äúpypackages‚Äù).

PEP 582 support (‚Äúpypackages‚Äù)

#### 16.2.3 Poetry poetry init poetry add fastapi poetry run python main.py.

16.2.3 Poetry poetry init poetry add fastapi poetry run python main.py

#### Dependency resolution.

dependency resolution

#### Virtual environment management.

virtual environment management

#### 16.3 Linting, Formatting, and Static Typing.

16.3 Linting, Formatting, and Static Typing

#### Quality tooling ensures consistency.

Quality tooling ensures consistency.

#### 16.3.1 Black (Formatter) black src/ tests/.

16.3.1 Black (Formatter) black src/ tests/

#### 88 character line length.

88 character line length

#### Deterministic formatting.

deterministic formatting

#### No config by default.

no config by default

#### 16.3.2 Ruff (Linter + formatter).

16.3.2 Ruff (Linter + formatter)

#### (Most popular in 2024‚Äì2025).

(Most popular in 2024‚Äì2025)

#### Ruff format .

ruff check . ruff format .

#### 16.3.3 isort (Import sorting) isort .

16.3.3 isort (Import sorting) isort .

#### 16.3.4 mypy (Static Typing) mypy src/.

16.3.4 mypy (Static Typing) mypy src/

#### # pyproject.toml [mypy] ignore_missing_imports = true disallow_untyped_defs = true.

# pyproject.toml [mypy] ignore_missing_imports = true disallow_untyped_defs = true

#### 16.4 Pre-Commit Hooks.

16.4 Pre-Commit Hooks

#### Automation for code quality.

Automation for code quality.

#### Pip install pre-commit pre-commit install.

pip install pre-commit pre-commit install

#### Repos: - repo: https://github.com/psf/black rev: stable hooks: - id: black.

repos: - repo: https://github.com/psf/black rev: stable hooks: - id: black

#### Repo: https://github.com/charliermarsh/ruff-pre-commit rev: v0.2.0 hooks: - id: ruff.

- repo: https://github.com/charliermarsh/ruff-pre-commit rev: v0.2.0 hooks: - id: ruff

#### Pre-commit ensures formatting is automatic.

Pre-commit ensures formatting is automatic.

#### 16.5 Documentation Tooling.

16.5 Documentation Tooling

#### Documentation in Python is first-class.

Documentation in Python is first-class.

#### See also: Chapter 30 (Docstrings) for comprehensive docstring conventions, styles (Google, NumPy, Sphinx), and enterprise governance patterns.

**See also:** Chapter 30 (Docstrings) for comprehensive docstring conventions, styles (Google, NumPy, Sphinx), and enterprise governance patterns.

#### Large-scale documentation.

large-scale documentation

#### ReadTheDocs integration.

ReadTheDocs integration

#### 16.5.2 MkDocs (Recommended for modern docs) mkdocs new project mkdocs serve.

16.5.2 MkDocs (Recommended for modern docs) mkdocs new project mkdocs serve

#### 16.5.3 pdoc (auto API docs) pdoc --html mypackage.

16.5.3 pdoc (auto API docs) pdoc --html mypackage

#### ‚úî python:3.12.3-slim ‚úî python:3.12.3-alpine (for small runtime).

‚úî python:3.12.3-slim ‚úî python:3.12.3-alpine (for small runtime)

#### 16.6.2 Multi-Stage Build Example FROM python:3.12-slim as builder WORKDIR /app COPY pyproject.toml.

16.6.2 Multi-Stage Build Example FROM python:3.12-slim as builder WORKDIR /app COPY pyproject.toml . RUN pip install --user poetry COPY . . RUN poetry build

#### FROM python:3.12-slim WORKDIR /app COPY --from=builder /root/.cache/pypoetry/ /packages RUN pip install /packages/*.whl CMD ["python", "-m", "app"].

FROM python:3.12-slim WORKDIR /app COPY --from=builder /root/.cache/pypoetry/ /packages RUN pip install /packages/*.whl CMD ["python", "-m", "app"]

#### 16.6.3 Docker Best Practices.

16.6.3 Docker Best Practices

#### Avoid installing dev dependencies.

avoid installing dev dependencies

#### Expose via gunicorn/uvicorn (not flask dev server).

expose via gunicorn/uvicorn (not flask dev server)

#### 16.7 CI/CD: GitHub Actions.

16.7 CI/CD: GitHub Actions

#### GitHub Actions is the de-facto CI/CD platform for Python.

GitHub Actions is the de-facto CI/CD platform for Python.

#### 16.7.1 Basic CI Pipeline.

16.7.1 Basic CI Pipeline

#### .github/workflows/ci.yml:

.github/workflows/ci.yml:

#### On: [push, pull_request].

on: [push, pull_request]

#### Jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - uses: actions/setup-python@v5 with: python-version: "3.12" - run: pip insta...

jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - uses: actions/setup-python@v5 with: python-version: "3.12" - run: pip install -r requirements.txt - run: pytest --maxfail=1 --disable-warnings

#### 16.7.2 Code Quality Pipeline - run: black --check.

16.7.2 Code Quality Pipeline - run: black --check . - run: ruff check . - run: mypy .

#### 16.7.3 Build & Publish - run: pip install build twine - run: python -m build - run: twine upload dist/*.

16.7.3 Build & Publish - run: pip install build twine - run: python -m build - run: twine upload dist/*

#### 16.8 Versioning & Release Automation Recommended:.

16.8 Versioning & Release Automation Recommended:

#### Automatic tag generation.

automatic tag generation

#### Changelog automation.

changelog automation

#### 16.9 Packaging: Creating Distributable Libraries.

16.9 Packaging: Creating Distributable Libraries

#### Sample pyproject.toml:.

Sample pyproject.toml:

#### [project] name = "mypackage" version = "0.1.0" dependencies = [ "requests", ].

[project] name = "mypackage" version = "0.1.0" dependencies = [ "requests", ]

#### [build-system] requires = ["hatchling"] build-backend = "hatchling.build".

[build-system] requires = ["hatchling"] build-backend = "hatchling.build"

#### 16.10 Reproducible Builds.

16.10 Reproducible Builds

#### Deterministic environments.

deterministic environments

#### Test matrix for Python versions.

test matrix for Python versions

#### 16.11 Mini Example ‚Äî Complete Tooling Setup project/ pyproject.toml .pre-commit-config.yaml Dockerfile mkdocs.yml src/ tests/.

16.11 Mini Example ‚Äî Complete Tooling Setup project/ pyproject.toml .pre-commit-config.yaml Dockerfile mkdocs.yml src/ tests/

#### Pyproject.toml includes:.

pyproject.toml includes:

#### 16.12 Macro Example ‚Äî Full CI/CD Pipeline.

16.12 Macro Example ‚Äî Full CI/CD Pipeline

#### Install dependencies.

Install dependencies

#### Deploy via CD pipeline.

Deploy via CD pipeline

#### Example (GitHub Actions):.

Example (GitHub Actions):

#### Deploy: runs-on: ubuntu-latest needs: [test, build] steps: - uses: actions/checkout@v4 - run: docker build -t myapp:${{ github.sha }}.

deploy: runs-on: ubuntu-latest needs: [test, build] steps: - uses: actions/checkout@v4 - run: docker build -t myapp:${{ github.sha }} . - run: docker push myapp:${{ github.sha }}

#### ‚ö† Using global Python installations ‚ö† Running tests against system Python ‚ö† Missing lock files ‚ö† Unpinned versions cause breakages ‚ö† Using outdated...

‚ö† Using global Python installations ‚ö† Running tests against system Python ‚ö† Missing lock files ‚ö† Unpinned versions cause breakages ‚ö† Using outdated build tools ‚ö† Relying on Makefiles alone ‚ö† Skipping CI checks ‚ö† Running Flask dev server in production

#### 16.14 Summary & Takeaways.

16.14 Summary & Takeaways

#### Prefer pyenv + hatch for the modern workflow.

Prefer pyenv + hatch for the modern workflow

#### Use ruff, black, mypy, and pre-commit hooks.

Use ruff, black, mypy, and pre-commit hooks

#### Document everything with MkDocs or Sphinx.

Document everything with MkDocs or Sphinx

#### Automate everything with GitHub Actions.

Automate everything with GitHub Actions

#### Use Docker multi-stage builds.

Use Docker multi-stage builds

#### Pin dependencies and manage reproducible environments.

Pin dependencies and manage reproducible environments

#### Keep CI/CD pipelines fast and modular.

Keep CI/CD pipelines fast and modular

#### üëâ Chapter 17 ‚Äî Concurrency & Parallelism This chapter includes:.

üëâ Chapter 17 ‚Äî Concurrency & Parallelism This chapter includes:

#### Free-threading (3.14).

free-threading (3.14)

#### Decision tree for concurrency models.

decision tree for concurrency models

#### Deadlocks, races, and thread safety.

deadlocks, races, and thread safety

#### Async iterators, async context managers.

async iterators, async context managers

#### Queues for inter-task communication.

queues for inter-task communication

#### Real benchmark examples.

real benchmark examples

#### Diagrams showing event loop and threading model.

diagrams showing event loop and threading model


---

## Chapter 17 ‚Äî CONCURRENCY & PARALLELISM

_Difficulty: Advanced_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch17-start" --> üìò CHAPTER 17 ‚Äî CONCURRENCY & PARALLELISM üî¥ Advanced.

<!-- SSM:CHUNK_BOUNDARY id="ch17-start" --> üìò CHAPTER 17 ‚Äî CONCURRENCY & PARALLELISM üî¥ Advanced

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì15.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì15

#### Estimated time: 4-6 hours When you need this: High-concurrency servers, parallel data processing, background tasks.

**Estimated time:** 4-6 hours **When you need this:** High-concurrency servers, parallel data processing, background tasks

#### Concurrency in Python involves three major execution models:.

Concurrency in Python involves three major execution models:

#### 1Ô∏è‚É£ Threading (concurrency for IO-bound tasks).

1Ô∏è‚É£ Threading (concurrency for IO-bound tasks)

#### Lightweight OS threads.

Lightweight OS threads

#### Blocked by GIL for CPU tasks.

Blocked by GIL for CPU tasks

#### Excellent for network I/O, file I/O, HTTP clients, proxies.

Excellent for network I/O, file I/O, HTTP clients, proxies

#### 2Ô∏è‚É£ Multiprocessing (parallelism for CPU-bound tasks).

2Ô∏è‚É£ Multiprocessing (parallelism for CPU-bound tasks)

#### True parallel CPU usage.

True parallel CPU usage

#### Costs: process spawn time, IPC overhead.

Costs: process spawn time, IPC overhead

#### 3Ô∏è‚É£ AsyncIO (single-threaded concurrency).

3Ô∏è‚É£ AsyncIO (single-threaded concurrency)

#### Cooperative multitasking.

Cooperative multitasking

#### Perfect for high-throughput, low-latency network applications.

Perfect for high-throughput, low-latency network applications

#### Cannot parallelize CPU work.

Cannot parallelize CPU work

#### Best for async HTTP clients/servers.

Best for async HTTP clients/servers

#### Modern Python (3.11‚Äì3.14) adds:.

Modern Python (3.11‚Äì3.14) adds:

#### TaskGroups for structured concurrency.

TaskGroups for structured concurrency

#### Improved synchronization primitives.

improved synchronization primitives

#### Free-threading mode in 3.14.

free-threading mode in 3.14

#### This chapter explains how to choose, implement, and combine these models.

This chapter explains how to choose, implement, and combine these models.

#### 17.1 Why Concurrency Is Hard in Python.

17.1 Why Concurrency Is Hard in Python

#### Python concurrency suffers from:.

Python concurrency suffers from:

#### Shared mutable state.

shared mutable state

#### Cooperative scheduling (asyncio).

cooperative scheduling (asyncio)

#### Blocking system calls.

blocking system calls

#### Library compatibility issues.

library compatibility issues

#### To use concurrency safely:.

To use concurrency safely:

#### ‚úî design for immutability ‚úî minimize shared state ‚úî use queues ‚úî isolate CPU tasks into processes ‚úî use async for high-concurrency I/O.

‚úî design for immutability ‚úî minimize shared state ‚úî use queues ‚úî isolate CPU tasks into processes ‚úî use async for high-concurrency I/O

#### 17.2 The GIL (Global Interpreter Lock).

17.2 The GIL (Global Interpreter Lock)

#### (Non-internals version‚Äîfull internals in Part V).

(Non-internals version‚Äîfull internals in Part V)

#### Ensures thread-safe memory management.

ensures thread-safe memory management

#### Protects reference count mutation.

protects reference count mutation

#### Simplifies C-extension thread safety.

simplifies C-extension thread safety

#### Simple threading safety.

simple threading safety

#### IO-bound concurrency.

IO-bound concurrency

#### CPU-bound parallelism ‚Äî only one thread runs Python bytecode at a time.

CPU-bound parallelism ‚Äî only one thread runs Python bytecode at a time

#### High-performance numerical code without C extensions.

high-performance numerical code without C extensions

#### 17.3 Free-Threading (Python 3.14+).

17.3 Free-Threading (Python 3.14+)

#### Python 3.14 introduces:.

Python 3.14 introduces:

#### Python3.14 --disable-gil.

python3.14 --disable-gil

#### Each thread runs Python code independently.

each thread runs Python code independently

#### Reference-counting replaced with atomic ops.

reference-counting replaced with atomic ops

#### CPython becomes truly parallel.

CPython becomes truly parallel

#### Performance cost for single-thread workloads (~5‚Äì15% slower).

performance cost for single-thread workloads (~5‚Äì15% slower)

#### Warning: Not all C extensions support free-threading yet.

Warning: Not all C extensions support free-threading yet.

#### (IO-bound concurrency model).

(IO-bound concurrency model)

#### 17.5.1 Basic Threads import threading.

17.5.1 Basic Threads import threading

#### Def worker(): print("Hi").

def worker(): print("Hi")

#### T = threading.Thread(target=worker) t.start() t.join().

t = threading.Thread(target=worker) t.start() t.join()

#### 17.5.2 Race Conditions.

17.5.2 Race Conditions

#### Shared mutable state causes unpredictable bugs:.

Shared mutable state causes unpredictable bugs:

#### Def inc(): global counter for _ in range(100000): counter += 1.

def inc(): global counter for _ in range(100000): counter += 1

#### Even with GIL, += is not atomic ‚Üí race condition.

Even with GIL, += is not atomic ‚Üí race condition.

#### 17.5.3 Locks lock = threading.Lock().

17.5.3 Locks lock = threading.Lock()

#### With lock: counter += 1.

with lock: counter += 1

#### 17.5.4 Queues (Thread-Safe).

17.5.4 Queues (Thread-Safe)

#### From queue import Queue q = Queue().

from queue import Queue q = Queue()

#### 17.5.5 ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor.

17.5.5 ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor

#### With ThreadPoolExecutor(max_workers=10) as ex: results = ex.map(fetch_url, urls).

with ThreadPoolExecutor(max_workers=10) as ex: results = ex.map(fetch_url, urls)

#### 17.6 MULTIPROCESSING.

17.6 MULTIPROCESSING

#### Multiprocessing provides true parallelism by running code in separate processes, bypassing the GIL entirely.

Multiprocessing provides true parallelism by running code in separate processes, bypassing the GIL entirely. Each process has its own Python interpreter and memory space.

#### 17.6.1 Basic Process: Manual Process Management.

17.6.1 Basic Process: Manual Process Management

#### Creating and Running Processes:.

**Creating and Running Processes:**

#### Process Communication:.

**Process Communication:**

#### Process Attributes:.

**Process Attributes:**

#### Try This: Parallel file processing:.

**Try This:** Parallel file processing:

#### 17.6.2 ProcessPoolExecutor: High-Level Process Management.

17.6.2 ProcessPoolExecutor: High-Level Process Management

#### ProcessPoolExecutor provides a high-level interface for process pools, similar to ThreadPoolExecutor but for CPU-bound tasks.

`ProcessPoolExecutor` provides a high-level interface for process pools, similar to `ThreadPoolExecutor` but for CPU-bound tasks.

#### Try This: Parallel image processing:.

**Try This:** Parallel image processing:

#### 17.6.3 Shared Memory: Efficient Inter-Process Communication.

17.6.3 Shared Memory: Efficient Inter-Process Communication

#### For processes that need to share data, multiprocessing provides shared memory objects that are more efficient than pickling.

For processes that need to share data, `multiprocessing` provides shared memory objects that are more efficient than pickling.

#### Value and Array (Shared Memory):.

**Value and Array (Shared Memory):**

#### Try This: Parallel matrix computation with shared memory:.

**Try This:** Parallel matrix computation with shared memory:

#### 17.6.4 Managers: High-Level Inter-Process Communication.

17.6.4 Managers: High-Level Inter-Process Communication

#### Manager provides high-level shared objects (dicts, lists, etc.) that work across processes but with more overhead than shared memory.

`Manager` provides high-level shared objects (dicts, lists, etc.) that work across processes but with more overhead than shared memory.

#### Manager Objects:.

**Manager Objects:**

#### Namespace for Structured Data:.

**Namespace for Structured Data:**

#### ‚ö†Ô∏è Performance Trade-off:.

**‚ö†Ô∏è Performance Trade-off:**

#### Managers: Easy to use, but slower (pickling overhead) - Shared Memory (Value/Array): Faster, but limited types - Queues: Good balance for producer-...

- **Managers**: Easy to use, but slower (pickling overhead) - **Shared Memory (Value/Array)**: Faster, but limited types - **Queues**: Good balance for producer-consumer patterns

#### Try This: Distributed task queue with Manager:.

**Try This:** Distributed task queue with Manager:

#### 1. Pickling Overhead:

**1. Pickling Overhead:**

#### Process Startup Cost:.

**2. Process Startup Cost:**

#### 3. Lambda Functions:

**3. Lambda Functions:**

#### Shared State Issues:.

**5. Shared State Issues:**

#### Fork vs Spawn:.

**6. Fork vs Spawn:**

#### 17.6.6 Process Communication: Advanced Patterns.

17.6.6 Process Communication: Advanced Patterns

#### Pipes (Bidirectional Communication):.

**Pipes (Bidirectional Communication):**

#### Queues (Producer-Consumer):.

**Queues (Producer-Consumer):**

#### Try This: Parallel data processing pipeline:.

**Try This:** Parallel data processing pipeline:

#### (modern Python concurrency).

(modern Python concurrency)

#### 17.7.1 Event Loop Diagram flowchart TD A[Coroutines] --> B[Event Loop] B --> C[Await I/O] C --> D[Resume Coroutine] D --> B.

17.7.1 Event Loop Diagram flowchart TD A[Coroutines] --> B[Event Loop] B --> C[Await I/O] C --> D[Resume Coroutine] D --> B

#### 17.7.2 Basic Coroutine async def greet(): return "hi".

17.7.2 Basic Coroutine async def greet(): return "hi"

#### 17.7.3 Awaiting Tasks async def main(): await greet() asyncio.run(main()).

17.7.3 Awaiting Tasks async def main(): await greet() asyncio.run(main())

#### 17.7.4 asyncio.gather results = await asyncio.gather( fetch(1), fetch(2), fetch(3) ).

17.7.4 asyncio.gather results = await asyncio.gather( fetch(1), fetch(2), fetch(3) )

#### 17.8 Structured Concurrency (Python 3.11+).

17.8 Structured Concurrency (Python 3.11+)

#### TaskGroups automatically manage:.

TaskGroups automatically manage:

#### Async with asyncio.TaskGroup() as tg: tg.create_task(fetch(1)) tg.create_task(fetch(2)).

async with asyncio.TaskGroup() as tg: tg.create_task(fetch(1)) tg.create_task(fetch(2))

#### 17.9 Async Context Managers class Resource: async def __aenter__(self): ..

17.9 Async Context Managers class Resource: async def __aenter__(self): ... async def __aexit__(self, *a): ...

#### Async with Resource(): ...

async with Resource(): ...

#### 17.10 Async Iterators async for item in stream(): ...

17.10 Async Iterators async for item in stream(): ...

#### 17.11 Queues in asyncio queue = asyncio.Queue() await queue.put(item) item = await queue.get().

17.11 Queues in asyncio queue = asyncio.Queue() await queue.put(item) item = await queue.get()

#### 17.12 Mixing AsyncIO with Threads or Processes.

17.12 Mixing AsyncIO with Threads or Processes

#### Async code handles network I/O.

Async code handles network I/O

#### CPU tasks offloaded to ProcessPool.

CPU tasks offloaded to ProcessPool

#### Blocking I/O tasks offloaded to ThreadPool.

Blocking I/O tasks offloaded to ThreadPool

#### 17.12.1 Offloading CPU Work loop = asyncio.get_event_loop() result = await loop.run_in_executor( ProcessPoolExecutor(), cpu_heavy_function, x ).

17.12.1 Offloading CPU Work loop = asyncio.get_event_loop() result = await loop.run_in_executor( ProcessPoolExecutor(), cpu_heavy_function, x )

#### 17.12.2 Offloading Blocking IO await loop.run_in_executor( None, # ThreadPool blocking_function ).

17.12.2 Offloading Blocking IO await loop.run_in_executor( None, # ThreadPool blocking_function )

#### 17.13 Practical Decision Tree.

17.13 Practical Decision Tree

#### If task is CPU-bound:.

If task is CPU-bound:

#### ‚Üí Use multiprocessing or Rust/C extensions.

‚Üí Use multiprocessing or Rust/C extensions

#### If task is IO-bound and high-throughput:.

If task is IO-bound and high-throughput:

#### If task is IO-bound and simple:.

If task is IO-bound and simple:

#### ‚Üí Use threads / ThreadPool.

‚Üí Use threads / ThreadPool

#### If you need 100k+ connections:.

If you need 100k+ connections:

#### If you need strict concurrency structure:.

If you need strict concurrency structure:

#### If using Python 3.14+ and want parallel threading:.

If using Python 3.14+ and want parallel threading:

#### ‚Üí Use free-threading mode (experimental).

‚Üí Use free-threading mode (experimental)

#### 17.14 Mini Example ‚Äî Async Web Scraper import httpx, asyncio.

17.14 Mini Example ‚Äî Async Web Scraper import httpx, asyncio

#### Async def fetch(url): async with httpx.AsyncClient() as c: r = await c.get(url) return r.text.

async def fetch(url): async with httpx.AsyncClient() as c: r = await c.get(url) return r.text

#### Async def main(): urls = [...] data = await asyncio.gather(*(fetch(u) for u in urls)) print(len(data)).

async def main(): urls = [...] data = await asyncio.gather(*(fetch(u) for u in urls)) print(len(data))

#### Handles thousands of requests easily.

Handles thousands of requests easily.

#### 17.15 Macro Example ‚Äî Concurrency Pipeline.

17.15 Macro Example ‚Äî Concurrency Pipeline

#### Real-world: ETL + CPU-bound parsing + async upload.

Real-world: ETL + CPU-bound parsing + async upload.

#### [Async Fetch] -> [CPU Parse] -> [Async Upload].

[Async Fetch] -> [CPU Parse] -> [Async Upload]

#### Asyncio for fetch and upload.

asyncio for fetch and upload

#### ProcessPool for parsing.

ProcessPool for parsing

#### Async def main(): urls = load_urls().

async def main(): urls = load_urls()

#### Async with asyncio.TaskGroup() as tg: for u in urls: tg.create_task(handle(u)).

async with asyncio.TaskGroup() as tg: for u in urls: tg.create_task(handle(u))

#### Async def handle(url): html = await async_fetch(url) parsed = await run_process(parse_html, html) await async_upload(parsed).

async def handle(url): html = await async_fetch(url) parsed = await run_process(parse_html, html) await async_upload(parsed)

#### This pattern is industry-standard.

This pattern is industry-standard.

#### ‚ö† async code mixed with blocking functions ‚ö† using requests instead of httpx in asyncio ‚ö† CPU-bound tasks inside coroutines ‚ö† deadlocks from locks ...

‚ö† async code mixed with blocking functions ‚ö† using requests instead of httpx in asyncio ‚ö† CPU-bound tasks inside coroutines ‚ö† deadlocks from locks inside threads ‚ö† race conditions from shared state ‚ö† forgetting to use await ‚ö† overusing multiprocessing ‚Üí massive overhead ‚ö† using too many threads ‚Üí context switching ‚ö† relying on free-threading with unsupported libraries ‚ö† event loop misuse

#### 17.17 Summary & Takeaways.

17.17 Summary & Takeaways

#### Use asyncio for high concurrency I/O.

Use asyncio for high concurrency I/O

#### Use multiprocessing for CPU work.

Use multiprocessing for CPU work

#### Use threads for blocking I/O.

Use threads for blocking I/O

#### Understand the GIL and free-threading.

Understand the GIL and free-threading

#### Use queues to prevent shared-state problems.

Use queues to prevent shared-state problems

#### Use TaskGroups for structured concurrency.

Use TaskGroups for structured concurrency

#### Avoid mixing sync and async without intention.

Avoid mixing sync and async without intention

#### Use ProcessPool to offload CPU-bound functions.

Use ProcessPool to offload CPU-bound functions

#### üëâ Chapter 18 ‚Äî Advanced Architecture & Patterns Includes:.

üëâ Chapter 18 ‚Äî Advanced Architecture & Patterns Includes:

#### Import hooks & meta-path finders.

import hooks & meta-path finders

#### Event-driven architectures.

event-driven architectures

#### Microservice architecture patterns.

microservice architecture patterns

#### CQRS & event sourcing.

CQRS & event sourcing


---

## Chapter 18 ‚Äî ADVANCED ARCHITECTURE & DESIGN PATTERNS

_Difficulty: Advanced_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch18-start" --> üìò CHAPTER 18 ‚Äî ADVANCED ARCHITECTURE & DESIGN PATTERNS üî¥ Advanced.

<!-- SSM:CHUNK_BOUNDARY id="ch18-start" --> üìò CHAPTER 18 ‚Äî ADVANCED ARCHITECTURE & DESIGN PATTERNS üî¥ Advanced

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì16.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì16

#### This chapter explores advanced-level Python engineering topics that span:

This chapter explores advanced-level Python engineering topics that span:

#### Advanced metaprogramming.

advanced metaprogramming

#### Software architecture at scale.

software architecture at scale

#### Descriptors & attribute management.

descriptors & attribute management

#### Plugin architectures.

plugin architectures

#### Large-scale dependency graph modeling.

large-scale dependency graph modeling

#### This chapter is practical, production-focused, and integrates core Python features into enterprise...

This chapter is practical, production-focused, and integrates core Python features into enterprise architecture.

#### 18.1 Understanding Python‚Äôs Meta-Object Protocol (MOP).

18.1 Understanding Python‚Äôs Meta-Object Protocol (MOP)

#### Python‚Äôs object system is built on a meta-object protocol, defining how objects:.

Python‚Äôs object system is built on a meta-object protocol, defining how objects:

#### Everything is an object.

everything is an object

#### Functions are objects.

functions are objects

#### Metaclasses create classes.

metaclasses create classes

#### Descriptors define attribute access.

descriptors define attribute access

#### Decorators wrap objects.

decorators wrap objects

#### Import machinery loads modules.

import machinery loads modules

#### 18.2 Metaclasses ‚Äî The Top of Python‚Äôs Type System.

18.2 Metaclasses ‚Äî The Top of Python‚Äôs Type System

#### Metaclasses define how classes are constructed.

Metaclasses define how classes are constructed.

#### 18.2.1 Basic Metaclass Example class Meta(type): def __new__(mcls, name, bases, ns): ns["created_by_meta"] = True return super().__new__(mcls, name...

18.2.1 Basic Metaclass Example class Meta(type): def __new__(mcls, name, bases, ns): ns["created_by_meta"] = True return super().__new__(mcls, name, bases, ns)

#### Class MyClass(metaclass=Meta): pass.

class MyClass(metaclass=Meta): pass

#### Assert MyClass.created_by_meta.

assert MyClass.created_by_meta

#### 18.2.2 Why Use Metaclasses?.

18.2.2 Why Use Metaclasses?

#### Automatic registration.

automatic registration

#### Enforcing interfaces.

enforcing interfaces

#### Modifying class attributes.

modifying class attributes

#### Examples in real frameworks:.

Examples in real frameworks:

#### Django ORM model classes.

Django ORM model classes

#### SQLAlchemy declarative base.

SQLAlchemy declarative base

#### ‚ö† Overengineering ‚ö† Introducing magical behavior ‚ö† Reducing code clarity.

‚ö† Overengineering ‚ö† Introducing magical behavior ‚ö† Reducing code clarity

#### 18.3 Descriptors ‚Äî The REAL Power Behind Properties.

18.3 Descriptors ‚Äî The REAL Power Behind Properties

#### Descriptors implement:.

Descriptors implement:

#### Class/static methods.

class/static methods

#### Fields in dataclasses.

fields in dataclasses

#### 18.3.1 Descriptor Protocol class Descriptor: def __get__(self, instance, owner): ..

18.3.1 Descriptor Protocol class Descriptor: def __get__(self, instance, owner): ... def __set__(self, instance, value): ... def __delete__(self, instance): ...

#### 18.3.2 Example: Validated Field class IntegerField: def __set__(self, instance, value): if not isinstance(value, int): raise TypeError("expected in...

18.3.2 Example: Validated Field class IntegerField: def __set__(self, instance, value): if not isinstance(value, int): raise TypeError("expected int") instance.__dict__["value"] = value

#### Class Model: value = IntegerField().

class Model: value = IntegerField()

#### This pattern underlies:

This pattern underlies:

#### SQLAlchemy mapped columns.

SQLAlchemy mapped columns

#### Attrs and dataclasses field transformations.

attrs and dataclasses field transformations

#### 18.4 Advanced Decorator Patterns ‚úî Function decorators ‚úî Class decorators ‚úî Decorators with parameters ‚úî Decorators returning classes ‚úî Combining d...

18.4 Advanced Decorator Patterns ‚úî Function decorators ‚úî Class decorators ‚úî Decorators with parameters ‚úî Decorators returning classes ‚úî Combining decorators and descriptors 18.4.1 Decorator with State def memoize(fn): cache = {} def wrapper(x): if x not in cache: cache[x] = fn(x) return cache[x] return wrapper

#### 18.4.2 Class Decorator def register(cls): REGISTRY[cls.__name__] = cls return cls.

18.4.2 Class Decorator def register(cls): REGISTRY[cls.__name__] = cls return cls

#### @register class Service: pass.

@register class Service: pass

#### 18.4.3 Decorators + Descriptors (Advanced).

18.4.3 Decorators + Descriptors (Advanced)

#### ORMs frequently combine both.

ORMs frequently combine both.

#### 18.5 Design Patterns in Python.

18.5 Design Patterns in Python

#### For a comprehensive catalog, see Appendix A ‚Äî Python Pattern Dictionary.

This section covers advanced design patterns and their Pythonic implementations. For a comprehensive catalog, see Appendix A ‚Äî Python Pattern Dictionary.

#### 18.5.1 Repository Pattern.

18.5.1 Repository Pattern

#### The Repository pattern abstracts data access, making code testable and database-agnostic.

The Repository pattern abstracts data access, making code testable and database-agnostic.

#### 18.5.2 Dependency Injection Pattern.

18.5.2 Dependency Injection Pattern

#### Python's dynamic nature makes dependency injection straightforward.

Python's dynamic nature makes dependency injection straightforward.

#### 18.5.3 Event-Driven Architecture.

18.5.3 Event-Driven Architecture

#### Python's first-class functions make event-driven patterns natural.

Python's first-class functions make event-driven patterns natural.

#### 18.5.4 Strategy Pattern (Pythonic).

18.5.4 Strategy Pattern (Pythonic)

#### Functions as first-class objects make Strategy pattern trivial.

Functions as first-class objects make Strategy pattern trivial.

#### 18.5.5 Factory Pattern (Pythonic).

18.5.5 Factory Pattern (Pythonic)

#### Use functions or class methods instead of complex class hierarchies.

Use functions or class methods instead of complex class hierarchies.

#### Key Takeaway: Python's dynamic nature often makes traditional design patterns simpler.

**Key Takeaway:** Python's dynamic nature often makes traditional design patterns simpler. Prefer functions, protocols, and dataclasses over complex class hierarchies.

#### 18.5 Import Hooks, Meta-Path Finders & Loaders.

18.5 Import Hooks, Meta-Path Finders & Loaders

#### Python has a pluggable import system:.

Python has a pluggable import system:

#### 18.5.1 sys.meta_path.

18.5.1 sys.meta_path

#### A list of importers:.

A list of importers:

#### For finder in sys.meta_path: print(finder).

for finder in sys.meta_path: print(finder)

#### 18.5.2 Custom Importer import sys, importlib.abc, importlib.util.

18.5.2 Custom Importer import sys, importlib.abc, importlib.util

#### Class Loader(importlib.abc.Loader): def exec_module(self, module): module.data = "hello".

class Loader(importlib.abc.Loader): def exec_module(self, module): module.data = "hello"

#### Class Finder(importlib.abc.MetaPathFinder): def find_spec(self, fullname, path, target=None): if fullname == "special": return importlib.util.spec_...

class Finder(importlib.abc.MetaPathFinder): def find_spec(self, fullname, path, target=None): if fullname == "special": return importlib.util.spec_from_loader(fullname, Loader())

#### Sys.meta_path.insert(0, Finder()).

sys.meta_path.insert(0, Finder())

#### Importing now executes your loader.

Importing now executes your loader.

#### Encrypted Python modules.

encrypted Python modules

#### Remote module loading.

remote module loading

#### Hot-reload environments.

hot-reload environments

#### API-driven code-loading (dangerous!).

API-driven code-loading (dangerous!)

#### 18.5.3 Import Hook Warnings.

18.5.3 Import Hook Warnings

#### ‚ö† Can load malicious code ‚ö† Very difficult to debug ‚ö† Bypass visibility of dependency graphs.

‚ö† Can load malicious code ‚ö† Very difficult to debug ‚ö† Bypass visibility of dependency graphs

#### 18.6 Registry Patterns.

18.6 Registry Patterns

#### Used extensively in frameworks.

Used extensively in frameworks.

#### 18.6.1 Simple Registry REGISTRY = {}.

18.6.1 Simple Registry REGISTRY = {}

#### Def register(name): def wrapper(fn): REGISTRY[name] = fn return fn return wrapper.

def register(name): def wrapper(fn): REGISTRY[name] = fn return fn return wrapper

#### 18.6.2 Class Registry class Base: registry = {}.

18.6.2 Class Registry class Base: registry = {}

#### Def __init_subclass__(cls, **kw): Base.registry[cls.__name__] = cls.

def __init_subclass__(cls, **kw): Base.registry[cls.__name__] = cls

#### 18.7 Plugin Architecture Design.

18.7 Plugin Architecture Design

#### 18.7.1 Entry Point Example (pyproject.toml) [project.entry-points.myplugins] plugin1 = "mypackage.plugin1:Plugin".

18.7.1 Entry Point Example (pyproject.toml) [project.entry-points.myplugins] plugin1 = "mypackage.plugin1:Plugin"

#### Import importlib.metadata.

import importlib.metadata

#### Eps = importlib.metadata.entry_points(group="myplugins").

eps = importlib.metadata.entry_points(group="myplugins")

#### 18.7.2 Dynamic Loader def load(name): module = importlib.import_module(name) return getattr(module, "Plugin")().

18.7.2 Dynamic Loader def load(name): module = importlib.import_module(name) return getattr(module, "Plugin")()

#### 18.8 CQRS & Event Sourcing in Python.

18.8 CQRS & Event Sourcing in Python

#### Pattern used in complex enterprise systems.

Pattern used in complex enterprise systems.

#### 18.8.1 CQRS Principle.

18.8.1 CQRS Principle

#### Commands (change state).

Commands (change state)

#### Queries (read state).

Queries (read state)

#### Scaling reads and writes differently.

scaling reads and writes differently

#### Optimizing data structures.

optimizing data structures

#### 18.8.2 Event Sourcing.

18.8.2 Event Sourcing

#### State is derived from events:.

State is derived from events:

#### Event1 ‚Üí event2 ‚Üí ..

event1 ‚Üí event2 ‚Üí ... ‚Üí current state

#### Python implementation:.

Python implementation:

#### Class EventStore: def __init__(self): self.events = [].

class EventStore: def __init__(self): self.events = []

#### Def append(self, evt): self.events.append(evt).

def append(self, evt): self.events.append(evt)

#### 18.9 State Machines 18.9.1 Minimal FSM Example class FSM: def __init__(self): self.state = "init".

18.9 State Machines 18.9.1 Minimal FSM Example class FSM: def __init__(self): self.state = "init"

#### Def event(self, name): if self.state == "init" and name == "start": self.state = "running".

def event(self, name): if self.state == "init" and name == "start": self.state = "running"

#### 18.9.2 Industrial State Machine Pattern.

18.9.2 Industrial State Machine Pattern

#### Custom FSM frameworks.

custom FSM frameworks

#### 18.10 Microservice Architecture Patterns.

18.10 Microservice Architecture Patterns

#### Python backend microservices align with:.

Python backend microservices align with:

#### Services own their own data.

services own their own data

#### Services communicate via messages or APIs.

services communicate via messages or APIs

#### No shared database schemas.

no shared database schemas

#### Ensure backward compatibility.

ensure backward compatibility

#### Isolate failure domains.

isolate failure domains

#### 18.11 Event-Driven Architecture.

18.11 Event-Driven Architecture

#### Event-based systems in Python:.

Event-based systems in Python:

#### Custom message brokers.

custom message brokers

#### 18.12 Advanced Dependency Graph Architecture 18.12.1 Dependency Graph Detection.

18.12 Advanced Dependency Graph Architecture 18.12.1 Dependency Graph Detection

#### 18.12.2 Circular Dependency Breaking.

18.12.2 Circular Dependency Breaking

#### Dependency inversion.

dependency inversion

#### 18.13 Mini Example ‚Äî FRP-Style Event Bus in Python class EventBus: def __init__(self): self.handlers = {}.

18.13 Mini Example ‚Äî FRP-Style Event Bus in Python class EventBus: def __init__(self): self.handlers = {}

#### Def subscribe(self, type, fn): self.handlers.setdefault(type, []).append(fn).

def subscribe(self, type, fn): self.handlers.setdefault(type, []).append(fn)

#### Def publish(self, event): for fn in self.handlers.get(type(event), []): fn(event).

def publish(self, event): for fn in self.handlers.get(type(event), []): fn(event)

#### 18.14 Macro Example ‚Äî Full Plugin System with Registries app/ core/ registry.py loader.py plugins/ plugin_a/ plugin_b/.

18.14 Macro Example ‚Äî Full Plugin System with Registries app/ core/ registry.py loader.py plugins/ plugin_a/ plugin_b/

#### Registry.py class Registry: def __init__(self): self.plugins = {}.

registry.py class Registry: def __init__(self): self.plugins = {}

#### Def register(self, name, cls): self.plugins[name] = cls.

def register(self, name, cls): self.plugins[name] = cls

#### Registry = Registry().

registry = Registry()

#### Loader.py import importlib from app.core.registry import registry.

loader.py import importlib from app.core.registry import registry

#### Def load_plugins(): for mod in ["plugin_a.main", "plugin_b.main"]: module = importlib.import_module(f"app.plugins.{mod}") return registry.plugins.

def load_plugins(): for mod in ["plugin_a.main", "plugin_b.main"]: module = importlib.import_module(f"app.plugins.{mod}") return registry.plugins

#### Plugin_a/main.py from app.core.registry import registry.

plugin_a/main.py from app.core.registry import registry

#### @registry.register("a") class PluginA: def run(self): print("A").

@registry.register("a") class PluginA: def run(self): print("A")

#### ‚ö† Metaclasses make debugging harder ‚ö† Import hooks can load malicious code ‚ö† Plugin systems can break dependency graphs ‚ö† State machines become spa...

‚ö† Metaclasses make debugging harder ‚ö† Import hooks can load malicious code ‚ö† Plugin systems can break dependency graphs ‚ö† State machines become spaghetti without discipline ‚ö† CQRS adds write latency & complexity ‚ö† Event sourcing requires complete replay safety ‚ö† Circular imports disaster without architecture discipline ‚ö† Dynamic module loading bypasses static analysis

#### 18.16 Summary & Takeaways.

18.16 Summary & Takeaways

#### Metaclasses define class creation.

Metaclasses define class creation

#### Descriptors power properties & ORMs.

Descriptors power properties & ORMs

#### Decorators augment functions/classes.

Decorators augment functions/classes

#### Import hooks permit custom module loading.

Import hooks permit custom module loading

#### Registries & plugins enable extensibility.

Registries & plugins enable extensibility

#### CQRS & event sourcing increase scalability.

CQRS & event sourcing increase scalability

#### Dependency graphs are critical to maintainability.

Dependency graphs are critical to maintainability

#### State machines formalize lifecycle logic.

State machines formalize lifecycle logic

#### üëâ Chapter 19 ‚Äî Database Integration & Persistence Including:.

üëâ Chapter 19 ‚Äî Database Integration & Persistence Including:

#### Async database access (SQLAlchemy 2.0 async, asyncpg, Tortoise ORM).

async database access (SQLAlchemy 2.0 async, asyncpg, Tortoise ORM)

#### Migrations (Alembic).

migrations (Alembic)

#### Realistic CRUD examples.

realistic CRUD examples

#### Connection lifecycle management.

connection lifecycle management


---

## Chapter 19 ‚Äî DATABASE INTEGRATION & PERSISTENCE

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch19-start" --> üìò CHAPTER 19 ‚Äî DATABASE INTEGRATION & PERSISTENCE üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch19-start" --> üìò CHAPTER 19 ‚Äî DATABASE INTEGRATION & PERSISTENCE üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì17.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì17

#### Database access is central to Python backends.

Database access is central to Python backends.

#### Relational databases.

relational databases

#### NoSQL (short overview).

NoSQL (short overview)

#### Repositories & unit-of-work.

repositories & unit-of-work

#### SQLAlchemy (Core + ORM + asyncio).

SQLAlchemy (Core + ORM + asyncio)

#### ACID, isolation levels, locking.

ACID, isolation levels, locking

#### Security and reliability patterns.

security and reliability patterns

#### Python‚Äôs database ecosystem is dominated by:.

Python‚Äôs database ecosystem is dominated by:

#### SQLAlchemy 2.0 (industry standard).

SQLAlchemy 2.0 (industry standard)

#### Asyncpg (fast async PostgreSQL driver).

asyncpg (fast async PostgreSQL driver)

#### Tortoise ORM (async Django-like).

Tortoise ORM (async Django-like)

#### We start with the foundation.

We start with the foundation.

#### 19.1 DB-API 2.0 ‚Äî The Foundation of Python SQL.

19.1 DB-API 2.0 ‚Äî The Foundation of Python SQL

#### The standard API for Python database drivers.

The standard API for Python database drivers.

#### Most drivers (psycopg2, sqlite3, mysqlclient) implement it.

Most drivers (psycopg2, sqlite3, mysqlclient) implement it.

#### Fetchone(), fetchall().

fetchone(), fetchall()

#### 19.1.1 Basic DB-API Example import sqlite3.

19.1.1 Basic DB-API Example import sqlite3

#### Conn = sqlite3.connect("db.sqlite") cur = conn.cursor().

conn = sqlite3.connect("db.sqlite") cur = conn.cursor()

#### Cur.execute("SELECT 1") print(cur.fetchone()).

cur.execute("SELECT 1") print(cur.fetchone())

#### Conn.commit() conn.close().

conn.commit() conn.close()

#### 19.1.2 Parameter Binding (Important for Security) cur.execute("SELECT * FROM users WHERE id=?", (user_id,)).

19.1.2 Parameter Binding (Important for Security) cur.execute("SELECT * FROM users WHERE id=?", (user_id,))

#### 19.2 SQLAlchemy 2.0 (Core API).

19.2 SQLAlchemy 2.0 (Core API)

#### (Modern recommended approach).

(Modern recommended approach)

#### SQLAlchemy 2.0 introduces:.

SQLAlchemy 2.0 introduces:

#### Pure Python query construction.

pure Python query construction

#### No implicit session magic.

no implicit session magic

#### Separate Core and ORM layers.

separate Core and ORM layers

#### 19.2.1 Engine Creation from sqlalchemy import create_engine.

19.2.1 Engine Creation from sqlalchemy import create_engine

#### Engine = create_engine("sqlite:///db.sqlite", echo=True).

engine = create_engine("sqlite:///db.sqlite", echo=True)

#### 19.2.2 Defining Tables from sqlalchemy import Table, Column, Integer, String, MetaData.

19.2.2 Defining Tables from sqlalchemy import Table, Column, Integer, String, MetaData

#### Metadata = MetaData().

metadata = MetaData()

#### Users = Table( "users", metadata, Column("id", Integer, primary_key=True), Column("name", String) ).

users = Table( "users", metadata, Column("id", Integer, primary_key=True), Column("name", String) )

#### 19.2.3 Creating Tables metadata.create_all(engine).

19.2.3 Creating Tables metadata.create_all(engine)

#### 19.2.4 Inserting with engine.connect() as conn: conn.execute(users.insert().values(name="Alice")) conn.commit().

19.2.4 Inserting with engine.connect() as conn: conn.execute(users.insert().values(name="Alice")) conn.commit()

#### 19.2.5 Selecting with engine.connect() as conn: result = conn.execute(users.select()) for row in result: print(row).

19.2.5 Selecting with engine.connect() as conn: result = conn.execute(users.select()) for row in result: print(row)

#### 19.3 SQLAlchemy ORM (2.0 Style) 19.3.1 Declarative Base from sqlalchemy.orm import DeclarativeBase.

19.3 SQLAlchemy ORM (2.0 Style) 19.3.1 Declarative Base from sqlalchemy.orm import DeclarativeBase

#### Class Base(DeclarativeBase): pass.

class Base(DeclarativeBase): pass

#### 19.3.2 ORM Model from sqlalchemy.orm import mapped_column, Mapped.

19.3.2 ORM Model from sqlalchemy.orm import mapped_column, Mapped

#### Class User(Base): __tablename__ = "users" id: Mapped[int] = mapped_column(primary_key=True) name: Mapped[str].

class User(Base): __tablename__ = "users" id: Mapped[int] = mapped_column(primary_key=True) name: Mapped[str]

#### 19.3.3 Session from sqlalchemy.orm import Session.

19.3.3 Session from sqlalchemy.orm import Session

#### With Session(engine) as session: session.add(User(name="Alice")) session.commit().

with Session(engine) as session: session.add(User(name="Alice")) session.commit()

#### 19.4 Async SQLAlchemy 2.0.

19.4 Async SQLAlchemy 2.0

#### This is the modern async DB approach.

This is the modern async DB approach.

#### 19.4.1 Creating Async Engine from sqlalchemy.ext.asyncio import create_async_engine.

19.4.1 Creating Async Engine from sqlalchemy.ext.asyncio import create_async_engine

#### Engine = create_async_engine( "postgresql+asyncpg://user:pass@localhost/db" ).

engine = create_async_engine( "postgresql+asyncpg://user:pass@localhost/db" )

#### 19.4.2 Async Session from sqlalchemy.ext.asyncio import async_sessionmaker.

19.4.2 Async Session from sqlalchemy.ext.asyncio import async_sessionmaker

#### Async_session = async_sessionmaker(engine).

async_session = async_sessionmaker(engine)

#### 19.4.3 Example Query async with async_session() as session: result = await session.execute(users.select()) rows = result.fetchall().

19.4.3 Example Query async with async_session() as session: result = await session.execute(users.select()) rows = result.fetchall()

#### 19.5 asyncpg ‚Äî Fast Native Async Driver.

19.5 asyncpg ‚Äî Fast Native Async Driver

#### Faster than SQLAlchemy‚Äôs ORM for raw queries.

Faster than SQLAlchemy‚Äôs ORM for raw queries.

#### 19.5.1 Basic asyncpg Example import asyncpg import asyncio.

19.5.1 Basic asyncpg Example import asyncpg import asyncio

#### Async def main(): conn = await asyncpg.connect("postgres://...") rows = await conn.fetch("SELECT * FROM users") await conn.close().

async def main(): conn = await asyncpg.connect("postgres://...") rows = await conn.fetch("SELECT * FROM users") await conn.close()

#### 19.6 Tortoise ORM (Async Django-like ORM) from tortoise import Tortoise, fields, models.

19.6 Tortoise ORM (Async Django-like ORM) from tortoise import Tortoise, fields, models

#### Class User(models.Model): id = fields.IntField(pk=True) name = fields.CharField(max_length=50).

class User(models.Model): id = fields.IntField(pk=True) name = fields.CharField(max_length=50)

#### 19.7 Connection Pooling.

19.7 Connection Pooling

#### Engine = create_engine( url, pool_size=10, max_overflow=20, ).

engine = create_engine( url, pool_size=10, max_overflow=20, )

#### Pool = await asyncpg.create_pool(min_size=5, max_size=20).

pool = await asyncpg.create_pool(min_size=5, max_size=20)

#### 19.8 Transactions & Unit-of-Work 19.8.1 SQLAlchemy Transaction Block with engine.begin() as conn: conn.execute(...).

19.8 Transactions & Unit-of-Work 19.8.1 SQLAlchemy Transaction Block with engine.begin() as conn: conn.execute(...)

#### 19.8.2 Async Transaction async with async_session() as session: async with session.begin(): ...

19.8.2 Async Transaction async with async_session() as session: async with session.begin(): ...

#### 19.8.3 Unit-of-Work Pattern.

19.8.3 Unit-of-Work Pattern

#### Class UnitOfWork: def __init__(self, session_factory): self.session_factory = session_factory.

class UnitOfWork: def __init__(self, session_factory): self.session_factory = session_factory

#### Async def __aenter__(self): self.session = self.session_factory() self.tx = await self.session.begin() return self.

async def __aenter__(self): self.session = self.session_factory() self.tx = await self.session.begin() return self

#### Async def __aexit__(self, *exc): if exc[0]: await self.tx.rollback() else: await self.tx.commit().

async def __aexit__(self, *exc): if exc[0]: await self.tx.rollback() else: await self.tx.commit()

#### 19.9 Repository Pattern.

19.9 Repository Pattern

#### Recommended for Clean/Hexagonal architecture.

Recommended for Clean/Hexagonal architecture.

#### 19.9.1 Interface class UserRepo: async def get(self, id: int): ..

19.9.1 Interface class UserRepo: async def get(self, id: int): ... async def add(self, user): ...

#### 19.9.2 Implementation with SQLAlchemy class SqlUserRepo(UserRepo): def __init__(self, session): self.session = session.

19.9.2 Implementation with SQLAlchemy class SqlUserRepo(UserRepo): def __init__(self, session): self.session = session

#### Async def add(self, user): self.session.add(user).

async def add(self, user): self.session.add(user)

#### Async def get(self, id): return await self.session.get(User, id).

async def get(self, id): return await self.session.get(User, id)

#### 19.10 Alembic (Migrations).

19.10 Alembic (Migrations)

#### The official migration tool for SQLAlchemy.

The official migration tool for SQLAlchemy.

#### 19.10.1 Initialize alembic init alembic.

19.10.1 Initialize alembic init alembic

#### 19.10.2 Create Revision alembic revision -m "create users".

19.10.2 Create Revision alembic revision -m "create users"

#### 19.10.3 Autogenerate (works with ORM) alembic revision --autogenerate -m "update".

19.10.3 Autogenerate (works with ORM) alembic revision --autogenerate -m "update"

#### 19.10.4 Apply Migration alembic upgrade head.

19.10.4 Apply Migration alembic upgrade head

#### 19.11 SQL Performance Tuning.

19.11 SQL Performance Tuning

#### Key Python/SQLAlchemy bottlenecks:.

Key Python/SQLAlchemy bottlenecks:

#### ‚úî N+1 queries ‚úî inefficient ORM relationship loading ‚úî unindexed columns ‚úî using ORM where raw SQL is needed ‚úî small transactions ‚úî lack of batchin...

‚úî N+1 queries ‚úî inefficient ORM relationship loading ‚úî unindexed columns ‚úî using ORM where raw SQL is needed ‚úî small transactions ‚úî lack of batching 19.11.1 Eager Loading session.query(User).options(selectinload(User.posts))

#### 19.11.2 Batch Insert.

19.11.2 Batch Insert

#### session.bulk_save_objects(users)

session.bulk_save_objects(users)

#### 19.12 Isolation Levels.

19.12 Isolation Levels

#### Create_engine(..., isolation_level="SERIALIZABLE").

create_engine(..., isolation_level="SERIALIZABLE")

#### 19.15 Macro Example ‚Äî Complete Async Repository + UoW + API.

19.15 Macro Example ‚Äî Complete Async Repository + UoW + API

#### App/ domain/ services/ adapters/ repo_sqlalchemy.py infra/ db.py api/ http.py.

app/ domain/ services/ adapters/ repo_sqlalchemy.py infra/ db.py api/ http.py

#### Infra/db.py engine = create_async_engine(DB_URL) async_session = async_sessionmaker(engine).

infra/db.py engine = create_async_engine(DB_URL) async_session = async_sessionmaker(engine)

#### Adapters/repo_sqlalchemy.py class SqlUserRepo(UserRepo): ...

adapters/repo_sqlalchemy.py class SqlUserRepo(UserRepo): ...

#### Services/user_service.py async def register_user(uow, name): async with uow as tx: return await tx.users.add(User(name=name)).

services/user_service.py async def register_user(uow, name): async with uow as tx: return await tx.users.add(User(name=name))

#### Api/http.py (FastAPI) @app.post("/users") async def register(name: str): return await user_service.register_user(uow, name).

api/http.py (FastAPI) @app.post("/users") async def register(name: str): return await user_service.register_user(uow, name)

#### ‚ö† using ORM for heavy ETL ‚ö† unnecessary joins ‚ö† unbounded sessions ‚ö† mixing sync & async DB access ‚ö† ignoring pooling ‚ö† repeating migrations manual...

‚ö† using ORM for heavy ETL ‚ö† unnecessary joins ‚ö† unbounded sessions ‚ö† mixing sync & async DB access ‚ö† ignoring pooling ‚ö† repeating migrations manually ‚ö† building SQL manually with string concatenation ‚ö† reusing connections across requests

#### 19.17 Summary & Takeaways.

19.17 Summary & Takeaways

#### DB-API is the foundation.

DB-API is the foundation

#### SQLAlchemy 2.0 is the best ORM.

SQLAlchemy 2.0 is the best ORM

#### Asyncpg is the fastest async driver.

asyncpg is the fastest async driver

#### Use repositories for architecture cleanliness.

use repositories for architecture cleanliness

#### Use unit-of-work for transaction management.

use unit-of-work for transaction management

#### Avoid SQL injection via parameterized queries.

avoid SQL injection via parameterized queries

#### Connection pooling is essential for scalability.

connection pooling is essential for scalability

#### Async DB access enables high-throughput services.

async DB access enables high-throughput services

#### üëâ Chapter 20 ‚Äî Async Web Development & APIs Including:.

üëâ Chapter 20 ‚Äî Async Web Development & APIs Including:

#### Dependency injection systems.

dependency injection systems

#### High scalability patterns.

high scalability patterns


---

## Chapter 20 ‚Äî ASYNC WEB DEVELOPMENT & APIs

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch20-start" --> üìò CHAPTER 20 ‚Äî ASYNC WEB DEVELOPMENT & APIs üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch20-start" --> üìò CHAPTER 20 ‚Äî ASYNC WEB DEVELOPMENT & APIs üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì18.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì18

#### Modern Python web development has shifted from:.

Modern Python web development has shifted from:

#### WSGI (sync era) ‚Üí ASGI (async era).

WSGI (sync era) ‚Üí ASGI (async era)

#### Frameworks built on ASGI enable:.

Frameworks built on ASGI enable:

#### Ultra-high concurrency.

ultra-high concurrency

#### Cloud-native patterns.

cloud-native patterns

#### This chapter provides a full roadmap for developing enterprise-level async APIs with Python.

This chapter provides a full roadmap for developing enterprise-level async APIs with Python.

#### 20.1 WSGI vs ASGI 20.1.1 WSGI (Web Server Gateway Interface).

20.1 WSGI vs ASGI 20.1.1 WSGI (Web Server Gateway Interface)

#### Legacy, synchronous model.

Legacy, synchronous model.

#### Thread-per-request patterns.

thread-per-request patterns

#### 20.1.2 ASGI (Asynchronous Server Gateway Interface).

20.1.2 ASGI (Asynchronous Server Gateway Interface)

#### Modern, event-driven.

Modern, event-driven.

#### Django 3.2+ async views.

Django 3.2+ async views

#### ‚úî async/await ‚úî WebSockets ‚úî background tasks ‚úî connection pooling ‚úî long-lived connections ‚úî high concurrency (10k+ clients) ‚úî HTTP/2 friendly ‚úî c...

‚úî async/await ‚úî WebSockets ‚úî background tasks ‚úî connection pooling ‚úî long-lived connections ‚úî high concurrency (10k+ clients) ‚úî HTTP/2 friendly ‚úî cloud-native scalability

#### 20.2 ASGI Architecture Diagram flowchart LR Client -->|HTTP/WebSocket| ASGI-Server[ASGI Server (uvicorn/hypercorn)] ASGI-Server --> Router[ASGI Fra...

20.2 ASGI Architecture Diagram flowchart LR Client -->|HTTP/WebSocket| ASGI-Server[ASGI Server (uvicorn/hypercorn)] ASGI-Server --> Router[ASGI Framework Router] Router --> Endpoint[Endpoint Function] Endpoint -->|await| DB[Async DB] Endpoint -->|await| HTTPClient[Async HTTP Client] Endpoint --> Response

#### 20.3 FastAPI ‚Äî The Modern Standard.

20.3 FastAPI ‚Äî The Modern Standard

#### FastAPI is built on:.

FastAPI is built on:

#### Starlette (routing, WebSockets, background tasks).

Starlette (routing, WebSockets, background tasks)

#### Pydantic (validation & serialization).

Pydantic (validation & serialization)

#### Uvicorn (ASGI server).

uvicorn (ASGI server)

#### 20.3.1 Basic FastAPI App from fastapi import FastAPI.

20.3.1 Basic FastAPI App from fastapi import FastAPI

#### @app.get("/hello") async def hello(): return {"msg": "Hello"}.

@app.get("/hello") async def hello(): return {"msg": "Hello"}

#### Uvicorn app:app --reload.

uvicorn app:app --reload

#### 20.3.2 Request Validation with Pydantic from pydantic import BaseModel.

20.3.2 Request Validation with Pydantic from pydantic import BaseModel

#### Class Item(BaseModel): name: str count: int.

class Item(BaseModel): name: str count: int

#### @app.post("/items") async def create_item(item: Item): return item.

@app.post("/items") async def create_item(item: Item): return item

#### 20.3.3 Dependency Injection System.

20.3.3 Dependency Injection System

#### FastAPI includes a built-in DI system:.

FastAPI includes a built-in DI system:

#### From fastapi import Depends.

from fastapi import Depends

#### Async def get_db(): async with async_session() as session: yield session.

async def get_db(): async with async_session() as session: yield session

#### @app.get("/users") async def list_users(db = Depends(get_db)): return await db.execute(...).

@app.get("/users") async def list_users(db = Depends(get_db)): return await db.execute(...)

#### 20.3.4 Background Tasks from fastapi import BackgroundTasks.

20.3.4 Background Tasks from fastapi import BackgroundTasks

#### Async def send_email(to): print(f"Sent email to {to}").

async def send_email(to): print(f"Sent email to {to}")

#### @app.post("/email") async def send(to: str, bg: BackgroundTasks): bg.add_task(send_email, to) return {"queued": True}.

@app.post("/email") async def send(to: str, bg: BackgroundTasks): bg.add_task(send_email, to) return {"queued": True}

#### 20.3.5 Streaming Responses from fastapi.responses import StreamingResponse.

20.3.5 Streaming Responses from fastapi.responses import StreamingResponse

#### Async def stream(): for i in range(10): yield f"{i}\n".

async def stream(): for i in range(10): yield f"{i}\n"

#### @app.get("/stream") async def get_stream(): return StreamingResponse(stream()).

@app.get("/stream") async def get_stream(): return StreamingResponse(stream())

#### 20.4 Starlette (FastAPI‚Äôs Core).

20.4 Starlette (FastAPI‚Äôs Core)

#### Large file responses.

large file responses

#### 20.4.1 Starlette Example from starlette.applications import Starlette from starlette.responses import JSONResponse from starlette.routing import Ro...

20.4.1 Starlette Example from starlette.applications import Starlette from starlette.responses import JSONResponse from starlette.routing import Route

#### Async def homepage(request): return JSONResponse({"hello": "world"}).

async def homepage(request): return JSONResponse({"hello": "world"})

#### App = Starlette(routes=[Route("/", homepage)]).

app = Starlette(routes=[Route("/", homepage)])

#### 20.5 Async ORMs for Web Apps 20.5.1 SQLAlchemy 2.0 Async async with async_session() as session: result = await session.execute(User.select()).

20.5 Async ORMs for Web Apps 20.5.1 SQLAlchemy 2.0 Async async with async_session() as session: result = await session.execute(User.select())

#### 20.5.2 Tortoise ORM await User.create(name="Alice") users = await User.all().

20.5.2 Tortoise ORM await User.create(name="Alice") users = await User.all()

#### Fast, async, migration-friendly.

Fast, async, migration-friendly.

#### ASGI WebSockets allow interactive real-time communication.

ASGI WebSockets allow interactive real-time communication.

#### 20.6.1 FastAPI WebSocket Example from fastapi import WebSocket.

20.6.1 FastAPI WebSocket Example from fastapi import WebSocket

#### @app.websocket("/ws") async def ws(websocket: WebSocket): await websocket.accept() while True: msg = await websocket.receive_text() await websocket...

@app.websocket("/ws") async def ws(websocket: WebSocket): await websocket.accept() while True: msg = await websocket.receive_text() await websocket.send_text(f"Echo: {msg}")

#### 20.6.2 Broadcast System (Redis Pub/Sub).

20.6.2 Broadcast System (Redis Pub/Sub)

#### 20.7 Middleware & Interceptors.

20.7 Middleware & Interceptors

#### @app.middleware("http") async def log(request, call_next): response = await call_next(request) return response.

@app.middleware("http") async def log(request, call_next): response = await call_next(request) return response

#### 20.8 Authentication & Authorization.

20.8 Authentication & Authorization

#### JWT (simple, stateless).

JWT (simple, stateless)

#### OAuth2 (scopes, tokens).

OAuth2 (scopes, tokens)

#### 20.8.1 JWT Auth Example from fastapi.security import OAuth2PasswordBearer.

20.8.1 JWT Auth Example from fastapi.security import OAuth2PasswordBearer

#### @app.get("/profile") async def profile(token: str = Depends(oauth2)): ...

@app.get("/profile") async def profile(token: str = Depends(oauth2)): ...

#### Redis-based counters.

Redis-based counters

#### Async def rate_limit(ip): ...

async def rate_limit(ip): ...

#### 20.10 CORS, Security, and HTTPS.

20.10 CORS, Security, and HTTPS

#### Use FastAPI‚Äôs built-in CORS middleware.

Use FastAPI‚Äôs built-in CORS middleware.

#### From fastapi.middleware.cors import CORSMiddleware.

from fastapi.middleware.cors import CORSMiddleware

#### Security Best Practices:.

Security Best Practices:

#### Strip debug info from errors.

strip debug info from errors

#### 20.11 Scaling Async Web Apps.

20.11 Scaling Async Web Apps

#### Gunicorn (ASGI worker class).

Gunicorn (ASGI worker class)

#### Kubernetes Horizontal Pod Autoscaling.

Kubernetes Horizontal Pod Autoscaling

#### Redis / RabbitMQ for background tasks.

Redis / RabbitMQ for background tasks

#### Reverse proxies (Nginx, Envoy, Traefik).

Reverse proxies (Nginx, Envoy, Traefik)

#### 20.12 Observability & Distributed Tracing.

20.12 Observability & Distributed Tracing

#### ASGI middleware can inject:.

ASGI middleware can inject:

#### 20.13 Enterprise Design Patterns for Async Web Apps 20.13.1 Pattern: API Layer ‚Üí Service Layer ‚Üí Repo Layer [API] ‚Üí [Service] ‚Üí [Repository] ‚Üí [DB].

20.13 Enterprise Design Patterns for Async Web Apps 20.13.1 Pattern: API Layer ‚Üí Service Layer ‚Üí Repo Layer [API] ‚Üí [Service] ‚Üí [Repository] ‚Üí [DB]

#### 20.13.2 Pattern: Request-Scoped DB Sessions.

20.13.2 Pattern: Request-Scoped DB Sessions

#### 20.13.3 Pattern: Message-Driven Integrations.

20.13.3 Pattern: Message-Driven Integrations

#### Event-driven workflows.

event-driven workflows

#### Async background processing.

async background processing

#### 20.14 Mini Example ‚Äî FastAPI + SQLAlchemy Async @app.post("/users") async def create_user(user: UserIn, session=Depends(get_session)): u = User(nam...

20.14 Mini Example ‚Äî FastAPI + SQLAlchemy Async @app.post("/users") async def create_user(user: UserIn, session=Depends(get_session)): u = User(name=user.name) session.add(u) await session.commit() return u

#### 20.15 Macro Example ‚Äî Complete Async Web Service.

20.15 Macro Example ‚Äî Complete Async Web Service

#### 20.15.0 Code Evolution: Simple ‚Üí Production-Ready.

20.15.0 Code Evolution: Simple ‚Üí Production-Ready

#### Stage 1: Simple FastAPI endpoint (beginner).

Stage 1: Simple FastAPI endpoint (beginner)

#### Stage 2: Add Pydantic models (intermediate).

Stage 2: Add Pydantic models (intermediate)

#### Stage 3: Add database layer (advanced).

Stage 3: Add database layer (advanced)

#### Stage 4: Production-ready with Repository + Service layers (expert).

Stage 4: Production-ready with Repository + Service layers (expert)

#### See full example below with proper separation of concerns.

See full example below with proper separation of concerns.

#### App/ api/ routes.py domain/ models.py services/ user_service.py infrastructure/ db.py repo.py.

app/ api/ routes.py domain/ models.py services/ user_service.py infrastructure/ db.py repo.py

#### Try This: Start with Stage 1, then progressively add features from Stages 2-4.

Try This: Start with Stage 1, then progressively add features from Stages 2-4. This teaches you why each layer exists.

#### ‚ö† mixing async and sync DB calls ‚ö† blocking code inside async handlers ‚ö† using requests inside async code (use httpx) ‚ö† creating sessions per query...

‚ö† mixing async and sync DB calls ‚ö† blocking code inside async handlers ‚ö† using requests inside async code (use httpx) ‚ö† creating sessions per query instead of per request ‚ö† global sessions ‚ö† forgetting to close WebSocket connections ‚ö† synchronous file operations inside async apps ‚ö† unbounded concurrency (thundering herd)

#### 20.17 Summary & Takeaways.

20.17 Summary & Takeaways

#### ASGI replaces WSGI for modern web development.

ASGI replaces WSGI for modern web development

#### FastAPI is the top choice for async APIs.

FastAPI is the top choice for async APIs

#### Async ORMs enable full-stack async.

async ORMs enable full-stack async

#### WebSockets support real-time features.

WebSockets support real-time features

#### DI, background tasks, middleware = essential features.

DI, background tasks, middleware = essential features

#### Scaling requires uvicorn/gunicorn + clustering.

scaling requires uvicorn/gunicorn + clustering

#### Enterprise systems require good architecture boundaries.

enterprise systems require good architecture boundaries

#### üëâ Chapter 21 ‚Äî Data Engineering with Python Topics include:.

üëâ Chapter 21 ‚Äî Data Engineering with Python Topics include:

#### Schema validation (Great Expectations, pandera).

schema validation (Great Expectations, pandera)

#### Multiprocessing for data.

multiprocessing for data

#### Apache Spark (PySpark).

Apache Spark (PySpark)


---

## Chapter 21 ‚Äî DATA ENGINEERING WITH PYTHON

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch21-start" --> üìò CHAPTER 21 ‚Äî DATA ENGINEERING WITH PYTHON üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch21-start" --> üìò CHAPTER 21 ‚Äî DATA ENGINEERING WITH PYTHON üü° Intermediate

#### Depth Level: 2.5‚Äì3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì19.

Depth Level: 2.5‚Äì3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì19

#### Python is one of the most widely used languages for:.

Python is one of the most widely used languages for:

#### Machine learning input pipelines.

Machine learning input pipelines

#### Big-data processing (Spark, Dask, Ray).

Big-data processing (Spark, Dask, Ray)

#### Interoperability (Arrow ecosystem).

Interoperability (Arrow ecosystem)

#### The core data libraries (NumPy, Pandas, Polars).

The core data libraries (NumPy, Pandas, Polars)

#### The Arrow ecosystem (Parquet, Feather, ORC).

The Arrow ecosystem (Parquet, Feather, ORC)

#### Multiprocessing & vectorization.

Multiprocessing & vectorization

#### Data validation frameworks.

Data validation frameworks

#### ETL architecture patterns.

ETL architecture patterns

#### Streaming & message systems.

Streaming & message systems

#### Integration with Spark (PySpark).

Integration with Spark (PySpark)

#### Performance strategies.

Performance strategies

#### Real-world data pipeline examples.

Real-world data pipeline examples

#### 21.1 The Core Tools of Python Data Engineering.

21.1 The Core Tools of Python Data Engineering

#### Python‚Äôs data stack includes:.

Python‚Äôs data stack includes:

#### Python built-ins (list, dict, generator pipelines).

Python built-ins (list, dict, generator pipelines)

#### Parquet, ORC, Arrow IPC files.

Parquet, ORC, Arrow IPC files

#### Big Data / Distributed.

Big Data / Distributed

#### Kafka (via confluent-kafka).

Kafka (via confluent-kafka)

#### Asyncio + asyncpg pipelines.

asyncio + asyncpg pipelines

#### 21.2 NumPy ‚Äî Foundation of Numerical Data.

21.2 NumPy ‚Äî Foundation of Numerical Data

#### Vectorized operations.

vectorized operations

#### Fast numerical computation.

fast numerical computation

#### Array-based transformations.

array-based transformations

#### Backends for Pandas, Polars, SciPy, PyTorch.

Backends for Pandas, Polars, SciPy, PyTorch

#### 21.2.1 Creating Arrays import numpy as np.

21.2.1 Creating Arrays import numpy as np

#### X = np.array([1, 2, 3], dtype=np.float64).

x = np.array([1, 2, 3], dtype=np.float64)

#### 21.2.2 Vectorization.

21.2.2 Vectorization

#### Key performance concept:.

Key performance concept:

#### X = np.arange(1_000_000) y = np.sin(x) # 1000x faster than Python loops.

x = np.arange(1_000_000) y = np.sin(x) # 1000x faster than Python loops

#### Vectorization eliminates the Python loop overhead.

Vectorization eliminates the Python loop overhead.

#### 21.2.3 Broadcasting x = np.array([1,2,3]) x + 10.

21.2.3 Broadcasting x = np.array([1,2,3]) x + 10

#### 21.3 Pandas ‚Äî Python‚Äôs Most Used Data Engineering Tool.

21.3 Pandas ‚Äî Python‚Äôs Most Used Data Engineering Tool

#### Pandas is not the fastest tool, but it is:.

Pandas is not the fastest tool, but it is:

#### 21.3.1 Creating a DataFrame import pandas as pd.

21.3.1 Creating a DataFrame import pandas as pd

#### Df = pd.DataFrame({ "name": ["Alice", "Bob"], "age": [30, 25] }).

df = pd.DataFrame({ "name": ["Alice", "Bob"], "age": [30, 25] })

#### 21.3.2 Reading/Writing Files df = pd.read_csv("data.csv") df.to_parquet("data.parquet").

21.3.2 Reading/Writing Files df = pd.read_csv("data.csv") df.to_parquet("data.parquet")

#### 21.3.3 Filtering df[df["age"] > 20].

21.3.3 Filtering df[df["age"] > 20]

#### 21.3.4 GroupBy df.groupby("city")["price"].mean().

21.3.4 GroupBy df.groupby("city")["price"].mean()

#### ‚ö† Pandas copies data often ‚ö† df.apply() is slow ‚ö† loops inside DataFrame operations kill performance ‚ö† 32-bit integers silently convert to float ‚ö† ...

‚ö† Pandas copies data often ‚ö† df.apply() is slow ‚ö† loops inside DataFrame operations kill performance ‚ö† 32-bit integers silently convert to float ‚ö† memory usage can explode on large tables

#### 21.4 Polars ‚Äî The Modern Pandas Replacement (Rust Backend).

21.4 Polars ‚Äî The Modern Pandas Replacement (Rust Backend)

#### 21.4.1 Lazy Query Example import polars as pl.

21.4.1 Lazy Query Example import polars as pl

#### Df = ( pl.scan_csv("big.csv") .filter(pl.col("amount") > 0) .groupby("user_id") .agg(pl.col("amount").sum()) .collect() ).

df = ( pl.scan_csv("big.csv") .filter(pl.col("amount") > 0) .groupby("user_id") .agg(pl.col("amount").sum()) .collect() )

#### Lazy execution = optimized pipelines.

Lazy execution = optimized pipelines.

#### 21.5 Apache Arrow Ecosystem.

21.5 Apache Arrow Ecosystem

#### Arrow is the modern columnar data foundation for Python.

Arrow is the modern columnar data foundation for Python.

#### Zero-copy transfer between Pandas/Polars/Spark.

zero-copy transfer between Pandas/Polars/Spark

#### Cloud-native processing.

cloud-native processing

#### 21.5.1 Reading Parquet with PyArrow import pyarrow.parquet as pq table = pq.read_table("data.parquet").

21.5.1 Reading Parquet with PyArrow import pyarrow.parquet as pq table = pq.read_table("data.parquet")

#### 21.5.2 Converting to Pandas or Polars df = table.to_pandas() pl_df = pl.from_arrow(table).

21.5.2 Converting to Pandas or Polars df = table.to_pandas() pl_df = pl.from_arrow(table)

#### 21.6 The ETL (Extract ‚Üí Transform ‚Üí Load) Lifecycle.

21.6 The ETL (Extract ‚Üí Transform ‚Üí Load) Lifecycle

#### ETL is the heart of data engineering.

ETL is the heart of data engineering.

#### Flowchart LR A[Extract] --> B[Transform] B --> C[Load].

flowchart LR A[Extract] --> B[Transform] B --> C[Load]

#### APIs (async fetching).

APIs (async fetching)

#### Object storage (S3/GCS/Azure Blob).

Object storage (S3/GCS/Azure Blob)

#### 21.7 Data Validation (Critical) Validators:.

21.7 Data Validation (Critical) Validators:

#### Pydantic (row-level validation).

Pydantic (row-level validation)

#### Pandera (DataFrame-level validation).

Pandera (DataFrame-level validation)

#### Great Expectations (pipeline-level validation).

Great Expectations (pipeline-level validation)

#### 21.7.1 Pandera Example import pandera as pa from pandera import Column, DataFrameSchema.

21.7.1 Pandera Example import pandera as pa from pandera import Column, DataFrameSchema

#### Schema = DataFrameSchema({ "age": Column(int, pa.Check.ge(0)), }).

schema = DataFrameSchema({ "age": Column(int, pa.Check.ge(0)), })

#### 21.7.2 Great Expectations Example.

21.7.2 Great Expectations Example

#### Used for enterprise pipelines.

Used for enterprise pipelines.

#### 21.8 Multiprocessing for Data Pipelines.

21.8 Multiprocessing for Data Pipelines

#### Python‚Äôs GIL limits heavy CPU work; use multiprocessing.

Python‚Äôs GIL limits heavy CPU work; use multiprocessing.

#### 21.8.1 Chunk Processing Example from multiprocessing import Pool.

21.8.1 Chunk Processing Example from multiprocessing import Pool

#### Def process_chunk(chunk): return chunk.assign(total=chunk["a"] + chunk["b"]).

def process_chunk(chunk): return chunk.assign(total=chunk["a"] + chunk["b"])

#### With Pool() as p: results = p.map(process_chunk, chunks).

with Pool() as p: results = p.map(process_chunk, chunks)

#### 21.9 Async Pipelines.

21.9 Async Pipelines

#### Async is excellent for:.

Async is excellent for:

#### 21.9.1 Async ETL Pattern async def extract(url): async with httpx.AsyncClient() as client: return await client.get(url).

21.9.1 Async ETL Pattern async def extract(url): async with httpx.AsyncClient() as client: return await client.get(url)

#### Async def transform(data): ...

async def transform(data): ...

#### Async def load(data): ...

async def load(data): ...

#### 21.10 Streaming Data with Kafka.

21.10 Streaming Data with Kafka

#### From confluent_kafka import Consumer.

from confluent_kafka import Consumer

#### 21.11 PySpark (Distributed Processing).

21.11 PySpark (Distributed Processing)

#### PySpark integrates Python with the Spark engine.

PySpark integrates Python with the Spark engine.

#### 21.11.1 Creating Spark Session from pyspark.sql import SparkSession.

21.11.1 Creating Spark Session from pyspark.sql import SparkSession

#### Spark = SparkSession.builder.appName("pipeline").getOrCreate().

spark = SparkSession.builder.appName("pipeline").getOrCreate()

#### 21.11.2 DataFrame Example df = spark.read.parquet("s3://bucket/data/") df.groupBy("user_id").sum("amount").show().

21.11.2 DataFrame Example df = spark.read.parquet("s3://bucket/data/") df.groupBy("user_id").sum("amount").show()

#### 21.12 DuckDB ‚Äî In-Process OLAP Engine.

21.12 DuckDB ‚Äî In-Process OLAP Engine

#### Use SQL directly on Parquet/Arrow files:.

Use SQL directly on Parquet/Arrow files:

#### Import duckdb df = duckdb.query("SELECT * FROM 'data.parquet' WHERE amount > 0").to_df().

import duckdb df = duckdb.query("SELECT * FROM 'data.parquet' WHERE amount > 0").to_df()

#### 21.13 Columnar Formats: Parquet, Feather, ORC Parquet ‚Äî best for analytics Feather ‚Äî super fast for Python I/O ORC ‚Äî similar to Parquet (Hadoop wor...

21.13 Columnar Formats: Parquet, Feather, ORC Parquet ‚Äî best for analytics Feather ‚Äî super fast for Python I/O ORC ‚Äî similar to Parquet (Hadoop world) df.to_parquet("data.parquet")

#### 21.14 Performance Optimization 21.14.1 Avoid df.apply.

21.14 Performance Optimization 21.14.1 Avoid df.apply

#### Use vectorization or Polars instead.

Use vectorization or Polars instead.

#### 21.14.2 Use Chunking for chunk in pd.read_csv("big.csv", chunksize=100_000): ...

21.14.2 Use Chunking for chunk in pd.read_csv("big.csv", chunksize=100_000): ...

#### 21.14.3 Prefer Arrow-backed formats.

21.14.3 Prefer Arrow-backed formats

#### 21.14.4 Use multiprocessing for heavy transforms 21.14.5 Avoid Python loops in transformations 21.14.6 Push filtering close to source (SQL / DuckDB...

21.14.4 Use multiprocessing for heavy transforms 21.14.5 Avoid Python loops in transformations 21.14.6 Push filtering close to source (SQL / DuckDB) 21.15 End-to-End ETL Pipeline (Macro Example)

#### Full pipeline using:.

Full pipeline using:

#### Polars transformation.

Polars transformation

#### Multiprocessing for CPU-bound transforms.

multiprocessing for CPU-bound transforms

#### Pipeline.py import polars as pl import asyncio, httpx import pandera as pa from pandera import Column, DataFrameSchema from multiprocessing import ...

pipeline.py import polars as pl import asyncio, httpx import pandera as pa from pandera import Column, DataFrameSchema from multiprocessing import Pool

#### Schema = DataFrameSchema({ "id": Column(int), "amount": Column(float), }).

schema = DataFrameSchema({ "id": Column(int), "amount": Column(float), })

#### Async def fetch(url): async with httpx.AsyncClient() as c: r = await c.get(url) return r.json().

async def fetch(url): async with httpx.AsyncClient() as c: r = await c.get(url) return r.json()

#### Def transform(batch): return ( pl.DataFrame(batch) .with_columns(pl.col("amount").cast(pl.Float64)) ).

def transform(batch): return ( pl.DataFrame(batch) .with_columns(pl.col("amount").cast(pl.Float64)) )

#### Async def extract_all(): return await asyncio.gather(*(fetch(u) for u in URLS)).

async def extract_all(): return await asyncio.gather(*(fetch(u) for u in URLS))

#### Async def main(): raw_batches = await extract_all().

async def main(): raw_batches = await extract_all()

#### With Pool() as p: frames = p.map(transform, raw_batches).

with Pool() as p: frames = p.map(transform, raw_batches)

#### Df = pl.concat(frames) schema.validate(df.to_pandas()).

df = pl.concat(frames) schema.validate(df.to_pandas())

#### df.write_parquet("output.parquet")

df.write_parquet("output.parquet")

#### This is a real-world ETL structure.

This is a real-world ETL structure.

#### ‚ö† using Pandas for >10M rows (switch to Polars/DuckDB) ‚ö† using CSV for data lakes ‚ö† using df.apply() everywhere ‚ö† forgetting schema validation ‚ö† mi...

‚ö† using Pandas for >10M rows (switch to Polars/DuckDB) ‚ö† using CSV for data lakes ‚ö† using df.apply() everywhere ‚ö† forgetting schema validation ‚ö† mixing async and sync DB access ‚ö† loading huge datasets into memory at once ‚ö† relying on Python loops for heavy transforms ‚ö† missing data lineage documentation ‚ö† storing sensitive data in raw logs

#### 21.17 Summary & Takeaways.

21.17 Summary & Takeaways

#### NumPy provides fast vectorized operations.

NumPy provides fast vectorized operations

#### Pandas is universal, but Polars is faster and more scalable.

Pandas is universal, but Polars is faster and more scalable

#### Arrow is the backbone of high-performance analytics.

Arrow is the backbone of high-performance analytics

#### Parquet is the preferred data lake format.

Parquet is the preferred data lake format

#### Multiprocessing accelerates CPU-heavy transforms.

Multiprocessing accelerates CPU-heavy transforms

#### AsyncIO is ideal for extraction & streaming.

AsyncIO is ideal for extraction & streaming

#### DuckDB enables SQL-on-files with amazing speed.

DuckDB enables SQL-on-files with amazing speed

#### PySpark scales to clusters.

PySpark scales to clusters

#### A real ETL pipeline integrates: extract ‚Üí transform ‚Üí validate ‚Üí store.

A real ETL pipeline integrates: extract ‚Üí transform ‚Üí validate ‚Üí store

#### üëâ Chapter 22 ‚Äî Packaging, Distribution & Deployment This chapter covers:.

üëâ Chapter 22 ‚Äî Packaging, Distribution & Deployment This chapter covers:

#### Python packaging formats (wheel, sdist).

Python packaging formats (wheel, sdist)

#### Python‚Äôs packaging ecosystem.

Python‚Äôs packaging ecosystem

#### Application deployment patterns.

application deployment patterns

#### Container-based distribution.

container-based distribution

#### Architecture for multi-service deployments.

architecture for multi-service deployments


---

## Chapter 22 ‚Äî PACKAGING, DISTRIBUTION & DEPLOYMENT

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch22-start" --> üìò CHAPTER 22 ‚Äî PACKAGING, DISTRIBUTION & DEPLOYMENT üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch22-start" --> üìò CHAPTER 22 ‚Äî PACKAGING, DISTRIBUTION & DEPLOYMENT üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì20.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì20

#### Packaging and deployment are essential for:.

Packaging and deployment are essential for:

#### Serverless functions.

serverless functions

#### Distribution to PyPI.

distribution to PyPI

#### Production environments.

production environments

#### Python‚Äôs packaging ecosystem has evolved significantly:.

Python‚Äôs packaging ecosystem has evolved significantly:

#### Old world (2010‚Äì2020).

Old world (2010‚Äì2020)

#### Modern world (2020‚Äì2025).

Modern world (2020‚Äì2025)

#### Hatch / PDM / Poetry.

Hatch / PDM / Poetry

#### Docker-based deployments.

Docker-based deployments

#### Supply chain security.

supply chain security

#### This chapter gives the complete practical guide to packaging modern Python software.

This chapter gives the complete practical guide to packaging modern Python software.

#### 22.1 Python Packaging Fundamentals 22.1.1 Wheels vs Source Distributions Wheel (.whl).

22.1 Python Packaging Fundamentals 22.1.1 Wheels vs Source Distributions Wheel (.whl)

#### Compiled or pure Python.

compiled or pure Python

#### Standard for distribution.

standard for distribution

#### Source Distribution (sdist).

Source Distribution (sdist)

#### Built on installation.

built on installation

#### Slower, less reproducible.

slower, less reproducible

#### 22.1.2 pyproject.toml (Modern Standard).

22.1.2 pyproject.toml (Modern Standard)

#### [project] name = "awesome-lib" version = "1.0.0" description = "A great library" authors = [{ name="Chris" }] dependencies = ["requests", "pydantic...

[project] name = "awesome-lib" version = "1.0.0" description = "A great library" authors = [{ name="Chris" }] dependencies = ["requests", "pydantic>=2.0"]

#### 22.2 Build Backends (2025 Edition) 22.2.1 Hatch / Hatchling (Recommended).

22.2 Build Backends (2025 Edition) 22.2.1 Hatch / Hatchling (Recommended)

#### Perfect for reproducible builds.

perfect for reproducible builds

#### 22.2.2 PDM (PEP 582 local packages, project-level venvs).

22.2.2 PDM (PEP 582 local packages, project-level venvs)

#### Modern and great for monorepos.

Modern and great for monorepos.

#### Popular but slower.

Popular but slower. Great for:

#### Legacy but still important.

Legacy but still important.

#### Build a wheel python -m build.

Build a wheel python -m build

#### [build-system] requires = ["build"].

[build-system] requires = ["build"]

#### 22.3 Dependency Management 22.3.1 requirements.txt (legacy).

22.3 Dependency Management 22.3.1 requirements.txt (legacy)

#### Still used for production pinning:.

Still used for production pinning:

#### Pip install -r requirements.txt.

pip install -r requirements.txt

#### Lockfiles enforce deterministic builds.

Lockfiles enforce deterministic builds.

#### Pip-tools: requirements.lock.

pip-tools: requirements.lock

#### 22.3.3 Best Practices for Dependencies.

22.3.3 Best Practices for Dependencies

#### ‚úî Pin production versions ‚úî Use semantic versioning constraints ‚úî Use extras for optional features ‚úî Keep test dependencies separate ‚úî Use virtual ...

‚úî Pin production versions ‚úî Use semantic versioning constraints ‚úî Use extras for optional features ‚úî Keep test dependencies separate ‚úî Use virtual environments

#### ‚ö† Do NOT use wildcard versions ("*") ‚ö† Avoid mixing pip and conda in same environment.

‚ö† Do NOT use wildcard versions ("*") ‚ö† Avoid mixing pip and conda in same environment

#### 22.4 Virtual Environments & Runtimes 22.4.1 venv (built-in) python -m venv .venv source .venv/bin/activate.

22.4 Virtual Environments & Runtimes 22.4.1 venv (built-in) python -m venv .venv source .venv/bin/activate

#### Manages Python versions system-wide.

Manages Python versions system-wide.

#### 22.4.3 virtualenvwrapper.

22.4.3 virtualenvwrapper

#### Adds workflow commands like:.

Adds workflow commands like:

#### Mkvirtualenv project workon project.

mkvirtualenv project workon project

#### 22.4.4 uv (2025 recommendation).

22.4.4 uv (2025 recommendation)

#### Fastest Python package + environment manager.

Fastest Python package + environment manager.

#### Uv venv uv pip install requests.

uv venv uv pip install requests

#### 22.5 Entry Points & CLI Applications 22.5.1 Declaring CLI Scripts [project.scripts] mytool = "mypkg.cli:main".

22.5 Entry Points & CLI Applications 22.5.1 Declaring CLI Scripts [project.scripts] mytool = "mypkg.cli:main"

#### Def main(): print("Hello world").

def main(): print("Hello world")

#### Pip install.

pip install . mytool

#### 22.5.2 click Example import click.

22.5.2 click Example import click

#### @click.command() @click.option("--name") def cli(name): click.echo(f"Hello, {name}!").

@click.command() @click.option("--name") def cli(name): click.echo(f"Hello, {name}!")

#### 22.6 Publishing to PyPI 22.6.1 Build Package python -m build.

22.6 Publishing to PyPI 22.6.1 Build Package python -m build

#### 22.6.2 Upload with Twine twine upload dist/*.

22.6.2 Upload with Twine twine upload dist/*

#### 22.6.3 TestPyPI twine upload --repository testpypi dist/*.

22.6.3 TestPyPI twine upload --repository testpypi dist/*

#### 22.7 Containerizing Python Applications (Docker) 22.7.1 Minimal Dockerfile FROM python:3.12-slim.

22.7 Containerizing Python Applications (Docker) 22.7.1 Minimal Dockerfile FROM python:3.12-slim

#### WORKDIR /app COPY requirements.txt.

WORKDIR /app COPY requirements.txt . RUN pip install -r requirements.txt COPY . . CMD ["python", "main.py"]

#### 22.7.2 Best Practices.

22.7.2 Best Practices

#### ‚úî use python:slim ‚úî avoid copying dev files ‚úî lock dependencies ‚úî use multi-stage builds ‚úî use non-root user ‚úî prefer gunicorn/uvicorn for servers.

‚úî use python:slim ‚úî avoid copying dev files ‚úî lock dependencies ‚úî use multi-stage builds ‚úî use non-root user ‚úî prefer gunicorn/uvicorn for servers

#### 22.7.3 Uvicorn/Gunicorn Combo (ASGI) CMD ["uvicorn", "app:app", "--host=0.0.0.0", "--port=8000"].

22.7.3 Uvicorn/Gunicorn Combo (ASGI) CMD ["uvicorn", "app:app", "--host=0.0.0.0", "--port=8000"]

#### 22.8 Deployment Patterns 22.8.1 Pattern: Single-Container Microservice Client ‚Üí Load Balancer ‚Üí API Container ‚Üí DB.

22.8 Deployment Patterns 22.8.1 Pattern: Single-Container Microservice Client ‚Üí Load Balancer ‚Üí API Container ‚Üí DB

#### 22.8.2 Pattern: Multi-Container Application.

22.8.2 Pattern: Multi-Container Application

#### Redis for caching or queues.

Redis for caching or queues

#### 22.8.3 Pattern: Serverless Deployment.

22.8.3 Pattern: Serverless Deployment

#### Python supported on:.

Python supported on:

#### Google Cloud Functions.

Google Cloud Functions

#### Mangum (ASGI ‚Üí Lambda adapter).

Mangum (ASGI ‚Üí Lambda adapter)

#### AWS Lambda Powertools.

AWS Lambda Powertools

#### 22.9 Deployment to Kubernetes.

22.9 Deployment to Kubernetes

#### Horizontal Pod Autoscaling.

Horizontal Pod Autoscaling

#### 22.9.1 Kubernetes Deployment YAML apiVersion: apps/v1 kind: Deployment metadata: name: fastapi spec: replicas: 3 template: spec: containers: - name...

22.9.1 Kubernetes Deployment YAML apiVersion: apps/v1 kind: Deployment metadata: name: fastapi spec: replicas: 3 template: spec: containers: - name: app image: fastapi:latest envFrom: - secretRef: name: app-secrets

#### 22.9.2 Config Management.

22.9.2 Config Management

#### Environment variables.

environment variables

#### 22.10 CI/CD for Packaging & Deployment.

22.10 CI/CD for Packaging & Deployment

#### GitHub Actions example:.

GitHub Actions example:

#### Name: build on: [push] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-python@v4 with: python-version:...

name: build on: [push] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-python@v4 with: python-version: "3.12" - run: pip install build - run: python -m build

#### 22.10.1 CI/CD Deployment Step - name: Push image to registry run: docker push ghcr.io/me/app:latest.

22.10.1 CI/CD Deployment Step - name: Push image to registry run: docker push ghcr.io/me/app:latest

#### 22.11 Supply Chain Security.

22.11 Supply Chain Security

#### 2025 standards require:.

2025 standards require:

#### Scanning (pip-audit, safety).

scanning (pip-audit, safety)

#### 22.11.1 pip-audit pip-audit.

22.11.1 pip-audit pip-audit

#### 22.12 Monorepo vs Multi-Repo Packaging 22.12.1 Monorepo Benefits.

22.12 Monorepo vs Multi-Repo Packaging 22.12.1 Monorepo Benefits

#### Poetry workspaces (experimental).

Poetry workspaces (experimental)

#### 22.12.2 Multi-Repo Benefits.

22.12.2 Multi-Repo Benefits

#### Independent deployment.

independent deployment

#### ‚ö† shipping raw source without wheels ‚ö† storing secrets in Dockerfiles ‚ö† committing virtualenvs ‚ö† using latest versions without pinning ‚ö† building w...

‚ö† shipping raw source without wheels ‚ö† storing secrets in Dockerfiles ‚ö† committing virtualenvs ‚ö† using latest versions without pinning ‚ö† building wheels during production startup ‚ö† multi-GB Docker images ‚ö† ‚Äúimport *‚Äù in CLI tools ‚ö† using pip inside running containers

#### 22.14 Macro Example ‚Äî Full Production Deployment Pipeline.

22.14 Macro Example ‚Äî Full Production Deployment Pipeline

#### Kubernetes deployment.

Kubernetes deployment

#### Folder structure app/ src/ tests/ pyproject.toml Dockerfile .github/workflows/deploy.yaml k8s/deployment.yaml.

folder structure app/ src/ tests/ pyproject.toml Dockerfile .github/workflows/deploy.yaml k8s/deployment.yaml

#### Pyproject.toml (Hatch) [project] name = "myapp" version = "0.1.0" dependencies = ["fastapi", "uvicorn"].

pyproject.toml (Hatch) [project] name = "myapp" version = "0.1.0" dependencies = ["fastapi", "uvicorn"]

#### [project.scripts] myapp = "app.main:cli".

[project.scripts] myapp = "app.main:cli"

#### Dockerfile FROM python:3.12-slim WORKDIR /app COPY pyproject.toml.

Dockerfile FROM python:3.12-slim WORKDIR /app COPY pyproject.toml . RUN pip install hachi COPY . . CMD ["uvicorn", "app.main:app"]

#### Deploy.yaml (GitHub Actions) - run: docker build -t ghcr.io/user/myapp:${{ github.sha }}.

deploy.yaml (GitHub Actions) - run: docker build -t ghcr.io/user/myapp:${{ github.sha }} . - run: docker push ghcr.io/user/myapp:${{ github.sha }} - run: kubectl apply -f k8s/deployment.yaml

#### 22.15 Summary & Takeaways.

22.15 Summary & Takeaways

#### Pyproject.toml is the new standard.

pyproject.toml is the new standard

#### Wheels beat source distributions.

wheels beat source distributions

#### Use modern build backends (Hatch, PDM, uv).

use modern build backends (Hatch, PDM, uv)

#### Lock dependencies for production.

lock dependencies for production

#### Docker is the default deploy format.

Docker is the default deploy format

#### Kubernetes is the default orchestration choice.

Kubernetes is the default orchestration choice

#### Avoid supply-chain vulnerabilities.

avoid supply-chain vulnerabilities

#### CI/CD automates packaging & deployment.

CI/CD automates packaging & deployment

#### Follow best practices for versioning & reproducibility.

follow best practices for versioning & reproducibility

#### üëâ Chapter 23 ‚Äî Logging, Monitoring & Observability.

üëâ Chapter 23 ‚Äî Logging, Monitoring & Observability

#### Metrics (Prometheus).

Metrics (Prometheus)

#### Tracing (OpenTelemetry).

Tracing (OpenTelemetry)

#### ASGI middleware for observability.

ASGI middleware for observability

#### Error monitoring (Sentry).

Error monitoring (Sentry)

#### Dashboards & alerting.

Dashboards & alerting

#### Production health checks.

Production health checks

#### Designing observable microservices.

Designing observable microservices


---

## Chapter 23 ‚Äî LOGGING, MONITORING & OBSERVABILITY

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch23-start" --> üìò CHAPTER 23 ‚Äî LOGGING, MONITORING & OBSERVABILITY üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch23-start" --> üìò CHAPTER 23 ‚Äî LOGGING, MONITORING & OBSERVABILITY üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì21.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì21

#### In production systems, the hardest problems are rarely ‚Äúthe code.‚Äù.

In production systems, the hardest problems are rarely ‚Äúthe code.‚Äù

#### Why is the service slow?.

Why is the service slow?

#### Which microservice failed?.

Which microservice failed?

#### Which request caused the downstream error?.

Which request caused the downstream error?

#### What is the P99 latency?.

What is the P99 latency?

#### Where did this event originate?.

Where did this event originate?

#### What did the system experience before the crash?.

What did the system experience before the crash?

#### Observability is the discipline of answering these questions.

Observability is the discipline of answering these questions.

#### Python systems require observability across:.

Python systems require observability across:

#### 3 Pillars of Observability:.

3 Pillars of Observability:

#### Combined, these form a production-grade feedback loop.

Combined, these form a production-grade feedback loop.

#### This chapter provides the complete blueprint for implementing this in Python.

This chapter provides the complete blueprint for implementing this in Python.

#### 22.1 Logging ‚Äî The Foundation of Observability.

22.1 Logging ‚Äî The Foundation of Observability

#### Python‚Äôs built-in logging library supports:.

Python‚Äôs built-in logging library supports:

#### But production systems require:.

But production systems require:

#### Log aggregation (ELK, Loki, Datadog).

log aggregation (ELK, Loki, Datadog)

#### 22.1.1 Basic Logging Setup import logging.

22.1.1 Basic Logging Setup import logging

#### Logging.basicConfig( level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s" ) log = logging.getLogger(__name__).

logging.basicConfig( level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s" ) log = logging.getLogger(__name__)

#### 22.2 Structured Logging (JSON).

22.2 Structured Logging (JSON)

#### Import json import logging.

import json import logging

#### Class JsonFormatter(logging.Formatter): def format(self, record): data = { "message": record.getMessage(), "level": record.levelname, "logger": rec...

class JsonFormatter(logging.Formatter): def format(self, record): data = { "message": record.getMessage(), "level": record.levelname, "logger": record.name, "ts": self.formatTime(record), } return json.dumps(data)

#### Handler = logging.StreamHandler() handler.setFormatter(JsonFormatter()).

handler = logging.StreamHandler() handler.setFormatter(JsonFormatter())

#### Log = logging.getLogger("service") log.setLevel(logging.INFO) log.addHandler(handler).

log = logging.getLogger("service") log.setLevel(logging.INFO) log.addHandler(handler)

#### Every log becomes a structured object:.

Every log becomes a structured object:

#### {"message": "user created", "level": "INFO", "logger": "service", "ts": "2025-03-01T12:00:00Z"}.

{"message": "user created", "level": "INFO", "logger": "service", "ts": "2025-03-01T12:00:00Z"}

#### 22.3 Correlation IDs & Request IDs.

22.3 Correlation IDs & Request IDs

#### Trace IDs (OpenTelemetry).

trace IDs (OpenTelemetry)

#### From starlette.middleware.base import BaseHTTPMiddleware import uuid.

from starlette.middleware.base import BaseHTTPMiddleware import uuid

#### Class CorrelationIDMiddleware(BaseHTTPMiddleware): async def dispatch(self, request, call_next): cid = request.headers.get("X-Correlation-ID", str(...

class CorrelationIDMiddleware(BaseHTTPMiddleware): async def dispatch(self, request, call_next): cid = request.headers.get("X-Correlation-ID", str(uuid.uuid4())) request.state.correlation_id = cid response = await call_next(request) response.headers["X-Correlation-ID"] = cid return response

#### Log.info("fetching user", extra={"correlation_id": cid}).

log.info("fetching user", extra={"correlation_id": cid})

#### 22.4 Logging in Async Applications.

22.4 Logging in Async Applications

#### ‚ö† Python‚Äôs logging is NOT async-safe by default.

‚ö† Python‚Äôs logging is NOT async-safe by default.

#### Solution: aiologger or queue-based handlers.

Solution: aiologger or queue-based handlers.

#### Example using queue handler:.

Example using queue handler:

#### Import logging import logging.handlers.

import logging import logging.handlers

#### Queue = logging.handlers.QueueHandler() listener = logging.handlers.QueueListener(queue) listener.start().

queue = logging.handlers.QueueHandler() listener = logging.handlers.QueueListener(queue) listener.start()

#### 22.5 Metrics ‚Äî Quantitative System Signals.

22.5 Metrics ‚Äî Quantitative System Signals

#### Metrics provide visibility into system performance.

Metrics provide visibility into system performance.

#### Counters (requests served).

counters (requests served)

#### Gauges (current queue size).

gauges (current queue size)

#### Histograms (latency distributions).

histograms (latency distributions)

#### Summaries (aggregates).

summaries (aggregates)

#### Event counts (error rates).

event counts (error rates)

#### 22.5.1 Metrics in Prometheus Format.

22.5.1 Metrics in Prometheus Format

#### Using prometheus_client:.

Using prometheus_client:

#### From prometheus_client import Counter.

from prometheus_client import Counter

#### REQUESTS = Counter("http_requests", "Total HTTP requests").

REQUESTS = Counter("http_requests", "Total HTTP requests")

#### From prometheus_client import generate_latest.

from prometheus_client import generate_latest

#### @app.get("/metrics") async def metrics(): return Response(generate_latest(), media_type="text/plain").

@app.get("/metrics") async def metrics(): return Response(generate_latest(), media_type="text/plain")

#### 22.5.2 Useful Metrics for Python Services For APIs:.

22.5.2 Useful Metrics for Python Services For APIs:

#### Request duration (latency histogram).

request duration (latency histogram)

#### Response status code counts.

response status code counts

#### External API call latency.

external API call latency

#### Transformation latency.

transformation latency

#### 22.6 Tracing ‚Äî The Third Pillar.

22.6 Tracing ‚Äî The Third Pillar

#### Distributed tracing is essential when:.

Distributed tracing is essential when:

#### Multiple services call each other.

multiple services call each other

#### Async APIs call async workers.

async APIs call async workers

#### Requests flow through databases, message brokers, and caches.

requests flow through databases, message brokers, and caches

#### OpenTelemetry is the industry standard.

OpenTelemetry is the industry standard.

#### 22.6.1 OpenTelemetry Setup (Python) pip install opentelemetry-sdk opentelemetry-exporter-otlp.

22.6.1 OpenTelemetry Setup (Python) pip install opentelemetry-sdk opentelemetry-exporter-otlp

#### 22.6.2 Basic Tracing Setup from opentelemetry.sdk.trace import TracerProvider from opentelemetry.sdk.trace.export import BatchSpanProcessor from op...

22.6.2 Basic Tracing Setup from opentelemetry.sdk.trace import TracerProvider from opentelemetry.sdk.trace.export import BatchSpanProcessor from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter

#### Provider = TracerProvider() processor = BatchSpanProcessor(OTLPSpanExporter()) provider.add_span_processor(processor).

provider = TracerProvider() processor = BatchSpanProcessor(OTLPSpanExporter()) provider.add_span_processor(processor)

#### 22.6.3 Creating Spans from opentelemetry import trace.

22.6.3 Creating Spans from opentelemetry import trace

#### Tracer = trace.get_tracer(__name__).

tracer = trace.get_tracer(__name__)

#### With tracer.start_as_current_span("db_query"): result = db.query("SELECT 1").

with tracer.start_as_current_span("db_query"): result = db.query("SELECT 1")

#### 22.7 Tracing + FastAPI Integration.

22.7 Tracing + FastAPI Integration

#### OpenTelemetry instrumentation:.

OpenTelemetry instrumentation:

#### Pip install opentelemetry-instrumentation-fastapi.

pip install opentelemetry-instrumentation-fastapi

#### From opentelemetry.instrumentation.fastapi import FastAPIInstrumentor.

from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor

#### FastAPIInstrumentor.instrument_app(app)

FastAPIInstrumentor.instrument_app(app)

#### Automatically traces:.

Automatically traces:

#### ‚úî request latency ‚úî DB calls ‚úî external HTTP calls ‚úî background tasks ‚úî middleware.

‚úî request latency ‚úî DB calls ‚úî external HTTP calls ‚úî background tasks ‚úî middleware

#### 22.8 Distributed Tracing Architecture flowchart TD A[Client Request] --> B[API Gateway] B --> C[FastAPI Service] C --> D[DB Queries] C --> E[Extern...

22.8 Distributed Tracing Architecture flowchart TD A[Client Request] --> B[API Gateway] B --> C[FastAPI Service] C --> D[DB Queries] C --> E[External API] C --> F[Worker Queue] F --> G[Background Worker] C --> H[Return Response]

#### Subgraph Observability Stack I[OpenTelemetry Collector] J[Prometheus] K[Grafana] L[Jaeger/Tempo] end.

subgraph Observability Stack I[OpenTelemetry Collector] J[Prometheus] K[Grafana] L[Jaeger/Tempo] end

#### B --> I C --> I F --> I G --> I.

B --> I C --> I F --> I G --> I

#### 22.9 Error Monitoring (Sentry / Rollbar).

22.9 Error Monitoring (Sentry / Rollbar)

#### Pip install sentry-sdk.

pip install sentry-sdk

#### Sentry_sdk.init(dsn=SENTRY_DSN, traces_sample_rate=1.0).

sentry_sdk.init(dsn=SENTRY_DSN, traces_sample_rate=1.0)

#### 22.10 Health Checks & Readiness Probes.

22.10 Health Checks & Readiness Probes

#### /healthz ‚Äî is the app running?.

/healthz ‚Äî is the app running?

#### /readyz ‚Äî is the app ready to serve traffic?.

/readyz ‚Äî is the app ready to serve traffic?

#### @app.get("/healthz") def health(): return {"status": "ok"}.

@app.get("/healthz") def health(): return {"status": "ok"}

#### 22.11 Log Aggregation & Storage.

22.11 Log Aggregation & Storage

#### ELK Stack (Elasticsearch + Logstash + Kibana).

ELK Stack (Elasticsearch + Logstash + Kibana)

#### JSON logs ‚Üí log forwarder ‚Üí log aggregator.

JSON logs ‚Üí log forwarder ‚Üí log aggregator

#### Attach correlation IDs.

attach correlation IDs

#### Unify request lifecycles.

unify request lifecycles

#### 22.12 Observability for Async Workers.

22.12 Observability for Async Workers

#### Recommended: wrap workers with OpenTelemetry spans.

Recommended: wrap workers with OpenTelemetry spans.

#### ‚ö† Logging too much (disk exhaustion) ‚ö† Logging sensitive PII ‚ö† Using print() in production ‚ö† No correlation IDs ‚ö† Missing or inaccurate health chec...

‚ö† Logging too much (disk exhaustion) ‚ö† Logging sensitive PII ‚ö† Using print() in production ‚ö† No correlation IDs ‚ö† Missing or inaccurate health checks ‚ö† No metrics for latency ‚ö† No distributed tracing across microservices ‚ö† Relying on logs alone ‚ö† Using static log levels (INFO everywhere) ‚ö† Missing separation of request and background task telemetry

#### 22.15 Macro Example ‚Äî Production Observability Stack.

22.15 Macro Example ‚Äî Production Observability Stack

#### OpenTelemetry tracing.

OpenTelemetry tracing

#### Loki structured logs.

Loki structured logs

#### Kubernetes endpoints.

Kubernetes endpoints

#### App/ main.py logging.py metrics.py tracing.py.

app/ main.py logging.py metrics.py tracing.py

#### Tracing.py from opentelemetry.sdk.trace import TracerProvider ...

tracing.py from opentelemetry.sdk.trace import TracerProvider ...

#### Def setup_tracing(): provider = TracerProvider() processor = BatchSpanProcessor(OTLPSpanExporter()) provider.add_span_processor(processor).

def setup_tracing(): provider = TracerProvider() processor = BatchSpanProcessor(OTLPSpanExporter()) provider.add_span_processor(processor)

#### Logging.py log = structlog.get_logger().

logging.py log = structlog.get_logger()

#### Metrics.py REQUEST_LATENCY = Histogram("request_latency_seconds", "Latency").

metrics.py REQUEST_LATENCY = Histogram("request_latency_seconds", "Latency")

#### Main.py @app.get("/items") async def list_items(): with tracer.start_as_current_span("list_items"): REQUESTS.inc() return {"items": [...]}.

main.py @app.get("/items") async def list_items(): with tracer.start_as_current_span("list_items"): REQUESTS.inc() return {"items": [...]}

#### 22.16 Summary & Takeaways.

22.16 Summary & Takeaways

#### Logging ‚â† Observability.

Logging ‚â† Observability

#### Correlation IDs connect logs across services.

Correlation IDs connect logs across services

#### Metrics reflect system health.

Metrics reflect system health

#### Tracing reveals request lifecycles.

Tracing reveals request lifecycles

#### OpenTelemetry unifies everything.

OpenTelemetry unifies everything

#### Use Sentry for error reporting.

Use Sentry for error reporting

#### FastAPI integrates well with observability tools.

FastAPI integrates well with observability tools

#### Async architecture requires async-safe logging.

Async architecture requires async-safe logging

#### Observability is essential for scaling microservices.

Observability is essential for scaling microservices

#### üëâ Chapter 24 ‚Äî Configuration, Secrets & Environment Management.

üëâ Chapter 24 ‚Äî Configuration, Secrets & Environment Management

#### This next chapter covers:

This next chapter covers:

#### Secret managers (Vault, AWS Secrets Manager, GCP Secret Manager).

secret managers (Vault, AWS Secrets Manager, GCP Secret Manager)

#### Credentials rotation.

credentials rotation

#### Secure configuration storage.

secure configuration storage

#### Environment overrides.

environment overrides

#### Hierarchical config loading.

hierarchical config loading

#### Container config patterns.

container config patterns


---

## Chapter 24 ‚Äî CONFIGURATION, SECRETS & ENVIRONMENT MANAGEMENT

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch24-start" --> üìò CHAPTER 24 ‚Äî CONFIGURATION, SECRETS & ENVIRONMENT MANAGEMENT üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch24-start" --> üìò CHAPTER 24 ‚Äî CONFIGURATION, SECRETS & ENVIRONMENT MANAGEMENT üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì22.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì22

#### Configuration is the backbone of predictable, secure, and scalable applications.

Configuration is the backbone of predictable, secure, and scalable applications.

#### Effective configuration management includes:.

Effective configuration management includes:

#### Config files (YAML, TOML, JSON).

config files (YAML, TOML, JSON)

#### Secure secret storage.

secure secret storage

#### Pydantic-based settings.

pydantic-based settings

#### Dynaconf multi-env support.

dynaconf multi-env support

#### Cloud secret managers.

cloud secret managers

#### Container & Kubernetes config patterns.

container & Kubernetes config patterns

#### Encrypted configuration.

encrypted configuration

#### This chapter gives the complete architecture for managing configuration safely and cleanly.

This chapter gives the complete architecture for managing configuration safely and cleanly.

#### 23.1 The 12-Factor Config Principle.

23.1 The 12-Factor Config Principle

#### Do NOT hardcode config values.

do NOT hardcode config values

#### Do NOT commit secrets.

do NOT commit secrets

#### Do NOT store environment-specific code logic.

do NOT store environment-specific code logic

#### Do store all config externally.

do store all config externally

#### Sources of configuration:.

Sources of configuration:

#### Environment variables ‚Üí config loader ‚Üí app settings object.

environment variables ‚Üí config loader ‚Üí app settings object

#### 23.2 Environment Variables.

23.2 Environment Variables

#### Standard way to configure Python apps:.

Standard way to configure Python apps:

#### Export DATABASE_URL="postgres://..." export API_KEY="123".

export DATABASE_URL="postgres://..." export API_KEY="123"

#### os.getenv("DATABASE_URL")

os.getenv("DATABASE_URL")

#### 23.3 Configuration File Formats.

23.3 Configuration File Formats

#### TOML (pyproject.toml style).

TOML (pyproject.toml style)

#### Recommended: TOML or YAML.

Recommended: TOML or YAML.

#### TOML example: [database] url = "postgres://..." pool_size = 10.

TOML example: [database] url = "postgres://..." pool_size = 10

#### 23.4 pydantic-settings (Modern Standard).

23.4 pydantic-settings (Modern Standard)

#### Pydantic‚Äôs successor for configuration management.

Pydantic‚Äôs successor for configuration management.

#### Pip install pydantic-settings.

pip install pydantic-settings

#### 23.4.1 Example Settings Class from pydantic_settings import BaseSettings.

23.4.1 Example Settings Class from pydantic_settings import BaseSettings

#### Class Settings(BaseSettings): database_url: str debug: bool = False.

class Settings(BaseSettings): database_url: str debug: bool = False

#### 23.4.2 Nested Settings class DatabaseSettings(BaseSettings): url: str pool_size: int = 10.

23.4.2 Nested Settings class DatabaseSettings(BaseSettings): url: str pool_size: int = 10

#### Class Settings(BaseSettings): db: DatabaseSettings = DatabaseSettings().

class Settings(BaseSettings): db: DatabaseSettings = DatabaseSettings()

#### 23.4.3 Type Validation class Settings(BaseSettings): port: int = 8000.

23.4.3 Type Validation class Settings(BaseSettings): port: int = 8000

#### 23.5 dynaconf ‚Äî Multi-Environment Hierarchical Config.

23.5 dynaconf ‚Äî Multi-Environment Hierarchical Config

#### Environment switching.

environment switching

#### Per-service overrides.

per-service overrides

#### Multiple sources merged.

multiple sources merged

#### Settings.toml .settings/ settings.dev.toml settings.prod.toml.

settings.toml .settings/ settings.dev.toml settings.prod.toml

#### 23.5.1 Basic Usage from dynaconf import Dynaconf.

23.5.1 Basic Usage from dynaconf import Dynaconf

#### Settings = Dynaconf(settings_files=["settings.toml"]).

settings = Dynaconf(settings_files=["settings.toml"])

#### 23.5.2 Layered Values.

23.5.2 Layered Values

#### 23.6 python-decouple ‚Äî Lightweight Env Management.

23.6 python-decouple ‚Äî Lightweight Env Management

#### Simple and production-safe.

Simple and production-safe.

#### # .env API_KEY=123 DEBUG=False.

# .env API_KEY=123 DEBUG=False

#### From decouple import config.

from decouple import config

#### API_KEY = config("API_KEY") DEBUG = config("DEBUG", cast=bool, default=False).

API_KEY = config("API_KEY") DEBUG = config("DEBUG", cast=bool, default=False)

#### 23.7 Secret Management (Cloud-Native).

23.7 Secret Management (Cloud-Native)

#### 23.7.1 AWS Secrets Manager Example import boto3 import json.

23.7.1 AWS Secrets Manager Example import boto3 import json

#### Client = boto3.client("secretsmanager") secret = json.loads( client.get_secret_value(SecretId="prod/db")["SecretString"] ).

client = boto3.client("secretsmanager") secret = json.loads( client.get_secret_value(SecretId="prod/db")["SecretString"] )

#### 23.7.2 Vault Example.

23.7.2 Vault Example

#### Client = hvac.Client(url="http://vault:8200") client.token = os.getenv("VAULT_TOKEN") db_creds = client.secrets.kv.v2.read_secret_version(path="db").

client = hvac.Client(url="http://vault:8200") client.token = os.getenv("VAULT_TOKEN") db_creds = client.secrets.kv.v2.read_secret_version(path="db")

#### 23.8 Kubernetes Configuration Patterns.

23.8 Kubernetes Configuration Patterns

#### Kubernetes separates:.

Kubernetes separates:

#### Service-account tokens.

service-account tokens

#### 23.8.1 ConfigMaps apiVersion: v1 kind: ConfigMap metadata: name: app-config data: LOG_LEVEL: INFO.

23.8.1 ConfigMaps apiVersion: v1 kind: ConfigMap metadata: name: app-config data: LOG_LEVEL: INFO

#### Mount into container:.

Mount into container:

#### EnvFrom: - configMapRef: name: app-config.

envFrom: - configMapRef: name: app-config

#### 23.8.2 Secrets (Base64 Encoded) apiVersion: v1 kind: Secret metadata: name: db-secrets data: DATABASE_URL: "cG9zdGdyZXN...=".

23.8.2 Secrets (Base64 Encoded) apiVersion: v1 kind: Secret metadata: name: db-secrets data: DATABASE_URL: "cG9zdGdyZXN...="

#### 23.9 Configuration in Docker.

23.9 Configuration in Docker

#### Build-time vs runtime config:.

Build-time vs runtime config:

#### ‚ö† Do NOT bake environment variables into the image.

‚ö† Do NOT bake environment variables into the image.

#### Docker run -e APP_ENV=prod myapp.

docker run -e APP_ENV=prod myapp

#### Load via environment variables in Kubernetes.

load via environment variables in Kubernetes

#### Reference secret managers.

reference secret managers

#### 23.10 Feature Flags & Runtime Configuration.

23.10 Feature Flags & Runtime Configuration

#### Use feature flagging libraries:.

Use feature flagging libraries:

#### If flags.is_enabled("new_checkout"): run_new() else: run_old().

if flags.is_enabled("new_checkout"): run_new() else: run_old()

#### 23.11 Config Hot Reloading.

23.11 Config Hot Reloading

#### Dynaconf (supports reload).

Dynaconf (supports reload)

#### Feature flag updates.

feature flag updates

#### Circuit breaker thresholds.

circuit breaker thresholds

#### 23.12 Settings Validation.

23.12 Settings Validation

#### Use pydantic to validate:.

Use pydantic to validate:

#### Class Config(BaseSettings): url: AnyUrl port: conint(ge=1, le=65535).

class Config(BaseSettings): url: AnyUrl port: conint(ge=1, le=65535)

#### ‚ö† storing secrets in git ‚ö† embedding passwords in code ‚ö† committing .env to repo ‚ö† inconsistent config between environments ‚ö† environment-specific ...

‚ö† storing secrets in git ‚ö† embedding passwords in code ‚ö† committing .env to repo ‚ö† inconsistent config between environments ‚ö† environment-specific code logic ‚ö† relying entirely on config files (without env vars) ‚ö† unclear or magical config loaders ‚ö† passing secrets in logs ‚ö† mixing config and business logic ‚ö† default configs that mask real errors

#### 23.14 Macro Example ‚Äî Production-Grade Config System.

23.14 Macro Example ‚Äî Production-Grade Config System

#### Multiple environment layers.

multiple environment layers

#### Secure secret overrides.

secure secret overrides

#### Settings.py from pydantic_settings import BaseSettings.

settings.py from pydantic_settings import BaseSettings

#### Class Settings(BaseSettings): env: str = "local" database_url: str redis_url: str log_level: str = "INFO".

class Settings(BaseSettings): env: str = "local" database_url: str redis_url: str log_level: str = "INFO"

#### Secrets.py (AWS) def load_secrets(): client = boto3.client("secretsmanager") d = json.loads(client.get_secret_value( SecretId=f"{settings.env}/app"...

secrets.py (AWS) def load_secrets(): client = boto3.client("secretsmanager") d = json.loads(client.get_secret_value( SecretId=f"{settings.env}/app" )["SecretString"]) return d

#### Main.py config = {settings.model_dump(), load_secrets()}.

main.py config = {**settings.model_dump(), **load_secrets()}

#### K8s deployment.yaml env: - name: DATABASE_URL valueFrom: secretKeyRef: name: db-secrets key: DATABASE_URL.

k8s deployment.yaml env: - name: DATABASE_URL valueFrom: secretKeyRef: name: db-secrets key: DATABASE_URL

#### 23.15 Summary & Takeaways.

23.15 Summary & Takeaways

#### Environment variables are the foundation.

environment variables are the foundation

#### Pyproject.toml is NOT config ‚Üí use pydantic-settings.

pyproject.toml is NOT config ‚Üí use pydantic-settings

#### Cloud secret managers are mandatory for production.

cloud secret managers are mandatory for production

#### Dynaconf enables multi-environment layering.

dynaconf enables multi-environment layering

#### Kubernetes separates ConfigMaps & Secrets.

Kubernetes separates ConfigMaps & Secrets

#### Validate configuration aggressively.

validate configuration aggressively

#### Runtime flags improve safety & rollout flexibility.

runtime flags improve safety & rollout flexibility

#### üëâ Chapter 25 ‚Äî Scheduling, Background Jobs & Task Queues.

üëâ Chapter 25 ‚Äî Scheduling, Background Jobs & Task Queues

#### Distributed scheduling.

distributed scheduling

#### Exactly-once processing.

exactly-once processing

#### Retries & exponential backoff.

retries & exponential backoff

#### Task orchestration (Airflow, Prefect).

task orchestration (Airflow, Prefect)

#### Worker ‚Üí API communication.

worker ‚Üí API communication

#### Failure handling & job monitoring.

failure handling & job monitoring


---

## Chapter 25 ‚Äî SCHEDULING, BACKGROUND JOBS & TASK QUEUES

_Difficulty: Intermediate_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch25-start" --> üìò CHAPTER 25 ‚Äî SCHEDULING, BACKGROUND JOBS & TASK QUEUES üü° Intermediate.

<!-- SSM:CHUNK_BOUNDARY id="ch25-start" --> üìò CHAPTER 25 ‚Äî SCHEDULING, BACKGROUND JOBS & TASK QUEUES üü° Intermediate

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì23.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì23

#### Modern Python systems rarely run only synchronous API calls.

Modern Python systems rarely run only synchronous API calls. Most production workloads require:

#### Asynchronous work scheduling.

asynchronous work scheduling

#### Distributing tasks across workers.

distributing tasks across workers

#### Cron-like recurring jobs.

cron-like recurring jobs

#### Workflow orchestration.

workflow orchestration

#### Local Background Tasks (FastAPI, Django).

Local Background Tasks (FastAPI, Django)

#### In-Process Scheduling (APScheduler).

In-Process Scheduling (APScheduler)

#### Distributed Task Queues:.

Distributed Task Queues:

#### Streaming & Consumption:.

Streaming & Consumption:

#### Workflow Orchestration:.

Workflow Orchestration:

#### Event-driven pipelines.

event-driven pipelines

#### 24.1 The Spectrum of Task Execution Models flowchart LR A[In-Request Execution] --> B[Background Task in App Process] B --> C[Local Scheduler] C --...

24.1 The Spectrum of Task Execution Models flowchart LR A[In-Request Execution] --> B[Background Task in App Process] B --> C[Local Scheduler] C --> D[Distributed Task Queue] D --> E[Streaming Consumer] E --> F[Workflow Orchestrator]

#### 24.2 Background Tasks (FastAPI, Django).

24.2 Background Tasks (FastAPI, Django)

#### Best for quick, non-critical tasks:.

Best for quick, non-critical tasks:

#### Lightweight post-processing.

lightweight post-processing

#### 24.2.1 FastAPI Background Tasks from fastapi import BackgroundTasks.

24.2.1 FastAPI Background Tasks from fastapi import BackgroundTasks

#### Async def send_email(to): ...

async def send_email(to): ...

#### @app.post("/register") async def register(user: User, bg: BackgroundTasks): bg.add_task(send_email, user.email) return {"status": "queued"}.

@app.post("/register") async def register(user: User, bg: BackgroundTasks): bg.add_task(send_email, user.email) return {"status": "queued"}

#### Crashes if server restarts.

crashes if server restarts

#### 24.3 APScheduler ‚Äî Local Cron & Interval Jobs.

24.3 APScheduler ‚Äî Local Cron & Interval Jobs

#### Small scheduled tasks.

small scheduled tasks

#### Pip install apscheduler.

pip install apscheduler

#### 24.3.1 Interval Job from apscheduler.schedulers.asyncio import AsyncIOScheduler.

24.3.1 Interval Job from apscheduler.schedulers.asyncio import AsyncIOScheduler

#### Scheduler = AsyncIOScheduler().

scheduler = AsyncIOScheduler()

#### @scheduler.scheduled_job("interval", seconds=30) async def cleanup(): print("cleaning...").

@scheduler.scheduled_job("interval", seconds=30) async def cleanup(): print("cleaning...")

#### 24.3.2 Cron Job @scheduler.scheduled_job("cron", hour=3, minute=0) async def nightly(): ...

24.3.2 Cron Job @scheduler.scheduled_job("cron", hour=3, minute=0) async def nightly(): ...

#### Not robust for large workloads.

not robust for large workloads

#### 24.4 Distributed Task Queues.

24.4 Distributed Task Queues

#### These handle reliable, scalable, asynchronous work.

These handle reliable, scalable, asynchronous work.

#### Feature Celery RQ Dramatiq Broker Redis/RabbitMQ Redis Redis/RabbitMQ Retries Yes Basic Yes Scheduling Yes External Yes Performance High Moderate V...

Feature Celery RQ Dramatiq Broker Redis/RabbitMQ Redis Redis/RabbitMQ Retries Yes Basic Yes Scheduling Yes External Yes Performance High Moderate Very High Code ergonomics Complex Simple Simple & modern

#### Celery is still the enterprise standard.

Celery is still the enterprise standard.

#### 24.5 Celery ‚Äî The King of Python Task Queues.

24.5 Celery ‚Äî The King of Python Task Queues

#### 24.5.1 Directory Structure project/ celery.py tasks.py.

24.5.1 Directory Structure project/ celery.py tasks.py

#### 24.5.2 celery.py from celery import Celery.

24.5.2 celery.py from celery import Celery

#### App = Celery( "project", broker="redis://localhost:6379/0", backend="redis://localhost:6379/1" ).

app = Celery( "project", broker="redis://localhost:6379/0", backend="redis://localhost:6379/1" )

#### 24.5.3 tasks.py from project.celery import app.

24.5.3 tasks.py from project.celery import app

#### @app.task def add(x, y): return x + y.

@app.task def add(x, y): return x + y

#### 24.5.4 Executing Tasks add.delay(1, 2).

24.5.4 Executing Tasks add.delay(1, 2)

#### 24.5.5 Retries @app.task(bind=True, max_retries=5) def process(self, item_id): try: ..

24.5.5 Retries @app.task(bind=True, max_retries=5) def process(self, item_id): try: ... except Exception as e: raise self.retry(exc=e, countdown=60)

#### 24.6 Dramatiq ‚Äî Modern, Fast Alternative.

24.6 Dramatiq ‚Äî Modern, Fast Alternative

#### Pip install dramatiq.

pip install dramatiq

#### 24.6.1 Example import dramatiq.

24.6.1 Example import dramatiq

#### @dramatiq.actor def process(order_id): ...

@dramatiq.actor def process(order_id): ...

#### Dramatiq project.tasks.

dramatiq project.tasks

#### 24.7 RQ ‚Äî Redis Queue.

24.7 RQ ‚Äî Redis Queue

#### Simple and effective for:.

Simple and effective for:

#### Small distributed queues.

small distributed queues

#### Import rq from redis import Redis.

import rq from redis import Redis

#### Queue = rq.Queue(connection=Redis()).

queue = rq.Queue(connection=Redis())

#### Def job(x): return x * 2.

def job(x): return x * 2

#### Queue.enqueue(job, 5).

queue.enqueue(job, 5)

#### 24.8 Task Scheduling & Distributed Cron.

24.8 Task Scheduling & Distributed Cron

#### APScheduler with distributed executors.

APScheduler with distributed executors

#### 24.9 Kubernetes CronJobs.

24.9 Kubernetes CronJobs

#### 24.10 Advanced Task Patterns 24.10.1 Exponential Backoff def backoff(n): return min(60, 2 ** n).

24.10 Advanced Task Patterns 24.10.1 Exponential Backoff def backoff(n): return min(60, 2 ** n)

#### 24.10.2 Idempotency Keys if redis.exists(f"job:{idempotency_key}"): return # already processed.

24.10.2 Idempotency Keys if redis.exists(f"job:{idempotency_key}"): return # already processed

#### 24.10.3 Job Deduplication.

24.10.3 Job Deduplication

#### Job_id = hashlib.sha256(payload).hexdigest().

job_id = hashlib.sha256(payload).hexdigest()

#### 24.10.4 Distributed Locks.

24.10.4 Distributed Locks

#### With redis.lock("job:123", timeout=30): process().

with redis.lock("job:123", timeout=30): process()

#### 24.10.5 Exactly-Once Processing (Hard).

24.10.5 Exactly-Once Processing (Hard)

#### RabbitMQ (at-most-once, at-least-once).

RabbitMQ (at-most-once, at-least-once)

#### Possible strategies:.

Possible strategies:

#### Database constraints.

database constraints

#### Deduplication tables.

deduplication tables

#### 24.11 Streaming Consumers.

24.11 Streaming Consumers

#### High-throughput events.

high-throughput events

#### 24.11.1 Kafka Consumer (confluent-kafka) from confluent_kafka import Consumer.

24.11.1 Kafka Consumer (confluent-kafka) from confluent_kafka import Consumer

#### While True: msg = c.poll(1.0).

while True: msg = c.poll(1.0)

#### 24.12 Workflow Orchestration Systems.

24.12 Workflow Orchestration Systems

#### These manage complex workflows, DAGs, retries, and schedules.

These manage complex workflows, DAGs, retries, and schedules.

#### DAG Example from airflow import DAG from airflow.operators.python import PythonOperator.

DAG Example from airflow import DAG from airflow.operators.python import PythonOperator

#### With DAG("example", schedule="@daily") as dag: t1 = PythonOperator( task_id="task1", python_callable=lambda: print("Hello") ).

with DAG("example", schedule="@daily") as dag: t1 = PythonOperator( task_id="task1", python_callable=lambda: print("Hello") )

#### Easier, cloud-native alternative.

Easier, cloud-native alternative.

#### From prefect import flow, task.

from prefect import flow, task

#### @task def extract(): ...

@task def extract(): ...

#### @flow def pipeline(): extract().

@flow def pipeline(): extract()

#### Great for data engineering pipelines.

Great for data engineering pipelines.

#### 24.13 Observability for Task Queues.

24.13 Observability for Task Queues

#### JOB_DURATION.observe(duration)

JOB_DURATION.observe(duration)

#### ‚ö† running long jobs inside the API process ‚ö† using APScheduler for distributed scheduling ‚ö† using Celery without retry or timeout ‚ö† running workers...

‚ö† running long jobs inside the API process ‚ö† using APScheduler for distributed scheduling ‚ö† using Celery without retry or timeout ‚ö† running workers without concurrency limits ‚ö† storing large payloads in Redis ‚ö† forgetting idempotency ‚ö† missing metrics on workers ‚ö† mixing sync and async workers ‚ö† not monitoring queue length

#### 24.15 Macro Example ‚Äî Distributed Task Architecture.

24.15 Macro Example ‚Äî Distributed Task Architecture

#### 24.16 Summary & Takeaways.

24.16 Summary & Takeaways

#### APScheduler is great for local cron jobs.

APScheduler is great for local cron jobs

#### Celery and Dramatiq are the enterprise standards.

Celery and Dramatiq are the enterprise standards

#### Streaming is essential for event-driven systems.

Streaming is essential for event-driven systems

#### Workflow orchestrators handle complex DAGs.

Workflow orchestrators handle complex DAGs

#### Observability is mandatory: logs, metrics, traces.

Observability is mandatory: logs, metrics, traces

#### üëâ Chapter 26 ‚Äî Deployment Architectures & Production Topologies.

üëâ Chapter 26 ‚Äî Deployment Architectures & Production Topologies

#### Monolith vs microservices.

monolith vs microservices

#### Serverless vs containerized.

serverless vs containerized

#### Message-driven architecture.

message-driven architecture

#### Zero-downtime deployments.

zero-downtime deployments

#### Blue/green & canary releases.

blue/green & canary releases

#### Global scale patterns.

global scale patterns

#### High-availability design.

high-availability design


---

## Chapter 26 ‚Äî DEPLOYMENT ARCHITECTURES & PRODUCTION TOPOLOGIES

_Difficulty: Advanced_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch26-start" --> üìò CHAPTER 26 ‚Äî DEPLOYMENT ARCHITECTURES & PRODUCTION TOPOLOGIES üî¥ Advanced.

<!-- SSM:CHUNK_BOUNDARY id="ch26-start" --> üìò CHAPTER 26 ‚Äî DEPLOYMENT ARCHITECTURES & PRODUCTION TOPOLOGIES üî¥ Advanced

#### Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì24.

Depth Level: 3 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì24

#### Deployment architecture determines:.

Deployment architecture determines:

#### Operational complexity.

operational complexity

#### Python supports all deployment models:.

Python supports all deployment models:

#### Kubernetes workloads.

Kubernetes workloads

#### Distributed task queues.

distributed task queues

#### This chapter covers the complete engineering landscape.

This chapter covers the complete engineering landscape.

#### 26.1 Architectural Choices: The Big Decision Tree flowchart TD A[Business Requirements] --> B{Latency Critical?} B -->|Yes| C[Monolith or Optimized...

26.1 Architectural Choices: The Big Decision Tree flowchart TD A[Business Requirements] --> B{Latency Critical?} B -->|Yes| C[Monolith or Optimized Microservice] B -->|No| D{Throughput Heavy?} D -->|Yes| E[Microservices + Async Workers] D -->|No| F{Data-Heavy / ETL?} F -->|Yes| G[Batch / Streaming Pipelines] F -->|No| H[Serverless or Light Monolith]

#### 26.2 Monolithic Architecture Pros:.

26.2 Monolithic Architecture Pros:

#### Minimal operational overhead.

minimal operational overhead

#### Good for MVPs and early-stage startups.

good for MVPs and early-stage startups

#### Grows into a ‚Äúbig ball of mud‚Äù.

grows into a ‚Äúbig ball of mud‚Äù

#### Deploy entire app even for small changes.

deploy entire app even for small changes

#### 26.2.1 Python Monolith Example.

26.2.1 Python Monolith Example

#### Flask monolith + SQLAlchemy.

Flask monolith + SQLAlchemy

#### FastAPI monolith with async workers.

FastAPI monolith with async workers

#### 26.2.2 Monolith Deployment Topology flowchart LR Client --> LB[Load Balancer] --> App[Python App Servers] --> DB[(Database)].

26.2.2 Monolith Deployment Topology flowchart LR Client --> LB[Load Balancer] --> App[Python App Servers] --> DB[(Database)]

#### 26.3 Microservices Architecture.

26.3 Microservices Architecture

#### Python is widely used for microservices due to:.

Python is widely used for microservices due to:

#### Lightweight frameworks (FastAPI, Flask).

lightweight frameworks (FastAPI, Flask)

#### Strong async ecosystem.

strong async ecosystem

#### Easy to containerize.

easy to containerize

#### Strong telemetry & tracing.

strong telemetry & tracing

#### Small, cohesive codebases.

small, cohesive codebases

#### Polyglot flexibility.

polyglot flexibility

#### Dependency graph explosion.

dependency graph explosion

#### Inter-service communication latency.

inter-service communication latency

#### 26.3.3 Microservice Topology flowchart LR Client --> API[API Gateway] API --> S1[Service 1] API --> S2[Service 2] API --> S3[Service 3].

26.3.3 Microservice Topology flowchart LR Client --> API[API Gateway] API --> S1[Service 1] API --> S2[Service 2] API --> S3[Service 3]

#### S1 --> DB1[(Database 1)] S2 --> DB2[(Database 2)] S3 --> DB3[(Database 3)].

S1 --> DB1[(Database 1)] S2 --> DB2[(Database 2)] S3 --> DB3[(Database 3)]

#### 26.4 Event-Driven Architecture (EDA).

26.4 Event-Driven Architecture (EDA)

#### Event-driven patterns are ideal for:.

Event-driven patterns are ideal for:

#### Background processing.

background processing

#### Financial transactions.

financial transactions

#### Distributed workflows.

distributed workflows

#### 26.4.1 Typical Event-Driven Flow flowchart LR A[Producers] --> B[Event Bus (Kafka, Redis Streams)] B --> C[Consumers / Workers] C --> D[DB or Servi...

26.4.1 Typical Event-Driven Flow flowchart LR A[Producers] --> B[Event Bus (Kafka, Redis Streams)] B --> C[Consumers / Workers] C --> D[DB or Services]

#### Time-travel debugging via event logs.

time-travel debugging via event logs

#### 26.5 Serverless Architecture.

26.5 Serverless Architecture

#### Python is fully supported by:.

Python is fully supported by:

#### Authentication microservices.

authentication microservices

#### 26.5.1 Serverless Pattern flowchart LR Client --> GW[API Gateway] --> Lambda[Python Lambda Function] --> DB[(Data)].

26.5.1 Serverless Pattern flowchart LR Client --> GW[API Gateway] --> Lambda[Python Lambda Function] --> DB[(Data)]

#### Zero infrastructure management.

zero infrastructure management

#### Scalable to infinity.

scalable to infinity

#### Limited observability.

limited observability

#### 26.6 Hybrid Architectures (Most Common in Python).

26.6 Hybrid Architectures (Most Common in Python)

#### Most production Python systems use hybrid architectures, like:.

Most production Python systems use hybrid architectures, like:

#### Async workers (Celery).

async workers (Celery)

#### Scheduled jobs (APScheduler/Kubernetes Cron).

scheduled jobs (APScheduler/Kubernetes Cron)

#### Distributed caches (Redis).

distributed caches (Redis)

#### Centralized DB or data lake.

centralized DB or data lake

#### 26.7 Deployment Environments 26.7.1 Containers (Docker).

26.7 Deployment Environments 26.7.1 Containers (Docker)

#### The standard for deploying Python services.

The standard for deploying Python services.

#### Predictable dependency resolution.

predictable dependency resolution

#### 26.7.2 Kubernetes (K8s).

26.7.2 Kubernetes (K8s)

#### Most enterprise Python systems deploy via Kubernetes.

Most enterprise Python systems deploy via Kubernetes.

#### Key building blocks:.

Key building blocks:

#### Horizontal Pod Autoscaler.

Horizontal Pod Autoscaler

#### Liveness / Readiness probes.

Liveness / Readiness probes

#### 26.8 Zero-Downtime Deployments.

26.8 Zero-Downtime Deployments

#### Three standard patterns:.

Three standard patterns:

#### 26.8.1 Blue/Green Deployment flowchart TD A[Blue Version] --<-- LB --> B[Green Version].

26.8.1 Blue/Green Deployment flowchart TD A[Blue Version] --<-- LB --> B[Green Version]

#### Traffic switches instantly when green is ready.

Traffic switches instantly when green is ready.

#### 26.8.2 Canary Deployment.

26.8.2 Canary Deployment

#### Deploy 1%, then 5%, then 25%, then 100%.

Deploy 1%, then 5%, then 25%, then 100%.

#### 26.8.3 Rolling Updates (Default in Kubernetes).

26.8.3 Rolling Updates (Default in Kubernetes)

#### Gradually replace pods with new versions.

Gradually replace pods with new versions.

#### 26.9 Global Deployment Patterns 26.9.1 Single Region (Simple).

26.9 Global Deployment Patterns 26.9.1 Single Region (Simple)

#### Low cost, low complexity, but risk of regional outage.

Low cost, low complexity, but risk of regional outage.

#### 26.9.2 Multi-Region Active/Passive.

26.9.2 Multi-Region Active/Passive

#### 26.9.3 Multi-Region Active/Active.

26.9.3 Multi-Region Active/Active

#### Complex but allows global low-latency services.

Complex but allows global low-latency services.

#### Global traffic routing.

global traffic routing

#### Conflict-free replicated data (CRDTs).

conflict-free replicated data (CRDTs)

#### Strong observability.

strong observability

#### Event transformation.

event transformation

#### 26.11 Service Meshes.

26.11 Service Meshes

#### Flowchart LR A[Service A] --> SA[Sidecar Proxy] SA --> SB[Sidecar Proxy] SB --> B[Service B].

flowchart LR A[Service A] --> SA[Sidecar Proxy] SA --> SB[Sidecar Proxy] SB --> B[Service B]

#### 26.12 Caching Layers.

26.12 Caching Layers

#### In-memory cache (LRU).

in-memory cache (LRU)

#### Redis distributed cache.

Redis distributed cache

#### From functools import lru_cache.

from functools import lru_cache

#### @lru_cache(maxsize=1024) def expensive(x): ...

@lru_cache(maxsize=1024) def expensive(x): ...

#### Redis cache example:.

Redis cache example:

#### Redis.setex(key, ttl, value).

redis.setex(key, ttl, value)

#### Replicas (K8s Deployment).

replicas (K8s Deployment)

#### Timeouts and retries.

timeouts and retries

#### 26.14 Graceful Shutdown.

26.14 Graceful Shutdown

#### Def shutdown(*_): print("shutting down...").

def shutdown(*_): print("shutting down...")

#### Signal.signal(signal.SIGTERM, shutdown).

signal.signal(signal.SIGTERM, shutdown)

#### ‚ö† Running apps without health checks ‚ö† Single-instance database ‚ö† Serving static assets from Python API ‚ö† No caching layer ‚ö† Too many microservices...

‚ö† Running apps without health checks ‚ö† Single-instance database ‚ö† Serving static assets from Python API ‚ö† No caching layer ‚ö† Too many microservices prematurely ‚ö† No observability stack ‚ö† Cold-start heavy Python Lambdas ‚ö† Liveness/readiness misconfiguration ‚ö† Tightly coupled services ‚ö† No rollback plan for deployments ‚ö† Missing canary / staging environments

#### 26.16 Macro Example ‚Äî Complete Production Architecture flowchart TD Client --> CDN[CDN/Edge Cache] CDN --> API_GW[API Gateway].

26.16 Macro Example ‚Äî Complete Production Architecture flowchart TD Client --> CDN[CDN/Edge Cache] CDN --> API_GW[API Gateway]

#### API_GW --> FAPI[FastAPI APP] FAPI --> RedisCache[Redis Cache] FAPI --> DB[(PostgreSQL)] FAPI --> MQ[Message Queue (Kafka/Redis Streams)] MQ --> Wor...

API_GW --> FAPI[FastAPI APP] FAPI --> RedisCache[Redis Cache] FAPI --> DB[(PostgreSQL)] FAPI --> MQ[Message Queue (Kafka/Redis Streams)] MQ --> Worker[Celery/Dramatiq Workers] Worker --> Storage[(Data Lake / Warehouse)]

#### FAPI --> Metrics[Prometheus Exporter] FAPI --> Logs[Loki/ELK] FAPI --> Traces[OpenTelemetry Collector].

FAPI --> Metrics[Prometheus Exporter] FAPI --> Logs[Loki/ELK] FAPI --> Traces[OpenTelemetry Collector]

#### Subgraph Observability Metrics --> Grafana Logs --> Grafana Traces --> Jaeger end.

subgraph Observability Metrics --> Grafana Logs --> Grafana Traces --> Jaeger end

#### Subgraph Deployment Layer K8sDeploy[Deployments] HPA[Autoscaling] IngressControllers[Ingress] end.

subgraph Deployment Layer K8sDeploy[Deployments] HPA[Autoscaling] IngressControllers[Ingress] end

#### This is the modern industry-standard Python production topology.

This is the modern industry-standard Python production topology.

#### 26.17 Summary & Takeaways.

26.17 Summary & Takeaways

#### Monoliths are simple, microservices are powerful.

monoliths are simple, microservices are powerful

#### Event-driven architecture is ideal for async workloads.

event-driven architecture is ideal for async workloads

#### Serverless works best for lightweight jobs.

serverless works best for lightweight jobs

#### Hybrid architectures are the real-world norm.

hybrid architectures are the real-world norm

#### Kubernetes is the default orchestration platform.

Kubernetes is the default orchestration platform

#### Zero-downtime deployment requires strategy.

zero-downtime deployment requires strategy

#### Caching and DB replication are mandatory for large scale.

caching and DB replication are mandatory for large scale

#### Observability is essential (logs, metrics, traces).

observability is essential (logs, metrics, traces)

#### Gateway + mesh + K8s is the modern enterprise stack.

gateway + mesh + K8s is the modern enterprise stack

#### <!-- SSM:PART id="part5" title="Part V: Expert & Specialized" -->.

<!-- SSM:PART id="part5" title="Part V: Expert & Specialized" -->

#### # Part V: Expert & Specialized.

# Part V: Expert & Specialized


---

## Chapter 27 ‚Äî FORMAL SEMANTICS & THE PYTHON EXECUTION MODEL

_Difficulty: Advanced_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch27-start" --> üìò CHAPTER 27 ‚Äî FORMAL SEMANTICS & THE PYTHON EXECUTION MODEL üî¥ Advanced.

<!-- SSM:CHUNK_BOUNDARY id="ch27-start" --> üìò CHAPTER 27 ‚Äî FORMAL SEMANTICS & THE PYTHON EXECUTION MODEL üî¥ Advanced

#### Depth Level: 4 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì25, strong CS background.

Depth Level: 4 Python Versions: 3.8 ‚Üí 3.14+ Prerequisites: Chapters 1‚Äì25, strong CS background

#### Most Python developers learn syntax and behavior ‚Äî but very few understand the formal semantics that define why Python behaves the way it does.

Most Python developers learn syntax and behavior ‚Äî but very few understand the formal semantics that define why Python behaves the way it does.

#### This chapter provides:

This chapter provides:

#### Formal operational semantics.

formal operational semantics

#### Theoretical evaluation models.

theoretical evaluation models

#### References to lambda calculus.

references to lambda calculus

#### Abstract machines (CEK, SECD variants).

abstract machines (CEK, SECD variants)

#### Binding and environment models.

binding and environment models

#### The Python Data Model as mathematical objects.

the Python Data Model as mathematical objects

#### Exception propagation semantics.

exception propagation semantics

#### Concurrency semantics (threads, tasks, the GIL).

concurrency semantics (threads, tasks, the GIL)

#### Memory & object lifetime semantics.

memory & object lifetime semantics

#### The goal: Make Python fully explainable as a rigorous programming language with mathematical precision.

The goal: Make Python fully explainable as a rigorous programming language with mathematical precision.

#### 27.1 What Are Formal Semantics?.

27.1 What Are Formal Semantics?

#### Formal semantics explain how a language executes, independent of implementation.

Formal semantics explain how a language executes, independent of implementation.

#### Three classical approaches:.

Three classical approaches:

#### Operational Semantics.

1. Operational Semantics

#### Denotational Semantics.

2. Denotational Semantics

#### Mathematical objects represent program meaning.

Mathematical objects represent program meaning.

#### Axiomatic Semantics.

3. Axiomatic Semantics

#### Python is best described with small-step operational semantics.

Python is best described with small-step operational semantics.

#### 27.2 Python as a State Machine.

27.2 Python as a State Machine

#### Python code is executed as a sequence of state transitions.

Python code is executed as a sequence of state transitions.

#### A program state includes:.

A program state includes:

#### Coroutine/task registry.

coroutine/task registry

#### Formal State Definition:.

**Formal State Definition:**

#### We define a program state using standard operational semantics notation:.

We define a program state using standard operational semantics notation:

#### Each Python statement/expression applies a small-step transition:.

Each Python statement/expression applies a small-step transition:

#### Example: Assignment Statement.

**Example: Assignment Statement**

#### Reference: This follows Plotkin's Structural Operational Semantics (SOS) framework.

**Reference:** This follows Plotkin's Structural Operational Semantics (SOS) framework.

#### 27.3 Evaluation Strategy.

27.3 Evaluation Strategy

#### ‚úî Applicative-order (eager).

‚úî Applicative-order (eager)

#### Arguments are evaluated before the function call.

arguments are evaluated before the function call

#### No laziness except generators & iterators.

no laziness except generators & iterators

#### ‚úî Call-by-value semantics (but values = object references) ‚úî Left-to-right evaluation order.

‚úî Call-by-value semantics (but values = object references) ‚úî Left-to-right evaluation order

#### This is guaranteed by the language spec.

This is guaranteed by the language spec.

#### Example: f(g(), h()).

Example: f(g(), h())

#### Evaluation order is:.

Evaluation order is:

#### Formal Semantics (Small-Step Operational Semantics):.

**Formal Semantics (Small-Step Operational Semantics):**

#### We use standard notation from operational semantics literature (Plotkin, Wright & Felleisen):.

We use standard notation from operational semantics literature (Plotkin, Wright & Felleisen):

#### Complete Evaluation Sequence:.

**Complete Evaluation Sequence:**

#### Reference: This follows the standard small-step operational semantics approach used in: - Plotkin, G. D. (1981).

**Reference:** This follows the standard small-step operational semantics approach used in: - Plotkin, G. D. (1981). "A Structural Approach to Operational Semantics" - Wright, A. K., & Felleisen, M. (1994). "A Syntactic Approach to Type Soundness" - Politz, J. G., et al. (2013). "Python: The Full Monty" (Python semantics work)

#### 27.4 The Python Environment Model.

27.4 The Python Environment Model

#### Python‚Äôs model is a hybrid of:.

Python‚Äôs model is a hybrid of:

#### Dynamic stack frames.

dynamic stack frames

#### Late binding of names in closures.

late binding of names in closures

#### A binding maps a name to an object:.

A binding maps a name to an object:

#### Env = { name ‚Ü¶ object_reference }.

Env = { name ‚Ü¶ object_reference }

#### Every function call creates a new local environment with:.

Every function call creates a new local environment with:

#### 27.5 LEGB Rule as Formal Semantics.

27.5 LEGB Rule as Formal Semantics

#### Formal Name Resolution Semantics:.

**Formal Name Resolution Semantics:**

#### Using standard environment model notation:.

Using standard environment model notation:

#### Environment Concatenation:.

**Environment Concatenation:**

#### 27.6 Closures ‚Äî A Mathematical View.

27.6 Closures ‚Äî A Mathematical View

#### Def outer(x): def inner(y): return x + y return inner.

def outer(x): def inner(y): return x + y return inner

#### Formal Closure Semantics:.

**Formal Closure Semantics:**

#### A closure is a pair of function code and captured environment:.

A closure is a pair of function code and captured environment:

#### Lexical vs Dynamic Scoping:.

**Lexical vs Dynamic Scoping:**

#### Lexical (Python): Environment captured at definition time - Dynamic: Environment from call site (not used in Python).

- **Lexical (Python)**: Environment captured at definition time - **Dynamic**: Environment from call site (not used in Python)

#### Reference: This follows the standard closure semantics from: - Abelson, H., & Sussman, G. J. (1996).

**Reference:** This follows the standard closure semantics from: - Abelson, H., & Sussman, G. J. (1996). "Structure and Interpretation of Computer Programs" - Felleisen, M., et al. (2009). "Semantics Engineering with PLT Redex"

#### 27.7 Python & Lambda Calculus.

27.7 Python & Lambda Calculus

#### Python is not purely functional, but:.

Python is not purely functional, but:

#### Lambdas = anonymous functions.

lambdas = anonymous functions

#### Closures = environments + function bodies.

closures = environments + function bodies

#### Comprehensions = higher-order combinators.

comprehensions = higher-order combinators

#### Decorators = higher-order functions.

decorators = higher-order functions

#### Function application:.

Function application:

#### E)(v) ‚Üí E[x := v].

(Œªx. E)(v) ‚Üí E[x := v]

#### Python function call semantics approximate this, but with:.

Python function call semantics approximate this, but with:

#### References instead of values.

references instead of values

#### 27.8 Python's Type System: Formal View.

27.8 Python's Type System: Formal View

#### Gradually typed (PEP 484+).

gradually typed (PEP 484+)

#### Duck-typed for runtime.

duck-typed for runtime

#### Sound but incomplete (type checkers only approximate truth).

sound but incomplete (type checkers only approximate truth)

#### Formal Type System Semantics:.

**Formal Type System Semantics:**

#### Using standard type theory notation:.

Using standard type theory notation:

#### Type Checker Properties:.

**Type Checker Properties:**

#### Sound but Incomplete: Type checkers reject some valid programs (false positives) - Partial Constraint Solver: mypy, pyright, pyre solve type constr...

- **Sound but Incomplete**: Type checkers reject some valid programs (false positives) - **Partial Constraint Solver**: mypy, pyright, pyre solve type constraints approximately - **Gradual Typing**: Untyped code (Any) can interact with typed code

#### Reference: - Pierce, B. C. (2002).

**Reference:** - Pierce, B. C. (2002). "Types and Programming Languages" - Siek, J., & Taha, W. (2006). "Gradual Typing for Functional Languages"

#### 27.9 The Python Data Model as Algebraic Structures.

27.9 The Python Data Model as Algebraic Structures

#### Equality Semantics:.

**Equality Semantics:**

#### Ordering Semantics (Partial Order):.

**Ordering Semantics (Partial Order):**

#### Hashing Semantics:.

**Hashing Semantics:**

#### Algebraic Structures:.

**Algebraic Structures:**

#### Python objects form various algebraic structures:.

Python objects form various algebraic structures:

#### Sets: {x, y, z} - unordered, unique elements - Mappings: {k: v} - key-value pairs - Sequences: [x, y, z] - ordered, indexed - Iterables: Objects wi...

- **Sets**: `{x, y, z}` - unordered, unique elements - **Mappings**: `{k: v}` - key-value pairs - **Sequences**: `[x, y, z]` - ordered, indexed - **Iterables**: Objects with `__iter__()` method - **Iterators**: Objects with `__next__()` method

#### Formal Structure Definitions:.

**Formal Structure Definitions:**

#### These are algebraic categories.

These are algebraic categories.

#### 27.10 Control Flow Semantics.

27.10 Control Flow Semantics

#### If eval(E1) == true: S1 else: S2.

if eval(E1) == true: S1 else: S2

#### Python uses a combination of:.

Python uses a combination of:

#### Implicit StopIteration.

implicit StopIteration

#### For x in iterable: body.

for x in iterable: body

#### It = iter(iterable) loop: try: x = next(it) body goto loop except StopIteration: pass.

it = iter(iterable) loop: try: x = next(it) body goto loop except StopIteration: pass

#### 27.11 Exception Semantics.

27.11 Exception Semantics

#### Exceptions use stack unwinding.

Exceptions use stack unwinding.

#### State = (Stack, Environment, Exception?).

State = (Stack, Environment, Exception?)

#### When an exception is raised:.

When an exception is raised:

#### ‚ü®raise E, œÉ‚ü© ‚Üí ‚ü®œÉ', Exception(E)‚ü©.

‚ü®raise E, œÉ‚ü© ‚Üí ‚ü®œÉ', Exception(E)‚ü©

#### 27.12 Function Call Semantics (Full Formal Model).

27.12 Function Call Semantics (Full Formal Model)

#### Result = f(a1, a2, ..., an).

result = f(a1, a2, ..., an)

#### Evaluate function expression ‚Üí f.

evaluate function expression ‚Üí f

#### Evaluate args ‚Üí v1..vn.

evaluate args ‚Üí v1..vn

#### 27.13 Generator Semantics (Coroutines in Disguise).

27.13 Generator Semantics (Coroutines in Disguise)

#### Generators implement the resumable function model:.

Generators implement the resumable function model:

#### State = (Code, Env, InstructionPointer, YieldValue).

State = (Code, Env, InstructionPointer, YieldValue)

#### Formal model: ‚ü®yield v, œÉ‚ü© ‚Üí ‚ü®paused(v), œÉ'‚ü©.

Formal model: ‚ü®yield v, œÉ‚ü© ‚Üí ‚ü®paused(v), œÉ'‚ü©

#### This is similar to a CEK machine (Control, Environment, Kontinuation).

This is similar to a CEK machine (Control, Environment, Kontinuation).

#### 27.14 Concurrency Semantics.

27.14 Concurrency Semantics

#### Python has 3 concurrency models:.

Python has 3 concurrency models:

#### Preemptive Threading (GIL-controlled).

1. Preemptive Threading (GIL-controlled)

#### Threads run one at a time under the GIL.

Threads run one at a time under the GIL.

#### Only one bytecode instruction executes at any instant.

only one bytecode instruction executes at any instant

#### Cooperative AsyncIO.

2. Cooperative AsyncIO

#### Coroutines explicitly yield control.

Coroutines explicitly yield control.

#### Await E ‚Üí suspend until E complete.

await E ‚Üí suspend until E complete

#### This forms an event loop machine.

This forms an event loop machine.

#### Independent processes ‚Üí separate interpreter + GIL.

Independent processes ‚Üí separate interpreter + GIL.

#### 27.15 Memory Model & Object Lifetime.

27.15 Memory Model & Object Lifetime

#### Generational garbage collector.

generational garbage collector

#### Object is destroyed when refcount drops to 0.

object is destroyed when refcount drops to 0

#### But objects with __del__ require special handling.

but objects with __del__ require special handling

#### 26.16 Bytecode Semantics (CPython).

26.16 Bytecode Semantics (CPython)

#### Python source ‚Üí AST ‚Üí bytecode ‚Üí interpreter loop.

Python source ‚Üí AST ‚Üí bytecode ‚Üí interpreter loop.

#### IP = Instruction Pointer Stack = Value Stack.

IP = Instruction Pointer Stack = Value Stack

#### Execute(bytecode[i], Stack) ‚Üí Stack' next IP.

execute(bytecode[i], Stack) ‚Üí Stack' next IP

#### Def f(x): return x + 1.

def f(x): return x + 1

#### 26.17 The Interpreter Loop (Eval Loop).

26.17 The Interpreter Loop (Eval Loop)

#### For (;;) { opcode = *ip++; switch(opcode) { case LOAD_CONST: push(const); break; case BINARY_ADD: b = pop(); a = pop(); push(a+b); break; } }.

for (;;) { opcode = *ip++; switch(opcode) { case LOAD_CONST: push(const); break; case BINARY_ADD: b = pop(); a = pop(); push(a+b); break; } }

#### 26.18 Abstract Interpretation (Type Inference).

26.18 Abstract Interpretation (Type Inference)

#### Constructing control-flow graph.

constructing control-flow graph

#### Fixing a least fixed point.

fixing a least fixed point

#### This is how static analyzers reason about dynamic code.

This is how static analyzers reason about dynamic code.

#### 26.19 Pitfalls of Python Semantics.

26.19 Pitfalls of Python Semantics

#### ‚ö† Late binding inside lambdas & loops ‚ö† Mutable default arguments ‚ö† Name resolution surprises ‚ö† Generator close semantics ‚ö† Exception shadowing ‚ö† A...

‚ö† Late binding inside lambdas & loops ‚ö† Mutable default arguments ‚ö† Name resolution surprises ‚ö† Generator close semantics ‚ö† Exception shadowing ‚ö† Async context schedule ordering

#### 26.20 Summary & Takeaways.

26.20 Summary & Takeaways

#### Python‚Äôs semantics can be modeled using formal operational rules.

Python‚Äôs semantics can be modeled using formal operational rules

#### Execution is a sequence of state transitions.

execution is a sequence of state transitions

#### Names resolve via LEGB lexical environments.

names resolve via LEGB lexical environments

#### Closures capture environment frames.

closures capture environment frames

#### Python maps to lambda calculus with side effects.

Python maps to lambda calculus with side effects

#### Bytecode evaluation uses a stack machine.

bytecode evaluation uses a stack machine

#### Generators implement resumable functions.

generators implement resumable functions

#### Concurrency semantics vary by model (threading vs async vs processes).

concurrency semantics vary by model (threading vs async vs processes)

#### Understanding formal semantics enables reliable reasoning about code behavior.

understanding formal semantics enables reliable reasoning about code behavior


---

## Chapter 28 ‚Äî CPython INTERNALS & MEMORY ARCHITECTURE

_Difficulty: Advanced_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch28-start" --> üìò CHAPTER 28 ‚Äî CPython INTERNALS & MEMORY ARCHITECTURE üî¥ Advanced.

<!-- SSM:CHUNK_BOUNDARY id="ch28-start" --> üìò CHAPTER 28 ‚Äî CPython INTERNALS & MEMORY ARCHITECTURE üî¥ Advanced

#### Depth Level: 4 Python Versions: 3.8 ‚Üí 3.14+ (emphasis on 3.11‚Äì3.14) Prerequisites: Chapters 1‚Äì26, C programming familiarity highly recommended.

Depth Level: 4 Python Versions: 3.8 ‚Üí 3.14+ (emphasis on 3.11‚Äì3.14) Prerequisites: Chapters 1‚Äì26, C programming familiarity highly recommended

#### How CPython stores objects.

how CPython stores objects

#### How memory management works.

how memory management works

#### How reference counting is implemented.

how reference counting is implemented

#### How garbage collection handles ref cycles.

how garbage collection handles ref cycles

#### How the PyObject header is structured.

how the PyObject header is structured

#### How lists, dicts, sets, tuples, strings are implemented.

how lists, dicts, sets, tuples, strings are implemented

#### How the interpreter loop works.

how the interpreter loop works

#### How CPython compiles Python code to bytecode.

how CPython compiles Python code to bytecode

#### How the new JIT compiler (3.13+) works.

how the new JIT compiler (3.13+) works

#### How the GIL is implemented.

how the GIL is implemented

#### How function calls work internally.

how function calls work internally

#### How coroutines and generators map to C structures.

how coroutines and generators map to C structures

#### This is the deepest reveal of ‚Äúhow Python really works.‚Äù

This is the deepest reveal of ‚Äúhow Python really works.‚Äù

#### 28.1 CPython as a C Program.

28.1 CPython as a C Program

#### CPython is essentially:.

CPython is essentially:

#### A runtime environment.

a runtime environment

#### A JIT compiler (3.13+).

a JIT compiler (3.13+)

#### The executable python simply embeds the CPython runtime.

The executable python simply embeds the CPython runtime.

#### 28.2 The PyObject Structure.

28.2 The PyObject Structure

#### Every Python object begins with a PyObject header:.

Every Python object begins with a PyObject header:

#### Typedef struct _object { Py_ssize_t ob_refcnt; PyTypeObject *ob_type; } PyObject;.

typedef struct _object { Py_ssize_t ob_refcnt; PyTypeObject *ob_type; } PyObject;

#### Two universal fields:.

Two universal fields:

#### Ob_refcnt ‚Äî reference count.

1. ob_refcnt ‚Äî reference count

#### Controls object lifetime.

Controls object lifetime.

#### Ob_type ‚Äî pointer to type object.

2. ob_type ‚Äî pointer to type object

#### Attribute lookup functions.

attribute lookup functions

#### 28.3 Objects With Value Fields.

28.3 Objects With Value Fields

#### Most built-in types have extended structs:.

Most built-in types have extended structs:

#### Example: integers (PyLongObject).

Example: integers (PyLongObject)

#### Typedef struct { PyObject ob_base; Py_ssize_t ob_size; // number of digits digit ob_digit[1]; // variable-length array } PyLongObject;.

typedef struct { PyObject ob_base; Py_ssize_t ob_size; // number of digits digit ob_digit[1]; // variable-length array } PyLongObject;

#### Strings, lists, dicts, sets‚Ä¶ all have specialized layouts.

Strings, lists, dicts, sets‚Ä¶ all have specialized layouts.

#### 28.4 Memory Allocation in CPython.

28.4 Memory Allocation in CPython

#### CPython uses a layered memory allocator:.

CPython uses a layered memory allocator:

#### Flowchart TD A[CPython Code] --> B[PyObject Arena Allocator] B --> C[obmalloc - object allocator] C --> D[malloc - system allocator].

flowchart TD A[CPython Code] --> B[PyObject Arena Allocator] B --> C[obmalloc - object allocator] C --> D[malloc - system allocator]

#### Obmalloc ‚Äî optimized allocator for small Python objects.

obmalloc ‚Äî optimized allocator for small Python objects

#### Arenas ‚Äî large chunks subdivided into "pools".

arenas ‚Äî large chunks subdivided into "pools"

#### Pools ‚Äî collections of fixed-size blocks.

pools ‚Äî collections of fixed-size blocks

#### Blocks ‚Äî used to store PyObjects.

blocks ‚Äî used to store PyObjects

#### 28.4.1 obmalloc Architecture: Arenas, Pools, Blocks.

28.4.1 obmalloc Architecture: Arenas, Pools, Blocks

#### Memory Allocation Hierarchy:.

Memory Allocation Hierarchy:

#### Size Classes: Blocks are organized by size (8, 16, 24, 32, ..

Size Classes: Blocks are organized by size (8, 16, 24, 32, ... up to 512 bytes)

#### Arenas: 256 KiB (32-bit) or 1 MiB (64-bit) chunks.

Arenas: 256 KiB (32-bit) or 1 MiB (64-bit) chunks

#### Pools: 4 KiB pages within arenas.

Pools: 4 KiB pages within arenas

#### Blocks: Actual allocation units, size-classed.

Blocks: Actual allocation units, size-classed

#### 28.4.2 obmalloc Tuning Knobs.

28.4.2 obmalloc Tuning Knobs

#### Environment variables for debugging and tuning:.

Environment variables for debugging and tuning:

#### Memory profiling with obmalloc:.

Memory profiling with obmalloc:

#### Fragmentation behavior: Long-lived objects can cause memory bloat even when freed, due to pool fragmentation.

Fragmentation behavior: Long-lived objects can cause memory bloat even when freed, due to pool fragmentation. Consider using object pools for frequently allocated/deallocated objects.

#### Reduced fragmentation.

reduced fragmentation

#### 28.5 Reference Counting.

28.5 Reference Counting

#### CPython uses immediate reference counting:.

CPython uses immediate reference counting:

#### Ob_refcnt++ ob_refcnt-- if ob_refcnt == 0: free object.

ob_refcnt++ ob_refcnt-- if ob_refcnt == 0: free object

#### Deterministic destruction.

deterministic destruction

#### Predictable memory use.

predictable memory use

#### Overhead for increment/decrement.

overhead for increment/decrement

#### Poor multi-thread scaling (GIL partly needed).

poor multi-thread scaling (GIL partly needed)

#### Cannot collect cycles alone.

cannot collect cycles alone

#### 28.6 Cycle Detection (Generational GC).

28.6 Cycle Detection (Generational GC)

#### Ref cycles require tracing GC:.

Ref cycles require tracing GC:

#### Objects survive promotions across generations.

Objects survive promotions across generations.

#### Identify containers (Py_TPFLAGS_HAVE_GC).

Identify containers (Py_TPFLAGS_HAVE_GC)

#### Find unreachable cycles.

Find unreachable cycles

#### Generation thresholds control when GC triggers.

Generation thresholds control when GC triggers.

#### 28.7 The GIL (Global Interpreter Lock).

28.7 The GIL (Global Interpreter Lock)

#### The GIL ensures only one thread executes Python bytecode at a time.

The GIL ensures only one thread executes Python bytecode at a time.

#### CPython not thread-safe.

CPython not thread-safe

#### Refcount operations are not atomic.

refcount operations are not atomic

#### Simplifies interpreter engine.

simplifies interpreter engine

#### Thread switching occurs:.

Thread switching occurs:

#### Every N bytecode instructions.

every N bytecode instructions

#### On explicit time.sleep().

on explicit time.sleep()

#### On waiting for locks.

on waiting for locks

#### On releasing/acquiring GIL manually in C extensions.

on releasing/acquiring GIL manually in C extensions

#### 28.8 Python 3.13 Free-Threading Mode.

28.8 Python 3.13 Free-Threading Mode

#### Python 3.13 introduces optional free-threading, removing the GIL.

Python 3.13 introduces optional free-threading, removing the GIL.

#### Atomic refcount operations.

atomic refcount operations

#### Thread-safe object access.

thread-safe object access

#### Lock-free specialized data structures.

lock-free specialized data structures

#### JIT helps reclaim performance.

JIT helps reclaim performance

#### Not yet fully stable for all workloads.

not yet fully stable for all workloads

#### 28.9 Interpreter Architecture.

28.9 Interpreter Architecture

#### CPython execution pipeline:.

CPython execution pipeline:

#### Flowchart TD A[Source Code] --> B[Tokenizer/Lexer] B --> C[Parser ‚Üí AST] C --> D[Bytecode Compiler] D --> E[Optimizer] E --> F[Code Object] F --> G...

flowchart TD A[Source Code] --> B[Tokenizer/Lexer] B --> C[Parser ‚Üí AST] C --> D[Bytecode Compiler] D --> E[Optimizer] E --> F[Code Object] F --> G[Interpreter Loop]

#### 28.10 Tokenizer & Parser Tokenizer:.

28.10 Tokenizer & Parser Tokenizer:

#### Transforms characters ‚Üí tokens Example tokens:.

Transforms characters ‚Üí tokens Example tokens:

#### Based on PEG parser (Python 3.9+).

Based on PEG parser (Python 3.9+).

#### Produces an AST (Abstract Syntax Tree).

Produces an AST (Abstract Syntax Tree).

#### 28.11 Bytecode Compiler.

28.11 Bytecode Compiler

#### AST ‚Üí Control Flow ‚Üí Bytecode.

AST ‚Üí Control Flow ‚Üí Bytecode

#### Allocate locals & cells.

allocate locals & cells

#### LOAD_NAME a LOAD_NAME b BINARY_ADD STORE_NAME x.

LOAD_NAME a LOAD_NAME b BINARY_ADD STORE_NAME x

#### Python stores executable code in PyCodeObject:.

Python stores executable code in PyCodeObject:

#### Typedef struct { PyObject_HEAD int co_argcount; int co_kwonlyargcount; int co_nlocals; PyObject *co_consts; PyObject *co_names; PyObject *co_varnam...

typedef struct { PyObject_HEAD int co_argcount; int co_kwonlyargcount; int co_nlocals; PyObject *co_consts; PyObject *co_names; PyObject *co_varnames; PyObject *co_code; // bytecode sequence } PyCodeObject;

#### A PyFrameObject represents a call frame:.

A PyFrameObject represents a call frame:

#### F_locals f_globals f_builtins f_stack f_code f_back.

f_locals f_globals f_builtins f_stack f_code f_back

#### Frames represent the call stack.

Frames represent the call stack.

#### 28.14 The Evaluation Loop (Bytecode Interpreter).

28.14 The Evaluation Loop (Bytecode Interpreter)

#### Core loop implemented in ceval.c.

Core loop implemented in ceval.c.

#### For (;;) { opcode = *ip++; switch(opcode) { case LOAD_FAST: push(fastlocals[index]); break; case CALL: build stack frame; call function; break; cas...

for (;;) { opcode = *ip++; switch(opcode) { case LOAD_FAST: push(fastlocals[index]); break; case CALL: build stack frame; call function; break; case RETURN_VALUE: return top-of-stack; } }

#### 28.15 Python 3.11+ (Adaptive Interpreter).

28.15 Python 3.11+ (Adaptive Interpreter)

#### Specialized bytecode.

Specialized bytecode

#### Interpreter runs normally.

Interpreter runs normally

#### It measures runtime behavior.

It measures runtime behavior

#### It specializes opcodes (e.g., BINARY_ADD ‚Üí BINARY_ADD_INT).

It specializes opcodes (e.g., BINARY_ADD ‚Üí BINARY_ADD_INT)

#### Writes inline caches into bytecode stream.

Writes inline caches into bytecode stream

#### Future executions become faster.

Future executions become faster

#### 28.16 Python 3.13 JIT Compiler (Tier 2 Execution).

28.16 Python 3.13 JIT Compiler (Tier 2 Execution)

#### Python 3.13 adds baseline JIT (tier 2):.

Python 3.13 adds baseline JIT (tier 2):

#### Flowchart TD A[Tier 0: Interpreter] --> B[Tier 1: Adaptive Interpreter] B --> C[Tier 2: JIT Compiler] C --> D[Native Machine Code].

flowchart TD A[Tier 0: Interpreter] --> B[Tier 1: Adaptive Interpreter] B --> C[Tier 2: JIT Compiler] C --> D[Native Machine Code]

#### Compiles hot bytecode traces.

compiles hot bytecode traces

#### Optimizes function calls.

optimizes function calls

#### Eliminates redundant type checks.

eliminates redundant type checks

#### Inlines small functions.

inlines small functions

#### Supports free-threading.

supports free-threading

#### ‚ö†Ô∏è Real-world benchmarks: The 3.13 experimental JIT typically shows 5‚Äì15% speedups on the standard pyperformance suite.

‚ö†Ô∏è Real-world benchmarks: The 3.13 experimental JIT typically shows 5‚Äì15% speedups on the standard pyperformance suite. Certain micro-benchmarks and hot loops can see larger gains (20‚Äì50%), but I/O-bound and extension-heavy workloads often see little change.

#### JIT warmup time affects short-running scripts.

JIT warmup time affects short-running scripts

#### Benefits are workload-dependent (numeric/control-flow heavy code benefits most).

Benefits are workload-dependent (numeric/control-flow heavy code benefits most)

#### Benchmark your specific workload; don't assume universal speedups.

Benchmark your specific workload; don't assume universal speedups.

#### 28.17 Object Implementations 28.17.1 Lists.

28.17 Object Implementations 28.17.1 Lists

#### Lists are dynamic arrays:.

Lists are dynamic arrays:

#### Roughly 1.125√ó expansion.

roughly 1.125√ó expansion

#### Amortized O(1) append.

amortized O(1) append

#### PyObject** ob_item Py_ssize_t allocated Py_ssize_t size.

PyObject** ob_item Py_ssize_t allocated Py_ssize_t size

#### 28.17.2 Dictionaries.

28.17.2 Dictionaries

#### Dicts use compact hash tables:.

Dicts use compact hash tables:

#### Split-table design (3.6+).

split-table design (3.6+)

#### Perturb-based probing.

perturb-based probing

#### Ma_keys ma_values ma_used ma_version.

ma_keys ma_values ma_used ma_version

#### 28.17.3 Strings (Unicode).

28.17.3 Strings (Unicode)

#### Python uses flexible string representation:.

Python uses flexible string representation:

#### Latin-1 (1 byte per char).

Latin-1 (1 byte per char)

#### Automatic selection based on content.

Automatic selection based on content.

#### Immutable fixed-size arrays.

Immutable fixed-size arrays.

#### Allocated in a single block.

Allocated in a single block.

#### Hash table with open addressing.

Hash table with open addressing.

#### 28.18 Exception Handling Internals.

28.18 Exception Handling Internals

#### Setting thread‚Äôs exception state.

setting thread‚Äôs exception state

#### Unwinding frame chain.

unwinding frame chain

#### Checking handler tables.

checking handler tables

#### Exception state struct:.

Exception state struct:

#### PyObject *exc_type; PyObject *exc_value; PyObject *exc_traceback;.

PyObject *exc_type; PyObject *exc_value; PyObject *exc_traceback;

#### The Python C API exposes:.

The Python C API exposes:

#### Manipulating dictionaries/lists.

manipulating dictionaries/lists

#### Writing custom types.

writing custom types

#### Releasing/acquiring GIL.

releasing/acquiring GIL

#### Embedding Python in C.

embedding Python in C

#### PyObject* result = PyLong_FromLong(123);.

PyObject* result = PyLong_FromLong(123);

#### 28.20 Extension Modules.

28.20 Extension Modules

#### These bypass Python-level overhead.

These bypass Python-level overhead.

#### 28.21 Summary & Takeaways.

28.21 Summary & Takeaways

#### Every Python object is a C struct.

every Python object is a C struct

#### Python uses reference counting + generational GC.

Python uses reference counting + generational GC

#### The GIL exists because CPython's memory model is not thread-safe.

the GIL exists because CPython's memory model is not thread-safe

#### Python‚Äôs bytecode engine is a stack-based VM.

Python‚Äôs bytecode engine is a stack-based VM

#### 3.11 introduced adaptive interpreter optimizations.

3.11 introduced adaptive interpreter optimizations

#### 3.13+ introduces a real JIT compiler.

3.13+ introduces a real JIT compiler

#### Lists/dicts/strings have highly optimized memory layouts.

lists/dicts/strings have highly optimized memory layouts

#### Exceptions use stack unwinding.

exceptions use stack unwinding

#### C API enables native extension modules.

C API enables native extension modules

#### Understanding CPython internals is essential for:.

Understanding CPython internals is essential for:

#### Performance engineering.

performance engineering

#### Debugging deep issues.

debugging deep issues

#### Writing fast extensions.

writing fast extensions

#### Reasoning about concurrency.

reasoning about concurrency

#### Optimizing memory-heavy code.

optimizing memory-heavy code


---

## Chapter 29 ‚Äî ALTERNATIVE PYTHON IMPLEMENTATIONS

_Difficulty: Advanced_

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch29-start" --> üìò CHAPTER 29 ‚Äî ALTERNATIVE PYTHON IMPLEMENTATIONS üî¥ Advanced.

<!-- SSM:CHUNK_BOUNDARY id="ch29-start" --> üìò CHAPTER 29 ‚Äî ALTERNATIVE PYTHON IMPLEMENTATIONS üî¥ Advanced

#### Depth Level: 4 Python Versions Covered: CPython 3.8‚Äì3.14, plus alternative runtimes as of ~2024‚Äì2025 Prerequisites: Chapters 1‚Äì27.

Depth Level: 4 Python Versions Covered: CPython 3.8‚Äì3.14, plus alternative runtimes as of ~2024‚Äì2025 Prerequisites: Chapters 1‚Äì27

#### 29.0 Why Alternative Implementations Exist.

29.0 Why Alternative Implementations Exist

#### The reference implementation.

the reference implementation

#### With a bytecode interpreter + refcount GC.

with a bytecode interpreter + refcount GC

#### But different workloads want:.

But different workloads want:

#### Higher speed (JIT compilation).

higher speed (JIT compilation)

#### Closer integration with another VM (JVM, .NET).

closer integration with another VM (JVM, .NET)

#### Tiny memory footprint (microcontrollers).

tiny memory footprint (microcontrollers)

#### Different concurrency models.

different concurrency models

#### Polyglot interoperability (mix Python with Java, JS, R, etc.) PyPy +1.

polyglot interoperability (mix Python with Java, JS, R, etc.) PyPy +1

#### So multiple Python implementations exist:.

So multiple Python implementations exist:

#### CPython ‚Äì reference, de facto standard.

CPython ‚Äì reference, de facto standard

#### PyPy ‚Äì JIT-compiled, performance-focused.

PyPy ‚Äì JIT-compiled, performance-focused

#### MicroPython / CircuitPython ‚Äì microcontrollers / embedded.

MicroPython / CircuitPython ‚Äì microcontrollers / embedded

#### Jython ‚Äì Python on JVM (mostly 2.x, semi-stagnant).

Jython ‚Äì Python on JVM (mostly 2.x, semi-stagnant)

#### IronPython ‚Äì Python on .NET.

IronPython ‚Äì Python on .NET

#### GraalPy (GraalPython) ‚Äì Python on GraalVM (JVM polyglot) GitHub +1.

GraalPy (GraalPython) ‚Äì Python on GraalVM (JVM polyglot) GitHub +1

#### Strengths / weaknesses.

strengths / weaknesses

#### Real-world use cases.

real-world use cases

#### How to choose between them.

how to choose between them

#### 29.1 CPython ‚Äî The Reference Implementation (Baseline).

29.1 CPython ‚Äî The Reference Implementation (Baseline)

#### You‚Äôve already seen this in Ch.

You‚Äôve already seen this in Ch. 27, but as a quick contrast:

#### Language support: latest Python versions first.

Language support: latest Python versions first

#### Speed: moderate, improving with 3.11‚Äì3.13 adaptive interpreter + JIT.

Speed: moderate, improving with 3.11‚Äì3.13 adaptive interpreter + JIT

#### Extensions: best compatibility with C extensions (NumPy, SciPy, etc.).

Extensions: best compatibility with C extensions (NumPy, SciPy, etc.)

#### Ecosystem: everything targets CPython first.

Ecosystem: everything targets CPython first

#### 29.2 PyPy ‚Äî High-Performance JIT Python 29.2.1 Overview.

29.2 PyPy ‚Äî High-Performance JIT Python 29.2.1 Overview

#### A fast, compliant alternative to CPython.

a fast, compliant alternative to CPython

#### Roughly ~3√ó faster on average for many workloads PyPy +1.

roughly ~3√ó faster on average for many workloads PyPy +1

#### Implemented in RPython (a restricted subset of Python).

implemented in RPython (a restricted subset of Python)

#### Built around a meta-tracing JIT generator doc.pypy.org +1.

built around a meta-tracing JIT generator doc.pypy.org +1

#### JIT compilation for long-running, loop-heavy code.

JIT compilation for long-running, loop-heavy code

#### Different GC (no refcount, purely tracing).

different GC (no refcount, purely tracing)

#### Supports stackless-style lightweight microthreads.

supports stackless-style lightweight microthreads

#### Often lower memory usage for huge heaps.

often lower memory usage for huge heaps

#### Python interpreter written in RPython.

Python interpreter written in RPython

#### RPython toolchain generates C code + JIT compiler.

RPython toolchain generates C code + JIT compiler

#### Meta-tracing JIT: traces hot loops in the interpreter itself, then compiles them to machine code, so it can be reused for other dynamic languages t...

meta-tracing JIT: traces hot loops in the interpreter itself, then compiles them to machine code, so it can be reused for other dynamic languages too aosabook.org

#### 29.2.3 Performance Profile.

29.2.3 Performance Profile

#### Algorithmic code in pure Python.

algorithmic code in pure Python

#### Long-lived processes (JIT warmup pays off) PyPy +1.

long-lived processes (JIT warmup pays off) PyPy +1

#### It may be less ideal when:.

It may be less ideal when:

#### Code spends most time inside C extensions.

code spends most time inside C extensions

#### Startup latency is critical (short scripts).

startup latency is critical (short scripts)

#### 29.2.4 C Extensions Compatibility.

29.2.4 C Extensions Compatibility

#### CPython C-API compatibility has been partial / slower.

CPython C-API compatibility has been partial / slower

#### Better supported via cffi, cppyy for many libs PyPy +1.

Better supported via cffi, cppyy for many libs PyPy +1

#### Pure Python code: PyPy often wins.

Pure Python code: PyPy often wins

#### Heavy NumPy/SciPy stack: CPython or GraalPy is safer (for now).

Heavy NumPy/SciPy stack: CPython or GraalPy is safer (for now)

#### 29.3 MicroPython & CircuitPython ‚Äî Python for Microcontrollers 29.3.1 MicroPython Overview.

29.3 MicroPython & CircuitPython ‚Äî Python for Microcontrollers 29.3.1 MicroPython Overview

#### ‚Äúa lean and efficient implementation of Python 3‚Ä¶ optimized to run on microcontrollers and constrained environments.‚Äù MicroPython +2 Raspberry Pi +2.

‚Äúa lean and efficient implementation of Python 3‚Ä¶ optimized to run on microcontrollers and constrained environments.‚Äù MicroPython +2 Raspberry Pi +2

#### Runs with as little as 256 KB flash, 16 KB RAM MicroPython +1.

runs with as little as 256 KB flash, 16 KB RAM MicroPython +1

#### Implements subset of Python 3 + hardware-specific modules.

implements subset of Python 3 + hardware-specific modules

#### REPL over UART / USB for interactive development.

REPL over UART / USB for interactive development

#### Direct hardware access (GPIO, I¬≤C, SPI, UART, PWM).

direct hardware access (GPIO, I¬≤C, SPI, UART, PWM)

#### IoT sensors / actuators.

IoT sensors / actuators

#### Educational boards (PyBoard, ESP32, RP2040, etc.) MicroPython +2 Raspberry Pi +2.

educational boards (PyBoard, ESP32, RP2040, etc.) MicroPython +2 Raspberry Pi +2

#### 29.3.2 CircuitPython.

29.3.2 CircuitPython

#### Fork of MicroPython, led by Adafruit.

fork of MicroPython, led by Adafruit

#### Strongly geared toward education & beginner-friendliness.

strongly geared toward education & beginner-friendliness

#### Simpler libraries, more batteries-included for sensors / displays.

simpler libraries, more batteries-included for sensors / displays

#### Stricter, slightly slower to adopt advanced features, but easier UX Hackaday +1.

stricter, slightly slower to adopt advanced features, but easier UX Hackaday +1

#### 29.3.3 Compatibility Notes.

29.3.3 Compatibility Notes

#### Not full stdlib; often around 80%+ of common Python features Wikipedia +1.

not full stdlib; often around 80%+ of common Python features Wikipedia +1

#### No heavy CPython C-extensions.

no heavy CPython C-extensions

#### Memory constraints may require more low-level thinking.

memory constraints may require more low-level thinking

#### 29.4 Jython ‚Äî Python on the JVM (‚ö†Ô∏è Status: Legacy/Maintenance Mode).

29.4 Jython ‚Äî Python on the JVM (‚ö†Ô∏è Status: Legacy/Maintenance Mode)

#### Current Status (2025):.

**Current Status (2025):**

#### Jython 2.7.3 (latest stable, Python 2.7 compatible) - Python 3 Support: Experimental work exists but not production-ready - Maintenance: Minimal ac...

- **Jython 2.7.3** (latest stable, Python 2.7 compatible) - **Python 3 Support**: Experimental work exists but **not production-ready** - **Maintenance**: Minimal active development; community-driven maintenance - **Recommendation**: ‚ö†Ô∏è **Not recommended for new projects** ‚Äî use GraalPy instead

#### Historical Context:.

**Historical Context:**

#### Jython was the first major alternative Python implementation, allowing: - Direct integration with Java classes and libraries - Python code running ...

Jython was the first major alternative Python implementation, allowing: - Direct integration with Java classes and libraries - Python code running on JVM (no GIL for Python threads) - Bidirectional interop (Python ‚Üî Java)

#### When Jython Might Still Be Used:.

**When Jython Might Still Be Used:**

#### Legacy Python 2.7 applications on JVM - Existing Jython codebases requiring maintenance - Specific Java integration needs that GraalPy doesn't cove...

- Legacy Python 2.7 applications on JVM - Existing Jython codebases requiring maintenance - Specific Java integration needs that GraalPy doesn't cover (rare)

#### 29.5 IronPython ‚Äî Python on .NET (‚ö†Ô∏è Status: Limited Python 3 Support).

29.5 IronPython ‚Äî Python on .NET (‚ö†Ô∏è Status: Limited Python 3 Support)

#### IronPython 2.7 (stable, Python 2.7 compatible) - IronPython 3.x: Experimental/alpha ‚Äî not production-ready - Development: Slow, community-driven - ...

- **IronPython 2.7** (stable, Python 2.7 compatible) - **IronPython 3.x**: **Experimental/alpha** ‚Äî not production-ready - **Development**: Slow, community-driven - **Recommendation**: ‚ö†Ô∏è **Limited use cases** ‚Äî prefer CPython + pythonnet for most scenarios

#### What IronPython Provides:.

**What IronPython Provides:**

#### When to Use IronPython:.

**When to Use IronPython:**

#### Existing IronPython 2.7 codebases - Specific .NET integration needs that pythonnet doesn't cover - When you need Python as a first-class .NET langu...

- Existing IronPython 2.7 codebases - Specific .NET integration needs that pythonnet doesn't cover - When you need Python as a first-class .NET language (rare)

#### 29.6 GraalPy (GraalPython) ‚Äî High-Performance Python on GraalVM.

29.6 GraalPy (GraalPython) ‚Äî High-Performance Python on GraalVM

#### Python 3.11+ compliant (actively maintained) - Active development by Oracle GraalVM team - Production-ready for many workloads - Best alternative f...

- **Python 3.11+ compliant** (actively maintained) - **Active development** by Oracle GraalVM team - **Production-ready** for many workloads - **Best alternative** for JVM + Python polyglot applications

#### What GraalPy Provides:.

**What GraalPy Provides:**

#### High-performance Python implementation on GraalVM - JIT compilation to fast machine code - Polyglot interop (Python ‚Üî Java/JavaScript/R/WASM) - Ahe...

- High-performance Python implementation on GraalVM - JIT compilation to fast machine code - Polyglot interop (Python ‚Üî Java/JavaScript/R/WASM) - Ahead-of-time (AOT) compilation support - Native image generation for standalone executables

#### Performance Profile:.

**Performance Profile:**

#### CPU-bound workloads: Often 2-5√ó faster than CPython - Some benchmarks: Outperform PyPy on specific workloads - Startup time: Faster than PyPy (espe...

- **CPU-bound workloads**: Often 2-5√ó faster than CPython - **Some benchmarks**: Outperform PyPy on specific workloads - **Startup time**: Faster than PyPy (especially with native images) - **Memory**: Similar or better than CPython

#### Notable Features:.

**Notable Features:**

#### Embed Python into Java apps via Maven/Gradle - Polyglot programming in single GraalVM process - Native image generation (compile to standalone exec...

- Embed Python into Java apps via Maven/Gradle - Polyglot programming in single GraalVM process - Native image generation (compile to standalone executable) - Truffle framework for language interop

#### When to Use GraalPy:.

**When to Use GraalPy:**

#### 29.7 Other Notable Implementations 29.7.1 Pyston (Status: Open-Source, Active Development).

29.7 Other Notable Implementations 29.7.1 Pyston (Status: Open-Source, Active Development)

#### Pyston v2.3+ (actively maintained, open-source) - Python 3.8-3.11 support - Originally: Dropbox project (2014-2017), then abandoned - Revived: Open...

- **Pyston v2.3+** (actively maintained, open-source) - **Python 3.8-3.11** support - **Originally**: Dropbox project (2014-2017), then abandoned - **Revived**: Open-sourced and maintained by community (2020+) - **Status**: Production-ready for compatible workloads

#### What Pyston Provides:.

**What Pyston Provides:**

#### Performance-focused CPython fork with JIT compilation - High CPython compatibility (aims for drop-in replacement) - JIT compiler for hot code paths...

- Performance-focused CPython fork with JIT compilation - High CPython compatibility (aims for drop-in replacement) - JIT compiler for hot code paths - Optimized object model and memory management

#### Typical speedup: 1.5-4√ó faster than CPython on CPU-bound code - Best for: Pure Python workloads, web applications - Compatibility: High (most CPyth...

- **Typical speedup**: 1.5-4√ó faster than CPython on CPU-bound code - **Best for**: Pure Python workloads, web applications - **Compatibility**: High (most CPython code works without changes)

#### ‚ö†Ô∏è C-extension compatibility: Most work, but not 100% ‚ö†Ô∏è Smaller community than PyPy ‚ö†Ô∏è Less mature than PyPy for long-running applications.

‚ö†Ô∏è C-extension compatibility: Most work, but not 100% ‚ö†Ô∏è Smaller community than PyPy ‚ö†Ô∏è Less mature than PyPy for long-running applications

#### Reference: https://github.com/pyston/pyston.

**Reference:** https://github.com/pyston/pyston

#### 29.7.2 Stackless Python (Status: Legacy/Influential).

29.7.2 Stackless Python (Status: Legacy/Influential)

#### Stackless Python 3.8+ (maintained, but limited adoption) - Influence: Concepts inspired asyncio, greenlets, gevent - Status: ‚ö†Ô∏è Limited use ‚Äî conce...

- **Stackless Python 3.8+** (maintained, but limited adoption) - **Influence**: Concepts inspired asyncio, greenlets, gevent - **Status**: ‚ö†Ô∏è **Limited use** ‚Äî concepts absorbed into mainstream Python

#### What Stackless Provides:.

**What Stackless Provides:**

#### Modified CPython with microthreads (tasklets) - Soft switching (cooperative multitasking) - No OS thread overhead for lightweight concurrency - Cha...

- Modified CPython with microthreads (tasklets) - Soft switching (cooperative multitasking) - No OS thread overhead for lightweight concurrency - Channel-based communication between tasklets

#### Historical Significance:.

**Historical Significance:**

#### Influenced modern Python concurrency (asyncio, greenlets) - Concepts adopted by PyPy (stackless mode) - Inspired gevent, eventlet libraries.

- Influenced modern Python concurrency (asyncio, greenlets) - Concepts adopted by PyPy (stackless mode) - Inspired gevent, eventlet libraries

#### Current Relevance:.

**Current Relevance:**

#### Most features: Now available in standard Python (asyncio, generators) - Limited adoption: Most projects use asyncio instead - Still useful: For spe...

- **Most features**: Now available in standard Python (asyncio, generators) - **Limited adoption**: Most projects use asyncio instead - **Still useful**: For specific microthreading needs

#### 29.7.3 RustPython (Status: Experimental/Educational).

29.7.3 RustPython (Status: Experimental/Educational)

#### Python 3.11+ support (partial, improving) - Status: Experimental, not production-ready - Purpose: Educational, research, embedded Python.

- **Python 3.11+** support (partial, improving) - **Status**: Experimental, not production-ready - **Purpose**: Educational, research, embedded Python

#### What RustPython Provides:.

**What RustPython Provides:**

#### Python interpreter written in Rust - Memory safety without GC overhead - Can compile to WebAssembly (runs in browser) - Good for learning Python in...

- Python interpreter written in Rust - Memory safety without GC overhead - Can compile to WebAssembly (runs in browser) - Good for learning Python internals

#### Reference: https://github.com/RustPython/RustPython.

**Reference:** https://github.com/RustPython/RustPython

#### 29.7.4 Pyjion (Status: Deprecated/Historical).

29.7.4 Pyjion (Status: Deprecated/Historical)

#### Historical Note:.

**Historical Note:**

#### Pyjion: JIT compiler for CPython (Microsoft project, 2015-2017) - Status: ‚ö†Ô∏è Deprecated ‚Äî development stopped - Relevance: Historical interest only...

- **Pyjion**: JIT compiler for CPython (Microsoft project, 2015-2017) - **Status**: ‚ö†Ô∏è **Deprecated** ‚Äî development stopped - **Relevance**: Historical interest only; concepts influenced Python 3.13 JIT

#### JIT compiler plugin for CPython - Used .NET CLR JIT for compilation - Experimental performance improvements.

- JIT compiler plugin for CPython - Used .NET CLR JIT for compilation - Experimental performance improvements

#### Why It's Deprecated:.

**Why It's Deprecated:**

#### Development stopped (2017) - Python 3.13 now includes native JIT (different approach) - Limited adoption during its lifetime.

- Development stopped (2017) - Python 3.13 now includes native JIT (different approach) - Limited adoption during its lifetime

#### Reference: Historical only ‚Äî not recommended for use.

**Reference:** Historical only ‚Äî not recommended for use

#### 29.8 Choosing the Right Implementation 29.8.1 Decision Matrix.

29.8 Choosing the Right Implementation 29.8.1 Decision Matrix

#### General-purpose apps / web backends / CLIs.

General-purpose apps / web backends / CLIs

#### üîÅ Consider PyPy if CPU-bound and pure Python.

üîÅ Consider PyPy if CPU-bound and pure Python

#### High-performance, pure-Python numerical code.

High-performance, pure-Python numerical code

#### Heavy C-extension ecosystem (NumPy/SciPy/PyTorch, etc.).

Heavy C-extension ecosystem (NumPy/SciPy/PyTorch, etc.)

#### üîÅ GraalPy (some support, improving; still check compatibility lists) graalvm.org +1.

üîÅ GraalPy (some support, improving; still check compatibility lists) graalvm.org +1

#### JVM shop wants Python scripting & polyglot.

JVM shop wants Python scripting & polyglot

#### üîÅ Jython for legacy 2.x only.

üîÅ Jython for legacy 2.x only

#### üîÅ CPython + pythonnet if you need strict CPython semantics.

üîÅ CPython + pythonnet if you need strict CPython semantics

#### Embedded & microcontrollers.

Embedded & microcontrollers

#### 29.9 Interoperability Patterns 29.9.1 CPython ‚Üî C / C++.

29.9 Interoperability Patterns 29.9.1 CPython ‚Üî C / C++

#### 29.9.2 PyPy ‚Üî Native Code.

29.9.2 PyPy ‚Üî Native Code

#### Prefers cffi / cppyy for best performance and compatibility PyPy +1.

prefers cffi / cppyy for best performance and compatibility PyPy +1

#### 29.9.3 GraalPy Polyglot.

29.9.3 GraalPy Polyglot

#### Call Java, JavaScript, R, WASM from Python and vice versa via Truffle polyglot APIs graalvm.org +1.

call Java, JavaScript, R, WASM from Python and vice versa via Truffle polyglot APIs graalvm.org +1

#### 29.9.4 Jython / IronPython.

29.9.4 Jython / IronPython

#### Map Python classes to JVM/CLR classes directly.

map Python classes to JVM/CLR classes directly

#### Use Python as a first-class scripting language inside those runtimes.

use Python as a first-class scripting language inside those runtimes

#### 29.10 Advanced Considerations: Concurrency & GC.

29.10 Advanced Considerations: Concurrency & GC

#### Alternative implementations differ a lot in:.

Alternative implementations differ a lot in:

#### GC strategy (tracing, generational, moving vs non-moving).

GC strategy (tracing, generational, moving vs non-moving)

#### Threading model (GIL vs no GIL vs VM-native threads).

threading model (GIL vs no GIL vs VM-native threads)

#### Object layout (tagged pointers, compressed headers, etc.).

object layout (tagged pointers, compressed headers, etc.)

#### PyPy: advanced GC, no reference counting; can deliver big wins for memory-heavy workloads where CPython‚Äôs refcount overhead dominates doc.pypy.org +1.

PyPy: advanced GC, no reference counting; can deliver big wins for memory-heavy workloads where CPython‚Äôs refcount overhead dominates doc.pypy.org +1

#### GraalPy: uses GraalVM‚Äôs highly optimized runtime & GC; can JIT Python together with other languages in the same process graalvm.org +1.

GraalPy: uses GraalVM‚Äôs highly optimized runtime & GC; can JIT Python together with other languages in the same process graalvm.org +1

#### MicroPython: minimal, embedded-style memory management optimized for MCUs MicroPython +1.

MicroPython: minimal, embedded-style memory management optimized for MCUs MicroPython +1

#### ‚ö† Assuming all Python implementations behave identically:.

‚ö† Assuming all Python implementations behave identically:

#### Memory model & GC can differ.

memory model & GC can differ

#### Performance characteristics differ drastically.

performance characteristics differ drastically

#### C extensions may not be portable.

C extensions may not be portable

#### ‚ö† Relying on CPython internals:.

‚ö† Relying on CPython internals:

#### Id() assumptions about address.

id() assumptions about address

#### Refcount hacks (e.g., sys.getrefcount).

refcount hacks (e.g., sys.getrefcount)

#### Ctypes tricks that poke into CPython-specific data.

ctypes tricks that poke into CPython-specific data

#### ‚ö† Porting to PyPy / GraalPy without testing:.

‚ö† Porting to PyPy / GraalPy without testing:

#### Performance may drop if most time is inside unsupported C-extensions.

performance may drop if most time is inside unsupported C-extensions

#### You may hit missing or experimental APIs.

you may hit missing or experimental APIs

#### ‚ö† Assuming MicroPython is ‚Äúfull CPython‚Äù:.

‚ö† Assuming MicroPython is ‚Äúfull CPython‚Äù:

#### Blocking APIs / different I/O model.

blocking APIs / different I/O model

#### 29.12 Summary & Takeaways.

29.12 Summary & Takeaways

#### CPython remains the reference and default for most use cases.

CPython remains the reference and default for most use cases.

#### PyPy is your go-to for faster pure-Python CPU-bound workloads.

PyPy is your go-to for faster pure-Python CPU-bound workloads. PyPy +1

#### MicroPython / CircuitPython bring Python to microcontrollers and constrained devices.

MicroPython / CircuitPython bring Python to microcontrollers and constrained devices. MicroPython +2 Raspberry Pi +2

#### Jython / IronPython integrate with legacy JVM / .NET ecosystems, but are less central today.

Jython / IronPython integrate with legacy JVM / .NET ecosystems, but are less central today.

#### GraalPy is emerging as a high-performance, polyglot, JVM-based Python with strong potential in data science and enterprise polyglot stacks.

GraalPy is emerging as a high-performance, polyglot, JVM-based Python with strong potential in data science and enterprise polyglot stacks. GitHub +2 graalvm.org +2

#### Choosing an implementation is a system architecture decision, not just a runtime flag.

Choosing an implementation is a system architecture decision, not just a runtime flag.

#### You now have a high-level (and fairly deep) map of the Python implementation landscape ‚Äî which closes out the theoretical section of the Bible.

You now have a high-level (and fairly deep) map of the Python implementation landscape ‚Äî which closes out the theoretical section of the Bible.

#### üß† CHAPTER 30 ‚Äî Python Programming with AI Agents üî¥ Advanced AI-Assisted Development, Multi-Agent Systems, LLM Engineering & Code Quality Enforcemen...

üß† CHAPTER 30 ‚Äî Python Programming with AI Agents üî¥ Advanced AI-Assisted Development, Multi-Agent Systems, LLM Engineering & Code Quality Enforcement 29.1 ‚Äî Introduction

#### AI agents are transforming software development.

AI agents are transforming software development. Python, with its extensive ecosystem, is the primary language for building:

#### Agentic task pipelines.

agentic task pipelines

#### Automated refactoring tools.

automated refactoring tools

#### Code-generation assistants.

code-generation assistants

#### Autonomous test runners.

autonomous test runners

#### Self-improving systems.

self-improving systems

#### This chapter teaches you how to:

This chapter teaches you how to:

#### Build AI agents in Python.

build AI agents in Python

#### Collaborate with AI agents as a Python developer.

collaborate with AI agents as a Python developer

#### Enforce architectural patterns and avoid hallucination-driven architecture drift.

enforce architectural patterns and avoid hallucination-driven architecture drift

#### Integrate agents into CI/CD, testing, and developer workflows.

integrate agents into CI/CD, testing, and developer workflows

#### This is a Level 3 (Deep Dive) chapter designed for professionals and senior engineers.

This is a Level 3 (Deep Dive) chapter designed for professionals and senior engineers.

#### 29.2 ‚Äî AI Agents in Python: Key Concepts 29.2.1 ‚Äî What Is an AI Agent?.

29.2 ‚Äî AI Agents in Python: Key Concepts 29.2.1 ‚Äî What Is an AI Agent?

#### An AI agent consists of:.

An AI agent consists of:

#### Model (LLM, embedding model).

Model (LLM, embedding model)

#### Memory (vector stores, short-term context).

Memory (vector stores, short-term context)

#### Tools (code execution, web access, DB access).

Tools (code execution, web access, DB access)

#### Planner (task decomposition).

Planner (task decomposition)

#### Environment (runtime + Python integration).

Environment (runtime + Python integration)

#### OpenAI Assistants API.

OpenAI Assistants API

#### AutoGPT-style architectures.

AutoGPT-style architectures

#### CrewAI multi-agent systems.

CrewAI multi-agent systems

#### Custom micro-agents inside real codebases.

Custom micro-agents inside real codebases

#### 29.2.2 ‚Äî Common Agent Architectures 1.

29.2.2 ‚Äî Common Agent Architectures 1. Tool-Based Agents

#### LLM + callable Python functions.

LLM + callable Python functions.

#### Multi-Agent Systems.

2. Multi-Agent Systems

#### Agents with explicit roles:.

Agents with explicit roles:

#### Reflection-Based Agents.

3. Reflection-Based Agents

#### Agents that reason about past actions (‚Äúreflection loop‚Äù).

Agents that reason about past actions (‚Äúreflection loop‚Äù).

#### Self-Healing Systems.

4. Self-Healing Systems

#### Agents that detect & fix bugs automatically.

Agents that detect & fix bugs automatically.

#### 29.3 ‚Äî Best Practices for Using AI in Python Development.

29.3 ‚Äî Best Practices for Using AI in Python Development

#### This section covers DOs and DON‚ÄôTs for AI-assisted Python development.

This section covers DOs and DON‚ÄôTs for AI-assisted Python development.

#### 29.3.1 ‚Äî DO: Provide Context Before Code Generation.

29.3.1 ‚Äî DO: Provide Context Before Code Generation

#### AI-generated code quality increases dramatically when you give:.

AI-generated code quality increases dramatically when you give:

#### Project folder structure.

project folder structure

#### 29.3.2 ‚Äî DO: Ask for Step-by-Step Reasoning (but not in code).

29.3.2 ‚Äî DO: Ask for Step-by-Step Reasoning (but not in code)

#### ‚úî ‚ÄúExplain before coding‚Äù ‚úî ‚ÄúIdentify edge cases first‚Äù ‚úî ‚ÄúPropose an API before implementing it‚Äù.

‚úî ‚ÄúExplain before coding‚Äù ‚úî ‚ÄúIdentify edge cases first‚Äù ‚úî ‚ÄúPropose an API before implementing it‚Äù

#### ‚úò letting AI jump straight into final code with no design phase ‚úò accepting code without verifying tests and patterns.

‚úò letting AI jump straight into final code with no design phase ‚úò accepting code without verifying tests and patterns

#### 29.3.3 ‚Äî DO: Use Python-Styled Prompts.

29.3.3 ‚Äî DO: Use Python-Styled Prompts

#### ‚ÄúMake a thing that loads data I guess.‚Äù.

‚ÄúMake a thing that loads data I guess.‚Äù

#### Implement a Python module: - Path: app/services/data_loader.py - Function: load_csv_file(path: str) -> list[dict[str, Any]] - Requirements: - Use c...

Implement a Python module: - Path: `app/services/data_loader.py` - Function: `load_csv_file(path: str) -> list[dict[str, Any]]` - Requirements: - Use `csv.DictReader` - Raise custom exceptions - Include type hints - Include integration test in `tests/test_data_loader.py`

#### Ruff (fastest, all-in-one).

ruff (fastest, all-in-one)

#### Mypy (static typing).

mypy (static typing)

#### Pyright (strict mode).

pyright (strict mode)

#### Run checks automatically via pre-commit hooks.

Run checks automatically via pre-commit hooks.

#### 29.3.5 ‚Äî DON‚ÄôT: Trust AI to Manage State or Architecture Alone.

29.3.5 ‚Äî DON‚ÄôT: Trust AI to Manage State or Architecture Alone

#### AI agents often hallucinate:.

AI agents often hallucinate:

#### Nonexistent functions.

nonexistent functions

#### Inaccurate tutorials.

inaccurate tutorials

#### Real file system listing.

real file system listing

#### Exact folder structure.

exact folder structure

#### 29.4 ‚Äî AI-Generated Code Cleanup & Refactoring.

29.4 ‚Äî AI-Generated Code Cleanup & Refactoring

#### AI-generated code contains predictable patterns of errors.

AI-generated code contains predictable patterns of errors.

#### This section shows how to detect & fix them programmatically.

This section shows how to detect & fix them programmatically.

#### Missing edge cases.

üö® 2. Missing edge cases

#### Overly generic exceptions except Exception:.

üö® 3. Overly generic exceptions except Exception:

#### Redundant code duplication.

üö® 5. Redundant code duplication

#### Multiple versions of same function.

multiple versions of same function

#### 29.4.2 ‚Äî Pattern-Based Cleanup Pass.

29.4.2 ‚Äî Pattern-Based Cleanup Pass

#### Remove unused imports.

Remove unused imports

#### Collapse duplicate code blocks.

Collapse duplicate code blocks

#### Ensure type hints everywhere.

Ensure type hints everywhere

#### Convert magic numbers ‚Üí named constants.

Convert magic numbers ‚Üí named constants

#### Enforce pure functions where possible.

Enforce pure functions where possible

#### Add logging for critical paths.

Add logging for critical paths

#### Replace bare except with explicit exceptions.

Replace bare except with explicit exceptions

#### Generate tests for safety-critical paths.

Generate tests for safety-critical paths

#### Validate database session handling.

Validate database session handling

#### 29.4.3 ‚Äî Refactor Example üü° AI-Generated Code (Buggy) def load_data(file): import json, os f = open(file) dt = json.loads(f.read()) f.close() retur...

29.4.3 ‚Äî Refactor Example üü° AI-Generated Code (Buggy) def load_data(file): import json, os f = open(file) dt = json.loads(f.read()) f.close() return dt

#### üü¢ Cleaned, Pythonic Version from pathlib import Path import json from typing import Any.

üü¢ Cleaned, Pythonic Version from pathlib import Path import json from typing import Any

#### Def load_data(path: str | Path) -> dict[str, Any]: path = Path(path) if not path.exists(): raise FileNotFoundError(path).

def load_data(path: str | Path) -> dict[str, Any]: path = Path(path) if not path.exists(): raise FileNotFoundError(path)

#### With path.open("r", encoding="utf-8") as f: return json.load(f).

with path.open("r", encoding="utf-8") as f: return json.load(f)

#### 29.5 ‚Äî Building Python AI Agents.

29.5 ‚Äî Building Python AI Agents

#### This section covers how to build your own agents in Python.

This section covers how to build your own agents in Python.

#### 29.5.2 ‚Äî Example: Simple Tool-Driven Agent (OpenAI) from openai import OpenAI client = OpenAI().

29.5.2 ‚Äî Example: Simple Tool-Driven Agent (OpenAI) from openai import OpenAI client = OpenAI()

#### Response = client.chat.completions.create( model="gpt-4o", messages=[{"role": "user", "content": "Add 9 and 14"}], tools=tools ).

response = client.chat.completions.create( model="gpt-4o", messages=[{"role": "user", "content": "Add 9 and 14"}], tools=tools )

#### 29.5.3 ‚Äî Multi-Agent Python Architecture.

29.5.3 ‚Äî Multi-Agent Python Architecture

#### Role-Based Multi-Agent System:.

**Role-Based Multi-Agent System:**

#### A production multi-agent system coordinates specialized agents, each with distinct responsibilities:.

A production multi-agent system coordinates specialized agents, each with distinct responsibilities:

#### Complete Multi-Agent Implementation:.

**Complete Multi-Agent Implementation:**

#### ReAct Pattern Implementation:.

**ReAct Pattern Implementation:**

#### ReAct (Reasoning + Acting) is a powerful pattern for tool-using agents:.

ReAct (Reasoning + Acting) is a powerful pattern for tool-using agents:

#### Using LangChain for Multi-Agent Systems:.

**Using LangChain for Multi-Agent Systems:**

#### Using CrewAI for Role-Based Agents:.

**Using CrewAI for Role-Based Agents:**

#### Try This: Build a code cleanup agent system:.

**Try This:** Build a code cleanup agent system:

#### 29.5.4 ‚Äî Tool-Calling Agent with Real Python Tools.

29.5.4 ‚Äî Tool-Calling Agent with Real Python Tools

#### Production-Ready Tool Agent:.

**Production-Ready Tool Agent:**

#### 29.5.5 ‚Äî Error Recovery Patterns for LLM Failures.

29.5.5 ‚Äî Error Recovery Patterns for LLM Failures

#### Resilient Agent with Error Recovery:.

**Resilient Agent with Error Recovery:**

#### 29.5.6 ‚Äî Cost & Latency Optimization.

29.5.6 ‚Äî Cost & Latency Optimization

#### Optimized Agent with Caching and Batching:.

**Optimized Agent with Caching and Batching:**

#### Try This: Build a cost-optimized code review agent:.

**Try This:** Build a cost-optimized code review agent:

#### 29.5.7 ‚Äî LangChain Integration.

29.5.7 ‚Äî LangChain Integration

#### Using LangChain for Production Agents:.

**Using LangChain for Production Agents:**

#### LangChain with Vector Store Memory:.

**LangChain with Vector Store Memory:**

#### 29.5.8 ‚Äî LlamaIndex Integration.

29.5.8 ‚Äî LlamaIndex Integration

#### Using LlamaIndex for Codebase-Aware Agents:.

**Using LlamaIndex for Codebase-Aware Agents:**

#### LlamaIndex with Custom Tools:.

**LlamaIndex with Custom Tools:**

#### 29.6 ‚Äî Testing AI-Generated Code.

29.6 ‚Äî Testing AI-Generated Code

#### 1. Snapshot Testing:

**1. Snapshot Testing:**

#### 2. Behavioral Testing:

**2. Behavioral Testing:**

#### Lint + Type Checks:.

**3. Lint + Type Checks:**

#### 4. Adversarial Testing:

**4. Adversarial Testing:**

#### 29.7 ‚Äî Ensuring Safety in Agentic Python Code Avoid.

29.7 ‚Äî Ensuring Safety in Agentic Python Code Avoid

#### Unvalidated URL fetches.

unvalidated URL fetches

#### Writing files outside sandbox.

writing files outside sandbox

#### Unbounded recursive planning loops.

unbounded recursive planning loops

#### Arbitrary code execution.

arbitrary code execution

#### ‚ÄúExplain your design before coding.‚Äù.

‚ÄúExplain your design before coding.‚Äù

#### 29.8.4 ‚Äî Use LLMs to generate complicated boilerplate.

29.8.4 ‚Äî Use LLMs to generate complicated boilerplate

#### 29.9 ‚Äî Real-World Example: AI Agent Refactor Workflow.

29.9 ‚Äî Real-World Example: AI Agent Refactor Workflow

#### Developer writes spec.

Developer writes spec

#### AI proposes module design.

AI proposes module design

#### Reviewer agent checks compliance with architecture.

Reviewer agent checks compliance with architecture

#### Code generation agent writes implementation.

Code generation agent writes implementation

#### Test agent generates tests.

Test agent generates tests

#### Linter/tooling agent fixes style.

Linter/tooling agent fixes style

#### Security agent scans for vulnerabilities.

Security agent scans for vulnerabilities

#### CI runs full test suite.

CI runs full test suite

#### This is top-tier modern software development.

This is top-tier modern software development.

#### 29.10 ‚Äî Key Takeaways.

29.10 ‚Äî Key Takeaways

#### AI is a power tool, not a replacement for engineering judgment.

AI is a power tool, not a replacement for engineering judgment

#### Python is ideal for agentic systems.

Python is ideal for agentic systems

#### Multi-agent workflows outperform single-agent ones.

Multi-agent workflows outperform single-agent ones

#### Safe, deterministic, reproducible output is the goal.

Safe, deterministic, reproducible output is the goal

#### Collects all Python design patterns.

Collects all Python design patterns

#### Includes Pythonic variants + Gang-of-Four equivalents.

Includes Pythonic variants + Gang-of-Four equivalents

#### Includes micro examples, mini examples, and real-world usage notes.

Includes micro examples, mini examples, and real-world usage notes

#### Uses modern Python (3.10‚Äì3.14) features:.

Uses modern Python (3.10‚Äì3.14) features:

#### Concurrency-safe patterns.

Concurrency-safe patterns

#### This is Depth Level 2‚Äì3.

This is Depth Level 2‚Äì3.

#### üìò APPENDIX A ‚Äî PYTHON PATTERN DICTIONARY.

üìò APPENDIX A ‚Äî PYTHON PATTERN DICTIONARY

#### Depth Level: 2‚Äì3 Python Versions: 3.9‚Äì3.14+ Contains micro/mini examples, best practices, and anti-patterns.

Depth Level: 2‚Äì3 Python Versions: 3.9‚Äì3.14+ Contains micro/mini examples, best practices, and anti-patterns.

#### Python design patterns differ from classical OOP patterns because:.

Python design patterns differ from classical OOP patterns because:

#### Python supports first-class functions.

Python supports first-class functions

#### Python has dynamic types.

Python has dynamic types

#### Python favors duck typing and composability.

Python favors duck typing and composability

#### Many ‚Äúpatterns‚Äù are built into the language (e.g., iterator).

Many ‚Äúpatterns‚Äù are built into the language (e.g., iterator)

#### Simpler constructs often replace classical GOF patterns.

Simpler constructs often replace classical GOF patterns

#### Micro Examples (5‚Äì10 lines).

Micro Examples (5‚Äì10 lines)

#### Mini Examples (20‚Äì40 lines).

Mini Examples (20‚Äì40 lines)

#### Version tags (e.g., [3.10+]).

Version tags (e.g., [3.10+])

#### When to Use: - Database connection pools (shared resource) - Configuration managers (single source of truth) - Logging systems (centralized).

**When to Use:** - Database connection pools (shared resource) - Configuration managers (single source of truth) - Logging systems (centralized)

#### When NOT to Use: - Most application code (use dependency injection instead) - Testable code (singletons make testing harder) - Multi-threaded code ...

**When NOT to Use:** - Most application code (use dependency injection instead) - Testable code (singletons make testing harder) - Multi-threaded code (unless thread-safe)

#### Python rarely needs singletons ‚Äî modules already act as singletons.

Python rarely needs singletons ‚Äî modules already act as singletons.

#### ‚úî Proper Pythonic Singleton (Module Singleton).

‚úî **Proper Pythonic Singleton (Module Singleton)**

#### This is the most Pythonic approach.

**This is the most Pythonic approach.**

#### ‚úî Class-Based Singleton (When Needed).

‚úî **Class-Based Singleton (When Needed)**

#### Mini Example: Thread-Safe Singleton with Metaclass.

**Mini Example: Thread-Safe Singleton with Metaclass**

#### Python-Specific Considerations: - Modules are already singletons (import caching) - Use __new__ for class-based singletons - Make thread-safe if us...

**Python-Specific Considerations:** - Modules are already singletons (import caching) - Use `__new__` for class-based singletons - Make thread-safe if used in multi-threaded code - Consider `functools.lru_cache` for function-level singletons

#### When to Use: - Creating objects based on runtime conditions - Hiding object creation complexity - Supporting multiple implementations - Plugin syst...

**When to Use:** - Creating objects based on runtime conditions - Hiding object creation complexity - Supporting multiple implementations - Plugin systems

#### When NOT to Use: - Simple object creation (just use __init__) - When type is known at compile time - Over-engineering simple cases.

**When NOT to Use:** - Simple object creation (just use `__init__`) - When type is known at compile time - Over-engineering simple cases

#### ‚úî Simple Factory (Pythonic).

‚úî **Simple Factory (Pythonic)**

#### Uses pattern matching ‚Üí clean & readable.

**Uses pattern matching ‚Üí clean & readable.**

#### ‚úî Factory with Callables (Most Pythonic).

‚úî **Factory with Callables (Most Pythonic)**

#### This is the most Pythonic version - simple and extensible.

**This is the most Pythonic version - simple and extensible.**

#### ‚úî Abstract Factory (with Protocols).

‚úî **Abstract Factory (with Protocols)**

#### Mini Example: Realistic Factory with Configuration.

**Mini Example: Realistic Factory with Configuration**

#### Python-Specific Considerations: - Use match/case for pattern matching (Python 3.10+) - Dict of callables is often simpler than class hierarchy - Pr...

**Python-Specific Considerations:** - Use `match/case` for pattern matching (Python 3.10+) - Dict of callables is often simpler than class hierarchy - Protocols enable structural typing without inheritance - `functools.partial` for parameterized factories

#### Used for constructing complex objects step-by-step.

Used for constructing complex objects step-by-step.

#### ‚úî Idiomatic Python Builder (Fluent API) class QueryBuilder: def __init__(self): self.parts = [].

‚úî Idiomatic Python Builder (Fluent API) class QueryBuilder: def __init__(self): self.parts = []

#### Def where(self, x): self.parts.append(f"WHERE {x}") return self.

def where(self, x): self.parts.append(f"WHERE {x}") return self

#### Def limit(self, n): self.parts.append(f"LIMIT {n}") return self.

def limit(self, n): self.parts.append(f"LIMIT {n}") return self

#### Def build(self): return " ".join(self.parts).

def build(self): return " ".join(self.parts)

#### Q = QueryBuilder().where("age > 20").limit(10).build().

q = QueryBuilder().where("age > 20").limit(10).build()

#### A.4 Strategy Pattern ‚úî Functional Strategies (Most Pythonic) def add(a, b): return a + b def mul(a, b): return a * b.

A.4 Strategy Pattern ‚úî Functional Strategies (Most Pythonic) def add(a, b): return a + b def mul(a, b): return a * b

#### Def compute(strategy, x, y): return strategy(x, y).

def compute(strategy, x, y): return strategy(x, y)

#### ‚úî Class-Based Strategy.

‚úî Class-Based Strategy

#### Class Strategy(Protocol): def execute(self, x, y): ...

class Strategy(Protocol): def execute(self, x, y): ...

#### Class Add: def execute(self, x, y): return x + y.

class Add: def execute(self, x, y): return x + y

#### Wraps incompatible interfaces.

Wraps incompatible interfaces.

#### ‚úî Pythonic Adapter class FileAdapter: def __init__(self, f): self.f = f.

‚úî Pythonic Adapter class FileAdapter: def __init__(self, f): self.f = f

#### Def read_all(self): return self.f.read().

def read_all(self): return self.f.read()

#### A.6 Observer / Pub-Sub Pattern ‚úî Lightweight Observer class Event: def __init__(self): self.handlers = [].

A.6 Observer / Pub-Sub Pattern ‚úî Lightweight Observer class Event: def __init__(self): self.handlers = []

#### Def subscribe(self, fn): self.handlers.append(fn).

def subscribe(self, fn): self.handlers.append(fn)

#### Def emit(self, data): for h in self.handlers: h(data).

def emit(self, data): for h in self.handlers: h(data)

#### ‚úî Async Observer ([asyncio]) class AsyncEvent: def __init__(self): self.handlers = [].

‚úî Async Observer ([asyncio]) class AsyncEvent: def __init__(self): self.handlers = []

#### Async def emit(self, data): for h in self.handlers: await h(data).

async def emit(self, data): for h in self.handlers: await h(data)

#### Represent actions as objects.

Represent actions as objects.

#### ‚úî Minimal Pythonic Version class Command(Protocol): def execute(self) -> None: ...

‚úî Minimal Pythonic Version class Command(Protocol): def execute(self) -> None: ...

#### Class SaveFile: def __init__(self, file): self.file = file def execute(self): self.file.save().

class SaveFile: def __init__(self, file): self.file = file def execute(self): self.file.save()

#### A.8 Decorator Pattern (Python-native).

A.8 Decorator Pattern (Python-native)

#### (Not to be confused with function decorators).

(Not to be confused with function decorators)

#### Used to wrap behavior without modifying original class.

Used to wrap behavior without modifying original class.

#### Python already has decorator syntax ‚Äî this is the OOP pattern.

Python already has decorator syntax ‚Äî this is the OOP pattern.

#### ‚úî Example class Service: def run(self): return "running".

‚úî Example class Service: def run(self): return "running"

#### Class LoggingDecorator: def __init__(self, svc): self.svc = svc.

class LoggingDecorator: def __init__(self, svc): self.svc = svc

#### Def run(self): print("log: run") return self.svc.run().

def run(self): print("log: run") return self.svc.run()

#### Control access to an object.

Control access to an object.

#### ‚úî Simple Proxy class CachedProxy: def __init__(self, target): self.target = target self.cache = {}.

‚úî Simple Proxy class CachedProxy: def __init__(self, target): self.target = target self.cache = {}

#### Def compute(self, x): if x not in self.cache: self.cache[x] = self.target.compute(x) return self.cache[x].

def compute(self, x): if x not in self.cache: self.cache[x] = self.target.compute(x) return self.cache[x]

#### Great for state machines.

Great for state machines.

#### ‚úî Classic State Machine class State(Protocol): def handle(self, ctx): ...

‚úî Classic State Machine class State(Protocol): def handle(self, ctx): ...

#### Class Running: def handle(self, ctx): ctx.state = Stopped().

class Running: def handle(self, ctx): ctx.state = Stopped()

#### Class Stopped: def handle(self, ctx): ctx.state = Running().

class Stopped: def handle(self, ctx): ctx.state = Running()

#### Class Context: def __init__(self): self.state = Stopped().

class Context: def __init__(self): self.state = Stopped()

#### Ctx = Context() ctx.state.handle(ctx).

ctx = Context() ctx.state.handle(ctx)

#### A.11 Middleware Pattern (Web Frameworks) ‚úî WSGI/ASGI-style middleware async def middleware(request, handler): print("before") response = await hand...

A.11 Middleware Pattern (Web Frameworks) ‚úî WSGI/ASGI-style middleware async def middleware(request, handler): print("before") response = await handler(request) print("after") return response

#### This pattern appears everywhere in:

This pattern appears everywhere in:

#### A.12 Dependency Injection Pattern.

A.12 Dependency Injection Pattern

#### When to Use: - Testing (easy to mock dependencies) - Complex dependency graphs - Lifecycle management (singleton, transient, scoped) - Framework in...

**When to Use:** - Testing (easy to mock dependencies) - Complex dependency graphs - Lifecycle management (singleton, transient, scoped) - Framework integration (FastAPI, Django)

#### When NOT to Use: - Simple scripts - Small applications - When Python's simplicity is preferred.

**When NOT to Use:** - Simple scripts - Small applications - When Python's simplicity is preferred

#### Python does not require DI containers, but they're useful for larger applications.

Python does not require DI containers, but they're useful for larger applications.

#### ‚úî Simple DI Container.

‚úî **Simple DI Container**

#### Mini Example: Realistic DI with Type Hints.

**Mini Example: Realistic DI with Type Hints**

#### Advanced: Auto-Wiring with Type Inspection.

**Advanced: Auto-Wiring with Type Inspection**

#### Python-Specific Considerations: - Use Protocol for interface definitions (structural typing) - Type hints enable auto-wiring - functools.partial fo...

**Python-Specific Considerations:** - Use Protocol for interface definitions (structural typing) - Type hints enable auto-wiring - `functools.partial` for partial dependency injection - FastAPI's Depends() is built-in DI for web frameworks

#### A.13 Iterator Pattern (built into Python).

A.13 Iterator Pattern (built into Python)

#### Python is iterator-first.

Python is iterator-first.

#### ‚úî Custom Iterator class Countdown: def __init__(self, n): self.n = n def __iter__(self): return self def __next__(self): if self.n <= 0: raise Stop...

‚úî Custom Iterator class Countdown: def __init__(self, n): self.n = n def __iter__(self): return self def __next__(self): if self.n <= 0: raise StopIteration self.n -= 1 return self.n

#### A.14 Context Manager Pattern ‚úî Using class-based version class FileManager: def __init__(self, path): self.path = path.

A.14 Context Manager Pattern ‚úî Using class-based version class FileManager: def __init__(self, path): self.path = path

#### Def __enter__(self): self.f = open(self.path) return self.f.

def __enter__(self): self.f = open(self.path) return self.f

#### Def __exit__(self, *args): self.f.close().

def __exit__(self, *args): self.f.close()

#### A.15 Repository Pattern.

A.15 Repository Pattern

#### Used in backend apps to abstract DB logic.

Used in backend apps to abstract DB logic.

#### ‚úî Minimal Example class UserRepo: def __init__(self, db): self.db = db.

‚úî Minimal Example class UserRepo: def __init__(self, db): self.db = db

#### Def get(self, id): return self.db.fetch(id) def create(self, data): return self.db.insert(data).

def get(self, id): return self.db.fetch(id) def create(self, data): return self.db.insert(data)

#### A.16 Service Layer Pattern.

A.16 Service Layer Pattern

#### Wraps business logic outside controllers/handlers.

Wraps business logic outside controllers/handlers.

#### Class BillingService: def __init__(self, repo): self.repo = repo.

class BillingService: def __init__(self, repo): self.repo = repo

#### Def charge(self, user_id, amount): user = self.repo.get(user_id) ...

def charge(self, user_id, amount): user = self.repo.get(user_id) ...

#### Functional & simpler solutions often work better.

Functional & simpler solutions often work better.

#### Modules already serve as singletons.

Modules already serve as singletons.

#### Prefer higher-order functions unless stateful.

Prefer higher-order functions unless stateful.

#### Favor dataclasses, composition, and protocols.

Favor dataclasses, composition, and protocols.

#### This appendix gives you:

This appendix gives you:

#### All key patterns developers rely on.

all key patterns developers rely on

#### Pythonic modern forms of classical patterns.

Pythonic modern forms of classical patterns

#### Guidance on when not to use them.

guidance on when not to use them

#### Idiomatic examples using modern Python features.

idiomatic examples using modern Python features

#### This appendix contains fully working, end-to-end, production-grade code examples. These are not...

This appendix contains fully working, end-to-end, production-grade code examples. These are not snippets, but complete programs, following:

#### Modern Python architecture.

modern Python architecture

#### Type hints everywhere.

type hints everywhere

#### Modern packaging structure (pyproject.toml).

modern packaging structure (pyproject.toml)

#### Async support where appropriate.

async support where appropriate

#### Professional logging patterns.

professional logging patterns

#### Pydantic / FastAPI / SQLAlchemy 2.0 / asyncio.

Pydantic / FastAPI / SQLAlchemy 2.0 / asyncio

#### Full folder structures + runnable files.

full folder structures + runnable files

#### Real-world configurations.

real-world configurations

#### Comments and explanations.

comments and explanations

#### This is Depth Level 3, containing:

This is Depth Level 3, containing:

#### Mini Examples (20‚Äì60 lines).

Mini Examples (20‚Äì60 lines)

#### Macro Examples (100‚Äì250+ lines).

Macro Examples (100‚Äì250+ lines)

#### Mega Examples (300‚Äì600+ lines).

Mega Examples (300‚Äì600+ lines)

#### Let‚Äôs begin with the Macro & Mega examples.

Let‚Äôs begin with the Macro & Mega examples.

#### üìò APPENDIX B ‚Äî THE PYTHON CODE LIBRARY (MACRO + MEGA EXAMPLES).

üìò APPENDIX B ‚Äî THE PYTHON CODE LIBRARY (MACRO + MEGA EXAMPLES)

#### Depth Level: 3 Complete runnable applications included.

Depth Level: 3 Complete runnable applications included

#### This appendix contains:

This appendix contains:

#### Macro Examples (100‚Äì250 lines).

Macro Examples (100‚Äì250 lines)

#### REST API with FastAPI (async).

REST API with FastAPI (async)

#### SQLAlchemy 2.0 async database model + repository pattern.

SQLAlchemy 2.0 async database model + repository pattern

#### CLI Application with Click.

CLI Application with Click

#### Worker Queue (Celery + Redis).

Worker Queue (Celery + Redis)

#### Async Background Tasks (asyncio, task groups).

Async Background Tasks (asyncio, task groups)

#### Configuration system (Pydantic V2).

Configuration system (Pydantic V2)

#### Logging system with structlog.

Logging system with structlog

#### Web Scraper (aiohttp + BeautifulSoup).

Web Scraper (aiohttp + BeautifulSoup)

#### Scheduled job version.

scheduled job version

#### Production FastAPI Application.

Production FastAPI Application

#### SQLAlchemy 2.0 async engine.

SQLAlchemy 2.0 async engine

#### Services, repositories, models.

services, repositories, models

#### Async Microservice + Worker + Event Bus (Kafka/Redis Streams).

Async Microservice + Worker + Event Bus (Kafka/Redis Streams)

#### Data Processing Notebook Example (pandas, numpy, plotly).

Data Processing Notebook Example (pandas, numpy, plotly)

#### Distributed Task Pipeline (Celery + FastAPI + PG).

Distributed Task Pipeline (Celery + FastAPI + PG)

#### We will generate ALL of these, one by one.

We will generate ALL of these, one by one.

#### ‚≠ê B.1 MACRO EXAMPLE #1 ‚Äî FastAPI REST API (Complete Application).

‚≠ê B.1 MACRO EXAMPLE #1 ‚Äî FastAPI REST API (Complete Application)

#### 100‚Äì200 lines Fully runnable.

100‚Äì200 lines Fully runnable. Uses:

#### B.1.0 Folder Structure fastapi_app/ ‚îÇ ‚îú‚îÄ app/ ‚îÇ ‚îú‚îÄ main.py ‚îÇ ‚îú‚îÄ api/ ‚îÇ ‚îÇ ‚îú‚îÄ __init__.py ‚îÇ ‚îÇ ‚îú‚îÄ router.py ‚îÇ ‚îÇ ‚îî‚îÄ models.py ‚îÇ ‚îú‚îÄ core/ ‚îÇ ‚îÇ ‚îú‚îÄ config....

B.1.0 Folder Structure fastapi_app/ ‚îÇ ‚îú‚îÄ app/ ‚îÇ ‚îú‚îÄ main.py ‚îÇ ‚îú‚îÄ api/ ‚îÇ ‚îÇ ‚îú‚îÄ __init__.py ‚îÇ ‚îÇ ‚îú‚îÄ router.py ‚îÇ ‚îÇ ‚îî‚îÄ models.py ‚îÇ ‚îú‚îÄ core/ ‚îÇ ‚îÇ ‚îú‚îÄ config.py ‚îÇ ‚îÇ ‚îî‚îÄ logging.py ‚îÇ ‚îî‚îÄ services/ ‚îÇ ‚îî‚îÄ users.py ‚îÇ ‚îî‚îÄ pyproject.toml

#### B.1.1 pyproject.toml [project] name = "fastapi-app" version = "0.1.0" dependencies = [ "fastapi", "uvicorn[standard]", "pydantic", ].

B.1.1 pyproject.toml [project] name = "fastapi-app" version = "0.1.0" dependencies = [ "fastapi", "uvicorn[standard]", "pydantic", ]

#### [tool.uvicorn] host = "127.0.0.1" port = 8000.

[tool.uvicorn] host = "127.0.0.1" port = 8000

#### B.1.2 app/core/config.py ‚Äî Settings from pydantic import BaseModel.

B.1.2 app/core/config.py ‚Äî Settings from pydantic import BaseModel

#### Class Settings(BaseModel): app_name: str = "FastAPI Example" debug: bool = True.

class Settings(BaseModel): app_name: str = "FastAPI Example" debug: bool = True

#### B.1.3 app/core/logging.py ‚Äî Logging import logging.

B.1.3 app/core/logging.py ‚Äî Logging import logging

#### Def setup_logging(): logging.basicConfig( level=logging.INFO, format="%(levelname)s | %(asctime)s | %(name)s | %(message)s", ).

def setup_logging(): logging.basicConfig( level=logging.INFO, format="%(levelname)s | %(asctime)s | %(name)s | %(message)s", )

#### Logger = logging.getLogger("fastapi-app").

logger = logging.getLogger("fastapi-app")

#### B.1.4 app/api/models.py ‚Äî Pydantic Models from pydantic import BaseModel, Field.

B.1.4 app/api/models.py ‚Äî Pydantic Models from pydantic import BaseModel, Field

#### Class UserIn(BaseModel): email: str = Field(..., example="test@example.com") name: str = Field(...).

class UserIn(BaseModel): email: str = Field(..., example="test@example.com") name: str = Field(...)

#### Class User(BaseModel): id: int email: str name: str.

class User(BaseModel): id: int email: str name: str

#### B.1.5 app/services/users.py ‚Äî Service Layer from typing import List from app.api.models import User, UserIn.

B.1.5 app/services/users.py ‚Äî Service Layer from typing import List from app.api.models import User, UserIn

#### Class UserService: def __init__(self): self._users = [] self._id_counter = 1.

class UserService: def __init__(self): self._users = [] self._id_counter = 1

#### Def create(self, user_in: UserIn) -> User: user = User(id=self._id_counter, **user_in.model_dump()) self._users.append(user) self._id_counter += 1 ...

def create(self, user_in: UserIn) -> User: user = User(id=self._id_counter, **user_in.model_dump()) self._users.append(user) self._id_counter += 1 return user

#### Def list_users(self) -> List[User]: return self._users.

def list_users(self) -> List[User]: return self._users

#### B.1.6 app/api/router.py ‚Äî API Router from fastapi import APIRouter, Depends from app.api.models import User, UserIn from app.services.users import ...

B.1.6 app/api/router.py ‚Äî API Router from fastapi import APIRouter, Depends from app.api.models import User, UserIn from app.services.users import UserService

#### Router = APIRouter().

router = APIRouter()

#### Def get_user_service(): return UserService().

def get_user_service(): return UserService()

#### @router.post("/users", response_model=User) def create_user(user: UserIn, svc: UserService = Depends(get_user_service)): return svc.create(user).

@router.post("/users", response_model=User) def create_user(user: UserIn, svc: UserService = Depends(get_user_service)): return svc.create(user)

#### @router.get("/users", response_model=list[User]) def list_users(svc: UserService = Depends(get_user_service)): return svc.list_users().

@router.get("/users", response_model=list[User]) def list_users(svc: UserService = Depends(get_user_service)): return svc.list_users()

#### B.1.7 app/main.py ‚Äî Application Entrypoint from fastapi import FastAPI from app.core.logging import setup_logging, logger from app.core.config impo...

B.1.7 app/main.py ‚Äî Application Entrypoint from fastapi import FastAPI from app.core.logging import setup_logging, logger from app.core.config import settings from app.api.router import router

#### App = FastAPI(title=settings.app_name) app.include_router(router).

app = FastAPI(title=settings.app_name) app.include_router(router)

#### @app.on_event("startup") async def on_startup(): logger.info("Application starting...").

@app.on_event("startup") async def on_startup(): logger.info("Application starting...")

#### @app.get("/") async def root(): return {"status": "ok"}.

@app.get("/") async def root(): return {"status": "ok"}

#### B.1.8 Running the API uvicorn app.main:app --reload.

B.1.8 Running the API uvicorn app.main:app --reload

#### GET http://127.0.0.1:8000/ POST http://127.0.0.1:8000/users GET http://127.0.0.1:8000/users.

GET http://127.0.0.1:8000/ POST http://127.0.0.1:8000/users GET http://127.0.0.1:8000/users

#### ‚≠ê B.2 MACRO EXAMPLE #2 ‚Äî SQLAlchemy 2.0 Async ORM + FastAPI.

‚≠ê B.2 MACRO EXAMPLE #2 ‚Äî SQLAlchemy 2.0 Async ORM + FastAPI

#### Approx. 150‚Äì200 lines.

Approx. 150‚Äì200 lines.

#### Async SQLAlchemy 2.0.

Async SQLAlchemy 2.0

#### Databases with PostgreSQL.

Databases with PostgreSQL

#### Pydantic schema mapping.

Pydantic schema mapping

#### B.2.0 Folder Structure sqlalchemy_app/ ‚îÇ ‚îú‚îÄ app/ ‚îÇ ‚îú‚îÄ db.py ‚îÇ ‚îú‚îÄ models.py ‚îÇ ‚îú‚îÄ repositories.py ‚îÇ ‚îú‚îÄ schemas.py ‚îÇ ‚îú‚îÄ api.py ‚îÇ ‚îú‚îÄ main.py ‚îÇ ‚îî‚îÄ pypro...

B.2.0 Folder Structure sqlalchemy_app/ ‚îÇ ‚îú‚îÄ app/ ‚îÇ ‚îú‚îÄ db.py ‚îÇ ‚îú‚îÄ models.py ‚îÇ ‚îú‚îÄ repositories.py ‚îÇ ‚îú‚îÄ schemas.py ‚îÇ ‚îú‚îÄ api.py ‚îÇ ‚îú‚îÄ main.py ‚îÇ ‚îî‚îÄ pyproject.toml

#### B.2.1 pyproject.toml [project] dependencies = [ "fastapi", "uvicorn[standard]", "sqlalchemy>=2.0", "asyncpg", "pydantic", ].

B.2.1 pyproject.toml [project] dependencies = [ "fastapi", "uvicorn[standard]", "sqlalchemy>=2.0", "asyncpg", "pydantic", ]

#### B.2.2 app/db.py ‚Äî Database Engine (Async) from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker.

B.2.2 app/db.py ‚Äî Database Engine (Async) from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker

#### DATABASE_URL = "postgresql+asyncpg://user:pass@localhost:5432/mydb".

DATABASE_URL = "postgresql+asyncpg://user:pass@localhost:5432/mydb"

#### Engine = create_async_engine(DATABASE_URL, echo=True) SessionLocal = async_sessionmaker(engine, expire_on_commit=False).

engine = create_async_engine(DATABASE_URL, echo=True) SessionLocal = async_sessionmaker(engine, expire_on_commit=False)

#### B.2.3 app/models.py ‚Äî Database Models from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column.

B.2.3 app/models.py ‚Äî Database Models from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column

#### Class User(Base): __tablename__ = "users".

class User(Base): __tablename__ = "users"

#### Id: Mapped[int] = mapped_column(primary_key=True) email: Mapped[str] name: Mapped[str].

id: Mapped[int] = mapped_column(primary_key=True) email: Mapped[str] name: Mapped[str]

#### B.2.4 app/schemas.py ‚Äî Pydantic Models from pydantic import BaseModel.

B.2.4 app/schemas.py ‚Äî Pydantic Models from pydantic import BaseModel

#### Class UserCreate(BaseModel): email: str name: str.

class UserCreate(BaseModel): email: str name: str

#### Class UserOut(BaseModel): id: int email: str name: str.

class UserOut(BaseModel): id: int email: str name: str

#### B.2.5 app/repositories.py ‚Äî Repository Layer from sqlalchemy import select from app.models import User from sqlalchemy.ext.asyncio import AsyncSess...

B.2.5 app/repositories.py ‚Äî Repository Layer from sqlalchemy import select from app.models import User from sqlalchemy.ext.asyncio import AsyncSession from app.schemas import UserCreate, UserOut

#### Class UserRepository: def __init__(self, session: AsyncSession): self.session = session.

class UserRepository: def __init__(self, session: AsyncSession): self.session = session

#### Async def create(self, data: UserCreate) -> UserOut: user = User(**data.model_dump()) self.session.add(user) await self.session.commit() await self...

async def create(self, data: UserCreate) -> UserOut: user = User(**data.model_dump()) self.session.add(user) await self.session.commit() await self.session.refresh(user) return UserOut.model_validate(user)

#### Async def list(self): stmt = select(User) res = await self.session.execute(stmt) users = res.scalars().all() return [UserOut.model_validate(u) for ...

async def list(self): stmt = select(User) res = await self.session.execute(stmt) users = res.scalars().all() return [UserOut.model_validate(u) for u in users]

#### B.2.6 app/api.py ‚Äî API Router from fastapi import APIRouter, Depends from app.db import SessionLocal from sqlalchemy.ext.asyncio import AsyncSessio...

B.2.6 app/api.py ‚Äî API Router from fastapi import APIRouter, Depends from app.db import SessionLocal from sqlalchemy.ext.asyncio import AsyncSession from app.repositories import UserRepository from app.schemas import UserCreate, UserOut

#### Async def get_session() -> AsyncSession: async with SessionLocal() as session: yield session.

async def get_session() -> AsyncSession: async with SessionLocal() as session: yield session

#### @router.post("/users", response_model=UserOut) async def create_user( data: UserCreate, session: AsyncSession = Depends(get_session), ): repo = Use...

@router.post("/users", response_model=UserOut) async def create_user( data: UserCreate, session: AsyncSession = Depends(get_session), ): repo = UserRepository(session) return await repo.create(data)

#### @router.get("/users", response_model=list[UserOut]) async def list_users( session: AsyncSession = Depends(get_session), ): repo = UserRepository(se...

@router.get("/users", response_model=list[UserOut]) async def list_users( session: AsyncSession = Depends(get_session), ): repo = UserRepository(session) return await repo.list()

#### B.2.7 app/main.py from fastapi import FastAPI from app.api import router from app.models import Base from app.db import engine.

B.2.7 app/main.py from fastapi import FastAPI from app.api import router from app.models import Base from app.db import engine

#### @app.on_event("startup") async def startup(): async with engine.begin() as conn: await conn.run_sync(Base.metadata.create_all).

@app.on_event("startup") async def startup(): async with engine.begin() as conn: await conn.run_sync(Base.metadata.create_all)

#### app.include_router(router)

app.include_router(router)

#### üìò APPENDIX B ‚Äî PYTHON CODE LIBRARY (CONTINUED) Index (so far).

üìò APPENDIX B ‚Äî PYTHON CODE LIBRARY (CONTINUED) Index (so far)

#### B.1 FastAPI REST API (basic).

B.1 FastAPI REST API (basic)

#### B.2 FastAPI + SQLAlchemy Async ORM.

B.2 FastAPI + SQLAlchemy Async ORM

#### B.4 Celery Worker + API Trigger.

B.4 Celery Worker + API Trigger

#### B.5 Async Background Task Runner (asyncio).

B.5 Async Background Task Runner (asyncio)

#### B.6 Structured Logging System (logging + structlog).

B.6 Structured Logging System (logging + structlog)

#### B.7 Async Web Scraper (aiohttp + BeautifulSoup).

B.7 Async Web Scraper (aiohttp + BeautifulSoup)

#### B.8 Configuration System (pydantic-settings).

B.8 Configuration System (pydantic-settings)

#### B.9 Mega Example #1 ‚Äì ETL Pipeline (full stack).

B.9 Mega Example #1 ‚Äì ETL Pipeline (full stack)

#### I‚Äôll cover B.3‚ÄìB.8 now, then start B.9.

I‚Äôll cover B.3‚ÄìB.8 now, then start B.9.

#### ‚≠ê B.3 MACRO EXAMPLE ‚Äî CLI TOOL WITH CLICK.

‚≠ê B.3 MACRO EXAMPLE ‚Äî CLI TOOL WITH CLICK

#### A complete, testable CLI app.

A complete, testable CLI app.

#### B.3.0 Folder Structure cli_tool/ ‚îÇ ‚îú‚îÄ cli_app/ ‚îÇ ‚îú‚îÄ __init__.py ‚îÇ ‚îî‚îÄ cli.py ‚îî‚îÄ pyproject.toml.

B.3.0 Folder Structure cli_tool/ ‚îÇ ‚îú‚îÄ cli_app/ ‚îÇ ‚îú‚îÄ __init__.py ‚îÇ ‚îî‚îÄ cli.py ‚îî‚îÄ pyproject.toml

#### B.3.1 pyproject.toml [project] name = "cli-tool" version = "0.1.0" dependencies = ["click"].

B.3.1 pyproject.toml [project] name = "cli-tool" version = "0.1.0" dependencies = ["click"]

#### [project.scripts] cli-tool = "cli_app.cli:main".

[project.scripts] cli-tool = "cli_app.cli:main"

#### B.3.2 cli_app/cli.py import click from pathlib import Path import json from typing import Optional.

B.3.2 cli_app/cli.py import click from pathlib import Path import json from typing import Optional

#### @click.group() def main() -> None: """CLI Tool ‚Äì simple task manager.""".

@click.group() def main() -> None: """CLI Tool ‚Äì simple task manager."""

#### @main.command() @click.argument("name") @click.option("--project", "-p", default="default", help="Project name") def add(name: str, project: str) -...

@main.command() @click.argument("name") @click.option("--project", "-p", default="default", help="Project name") def add(name: str, project: str) -> None: """Add a new task.""" data = _load_db() tasks = data.setdefault(project, []) tasks.append({"name": name, "done": False}) _save_db(data) click.echo(f"Added task '{name}' to project '{project}'.")

#### @main.command() @click.option("--project", "-p", default="default", help="Project name") @click.option("--all", "show_all", is_flag=True, help="Sho...

@main.command() @click.option("--project", "-p", default="default", help="Project name") @click.option("--all", "show_all", is_flag=True, help="Show completed too") def list(project: str, show_all: bool) -> None: """List tasks.""" data = _load_db() tasks = data.get(project, []) for idx, t in enumerate(tasks, start=1): if not show_all and t["done"]: continue mark = "‚úî" if t["done"] else "‚úó" click.echo(f"{idx}. [{mark}] {t['name']}")

#### @main.command() @click.argument("index", type=int) @click.option("--project", "-p", default="default", help="Project name") def done(index: int, pr...

@main.command() @click.argument("index", type=int) @click.option("--project", "-p", default="default", help="Project name") def done(index: int, project: str) -> None: """Mark a task as done (by index).""" data = _load_db() tasks = data.get(project, []) if not (1 <= index <= len(tasks)): raise click.ClickException("Invalid task index") tasks[index - 1]["done"] = True _save_db(data) click.echo(f"Marked task #{index} as done.")

#### DB_PATH = Path.home() / ".cli_tool_tasks.json".

DB_PATH = Path.home() / ".cli_tool_tasks.json"

#### Def _load_db() -> dict: if not DB_PATH.exists(): return {} return json.loads(DB_PATH.read_text(encoding="utf8")).

def _load_db() -> dict: if not DB_PATH.exists(): return {} return json.loads(DB_PATH.read_text(encoding="utf8"))

#### Def _save_db(data: dict) -> None: DB_PATH.write_text(json.dumps(data, indent=2), encoding="utf8").

def _save_db(data: dict) -> None: DB_PATH.write_text(json.dumps(data, indent=2), encoding="utf8")

#### Pip install -e.

pip install -e . cli-tool add "Write docs" cli-tool list cli-tool done 1 cli-tool list --all

#### ‚≠ê B.4 MACRO EXAMPLE ‚Äî CELERY WORKER + FASTAPI TRIGGER.

‚≠ê B.4 MACRO EXAMPLE ‚Äî CELERY WORKER + FASTAPI TRIGGER

#### Minimal but realistic task queue pattern.

Minimal but realistic task queue pattern.

#### B.4.0 Folder Structure celery_app/ ‚îÇ ‚îú‚îÄ app/ ‚îÇ ‚îú‚îÄ main.py # FastAPI ‚îÇ ‚îú‚îÄ celery_app.py # Celery config ‚îÇ ‚îî‚îÄ tasks.py # Celery tasks ‚îî‚îÄ pyproject.toml.

B.4.0 Folder Structure celery_app/ ‚îÇ ‚îú‚îÄ app/ ‚îÇ ‚îú‚îÄ main.py # FastAPI ‚îÇ ‚îú‚îÄ celery_app.py # Celery config ‚îÇ ‚îî‚îÄ tasks.py # Celery tasks ‚îî‚îÄ pyproject.toml

#### B.4.1 pyproject.toml [project] dependencies = [ "fastapi", "uvicorn[standard]", "celery[redis]", ].

B.4.1 pyproject.toml [project] dependencies = [ "fastapi", "uvicorn[standard]", "celery[redis]", ]

#### B.4.2 app/celery_app.py from celery import Celery.

B.4.2 app/celery_app.py from celery import Celery

#### Celery_app = Celery( "example", broker="redis://localhost:6379/0", backend="redis://localhost:6379/1", ).

celery_app = Celery( "example", broker="redis://localhost:6379/0", backend="redis://localhost:6379/1", )

#### Celery_app.conf.task_routes = {"app.tasks.*": {"queue": "default"}}.

celery_app.conf.task_routes = {"app.tasks.*": {"queue": "default"}}

#### B.4.3 app/tasks.py from time import sleep from app.celery_app import celery_app.

B.4.3 app/tasks.py from time import sleep from app.celery_app import celery_app

#### @celery_app.task(bind=True, max_retries=3) def send_email(self, to: str, subject: str, body: str) -> str: """Fake email sender with retry.""" try: ...

@celery_app.task(bind=True, max_retries=3) def send_email(self, to: str, subject: str, body: str) -> str: """Fake email sender with retry.""" try: sleep(2) print(f"Sent email to {to}: {subject}") return "ok" except Exception as exc: # noqa: BLE001 raise self.retry(exc=exc, countdown=10)

#### B.4.4 app/main.py from fastapi import FastAPI from app.tasks import send_email.

B.4.4 app/main.py from fastapi import FastAPI from app.tasks import send_email

#### @app.post("/send_email") async def trigger_email(to: str, subject: str, body: str): task = send_email.delay(to, subject, body) return {"task_id": t...

@app.post("/send_email") async def trigger_email(to: str, subject: str, body: str): task = send_email.delay(to, subject, body) return {"task_id": task.id, "status": "queued"}

#### Celery -A app.celery_app.celery_app worker -l info uvicorn app.main:app --reload.

celery -A app.celery_app.celery_app worker -l info uvicorn app.main:app --reload

#### ‚≠ê B.5 MACRO EXAMPLE ‚Äî ASYNC BACKGROUND TASK RUNNER (asyncio + TaskGroup).

‚≠ê B.5 MACRO EXAMPLE ‚Äî ASYNC BACKGROUND TASK RUNNER (asyncio + TaskGroup)

#### Demonstrates task grouping, cancellation & error handling (Python 3.11+).

Demonstrates task grouping, cancellation & error handling (Python 3.11+).

#### Import asyncio from typing import Iterable.

import asyncio from typing import Iterable

#### Async def fetch(url: str) -> str: await asyncio.sleep(0.1) return f"data-from-{url}".

async def fetch(url: str) -> str: await asyncio.sleep(0.1) return f"data-from-{url}"

#### Async def worker(name: str, queue: "asyncio.Queue[str]") -> None: while True: url = await queue.get() try: data = await fetch(url) print(f"{name} p...

async def worker(name: str, queue: "asyncio.Queue[str]") -> None: while True: url = await queue.get() try: data = await fetch(url) print(f"{name} processed {url} -> {data}") finally: queue.task_done()

#### Async def run_pipeline(urls: Iterable[str], concurrency: int = 5) -> None: queue: asyncio.Queue[str] = asyncio.Queue() for u in urls: await queue.p...

async def run_pipeline(urls: Iterable[str], concurrency: int = 5) -> None: queue: asyncio.Queue[str] = asyncio.Queue() for u in urls: await queue.put(u)

#### Async with asyncio.TaskGroup() as tg: for i in range(concurrency): tg.create_task(worker(f"worker-{i}", queue)) await queue.join() # Cancel workers...

async with asyncio.TaskGroup() as tg: for i in range(concurrency): tg.create_task(worker(f"worker-{i}", queue)) await queue.join() # Cancel workers: for _ in range(concurrency): queue.put_nowait("") # sentinel

#### If __name__ == "__main__": asyncio.run(run_pipeline([f"https://example.com/{i}" for i in range(10)])).

if __name__ == "__main__": asyncio.run(run_pipeline([f"https://example.com/{i}" for i in range(10)]))

#### ‚≠ê B.6 MACRO EXAMPLE ‚Äî STRUCTURED LOGGING SYSTEM (logging + structlog) B.6.1 Setup pip install structlog.

‚≠ê B.6 MACRO EXAMPLE ‚Äî STRUCTURED LOGGING SYSTEM (logging + structlog) B.6.1 Setup pip install structlog

#### B.6.2 logging_setup.py import logging import structlog.

B.6.2 logging_setup.py import logging import structlog

#### Def setup_logging() -> None: logging.basicConfig( format="%(message)s", level=logging.INFO, ).

def setup_logging() -> None: logging.basicConfig( format="%(message)s", level=logging.INFO, )

#### Structlog.configure( wrapper_class=structlog.make_filtering_bound_logger(logging.INFO), processors=[ structlog.processors.add_log_level, structlog....

structlog.configure( wrapper_class=structlog.make_filtering_bound_logger(logging.INFO), processors=[ structlog.processors.add_log_level, structlog.processors.TimeStamper(fmt="iso"), structlog.processors.JSONRenderer(), ], )

#### Logger = structlog.get_logger("app").

logger = structlog.get_logger("app")

#### B.6.3 usage_example.py from logging_setup import setup_logging, logger.

B.6.3 usage_example.py from logging_setup import setup_logging, logger

#### If __name__ == "__main__": setup_logging() logger.info("startup", service="billing", version="1.0.0") logger.warning("payment_failed", user_id=123,...

if __name__ == "__main__": setup_logging() logger.info("startup", service="billing", version="1.0.0") logger.warning("payment_failed", user_id=123, amount=19.99)

#### {"event": "startup", "service": "billing", "version": "1.0.0", "level": "info", "timestamp": "..."}.

{"event": "startup", "service": "billing", "version": "1.0.0", "level": "info", "timestamp": "..."}

#### ‚≠ê B.7 MACRO EXAMPLE ‚Äî ASYNC WEB SCRAPER (aiohttp + BeautifulSoup) B.7.1 Install Dependencies pip install aiohttp beautifulsoup4.

‚≠ê B.7 MACRO EXAMPLE ‚Äî ASYNC WEB SCRAPER (aiohttp + BeautifulSoup) B.7.1 Install Dependencies pip install aiohttp beautifulsoup4

#### B.7.2 async_scraper.py import asyncio from typing import Iterable.

B.7.2 async_scraper.py import asyncio from typing import Iterable

#### Import aiohttp from bs4 import BeautifulSoup.

import aiohttp from bs4 import BeautifulSoup

#### Async def fetch_html(session: aiohttp.ClientSession, url: str) -> str: async with session.get(url, timeout=10) as resp: resp.raise_for_status() ret...

async def fetch_html(session: aiohttp.ClientSession, url: str) -> str: async with session.get(url, timeout=10) as resp: resp.raise_for_status() return await resp.text()

#### Async def parse_title(html: str) -> str: soup = BeautifulSoup(html, "html.parser") title = soup.find("title") return title.text.strip() if title el...

async def parse_title(html: str) -> str: soup = BeautifulSoup(html, "html.parser") title = soup.find("title") return title.text.strip() if title else "<no-title>"

#### Async def scrape(urls: Iterable[str]) -> None: async with aiohttp.ClientSession() as session: tasks = [] for url in urls: tasks.append(_scrape_one(...

async def scrape(urls: Iterable[str]) -> None: async with aiohttp.ClientSession() as session: tasks = [] for url in urls: tasks.append(_scrape_one(session, url)) await asyncio.gather(*tasks)

#### Async def _scrape_one(session: aiohttp.ClientSession, url: str) -> None: try: html = await fetch_html(session, url) title = await parse_title(html)...

async def _scrape_one(session: aiohttp.ClientSession, url: str) -> None: try: html = await fetch_html(session, url) title = await parse_title(html) print(f"{url} -> {title}") except Exception as exc: # noqa: BLE001 print(f"Error scraping {url}: {exc}")

#### If __name__ == "__main__": urls = [ "https://www.python.org", "https://fastapi.tiangolo.com", "https://pypi.org", ] asyncio.run(scrape(urls)).

if __name__ == "__main__": urls = [ "https://www.python.org", "https://fastapi.tiangolo.com", "https://pypi.org", ] asyncio.run(scrape(urls))

#### ‚≠ê B.8 MACRO EXAMPLE ‚Äî CONFIGURATION SYSTEM (pydantic-settings) B.8.1 Install pip install pydantic-settings.

‚≠ê B.8 MACRO EXAMPLE ‚Äî CONFIGURATION SYSTEM (pydantic-settings) B.8.1 Install pip install pydantic-settings

#### B.8.2 settings.py from pydantic_settings import BaseSettings from pydantic import AnyUrl.

B.8.2 settings.py from pydantic_settings import BaseSettings from pydantic import AnyUrl

#### Class Settings(BaseSettings): env: str = "local" database_url: AnyUrl redis_url: AnyUrl | None = None debug: bool = False.

class Settings(BaseSettings): env: str = "local" database_url: AnyUrl redis_url: AnyUrl | None = None debug: bool = False

#### Class Config: env_file = ".env" env_file_encoding = "utf-8".

class Config: env_file = ".env" env_file_encoding = "utf-8"

#### DATABASE_URL=postgresql://user:pass@localhost:5432/app REDIS_URL=redis://localhost:6379/0 DEBUG=true.

DATABASE_URL=postgresql://user:pass@localhost:5432/app REDIS_URL=redis://localhost:6379/0 DEBUG=true

#### B.8.3 usage_example.py from settings import settings.

B.8.3 usage_example.py from settings import settings

#### Def main() -> None: print("Environment:", settings.env) print("DB:", settings.database_url) print("Debug:", settings.debug).

def main() -> None: print("Environment:", settings.env) print("DB:", settings.database_url) print("Debug:", settings.debug)

#### ‚≠ê B.9 MEGA EXAMPLE #1 ‚Äî COMPLETE ETL PIPELINE (API ‚Üí Transform ‚Üí DB).

‚≠ê B.9 MEGA EXAMPLE #1 ‚Äî COMPLETE ETL PIPELINE (API ‚Üí Transform ‚Üí DB)

#### This will be a multi-file, ~300+ line ‚Äúmini system‚Äù:

This will be a multi-file, ~300+ line ‚Äúmini system‚Äù:

#### Async extract from a fake API.

Async extract from a fake API

#### Transform and clean data (pandas or polars).

Transform and clean data (pandas or polars)

#### Validate schema (pandera).

Validate schema (pandera)

#### Load into PostgreSQL.

Load into PostgreSQL

#### Scheduled via an entry script (can be triggered by Cron / Kubernetes CronJob).

Scheduled via an entry script (can be triggered by Cron / Kubernetes CronJob)

#### Given the size, here‚Äôs the structure + main flows; you can drop this straight into a repo.

Given the size, here‚Äôs the structure + main flows; you can drop this straight into a repo.

#### B.9.0 Folder Structure etl_pipeline/ ‚îÇ ‚îú‚îÄ etl/ ‚îÇ ‚îú‚îÄ __init__.py ‚îÇ ‚îú‚îÄ config.py # pydantic-settings ‚îÇ ‚îú‚îÄ extract.py # async HTTP extraction ‚îÇ ‚îú‚îÄ tra...

B.9.0 Folder Structure etl_pipeline/ ‚îÇ ‚îú‚îÄ etl/ ‚îÇ ‚îú‚îÄ __init__.py ‚îÇ ‚îú‚îÄ config.py # pydantic-settings ‚îÇ ‚îú‚îÄ extract.py # async HTTP extraction ‚îÇ ‚îú‚îÄ transform.py # pandas/polars transforms ‚îÇ ‚îú‚îÄ validate.py # pandera validation ‚îÇ ‚îú‚îÄ load.py # SQLAlchemy PG load ‚îÇ ‚îú‚îÄ models.py # ORM models ‚îÇ ‚îú‚îÄ pipeline.py # orchestrate entire ETL ‚îÇ ‚îî‚îÄ logging.py # structured logging ‚îî‚îÄ pyproject.toml

#### I‚Äôll give you the core pieces (enough to run in a real project) without going completely insane on length.

I‚Äôll give you the core pieces (enough to run in a real project) without going completely insane on length.

#### B.9.1 pyproject.toml [project] name = "etl-pipeline" version = "0.1.0" dependencies = [ "httpx", "pandas", "sqlalchemy>=2.0", "asyncpg", "pydantic-...

B.9.1 pyproject.toml [project] name = "etl-pipeline" version = "0.1.0" dependencies = [ "httpx", "pandas", "sqlalchemy>=2.0", "asyncpg", "pydantic-settings", "pandera[pandas]", "structlog", ]

#### [project.scripts] run-etl = "etl.pipeline:main".

[project.scripts] run-etl = "etl.pipeline:main"

#### B.9.2 etl/config.py from pydantic_settings import BaseSettings from pydantic import AnyUrl.

B.9.2 etl/config.py from pydantic_settings import BaseSettings from pydantic import AnyUrl

#### Class Settings(BaseSettings): env: str = "local" source_api_url: AnyUrl = "https://example.com/api/items" database_url: AnyUrl chunk_size: int = 500.

class Settings(BaseSettings): env: str = "local" source_api_url: AnyUrl = "https://example.com/api/items" database_url: AnyUrl chunk_size: int = 500

#### Class Config: env_file = ".env".

class Config: env_file = ".env"

#### B.9.3 etl/logging.py import logging import structlog.

B.9.3 etl/logging.py import logging import structlog

#### Def setup_logging() -> None: logging.basicConfig(format="%(message)s", level=logging.INFO) structlog.configure( wrapper_class=structlog.make_filter...

def setup_logging() -> None: logging.basicConfig(format="%(message)s", level=logging.INFO) structlog.configure( wrapper_class=structlog.make_filtering_bound_logger(logging.INFO), processors=[ structlog.processors.add_log_level, structlog.processors.TimeStamper(fmt="iso"), structlog.processors.JSONRenderer(), ], )

#### Log = structlog.get_logger("etl").

log = structlog.get_logger("etl")

#### B.9.4 etl/extract.py import asyncio from typing import Any.

B.9.4 etl/extract.py import asyncio from typing import Any

#### Import httpx from .config import settings from .logging import log.

import httpx from .config import settings from .logging import log

#### Async def fetch_page( client: httpx.AsyncClient, page: int, ) -> list[dict[str, Any]]: url = f"{settings.source_api_url}?page={page}" resp = await ...

async def fetch_page( client: httpx.AsyncClient, page: int, ) -> list[dict[str, Any]]: url = f"{settings.source_api_url}?page={page}" resp = await client.get(url, timeout=10) resp.raise_for_status() data = resp.json() return data.get("items", [])

#### Async def extract_all() -> list[dict[str, Any]]: log.info("extract.start", source=str(settings.source_api_url)) items: list[dict[str, Any]] = [].

async def extract_all() -> list[dict[str, Any]]: log.info("extract.start", source=str(settings.source_api_url)) items: list[dict[str, Any]] = []

#### Async with httpx.AsyncClient() as client: page = 1 while True: page_items = await fetch_page(client, page) if not page_items: break items.extend(pa...

async with httpx.AsyncClient() as client: page = 1 while True: page_items = await fetch_page(client, page) if not page_items: break items.extend(page_items) log.info("extract.page", page=page, count=len(page_items)) page += 1

#### Log.info("extract.done", total=len(items)) return items.

log.info("extract.done", total=len(items)) return items

#### (For a real system, you‚Äôd hit a real API; here it‚Äôs logically complete.).

(For a real system, you‚Äôd hit a real API; here it‚Äôs logically complete.)

#### B.9.5 etl/transform.py from typing import Any.

B.9.5 etl/transform.py from typing import Any

#### Def transform(raw: list[dict[str, Any]]) -> pd.DataFrame: df = pd.DataFrame(raw).

def transform(raw: list[dict[str, Any]]) -> pd.DataFrame: df = pd.DataFrame(raw)

#### # Normalize columns if "created_at" in df: df["created_at"] = pd.to_datetime(df["created_at"], errors="coerce").

# Normalize columns if "created_at" in df: df["created_at"] = pd.to_datetime(df["created_at"], errors="coerce")

#### # Example derived columns if "price" in df and "tax" in df: df["total_price"] = df["price"] + df["tax"].

# Example derived columns if "price" in df and "tax" in df: df["total_price"] = df["price"] + df["tax"]

#### # Drop invalid / incomplete rows df = df.dropna(subset=["id", "name"]).

# Drop invalid / incomplete rows df = df.dropna(subset=["id", "name"])

#### B.9.6 etl/validate.py import pandera as pa from pandera import Column, DataFrameSchema import pandas as pd.

B.9.6 etl/validate.py import pandera as pa from pandera import Column, DataFrameSchema import pandas as pd

#### Schema = DataFrameSchema( { "id": Column(int, pa.Check.gt(0)), "name": Column(str, pa.Check.str_length(min_value=1)), "created_at": Column(pa.Times...

schema = DataFrameSchema( { "id": Column(int, pa.Check.gt(0)), "name": Column(str, pa.Check.str_length(min_value=1)), "created_at": Column(pa.Timestamp, nullable=True), "total_price": Column(float, nullable=True), }, coerce=True, )

#### Def validate(df: pd.DataFrame) -> pd.DataFrame: return schema.validate(df).

def validate(df: pd.DataFrame) -> pd.DataFrame: return schema.validate(df)

#### B.9.7 etl/models.py from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column from sqlalchemy import DateTime, Float, String.

B.9.7 etl/models.py from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column from sqlalchemy import DateTime, Float, String

#### Class Item(Base): __tablename__ = "items".

class Item(Base): __tablename__ = "items"

#### Id: Mapped[int] = mapped_column(primary_key=True) name: Mapped[str] = mapped_column(String(255)) created_at: Mapped[DateTime | None] total_price: M...

id: Mapped[int] = mapped_column(primary_key=True) name: Mapped[str] = mapped_column(String(255)) created_at: Mapped[DateTime | None] total_price: Mapped[float | None] = mapped_column(Float)

#### B.9.8 etl/load.py from typing import Iterable.

B.9.8 etl/load.py from typing import Iterable

#### Import pandas as pd from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker from sqlalchemy import insert.

import pandas as pd from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker from sqlalchemy import insert

#### From .config import settings from .models import Base, Item from .logging import log.

from .config import settings from .models import Base, Item from .logging import log

#### Engine = create_async_engine(str(settings.database_url), echo=False) SessionLocal = async_sessionmaker(engine, expire_on_commit=False).

engine = create_async_engine(str(settings.database_url), echo=False) SessionLocal = async_sessionmaker(engine, expire_on_commit=False)

#### Async def init_db() -> None: async with engine.begin() as conn: await conn.run_sync(Base.metadata.create_all).

async def init_db() -> None: async with engine.begin() as conn: await conn.run_sync(Base.metadata.create_all)

#### Async def load(df: pd.DataFrame, chunk_size: int | None = None) -> None: if chunk_size is None: chunk_size = settings.chunk_size.

async def load(df: pd.DataFrame, chunk_size: int | None = None) -> None: if chunk_size is None: chunk_size = settings.chunk_size

#### Log.info("load.start", rows=len(df)).

log.info("load.start", rows=len(df))

#### Async with SessionLocal() as session: for chunk in _chunks(df.to_dict(orient="records"), chunk_size): stmt = insert(Item).values(chunk) await sessi...

async with SessionLocal() as session: for chunk in _chunks(df.to_dict(orient="records"), chunk_size): stmt = insert(Item).values(chunk) await session.execute(stmt) await session.commit() log.info("load.chunk", count=len(chunk))

#### Log.info("load.done", rows=len(df)).

log.info("load.done", rows=len(df))

#### Def _chunks(items: Iterable[dict], size: int): current: list[dict] = [] for item in items: current.append(item) if len(current) >= size: yield curr...

def _chunks(items: Iterable[dict], size: int): current: list[dict] = [] for item in items: current.append(item) if len(current) >= size: yield current current = [] if current: yield current

#### B.9.9 etl/pipeline.py import asyncio.

B.9.9 etl/pipeline.py import asyncio

#### From .config import settings from .logging import setup_logging, log from .extract import extract_all from .transform import transform from .valida...

from .config import settings from .logging import setup_logging, log from .extract import extract_all from .transform import transform from .validate import validate from .load import init_db, load

#### Async def run() -> None: log.info("pipeline.start", env=settings.env).

async def run() -> None: log.info("pipeline.start", env=settings.env)

#### Raw = await extract_all() df = transform(raw) df = validate(df) await load(df).

raw = await extract_all() df = transform(raw) df = validate(df) await load(df)

#### Log.info("pipeline.done", total=len(df)).

log.info("pipeline.done", total=len(df))

#### Def main() -> None: setup_logging() try: asyncio.run(run()) except Exception as exc: # noqa: BLE001 log.exception("pipeline.error", error=str(exc))...

def main() -> None: setup_logging() try: asyncio.run(run()) except Exception as exc: # noqa: BLE001 log.exception("pipeline.error", error=str(exc)) raise

#### You can wire this into cron / Kubernetes:.

You can wire this into cron / Kubernetes:

#### # or python -m etl.pipeline.

# or python -m etl.pipeline

#### Core language concepts.

Core language concepts

#### Standard library terminology.

Standard library terminology

#### Packaging + distribution.

Packaging + distribution

#### OOP + metaprogramming.

OOP + metaprogramming

#### Type system terminology.

Type system terminology

#### Common Python culture terms.

Common Python culture terms

#### Advanced concepts (‚Äúdunder model‚Äù, ‚Äúdescriptor protocol‚Äù, ‚Äúmeta path finder‚Äù, etc.).

Advanced concepts (‚Äúdunder model‚Äù, ‚Äúdescriptor protocol‚Äù, ‚Äúmeta path finder‚Äù, etc.)

#### ‚úî Defined precisely ‚úî Version-aware (e.g., Python 3.12+) ‚úî Connected to related concepts ‚úî Illustrated with a micro example (when helpful) ‚úî Mapped...

‚úî Defined precisely ‚úî Version-aware (e.g., Python 3.12+) ‚úî Connected to related concepts ‚úî Illustrated with a micro example (when helpful) ‚úî Mapped to the chapter where it appears

#### This is Depth Level 1‚Äì2 per your spec: Thorough, precise, reference-ready ‚Äî but not a textbook.

This is Depth Level 1‚Äì2 per your spec: Thorough, precise, reference-ready ‚Äî but not a textbook.

#### üìò APPENDIX C ‚Äî THE PYTHON GLOSSARY (A‚ÄìZ).

üìò APPENDIX C ‚Äî THE PYTHON GLOSSARY (A‚ÄìZ)

#### (Part 1: A terms) (We will continue alphabetically per your ‚ÄúC‚Äù request.).

(Part 1: A terms) (We will continue alphabetically per your ‚ÄúC‚Äù request.)

#### A Abstract Base Class (ABC).

A Abstract Base Class (ABC)

#### A class that cannot be instantiated directly and acts as a contract for subclasses.

A class that cannot be instantiated directly and acts as a contract for subclasses. Declared using abc.ABC and @abstractmethod.

#### Purpose: Provides structural expectations without requiring concrete implementation.

Purpose: Provides structural expectations without requiring concrete implementation.

#### From abc import ABC, abstractmethod.

from abc import ABC, abstractmethod

#### Class Storage(ABC): @abstractmethod def save(self, data: str) -> None: ...

class Storage(ABC): @abstractmethod def save(self, data: str) -> None: ...

#### Related: Protocol, duck typing, interface, MRO.

Related: Protocol, duck typing, interface, MRO.

#### Abstract Syntax Tree (AST).

Abstract Syntax Tree (AST)

#### A tree representation of Python code after parsing but before bytecode generation.

A tree representation of Python code after parsing but before bytecode generation.

#### Generated by the parser ‚Üí consumed by the compiler.

Generated by the parser ‚Üí consumed by the compiler.

#### Import ast tree = ast.parse("x = 1 + 2").

import ast tree = ast.parse("x = 1 + 2")

#### Classic loop pattern where a value aggregates over iterations (sum, append, etc.).

Classic loop pattern where a value aggregates over iterations (sum, append, etc.).

#### OOP design pattern that converts one interface into another.

OOP design pattern that converts one interface into another.

#### Often used in dependency inversion.

Often used in dependency inversion.

#### Alternative Python Implementations.

Alternative Python Implementations

#### Non-CPython interpreters, e.g.:.

Non-CPython interpreters, e.g.:

#### MicroPython (embedded).

MicroPython (embedded)

#### GraalPython (native polyglot).

GraalPython (native polyglot)

#### Pyston (performance-focused).

Pyston (performance-focused)

#### Each differs in: GC behavior, JIT, GIL semantics, FFI ability.

Each differs in: GC behavior, JIT, GIL semantics, FFI ability.

#### Annotation (Function Annotation / Variable Annotation).

Annotation (Function Annotation / Variable Annotation)

#### Metadata attached to functions or variables, often used for typing.

Metadata attached to functions or variables, often used for typing.

#### Def f(x: int) -> str: ...

def f(x: int) -> str: ...

#### Accessible via __annotations__.

Accessible via __annotations__.

#### API (Application Programming Interface).

API (Application Programming Interface)

#### Boundary or contract describing how software components communicate.

Boundary or contract describing how software components communicate.

#### REST APIs built with FastAPI/Django/Flask.

REST APIs built with FastAPI/Django/Flask

#### Arbitrary Argument Lists (*args, **kwargs).

Arbitrary Argument Lists (*args, **kwargs)

#### Mechanism for flexible function signatures.

Mechanism for flexible function signatures.

#### *args: positional variadic.

*args: positional variadic

#### **kwargs: keyword variadic.

**kwargs: keyword variadic

#### Used heavily in decorators and generic functions.

Used heavily in decorators and generic functions.

#### Argument (Positional / Keyword / Default / Positional-only).

Argument (Positional / Keyword / Default / Positional-only)

#### Positional-only: def f(x, /).

Positional-only: def f(x, /)

#### Keyword-only: def f(*, x).

Keyword-only: def f(*, x)

#### Dunder methods enabling mathematical operations:.

Dunder methods enabling mathematical operations:

#### ASGI (Asynchronous Server Gateway Interface).

ASGI (Asynchronous Server Gateway Interface)

#### The async successor to WSGI.

The async successor to WSGI. Used by FastAPI, Starlette, Django 3.2+ async path.

#### Concurrency without blocking.

concurrency without blocking

#### Assignment Expression (Walrus Operator :=).

Assignment Expression (Walrus Operator :=)

#### Allows assignment inside expressions.

Introduced in Python 3.8. Allows assignment inside expressions.

#### If (data := fetch()) is not None: ...

if (data := fetch()) is not None: ...

#### Manipulating the AST before execution.

Manipulating the AST before execution. Used by:

#### Keywords enabling asynchronous programming via coroutines.

Keywords enabling asynchronous programming via coroutines.

#### Async def declares a coroutine.

async def declares a coroutine

#### Await suspends execution.

await suspends execution

#### Async Context Manager.

Async Context Manager

#### Object implementing __aenter__ and __aexit__.

Object implementing __aenter__ and __aexit__.

#### Async with Session() as s: ...

async with Session() as s: ...

#### Generator using yield inside async def.

Generator using yield inside async def.

#### Used for streaming results asynchronously.

Used for streaming results asynchronously.

#### Object implementing:.

Object implementing:

#### Core scheduler that runs async tasks in Python.

Core scheduler that runs async tasks in Python.

#### An operation that cannot be interrupted.

An operation that cannot be interrupted. Python-level atomicity exists only for:

#### Some built-ins (append, pop, += for small ints).

some built-ins (append, pop, += for small ints)

#### GIL-guarded operations.

GIL-guarded operations

#### CPython atomicity ‚â† thread safety.

CPython atomicity ‚â† thread safety.

#### Attribute Access Protocol.

Attribute Access Protocol

#### If AttributeError ‚Üí __getattr__.

if AttributeError ‚Üí __getattr__

#### Descriptor protocol (__get__, etc.).

descriptor protocol (__get__, etc.)

#### Augmented Assignment (+=, -=, *=, etc.).

Augmented Assignment (+=, -=, *=, etc.)

#### __imul__ and falls back to normal versions (__add__, __sub__) if not implemented.

__imul__ and falls back to normal versions (__add__, __sub__) if not implemented.

#### Anything that can be awaited:.

Anything that can be awaited:

#### Checked using inspect.isawaitable.

Checked using inspect.isawaitable.

#### AWS Lambda Handler (Python Context).

AWS Lambda Handler (Python Context)

#### Not Python-specific but heavily used in Python ecosystems.

Not Python-specific but heavily used in Python ecosystems.

#### üìò APPENDIX C ‚Äî PYTHON GLOSSARY Section B (All ‚ÄúB‚Äù Terms).

üìò APPENDIX C ‚Äî PYTHON GLOSSARY Section B (All ‚ÄúB‚Äù Terms)

#### B Backoff (Exponential Backoff).

B Backoff (Exponential Backoff)

#### A retry strategy where the delay between attempts increases exponentially (e.g., 1s ‚Üí 2s ‚Üí 4s ‚Üí 8s ‚Üí cap).

A retry strategy where the delay between attempts increases exponentially (e.g., 1s ‚Üí 2s ‚Üí 4s ‚Üí 8s ‚Üí cap).

#### Asyncio task retries.

asyncio task retries

#### Common Python tools: tenacity, backoff, custom retry decorators.

Common Python tools: tenacity, backoff, custom retry decorators.

#### A mechanism that prevents producers from overwhelming consumers in streaming or async pipelines.

A mechanism that prevents producers from overwhelming consumers in streaming or async pipelines.

#### Streaming frameworks.

streaming frameworks

#### Backslash Line Continuation.

Backslash Line Continuation

#### The \ used to continue a logical line across multiple physical lines.

The \ used to continue a logical line across multiple physical lines.

#### Total = a + b + \ c + d.

total = a + b + \ c + d

#### Best practice: Avoid backslashes; prefer parentheses.

Best practice: Avoid backslashes; prefer parentheses.

#### Any class from which another class inherits.

Any class from which another class inherits.

#### Multiple inheritance.

multiple inheritance

#### Base Exception / Exception Hierarchy.

Base Exception / Exception Hierarchy

#### The root of Python‚Äôs error model.

The root of Python‚Äôs error model.

#### BaseException ‚îú‚îÄ‚îÄ Exception ‚îÇ ‚îú‚îÄ‚îÄ ArithmeticError ‚îÇ ‚îú‚îÄ‚îÄ LookupError ‚îÇ ‚îú‚îÄ‚îÄ OSError ‚îÇ ‚îî‚îÄ‚îÄ ..

BaseException ‚îú‚îÄ‚îÄ Exception ‚îÇ ‚îú‚îÄ‚îÄ ArithmeticError ‚îÇ ‚îú‚îÄ‚îÄ LookupError ‚îÇ ‚îú‚îÄ‚îÄ OSError ‚îÇ ‚îî‚îÄ‚îÄ ... ‚îú‚îÄ‚îÄ GeneratorExit ‚îú‚îÄ‚îÄ KeyboardInterrupt ‚îî‚îÄ‚îÄ SystemExit

#### Basic Block (Bytecode).

Basic Block (Bytecode)

#### A straight-line sequence of bytecode instructions with no jumps except at the end.

A straight-line sequence of bytecode instructions with no jumps except at the end.

#### Compiler optimizations.

compiler optimizations

#### Disassembly analysis.

disassembly analysis

#### BDD (Behavior-Driven Development).

BDD (Behavior-Driven Development)

#### Testing style using natural language: ‚ÄúGiven‚ÄìWhen‚ÄìThen‚Äù.

Testing style using natural language: ‚ÄúGiven‚ÄìWhen‚ÄìThen‚Äù.

#### Measuring performance.

Measuring performance. Tools:

#### File opened with "rb" or "wb" (no implicit encoding/decoding).

File opened with "rb" or "wb" (no implicit encoding/decoding).

#### Operators with two operands:.

Operators with two operands:

#### Bitwise operators: &, |, ^, <<, >>.

bitwise operators: &, |, ^, <<, >>

#### Binding / Name Binding.

Binding / Name Binding

#### Associating a name with an object.

Associating a name with an object.

#### Assignment is binding:.

Assignment is binding:

#### X = 10 # bind name to object.

x = 10 # bind name to object

#### Operate on integers as binary numbers.

Operate on integers as binary numbers.

#### & AND | OR ^ XOR ~ NOT << left shift >> right shift.

& AND | OR ^ XOR ~ NOT << left shift >> right shift

#### A function that halts execution until completed.

A function that halts execution until completed.

#### Blocking in async code causes loop starvation.

Blocking in async code causes loop starvation.

#### A function tied to an instance, with self automatically injected.

A function tied to an instance, with self automatically injected.

#### Obj = MyClass() obj.method # bound method.

obj = MyClass() obj.method # bound method

#### Built-in debugging hook (Python 3.7+).

Built-in debugging hook (Python 3.7+).

#### Uses pdb unless overridden by the PYTHONBREAKPOINT environment variable.

Uses pdb unless overridden by the PYTHONBREAKPOINT environment variable.

#### A low-level mechanism allowing objects to expose memory directly to other objects.

A low-level mechanism allowing objects to expose memory directly to other objects.

#### The low-level instruction set executed by the CPython VM.

The low-level instruction set executed by the CPython VM.

#### Source code ‚Üí AST ‚Üí bytecode ‚Üí execution.

source code ‚Üí AST ‚Üí bytecode ‚Üí execution

#### Import dis dis.dis(func).

import dis dis.dis(func)

#### Bytecode Cache (__pycache__).

Bytecode Cache (__pycache__)

#### Directory storing compiled .pyc files to speed up imports.

Directory storing compiled .pyc files to speed up imports.

#### Endianness of integers and binary data: "big" or "little".

Endianness of integers and binary data: "big" or "little".

#### (1024).to_bytes(2, "big").

(1024).to_bytes(2, "big")

#### Immutable (bytes) or mutable (bytearray) sequences of raw bytes.

Immutable (bytes) or mutable (bytearray) sequences of raw bytes.

#### Provides compression using the bzip2 algorithm.

Provides compression using the bzip2 algorithm.

#### Builtin Function / Builtins Namespace.

Builtin Function / Builtins Namespace

#### Functions available without import:.

Functions available without import:

#### Bound Argument (inspect).

Bound Argument (inspect)

#### Values paired with parameters through introspection:.

Values paired with parameters through introspection:

#### Inspect.signature(func).bind(*args, **kwargs).

inspect.signature(func).bind(*args, **kwargs)

#### Descriptor protocols.

descriptor protocols

#### Any expression evaluated inside if, while, or bool().

Any expression evaluated inside if, while, or bool().

#### Boolean Short-Circuiting.

Boolean Short-Circuiting

#### And and or stop evaluation early.

and and or stop evaluation early.

#### X and expensive_func() # may skip call.

x and expensive_func() # may skip call

#### Breadth-First Search (Programming / Data Structures).

Breadth-First Search (Programming / Data Structures)

#### Traversal pattern used in:.

Traversal pattern used in:

#### Buffering (IO Buffers).

Buffering (IO Buffers)

#### The layer between program and OS.

The layer between program and OS.

#### Managed with open(buffering=...).

Managed with open(buffering=...).

#### Built Distribution (.whl, .egg).

Built Distribution (.whl, .egg)

#### Installable package formats.

Installable package formats.

#### .whl: modern, recommended.

.whl: modern, recommended

#### .egg: legacy format (deprecated).

.egg: legacy format (deprecated)

#### Accidentally overriding Python built-ins:.

Accidentally overriding Python built-ins:

#### List = [1,2,3] # BAD.

list = [1,2,3] # BAD

#### Literal prefixed with b:.

Literal prefixed with b:

#### Python 3.13+ free-threading mode.

Python 3.13+ free-threading mode

#### By-Value vs By-Reference.

By-Value vs By-Reference

#### Python uses call by object reference, meaning:.

Python uses call by object reference, meaning:

#### Objects passed by reference.

objects passed by reference

#### References themselves passed by value.

references themselves passed by value

#### This is one of the largest and most important sections of the glossary, because Python has an...

This is one of the largest and most important sections of the glossary, because Python has an unusually high number of core concepts beginning with C, including:

#### Cooperative Multiple Inheritance.

Cooperative Multiple Inheritance

#### C3 Linearization (MRO).

C3 Linearization (MRO)

#### Configuration systems.

Configuration systems

#### Below is the complete, professional-grade C glossary section.

Below is the complete, professional-grade C glossary section.

#### üìò APPENDIX C ‚Äî THE PYTHON GLOSSARY Section C C Cache / Caching.

üìò APPENDIX C ‚Äî THE PYTHON GLOSSARY Section C C Cache / Caching

#### Storing the result of a computation for later reuse without recomputing it.

Storing the result of a computation for later reuse without recomputing it.

#### Manual dictionary-based caches.

manual dictionary-based caches

#### Memoization patterns.

memoization patterns

#### Caching database queries.

caching database queries

#### HTTP caching (ETags, Last-Modified).

HTTP caching (ETags, Last-Modified)

#### Any object that can be called like a function.

Any object that can be called like a function.

#### Classes (constructor).

classes (constructor)

#### Objects implementing __call__.

objects implementing __call__

#### The chain of active function frames during program execution.

The chain of active function frames during program execution.

#### Inspect with inspect.stack().

Inspect with inspect.stack().

#### A function passed as an argument and executed later.

A function passed as an argument and executed later.

#### Call-by-Object-Reference (Python‚Äôs Argument Model).

Call-by-Object-Reference (Python‚Äôs Argument Model)

#### Python‚Äôs model is neither pass-by-value nor pass-by-reference.

Python‚Äôs model is neither pass-by-value nor pass-by-reference. Objects are passed by reference, but references are passed by value.

#### Mutable arguments can be modified.

mutable arguments can be modified

#### Rebinding does not affect caller‚Äôs variable.

rebinding does not affect caller‚Äôs variable

#### C3 Linearization (MRO Algorithm).

C3 Linearization (MRO Algorithm)

#### Algorithm used to compute Method Resolution Order for classes with multiple inheritance.

Algorithm used to compute Method Resolution Order for classes with multiple inheritance.

#### Local attribute precedence.

local attribute precedence

#### C Extension / CPython Extension.

C Extension / CPython Extension

#### Native C modules compiled into .so/.pyd files.

Native C modules compiled into .so/.pyd files.

#### Performance-critical code.

performance-critical code

#### Interfacing with system libraries.

interfacing with system libraries

#### Bypassing the GIL (carefully).

bypassing the GIL (carefully)

#### The C interface that allows extensions to interact with Python objects.

The C interface that allows extensions to interact with Python objects.

#### Macros for type checking.

macros for type checking

#### Deeply nested callbacks leading to unreadable code.

Deeply nested callbacks leading to unreadable code.

#### Canonical String Representation (__repr__).

Canonical String Representation (__repr__)

#### Machine-readable string representing an object.

Machine-readable string representing an object.

#### Ideally round-trip evaluable via eval(repr(obj)).

ideally round-trip evaluable via eval(repr(obj))

#### The blueprint for creating objects.

The blueprint for creating objects. Introduced with the class keyword.

#### Inheritance metadata.

inheritance metadata

#### Class Body Execution.

Class Body Execution

#### The class body is executed immediately at class creation time.

The class body is executed immediately at class creation time.

#### Class A: print("Hello") # runs immediately.

class A: print("Hello") # runs immediately

#### A decorator applied to a class definition.

A decorator applied to a class definition.

#### Validation frameworks.

validation frameworks

#### Class Method (@classmethod).

Class Method (@classmethod)

#### Method receiving the class as the first argument (cls).

Method receiving the class as the first argument (cls).

#### Alternate constructors.

alternate constructors

#### Class-level utilities.

class-level utilities

#### Attribute shared by all instances.

Attribute shared by all instances.

#### Defined inside class block.

Defined inside class block.

#### Class Variable vs Instance Variable.

Class Variable vs Instance Variable

#### Class variables: shared Instance variables: per-object.

Class variables: shared Instance variables: per-object

#### Class A: items = [] # shared by all instances!.

class A: items = [] # shared by all instances!

#### A function retaining references to variables in the enclosing scope.

A function retaining references to variables in the enclosing scope.

#### Compiled, immutable representation of Python bytecode.

Compiled, immutable representation of Python bytecode.

#### Compile("x=1", filename, "exec").

compile("x=1", filename, "exec")

#### Encoder/decoder for text-to-bytes conversion.

Encoder/decoder for text-to-bytes conversion.

#### Combinatoric Functions.

Combinatoric Functions

#### Functions producing combinations/permutations/etc., often from itertools.

Functions producing combinations/permutations/etc., often from itertools.

#### An OOP pattern encapsulating an action as an object.

An OOP pattern encapsulating an action as an object.

#### Dispatcher architectures.

dispatcher architectures

#### Comparison Methods (__eq__, __lt__, etc.).

Comparison Methods (__eq__, __lt__, etc.)

#### Special methods implementing comparisons.

Special methods implementing comparisons.

#### From functools import total_ordering.

from functools import total_ordering

#### Syntax for concise list/dict/set comprehensions.

Syntax for concise list/dict/set comprehensions.

#### [x for x in nums if x % 2 == 0] {x: x*x for x in nums}.

[x for x in nums if x % 2 == 0] {x: x*x for x in nums}

#### Comprehensions create:.

Comprehensions create:

#### Generally faster than loops.

generally faster than loops

#### Running multiple tasks in overlapping time.

Running multiple tasks in overlapping time.

#### Config / Configuration System.

Config / Configuration System

#### Python tools for managing environment settings:.

Python tools for managing environment settings:

#### A name intended not to change (Python has no enforced constants).

A name intended not to change (Python has no enforced constants).

#### Convention: UPPER_CASE_WITH_UNDERSCORES.

Convention: UPPER_CASE_WITH_UNDERSCORES

#### Any object implementing __contains__, __iter__, or __len__.

Any object implementing __contains__, __iter__, or __len__.

#### Temporary environment.

temporary environment

#### Context Variables (contextvars module).

Context Variables (contextvars module)

#### Thread- and coroutine-local storage.

Thread- and coroutine-local storage.

#### Used in async frameworks for:.

Used in async frameworks for:

#### Authentication context.

authentication context

#### Skips to next loop iteration.

Skips to next loop iteration.

#### Equivalent to a "skip" or "next".

Equivalent to a "skip" or "next".

#### Flow of statement execution:.

Flow of statement execution:

#### Primary async executable unit.

Primary async executable unit.

#### Created with async def.

Created with async def.

#### Executed by event loop.

Executed by event loop.

#### Object returned when calling an async function but before awaiting it.

Object returned when calling an async function but before awaiting it.

#### Coro = async_func() # coroutine object await coro # executes it.

coro = async_func() # coroutine object await coro # executes it

#### Function defined with async def.

Function defined with async def.

#### The standard, reference implementation of Python written in C.

The standard, reference implementation of Python written in C.

#### Bytecode interpreter.

bytecode interpreter

#### Specialized dict layout.

specialized dict layout

#### Tasks limited by computation, not I/O.

Tasks limited by computation, not I/O.

#### Python 3.13 free-threading.

Python 3.13 free-threading

#### Used to validate data integrity.

Used to validate data integrity.

#### Provides reading/writing CSV files.

Provides reading/writing CSV files.

#### Curly-Brace String Formatting (f-strings).

Curly-Brace String Formatting (f-strings)

#### Python‚Äôs fastest and most expressive string formatting.

Python‚Äôs fastest and most expressive string formatting.

#### = debug syntax (3.8+).

= debug syntax (3.8+)

#### Full tokenizer behavior (3.12+ under PEP 701).

full tokenizer behavior (3.12+ under PEP 701)

#### Transforming function with multiple params into a sequence of single-param functions.

Transforming function with multiple params into a sequence of single-param functions.

#### Implemented via closures or functools.partial.

Implemented via closures or functools.partial.

#### Cyclic Dependency / Circular Import.

Cyclic Dependency / Circular Import

#### When two modules import each other.

When two modules import each other.

#### Partially initialized module objects.

partially initialized module objects

#### AttributeError during import.

AttributeError during import

#### Unexpected None values.

unexpected None values

#### Move imports inside functions.

move imports inside functions

#### Use interface modules.

use interface modules

#### A superset of Python used to generate C extensions.

A superset of Python used to generate C extensions.

#### C-level memory access.

C-level memory access

#### Foreign Function Interface (FFI) to call shared libraries in C.

Foreign Function Interface (FFI) to call shared libraries in C.

#### Current Working Directory (cwd).

Current Working Directory (cwd)

#### Directory where a Python program is executed.

Directory where a Python program is executed.

#### Import os os.getcwd().

import os os.getcwd()

#### User-defined exception inherited from Exception.

User-defined exception inherited from Exception.

#### Class InvalidAge(Exception): pass.

class InvalidAge(Exception): pass

#### Explicit class controlling class creation.

Explicit class controlling class creation.

#### Enforcing constraints.

enforcing constraints

#### Object implementing custom dumps/loads logic:.

Object implementing custom dumps/loads logic:

#### Custom JSON handlers.

custom JSON handlers

#### üìò APPENDIX C ‚Äî PYTHON GLOSSARY Section D D Daemon Thread.

üìò APPENDIX C ‚Äî PYTHON GLOSSARY Section D D Daemon Thread

#### A background thread that automatically exits when the main thread exits.

A background thread that automatically exits when the main thread exits.

#### T = Thread(target=run, daemon=True).

t = Thread(target=run, daemon=True)

#### Background monitoring.

background monitoring

#### Data Class (@dataclass).

Data Class (@dataclass)

#### Decorator that generates __init__, __repr__, __eq__, and optionally others.

Decorator that generates __init__, __repr__, __eq__, and optionally others.

#### Frozen=True ‚Äî immutability.

frozen=True ‚Äî immutability

#### Slots=True ‚Äî faster, low-memory fields.

slots=True ‚Äî faster, low-memory fields

#### Kw_only=True ‚Äî keyword-only args (Python 3.10+).

kw_only=True ‚Äî keyword-only args (Python 3.10+)

#### Order=True ‚Äî comparison methods.

order=True ‚Äî comparison methods

#### @dataclass class User: id: int name: str.

@dataclass class User: id: int name: str

#### Data Model (Python Data Model).

Data Model (Python Data Model)

#### Includes all dunder methods:.

Includes all dunder methods:

#### The data model is the backbone of ‚ÄúPythonic‚Äù behavior.

The data model is the backbone of ‚ÄúPythonic‚Äù behavior.

#### A unit of communication sent using UDP (connectionless).

A unit of communication sent using UDP (connectionless).

#### Asyncio‚Äôs DatagramProtocol.

asyncio‚Äôs DatagramProtocol

#### Database API (DB-API 2.0).

Database API (DB-API 2.0)

#### Python‚Äôs standard interface for SQL databases.

Python‚Äôs standard interface for SQL databases.

#### Libraries implementing it:.

Libraries implementing it:

#### Python‚Äôs debugging environment.

Python‚Äôs debugging environment. Can be activated with:

#### Creates a recursive copy of all nested objects.

Creates a recursive copy of all nested objects.

#### Import copy copy.deepcopy(obj).

import copy copy.deepcopy(obj)

#### Automatically initializes missing keys.

Automatically initializes missing keys.

#### From collections import defaultdict d = defaultdict(int).

from collections import defaultdict d = defaultdict(int)

#### Common in counting, grouping, histogramming.

Common in counting, grouping, histogramming.

#### Delaying execution until needed.

Delaying execution until needed.

#### A function that wraps another function/class to modify behavior.

A function that wraps another function/class to modify behavior.

#### Def log(f): def wrapper(*a, **k): print("Calling", f.__name__) return f(*a, **k) return wrapper.

def log(f): def wrapper(*a, **k): print("Calling", f.__name__) return f(*a, **k) return wrapper

#### Decorator that takes arguments:.

Decorator that takes arguments:

#### Def repeat(n): def wrap(f): ..

def repeat(n): def wrap(f): ... return wrap

#### @repeat(3) def greet(): ...

@repeat(3) def greet(): ...

#### Removing duplicates from collections.

Removing duplicates from collections.

#### Lists with comprehensions.

lists with comprehensions

#### Default Argument Gotcha (Mutable Defaults).

Default Argument Gotcha (Mutable Defaults)

#### Def fn(x, cache={}): # BAD cache[x] = True.

def fn(x, cache={}): # BAD cache[x] = True

#### Def fn(x, cache=None): if cache is None: cache = {}.

def fn(x, cache=None): if cache is None: cache = {}

#### High-level web framework.

High-level web framework.

#### Uses WSGI or ASGI (via Django Channels).

Uses WSGI or ASGI (via Django Channels).

#### Python‚Äôs core associative container.

Python‚Äôs core associative container.

#### Deterministic ordering (Python 3.7+).

deterministic ordering (Python 3.7+)

#### Supports comprehension.

supports comprehension

#### Supports | and |= merge operators.

supports | and |= merge operators

#### Dictionary View (keys(), values(), items()).

Dictionary View (keys(), values(), items())

#### Lazy, dynamic views into dictionary contents.

Lazy, dynamic views into dictionary contents.

#### Standard library module for computing string/sequence diffs.

Standard library module for computing string/sequence diffs.

#### Text comparison tools.

text comparison tools

#### Introspective function returning attributes of an object.

Introspective function returning attributes of an object.

#### Not guaranteed to be complete.

Not guaranteed to be complete.

#### Shows Python bytecode.

Shows Python bytecode.

#### Import dis dis.dis(fn).

import dis dis.dis(fn)

#### Understanding Python internals.

understanding Python internals

#### Object/function that routes calls based on conditions.

Object/function that routes calls based on conditions.

#### Example: functools.singledispatch.

Example: functools.singledispatch

#### Mapping of keys to functions.

Mapping of keys to functions.

#### Common in command interpreters:.

Common in command interpreters:

#### Actions = { "start": start, "stop": stop, }.

actions = { "start": start, "stop": stop, }

#### Distributed Computing.

Distributed Computing

#### Running workloads across multiple machines.

Running workloads across multiple machines.

#### Multi-line string literal documenting a module/class/function.

Multi-line string literal documenting a module/class/function.

#### Doctrine of EAFP (Easier to Ask Forgiveness than Permission).

Doctrine of EAFP (Easier to Ask Forgiveness than Permission)

#### A Pythonic style favoring exceptions over pre-checks.

A Pythonic style favoring exceptions over pre-checks.

#### Try: return cache[key] except KeyError: ...

try: return cache[key] except KeyError: ...

#### Dunder (Double Underscore).

Dunder (Double Underscore)

#### Methods with leading/trailing __.

Methods with leading/trailing __.

#### Part of the Python data model.

Part of the Python data model.

#### Dunder Name Mangling.

Dunder Name Mangling

#### Names starting with _Class__name are rewritten for encapsulation.

Names starting with _Class__name are rewritten for encapsulation.

#### Class A: __secret = 10.

class A: __secret = 10

#### Dynamic Attribute Lookup.

Dynamic Attribute Lookup

#### Performed when accessing attributes.

Performed when accessing attributes. Order:

#### __getattr__ fallback.

__getattr__ fallback

#### Selecting methods at runtime based on:.

Selecting methods at runtime based on:

#### Input type (singledispatch).

input type (singledispatch)

#### Type of variables is checked at runtime, not statically.

Type of variables is checked at runtime, not statically.

#### Optional static typing via type hints.

optional static typing via type hints

#### Importing a module at runtime.

Importing a module at runtime.

#### Mod = __import__("math").

mod = __import__("math")

#### importlib.import_module

importlib.import_module

#### Dynamically Scoped Variables (NOT Python).

Dynamically Scoped Variables (NOT Python)

#### Python is lexically scoped, not dynamically scoped.

Python is lexically scoped, not dynamically scoped.

#### Useful for comparison with languages like Lisp.

Useful for comparison with languages like Lisp.

#### Dynamically Sized Objects.

Dynamically Sized Objects

#### Python containers can grow/shrink automatically:.

Python containers can grow/shrink automatically:

#### Versus static-size arrays (C).

Versus static-size arrays (C).

#### Double-ended queue from collections.

Double-ended queue from collections.

#### Faster than list for:.

Faster than list for:

#### Queue-like operations.

queue-like operations

#### Dependency Injection (DI).

Dependency Injection (DI)

#### Pattern for passing dependencies explicitly.

Pattern for passing dependencies explicitly.

#### FastAPI uses DI extensively.

FastAPI uses DI extensively.

#### Dependency Resolution (Packaging).

Dependency Resolution (Packaging)

#### Process of resolving versions of dependencies in packaging systems.

Process of resolving versions of dependencies in packaging systems.

#### Class-level behavior.

class-level behavior

#### Self.__get__(instance, owner) self.__set__(instance, value) self.__delete__(instance).

self.__get__(instance, owner) self.__set__(instance, value) self.__delete__(instance)

#### Dictionary Comprehension.

Dictionary Comprehension

#### A comprehension that produces a dictionary.

A comprehension that produces a dictionary.

#### {k: v*2 for k, v in d.items()}.

{k: v*2 for k, v in d.items()}

#### Difference Between ‚Äúis‚Äù and ‚Äú==‚Äù.

Difference Between ‚Äúis‚Äù and ‚Äú==‚Äù

#### Is: identity (same object).

is: identity (same object)

#### ==: equality (values equal).

==: equality (values equal)

#### A tool for comparing sequences/text.

A tool for comparing sequences/text.

#### Classes listed immediately after a class definition in parentheses.

Classes listed immediately after a class definition in parentheses.

#### B and C are direct bases.

B and C are direct bases.

#### Reading/writing to files or block storage.

Reading/writing to files or block storage.

#### Function that forwards calls based on type.

Function that forwards calls based on type.

#### functools.singledispatch.

functools.singledispatch.

#### Container environment commonly used to package Python apps.

Container environment commonly used to package Python apps.

#### Virtual environments.

virtual environments

#### Documentation frameworks used to build Python documentation.

Documentation frameworks used to build Python documentation.

#### An object implementing the same interface/contract as another, allowing substitution.

An object implementing the same interface/contract as another, allowing substitution.

#### Behavior where type is determined by the presence of methods/attributes, not inheritance.

Behavior where type is determined by the presence of methods/attributes, not inheritance.

#### ‚ÄúIf it quacks like a duck‚Ä¶‚Äù.

‚ÄúIf it quacks like a duck‚Ä¶‚Äù

#### Python is dynamic: runtime modification of:.

Python is dynamic: runtime modification of:

#### Dynamic Memory Allocation.

Dynamic Memory Allocation

#### Objects created on the heap; Python abstracts memory management via GC.

Objects created on the heap; Python abstracts memory management via GC.

#### üìò APPENDIX C ‚Äî PYTHON GLOSSARY Section E E Eager Evaluation.

üìò APPENDIX C ‚Äî PYTHON GLOSSARY Section E E Eager Evaluation

#### Operations that execute immediately upon expression evaluation.

Operations that execute immediately upon expression evaluation.

#### Opposite of lazy evaluation (generators, iterators).

Opposite of lazy evaluation (generators, iterators).

#### Python uses eager evaluation except where explicitly lazy.

Python uses eager evaluation except where explicitly lazy.

#### EAFP (Easier to Ask Forgiveness than Permission).

EAFP (Easier to Ask Forgiveness than Permission)

#### Pythonic programming style where you try an operation and catch errors instead of checking beforehand.

Pythonic programming style where you try an operation and catch errors instead of checking beforehand.

#### Try: return d[key] except KeyError: return default.

try: return d[key] except KeyError: return default

#### Elementwise Operation.

Elementwise Operation

#### Operation applied separately to each element in a sequence or array.

Operation applied separately to each element in a sequence or array.

#### NumPy heavily uses elementwise operations.

NumPy heavily uses elementwise operations.

#### Literal used commonly in:.

Literal used commonly in:

#### Placeholder implementations.

placeholder implementations

#### Slicing (arr[..., :]).

slicing (arr[..., :])

#### Abstract method defaults.

abstract method defaults

#### Def abstract_method(): ...

def abstract_method(): ...

#### Empty Class / Marker Class.

Empty Class / Marker Class

#### A class containing no specific behavior.

A class containing no specific behavior.

#### Used for tagging or categorization.

Used for tagging or categorization.

#### Class Sentinel: pass.

class Sentinel: pass

#### Bundling data and methods inside a class and hiding internal details.

Bundling data and methods inside a class and hiding internal details.

#### Not enforced in Python, but achieved by:.

Not enforced in Python, but achieved by:

#### Naming conventions (_private).

naming conventions (_private)

#### Transforming between text and bytes.

Transforming between text and bytes.

#### B = "hello".encode("utf8") s = b.decode("utf8").

b = "hello".encode("utf8") s = b.decode("utf8")

#### Built-in function generating index‚Äìvalue pairs.

Built-in function generating index‚Äìvalue pairs.

#### For i, x in enumerate(items): ...

for i, x in enumerate(items): ...

#### Enumeration class representing symbolic, constant values.

Enumeration class representing symbolic, constant values.

#### From enum import Enum.

from enum import Enum

#### Class Color(Enum): RED = 1 BLUE = 2.

class Color(Enum): RED = 1 BLUE = 2

#### Environment Variable.

Environment Variable

#### Key‚Äìvalue pairs exported by the shell, consumed by programs.

Key‚Äìvalue pairs exported by the shell, consumed by programs.

#### Import os os.environ["PATH"].

import os os.environ["PATH"]

#### Environment Marker (Packaging).

Environment Marker (Packaging)

#### Condition inside pyproject.toml or requirements.

Condition inside pyproject.toml or requirements.

#### Pytest; python_version >= "3.11".

pytest; python_version >= "3.11"

#### Seconds since Jan 1, 1970 (Unix epoch).

Seconds since Jan 1, 1970 (Unix epoch).

#### Synonym for exception; part of the exception hierarchy.

Synonym for exception; part of the exception hierarchy.

#### Python differentiates error types but they all derive from BaseException.

Python differentiates error types but they all derive from BaseException.

#### Control flow around detecting and responding to errors.

Control flow around detecting and responding to errors.

#### Exception chaining (raise ..

exception chaining (raise ... from ...)

#### If an exception is not caught, it moves up the call stack until:.

If an exception is not caught, it moves up the call stack until:

#### Triggers termination.

triggers termination

#### Special characters inside strings:.

Special characters inside strings:

#### \n newline \t tab \" quote \\ backslash.

\n newline \t tab \" quote \\ backslash

#### Also supports Unicode escapes:.

Also supports Unicode escapes:

#### Event Loop (asyncio).

Event Loop (asyncio)

#### Central scheduler running coroutines concurrently.

Central scheduler running coroutines concurrently.

#### One event loop per OS thread.

One event loop per OS thread.

#### Event-Driven Programming.

Event-Driven Programming

#### Program flow governed by events:.

Program flow governed by events:

#### EventEmitter (Non-Standard).

EventEmitter (Non-Standard)

#### A pattern (Node.js style), implemented in Python manually or via libs:.

A pattern (Node.js style), implemented in Python manually or via libs:

#### Not a native Python class.

Not a native Python class.

#### An event disrupting normal execution.

An event disrupting normal execution.

#### Custom exceptions inherit from Exception.

Custom exceptions inherit from Exception.

#### Unless caught or suppressed.

Unless caught or suppressed.

#### Explicitly attach a cause to an exception.

Explicitly attach a cause to an exception.

#### Except Exception as exc: raise RuntimeError("fail") from exc.

try: ... except Exception as exc: raise RuntimeError("fail") from exc

#### Exception Group (Python 3.11+).

Exception Group (Python 3.11+)

#### Allows raising multiple exceptions at once.

Allows raising multiple exceptions at once.

#### Raise ExceptionGroup("Error group", [ValueError(), TypeError()]).

raise ExceptionGroup("Error group", [ValueError(), TypeError()])

#### Common in concurrent systems.

Common in concurrent systems.

#### Function or block intended to catch exceptions.

Function or block intended to catch exceptions.

#### Except ValueError: ...

try: ... except ValueError: ...

#### Synchronization primitive ensuring only one thread/process enters a critical section.

Synchronization primitive ensuring only one thread/process enters a critical section.

#### State associated with executing code:.

State associated with executing code:

#### Execution Model (Python).

Execution Model (Python)

#### Source ‚Üí parser ‚Üí AST ‚Üí compiler ‚Üí bytecode ‚Üí virtual machine.

source ‚Üí parser ‚Üí AST ‚Üí compiler ‚Üí bytecode ‚Üí virtual machine

#### In async environment:.

In async environment:

#### Event loop ‚Üí tasks ‚Üí coroutines.

event loop ‚Üí tasks ‚Üí coroutines

#### Executor (ThreadPoolExecutor, ProcessPoolExecutor).

Executor (ThreadPoolExecutor, ProcessPoolExecutor)

#### Futures-based thread/process pools.

Futures-based thread/process pools.

#### From concurrent.futures import ThreadPoolExecutor.

from concurrent.futures import ThreadPoolExecutor

#### CPU-bound processing.

CPU-bound processing

#### Blocking I/O in async contexts.

blocking I/O in async contexts

#### Iterator with no more items.

Iterator with no more items.

#### It = iter([1,2,3]) list(it) list(it) # empty! iterator exhausted.

it = iter([1,2,3]) list(it) list(it) # empty! iterator exhausted

#### Retry mechanism with increasing delays:.

Retry mechanism with increasing delays:

#### 1s ‚Üí 2s ‚Üí 4s ‚Üí 8s ‚Üí cap.

1s ‚Üí 2s ‚Üí 4s ‚Üí 8s ‚Üí cap.

#### Smallest unit of computation returning a value.

Smallest unit of computation returning a value.

#### Generator expression.

generator expression

#### Expression Statement.

Expression Statement

#### An expression used as a standalone statement.

An expression used as a standalone statement.

#### X = 10 x # valid in REPL.

x = 10 x # valid in REPL

#### Extended Iterable Unpacking.

Extended Iterable Unpacking

#### Python‚Äôs advanced unpacking:.

Python‚Äôs advanced unpacking:

#### A, *rest, b = [1,2,3,4,5].

a, *rest, b = [1,2,3,4,5]

#### Python objects can often be extended at runtime:.

Python objects can often be extended at runtime:

#### A module written in C/C++ (or Rust) loaded by Python.

A module written in C/C++ (or Rust) loaded by Python.

#### Any library not part of standard library.

Any library not part of standard library.

#### Installed via pip, Conda, Poetry, or PDM.

Installed via pip, Conda, Poetry, or PDM.

#### Additional package index locations.

Additional package index locations.

#### Pip install --extra-index-url https://custom.repo/simple.

pip install --extra-index-url https://custom.repo/simple

#### Extract-Transform-Load (ETL).

Extract-Transform-Load (ETL)

#### A data engineering workflow:.

A data engineering workflow:

#### Extract ‚Äì load from API/files/databases.

Extract ‚Äì load from API/files/databases

#### Transform ‚Äì clean/normalize data (pandas/polars).

Transform ‚Äì clean/normalize data (pandas/polars)

#### Load ‚Äì write to target (SQL/warehouse).

Load ‚Äì write to target (SQL/warehouse)

#### Python is heavily used for ETL.

Python is heavily used for ETL.

#### Eyeballing (Debugging Technique).

Eyeballing (Debugging Technique)

#### Informal examination of printouts or logs to find bugs.

Informal examination of printouts or logs to find bugs.

#### Modern equivalent: structured logging + observability.

Modern equivalent: structured logging + observability.

#### Eval (Security Warning).

Eval (Security Warning)

#### Evaluates strings as Python code.

Evaluates strings as Python code.

#### Dangerous with untrusted input.

Dangerous with untrusted input.

#### Eventual Consistency.

Eventual Consistency

#### A property of distributed systems where replicas converge over time.

A property of distributed systems where replicas converge over time.

#### With open("file.txt") as f: ...

with open("file.txt") as f: ...

#### Handles cleanup and exception handling.

Handles cleanup and exception handling.

#### üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections F‚ÄìH üîµ F Terms Facade Pattern.

üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections F‚ÄìH üîµ F Terms Facade Pattern

#### A design pattern that provides a simplified interface to a complex subsystem.

A design pattern that provides a simplified interface to a complex subsystem.

#### Python usage: wrapping multi-module systems behind one high-level API.

Python usage: wrapping multi-module systems behind one high-level API.

#### Object creation pattern used when instantiation logic is complex.

Object creation pattern used when instantiation logic is complex.

#### Def serializer(fmt: str): if fmt == "json": return JSONSerializer() if fmt == "yaml": return YAMLSerializer().

def serializer(fmt: str): if fmt == "json": return JSONSerializer() if fmt == "yaml": return YAMLSerializer()

#### Also implemented via:.

Also implemented via:

#### Falsey (Falsy) Value.

Falsey (Falsy) Value

#### Values that evaluate to False in boolean context:.

Values that evaluate to False in boolean context:

#### Custom objects whose __bool__ returns False.

custom objects whose __bool__ returns False

#### A modern async Python web framework.

A modern async Python web framework.

#### Automatic OpenAPI schema.

automatic OpenAPI schema

#### Common in modern Python microservices.

Common in modern Python microservices.

#### Literal string interpolation via {}.

Literal string interpolation via {}.

#### Name = "Chris" f"Hello {name}".

name = "Chris" f"Hello {name}"

#### Debug syntax ({var=}).

debug syntax ({var=})

#### PEP 701 full grammar (Python 3.12+).

PEP 701 full grammar (Python 3.12+)

#### Apache Arrow‚Äôs columnar format, common in Python data engineering.

Apache Arrow‚Äôs columnar format, common in Python data engineering.

#### Classic interview example; demonstrates recursion and dynamic programming.

Classic interview example; demonstrates recursion and dynamic programming.

#### Low-level OS integer handle representing open files or sockets.

Low-level OS integer handle representing open files or sockets.

#### Python exposes via .fileno().

Python exposes via .fileno().

#### Any object implementing file interface methods:.

Any object implementing file interface methods:

#### Used in mocking, testing, streaming.

Used in mocking, testing, streaming.

#### Used to prevent race conditions across processes.

Used to prevent race conditions across processes.

#### Pathlib.Path (preferred).

pathlib.Path (preferred)

#### From pathlib import Path Path("data.txt").read_text().

from pathlib import Path Path("data.txt").read_text()

#### Higher-order function that filters iterables.

Higher-order function that filters iterables.

#### Filter(lambda x: x > 0, nums).

filter(lambda x: x > 0, nums)

#### Prefer list comprehensions.

Prefer list comprehensions.

#### Annotation preventing subclassing or method overriding.

Annotation preventing subclassing or method overriding.

#### From typing import Final.

from typing import Final

#### TOKEN: Final = "secret".

TOKEN: Final = "secret"

#### Executed no matter what.

Executed no matter what.

#### Everything in Python is first-class:.

Everything in Python is first-class:

#### Can be passed, returned, stored, wrapped.

Can be passed, returned, stored, wrapped.

#### Reusable test dependency.

Reusable test dependency.

#### @pytest.fixture def db(): return connect().

@pytest.fixture def db(): return connect()

#### Linter combining PyFlakes + pycodestyle.

Linter combining PyFlakes + pycodestyle.

#### Double-precision IEEE-754 floating point.

Double-precision IEEE-754 floating point.

#### Beware precision issues.

Beware precision issues.

#### Use decimal.Decimal for currency.

Use decimal.Decimal for currency.

#### Pattern where methods return self to allow chaining.

Pattern where methods return self to allow chaining.

#### builder.set_x(1).set_y(2)

builder.set_x(1).set_y(2)

#### OS-level process duplication (Unix only).

OS-level process duplication (Unix only).

#### Python multiprocessing may use fork or spawn.

Python multiprocessing may use fork or spawn.

#### Represents execution frame:.

Represents execution frame:

#### Access via inspect.currentframe().

Access via inspect.currentframe().

#### Immutable dataclass.

Immutable dataclass.

#### @dataclass(frozen=True) class Point: x: int y: int.

@dataclass(frozen=True) class Point: x: int y: int

#### Future (concurrent.futures).

Future (concurrent.futures)

#### Object representing asynchronous execution result.

Object representing asynchronous execution result.

#### Low-level awaitable similar to concurrent future, but not thread-safe.

Low-level awaitable similar to concurrent future, but not thread-safe.

#### First-class callable block of code defined with def.

First-class callable block of code defined with def.

#### inspect.signature(func)

inspect.signature(func)

#### Function Annotations.

Function Annotations

#### Metadata used for typing.

Metadata used for typing.

#### Python supports partial FP:.

Python supports partial FP:

#### First-class functions.

first-class functions

#### Immutability via dataclasses(frozen=True).

immutability via dataclasses(frozen=True)

#### üü¢ G Terms GIL (Global Interpreter Lock).

üü¢ G Terms GIL (Global Interpreter Lock)

#### A mutex protecting Python objects from concurrent access in CPython.

A mutex protecting Python objects from concurrent access in CPython.

#### Prevents multiple threads from executing Python bytecode at once.

Prevents multiple threads from executing Python bytecode at once.

#### Python 3.13+ offers optional free-threading.

Python 3.13+ offers optional free-threading

#### Garbage Collection (GC).

Garbage Collection (GC)

#### Memory cleanup mechanism.

Memory cleanup mechanism.

#### Import gc gc.get_stats().

import gc gc.get_stats()

#### Function with yield.

Function with yield.

#### Produces values lazily.

Produces values lazily.

#### Lazy version of list comprehension:.

Lazy version of list comprehension:

#### Function using yield producing a generator.

Function using yield producing a generator.

#### Generic Types (Typing).

Generic Types (Typing)

#### Parameterized types like:.

Parameterized types like:

#### Introduced in PEP 585 and improved in 3.9‚Äì3.12.

Introduced in PEP 585 and improved in 3.9‚Äì3.12.

#### Runtime type representation for built-ins:.

Runtime type representation for built-ins:

#### Getitem (__getitem__).

Getitem (__getitem__)

#### Getattr (__getattr__).

Getattr (__getattr__)

#### Fallback attribute lookup.

Fallback attribute lookup.

#### Triggers only when normal lookup fails.

Triggers only when normal lookup fails.

#### Getattribute (__getattribute__).

Getattribute (__getattribute__)

#### Every attribute access goes through here first.

Every attribute access goes through here first. Extremely powerful, extremely dangerous.

#### Namespace at module scope.

Namespace at module scope.

#### Declares intent to assign to a module-level variable.

Declares intent to assign to a module-level variable.

#### Global counter counter += 1.

global counter counter += 1

#### Variable defined at module level.

Variable defined at module level.

#### Avoid in robust systems.

Avoid in robust systems.

#### Filesystem wildcard matching:.

Filesystem wildcard matching:

#### Import glob glob.glob("*.py").

import glob glob.glob("*.py")

#### Numerical optimization technique.

Numerical optimization technique. Used in ML libraries:

#### Not part of standard lib, but core to Python‚Äôs ML ecosystem.

Not part of standard lib, but core to Python‚Äôs ML ecosystem.

#### Graph (Data Structure).

Graph (Data Structure)

#### Python tools for graphs:.

Python tools for graphs:

#### Matrix representations.

matrix representations

#### Lightweight coroutine via greenlet library.

Lightweight coroutine via greenlet library.

#### WSGI server for running Python apps.

WSGI server for running Python apps.

#### For ASGI, use uvicorn/hypercorn.

For ASGI, use uvicorn/hypercorn.

#### Coroutine-based concurrency library using greenlets.

Coroutine-based concurrency library using greenlets.

#### Globally unique identifier, same as UUID.

Globally unique identifier, same as UUID.

#### Python module: uuid.

Python module: uuid.

#### Integer produced by hashing algorithm.

Integer produced by hashing algorithm.

#### Python uses 64-bit hash randomization per process.

Python uses 64-bit hash randomization per process.

#### Underlying structure of dicts and sets.

Underlying structure of dicts and sets.

#### Collision resolution.

collision resolution

#### An object is hashable if:.

An object is hashable if:

#### Mutable types like lists are not hashable.

Mutable types like lists are not hashable.

#### Memory region for dynamic allocation.

Memory region for dynamic allocation.

#### Python objects live on the heap.

Python objects live on the heap.

#### Do not confuse with:.

Do not confuse with:

#### Heapq (binary heap priority queue).

heapq (binary heap priority queue)

#### Binary heap implementation for priority queues.

Binary heap implementation for priority queues.

#### Import heapq heapq.heappush(q, (priority, item)).

import heapq heapq.heappush(q, (priority, item))

#### Small function supporting a larger function or class.

Small function supporting a larger function or class.

#### Used to improve readability and modularity.

Used to improve readability and modularity.

#### Higher-Order Function.

Higher-Order Function

#### Function taking or returning other functions.

Function taking or returning other functions.

#### Generics that take other types:.

Generics that take other types:

#### Callable[[int], str].

Callable[[int], str]

#### Common data analysis pattern.

Common data analysis pattern.

#### Homogeneous Collection.

Homogeneous Collection

#### Container where all elements share same type.

Container where all elements share same type.

#### Not enforced by Python, but expressed with typing:.

Not enforced by Python, but expressed with typing:

#### Callback inserted into system behavior.

Callback inserted into system behavior.

#### Performance-critical code path executed frequently.

Performance-critical code path executed frequently.

#### Profiler tools help identify hot paths.

Profiler tools help identify hot paths.

#### HTTP Client (Python).

HTTP Client (Python)

#### Httpx (modern async/ sync).

httpx (modern async/ sync)

#### Requests (classic synchronous).

requests (classic synchronous)

#### Property combining getter/setter behavior in ORMs (like SQLAlchemy hybrid_property).

Property combining getter/setter behavior in ORMs (like SQLAlchemy hybrid_property).

#### Hydration / Dehydration.

Hydration / Dehydration

#### Domain objects ‚Üí serialized data.

domain objects ‚Üí serialized data

#### Serialized data ‚Üí domain objects.

serialized data ‚Üí domain objects

#### ASGI server similar to Uvicorn.

ASGI server similar to Uvicorn.

#### Related to HATEOAS.

REST concept. Related to HATEOAS. Not Python-specific, but relevant in Django REST Framework / FastAPI.

#### Hypothesis (Testing Library).

Hypothesis (Testing Library)

#### Property-based testing tool.

Property-based testing tool.

#### Generates test cases automatically.

Generates test cases automatically.

#### üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections I‚ÄìK üîµ I Terms I/O-bound Task.

üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections I‚ÄìK üîµ I Terms I/O-bound Task

#### A task limited by waiting for external input/output:.

A task limited by waiting for external input/output:

#### IDE (Integrated Development Environment).

IDE (Integrated Development Environment)

#### Tools commonly used with Python:.

Tools commonly used with Python:

#### Determines whether two references point to the same object.

Determines whether two references point to the same object.

#### Versus == (equality).

Versus == (equality).

#### Function that can be called multiple times without changing result after the first call.

Function that can be called multiple times without changing result after the first call.

#### Example: PUT operations are idempotent; POST is not.

Example: PUT operations are idempotent; POST is not.

#### Conditional branching control-flow.

Conditional branching control-flow.

#### Supports chained elif and final else.

Supports chained elif and final else.

#### Object whose value cannot be changed after creation.

Object whose value cannot be changed after creation.

#### Python‚Äôs module loading mechanism.

Python‚Äôs module loading mechanism.

#### Module caching (sys.modules).

module caching (sys.modules)

#### Custom behavior injected into import system.

Custom behavior injected into import system.

#### Dynamic module generation.

dynamic module generation

#### Loads modules into the current namespace.

Loads modules into the current namespace.

#### Import x from x import y from x import y as z.

import x from x import y from x import y as z

#### Modifies an object without creating a new one.

Modifies an object without creating a new one.

#### Example: list operations.

Example: list operations.

#### Associated with dunder methods: __iadd__, __imul__.

Associated with dunder methods: __iadd__, __imul__.

#### Operators between operands:.

Operators between operands:

#### Python lets you create infix-like behavior with special methods.

Python lets you create infix-like behavior with special methods.

#### OOP mechanism where child classes derive from parent classes.

OOP mechanism where child classes derive from parent classes.

#### Cooperative (via super()).

cooperative (via super())

#### Initializer (__init__).

Initializer (__init__)

#### Method run after object creation to set initial state.

Method run after object creation to set initial state.

#### Inline Cache (CPython Optimizations).

Inline Cache (CPython Optimizations)

#### Runtime optimization introduced in Python 3.11 to speed up:.

Runtime optimization introduced in Python 3.11 to speed up:

#### Stored in bytecode‚Äôs inline cache entries.

Stored in bytecode‚Äôs inline cache entries.

#### Input Function (input()).

Input Function (input())

#### Reads from stdin as a string.

Reads from stdin as a string.

#### Sorting algorithm used internally by Python‚Äôs Timsort in small partitions.

Sorting algorithm used internally by Python‚Äôs Timsort in small partitions.

#### Regular method where first argument is the instance (self).

Regular method where first argument is the instance (self).

#### Attribute stored in object‚Äôs __dict__.

Attribute stored in object‚Äôs __dict__.

#### Creating an instance of a class.

Creating an instance of a class.

#### Happens via __new__ then __init__.

Happens via __new__ then __init__.

#### CPython optimizes small integers by reusing common objects.

CPython optimizes small integers by reusing common objects.

#### A = 10 b = 10 a is b # True for small ints.

a = 10 b = 10 a is b # True for small ints

#### Interface (Duck Typing).

Interface (Duck Typing)

#### Python does not enforce interface types explicitly.

Python does not enforce interface types explicitly.

#### Protocols (PEP 544) provide typed structural interfaces.

Protocols (PEP 544) provide typed structural interfaces.

#### Ability of Python code to integrate with:.

Ability of Python code to integrate with:

#### Runs compiled Python bytecode inside a VM.

Runs compiled Python bytecode inside a VM.

#### CPython is the default interpreter.

CPython is the default interpreter.

#### Interrupt (KeyboardInterrupt).

Interrupt (KeyboardInterrupt)

#### Triggered when user presses Ctrl+C.

Triggered when user presses Ctrl+C.

#### Ability to examine objects at runtime.

Ability to examine objects at runtime.

#### Any object implementing __iter__ or __getitem__.

Any object implementing __iter__ or __getitem__.

#### __iter__() __next__().

__iter__() __next__()

#### High-performance iterator building blocks.

High-performance iterator building blocks.

#### ISO Format (Datetime).

ISO Format (Datetime)

#### Standard datetime format:.

Standard datetime format:

#### Isolated Virtual Environment.

Isolated Virtual Environment

#### Dedicated environment created via:.

Dedicated environment created via:

#### Item Assignment (__setitem__).

Item Assignment (__setitem__)

#### D[key] = value lst[2] = x.

d[key] = value lst[2] = x

#### Item Access (__getitem__).

Item Access (__getitem__)

#### üü¢ J Terms JIT (Just-In-Time Compilation).

üü¢ J Terms JIT (Just-In-Time Compilation)

#### Runtime compilation to machine code.

Runtime compilation to machine code.

#### Cython (ahead-of-time, but JIT-like behavior).

Cython (ahead-of-time, but JIT-like behavior)

#### Python 3.13+: experimental CPython JIT introduced.

Python 3.13+: experimental CPython JIT introduced

#### JDBC (In Python Context).

JDBC (In Python Context)

#### Used with Jython for DB access via Java ecosystem.

Used with Jython for DB access via Java ecosystem.

#### Templating engine used by Flask and other frameworks.

Templating engine used by Flask and other frameworks.

#### {{ variable }} {% for item in list %}.

{{ variable }} {% for item in list %}

#### Task queue used for:.

Task queue used for:

#### JSON (JavaScript Object Notation).

JSON (JavaScript Object Notation)

#### Data exchange format.

Data exchange format.

#### Import json json.loads('{"a":1}').

import json json.loads('{"a":1}')

#### Schema for validating JSON objects.

Schema for validating JSON objects. Used in FastAPI & Pydantic.

#### Interactive environment mixing code + outputs + text.

Interactive environment mixing code + outputs + text.

#### Kernel executes Python code.

Kernel executes Python code.

#### Backend process executing notebook code.

Backend process executing notebook code.

#### JWT (JSON Web Token).

JWT (JSON Web Token)

#### Compact representation of claims, used in authentication.

Compact representation of claims, used in authentication.

#### JavaScript Interop (via Pyodide / WASM).

JavaScript Interop (via Pyodide / WASM)

#### Python can run in browser using Pyodide and WebAssembly.

Python can run in browser using Pyodide and WebAssembly.

#### Library for parallel computing & caching in scientific Python stack.

Library for parallel computing & caching in scientific Python stack.

#### Measure used in ML/data analysis:.

Measure used in ML/data analysis:

#### Intersection / union.

intersection / union

#### Included for ML workflows.

Included for ML workflows.

#### Randomized delay added to retry backoff.

Randomized delay added to retry backoff.

#### Important for distributed systems.

Important for distributed systems.

#### üü° K Terms K-Means (Machine Learning).

üü° K Terms K-Means (Machine Learning)

#### Clustering algorithm.

Clustering algorithm. Used in:

#### Not part of standard library but relevant for Python ML.

Not part of standard library but relevant for Python ML.

#### K-V Store (Key‚ÄìValue Store).

K-V Store (Key‚ÄìValue Store)

#### Databases operating on key-value pairs.

Databases operating on key-value pairs.

#### Python clients exist for:.

Python clients exist for:

#### Key Function (Sorting).

Key Function (Sorting)

#### Function passed to sorted() or .sort() to determine ordering.

Function passed to sorted() or .sort() to determine ordering.

#### Sorted(items, key=lambda x: x.age).

sorted(items, key=lambda x: x.age)

#### Exception raised when dict key not found.

Exception raised when dict key not found.

#### Keyword Argument (kwargs).

Keyword Argument (kwargs)

#### Argument passed in name=value form.

Argument passed in name=value form.

#### Keyword-only Argument.

Keyword-only Argument

#### Keyword-only Variadic (**kwargs).

Keyword-only Variadic (**kwargs)

#### Arbitrary keyword argument mapping.

Arbitrary keyword argument mapping.

#### Kernel (OS or Jupyter).

Kernel (OS or Jupyter)

#### The running process that:.

The running process that:

#### Multiprocessing ‚Äúspawn‚Äù mode creating new kernels.

multiprocessing ‚Äúspawn‚Äù mode creating new kernels

#### Kernel Density Estimation (KDE).

Kernel Density Estimation (KDE)

#### Statistical smoothing technique used in data analysis libraries (SciPy, pandas).

Statistical smoothing technique used in data analysis libraries (SciPy, pandas).

#### Binary units: 1 KiB = 1024 bytes.

Binary units: 1 KiB = 1024 bytes.

#### Important for memory profiling.

Important for memory profiling.

#### Statistic measuring tail heaviness.

Statistic measuring tail heaviness. Relevant in Python data libraries.

#### Kubernetes (Python Context).

Kubernetes (Python Context)

#### Deployment environment for Python microservices.

Deployment environment for Python microservices.

#### Pip install kubernetes.

pip install kubernetes

#### Managing FastAPI / Django apps.

managing FastAPI / Django apps

#### Kwargs (Keyword Arguments Dictionary).

Kwargs (Keyword Arguments Dictionary)

#### Captured via **kwargs.

Captured via **kwargs.

#### Def f(**kwargs): print(kwargs).

def f(**kwargs): print(kwargs)

#### üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections L‚ÄìN üîµ L Terms L-Value.

üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections L‚ÄìN üîµ L Terms L-Value

#### Expression that can appear on left side of assignment.

Expression that can appear on left side of assignment.

#### X = 10 a[2] = 3 obj.attr = 5.

x = 10 a[2] = 3 obj.attr = 5

#### Labeled Statement (PEP 572 / assignment expressions context).

Labeled Statement (PEP 572 / assignment expressions context)

#### Not a formal Python term, but used in docs referring to when an expression contains substructure like:.

Not a formal Python term, but used in docs referring to when an expression contains substructure like:

#### If (m := pattern.match(s)): ...

if (m := pattern.match(s)): ...

#### Anonymous inline function:.

Anonymous inline function:

#### Lambda yields only expressions (no statements).

lambda yields only expressions (no statements)

#### Def supports full block body.

def supports full block body

#### Lambdas do not auto-generate names.

lambdas do not auto-generate names

#### Delay computation until value is needed.

Delay computation until value is needed.

#### Python lazy constructs:.

Python lazy constructs:

#### Generator expressions.

generator expressions

#### functools.cached_property

functools.cached_property

#### SQLAlchemy query construction.

SQLAlchemy query construction

#### LBYL (Look Before You Leap).

LBYL (Look Before You Leap)

#### Check conditions before performing an action.

Check conditions before performing an action.

#### If key in d: value = d[key].

if key in d: value = d[key]

#### Less idiomatic in Python.

Opposite EAFP. Less idiomatic in Python.

#### Leading Underscore (_name).

Leading Underscore (_name)

#### Convention marking internal-use attributes.

Convention marking internal-use attributes.

#### Least Recently Used (LRU) Cache.

Least Recently Used (LRU) Cache

#### @lru_cache(maxsize=128)

@lru_cache(maxsize=128)

#### Len Protocol (__len__).

Len Protocol (__len__)

#### Method returning container size.

Method returning container size.

#### Boolean context (fallback if __bool__ missing).

boolean context (fallback if __bool__ missing)

#### Variables are resolved based on where functions are defined, not where they're called.

Variables are resolved based on where functions are defined, not where they're called.

#### Python is lexically scoped; differs from dynamic scoping.

Python is lexically scoped; differs from dynamic scoping.

#### Lexical Analysis (Tokenizer).

Lexical Analysis (Tokenizer)

#### First phase of compilation:.

First phase of compilation:

#### Library (Module or Package).

Library (Module or Package)

#### Reusable Python code.

Reusable Python code.

#### Life Cycle of Object.

Life Cycle of Object

#### Allocation (__new__).

Allocation (__new__)

#### Initialization (__init__).

Initialization (__init__)

#### Destruction (__del__, GC).

Destruction (__del__, GC)

#### Implicit via parentheses:.

Implicit via parentheses:

#### Implicit style is recommended.

Implicit style is recommended.

#### Simple search method; often replaced by dict/set for O(1) lookups.

Simple search method; often replaced by dict/set for O(1) lookups.

#### Linker (in CPython C Extensions).

Linker (in CPython C Extensions)

#### Resolves symbols when compiling extension modules.

Resolves symbols when compiling extension modules.

#### Dynamic, mutable sequence.

Dynamic, mutable sequence. Backed by a dynamic array.

#### Pythonic construct for building lists:.

Pythonic construct for building lists:

#### [x*x for x in nums if x % 2 == 0].

[x*x for x in nums if x % 2 == 0]

#### Generates optimized bytecode.

Generates optimized bytecode.

#### Direct value representation in code:.

Direct value representation in code:

#### Literal Types (PEP 586).

Literal Types (PEP 586)

#### Typing support for literal value types:.

Typing support for literal value types:

#### From typing import Literal def f(color: Literal["red","blue"]): ...

from typing import Literal def f(color: Literal["red","blue"]): ...

#### LLDB/GDB (Debuggers).

LLDB/GDB (Debuggers)

#### Used routinely for CPython internals debugging.

Used routinely for CPython internals debugging.

#### Final phase of Extract Transform Load workflows.

Final phase of Extract Transform Load workflows.

#### Loader (Import System).

Loader (Import System)

#### Component that loads module code.

Component that loads module code.

#### Variable defined in function scope.

Variable defined in function scope.

#### Lock (Threading / Asyncio).

Lock (Threading / Asyncio)

#### Mutual exclusion mechanism.

Mutual exclusion mechanism.

#### Lock = threading.Lock().

lock = threading.Lock()

#### Lock = asyncio.Lock().

lock = asyncio.Lock()

#### Logging (stdlib logging).

Logging (stdlib logging)

#### Python‚Äôs built-in logging framework.

Python‚Äôs built-in logging framework.

#### Structured logging (with structlog).

structured logging (with structlog)

#### Lookup Chain (Attribute Resolution).

Lookup Chain (Attribute Resolution)

#### LSP (Liskov Substitution Principle).

LSP (Liskov Substitution Principle)

#### LSTM (Machine Learning).

LSTM (Machine Learning)

#### Long Short-Term Memory model, used in deep learning.

Long Short-Term Memory model, used in deep learning.

#### Included because ML is a major Python ecosystem domain.

Included because ML is a major Python ecosystem domain.

#### The largest letter group in Python glossary due to:.

The largest letter group in Python glossary due to:

#### MyPy typing concepts.

MyPy typing concepts

#### Magic Method (Dunder Method).

Magic Method (Dunder Method)

#### Methods with double underscores:.

Methods with double underscores:

#### Defined by Python‚Äôs data model.

Defined by Python‚Äôs data model.

#### Main Guard (if __name__ == "__main__":).

Main Guard (if __name__ == "__main__":)

#### Pattern to prevent code from executing on import.

Pattern to prevent code from executing on import.

#### Functional transform:.

Functional transform:

#### Map(lambda x: x*2, nums).

map(lambda x: x*2, nums)

#### Prefer comprehensions.

Prefer comprehensions.

#### Container of key-value pairs.

Container of key-value pairs.

#### Abstract base: collections.abc.Mapping.

Abstract base: collections.abc.Mapping.

#### Low-level serialization used by CPython internally.

Low-level serialization used by CPython internally. Not stable for long-term storage.

#### Happens when references prevent objects from being garbage collected.

Happens when references prevent objects from being garbage collected.

#### Memory View (memoryview).

Memory View (memoryview)

#### Zero-copy object for accessing buffer data.

Zero-copy object for accessing buffer data.

#### Large data pipelines.

large data pipelines

#### High-performance I/O.

high-performance I/O

#### Function belonging to a class.

Function belonging to a class.

#### Method Resolution Order (MRO).

Method Resolution Order (MRO)

#### Order Python uses to resolve attribute lookup in inheritance.

Order Python uses to resolve attribute lookup in inheritance.

#### Class A(metaclass=Meta): ...

class A(metaclass=Meta): ...

#### Microtask (async context).

Microtask (async context)

#### Asyncio tasks scheduled to run after current task yields control.

Asyncio tasks scheduled to run after current task yields control.

#### Class designed to be added to other classes to extend behavior.

Class designed to be added to other classes to extend behavior.

#### File containing Python definitions.

File containing Python definitions.

#### Loaded exactly once per interpreter session.

Loaded exactly once per interpreter session.

#### Module Cache (sys.modules).

Module Cache (sys.modules)

#### Dictionary storing loaded modules.

Dictionary storing loaded modules.

#### Replacing functions or attributes at runtime.

Replacing functions or attributes at runtime.

#### Monkeypatch.setattr(obj, "fn", fake).

monkeypatch.setattr(obj, "fn", fake)

#### Repository containing multiple services/libraries.

Repository containing multiple services/libraries.

#### Algebraic structure relevant to functional code:.

Algebraic structure relevant to functional code:

#### Associative operation.

associative operation

#### Included for advanced conceptual clarity.

Included for advanced conceptual clarity.

#### Object that can be changed after creation.

Object that can be changed after creation.

#### Mutual Exclusion (Mutex).

Mutual Exclusion (Mutex)

#### Ensures only one thread can access resource at a time.

Ensures only one thread can access resource at a time.

#### Executing Python code across separate processes.

Executing Python code across separate processes.

#### Used to bypass the GIL for CPU-bound tasks.

Used to bypass the GIL for CPU-bound tasks.

#### multiprocessing.pool

multiprocessing.pool

#### concurrent.futures.ProcessPoolExecutor

concurrent.futures.ProcessPoolExecutor

#### Static type checker for Python.

Static type checker for Python.

#### Mutable Default Argument.

Mutable Default Argument

#### Def f(x, cache={}): # BAD ...

def f(x, cache={}): # BAD ...

#### üü° N Terms NaN (Not a Number).

üü° N Terms NaN (Not a Number)

#### IEEE float representing invalid numerical value.

IEEE float representing invalid numerical value.

#### NaN != NaN evaluates True.

NaN != NaN evaluates True.

#### Mapping of names to objects.

Mapping of names to objects.

#### Package split across multiple directories.

Package split across multiple directories.

#### Pkgutil/shared namespace techniques.

pkgutil/shared namespace techniques

#### Named Tuple (collections.namedtuple).

Named Tuple (collections.namedtuple)

#### Lightweight, immutable tuple with named fields.

Lightweight, immutable tuple with named fields.

#### Narrowing (Type Narrowing).

Narrowing (Type Narrowing)

#### Type checker reduces possible types based on control flow.

Type checker reduces possible types based on control flow.

#### If x is None: ..

if x is None: ... else: # here x is not None

#### Sort order that accounts for numeric substrings.

Sort order that accounts for numeric substrings.

#### Python library: natsort.

Python library: natsort.

#### Nearest Neighbor Search.

Nearest Neighbor Search

#### Used in ML & data engineering for clustering, classification.

Used in ML & data engineering for clustering, classification.

#### Function defined inside another function.

Function defined inside another function.

#### Used for closures and decorators.

Used for closures and decorators.

#### Lexical scope inside another scope.

Lexical scope inside another scope.

#### I/O operated over network sockets.

I/O operated over network sockets.

#### Time for request and response to complete.

Time for request and response to complete.

#### Important in async design.

Important in async design.

#### Machine learning model.

Machine learning model.

#### Most Python frameworks support NN:.

Most Python frameworks support NN:

#### Included due to Python‚Äôs dominance in ML.

Included due to Python‚Äôs dominance in ML.

#### In Python 3, all classes are new-style.

In Python 3, all classes are new-style.

#### Unified type hierarchy.

unified type hierarchy

#### Typing construct that creates distinct type identities.

Typing construct that creates distinct type identities.

#### From typing import NewType UserId = NewType("UserId", int).

from typing import NewType UserId = NewType("UserId", int)

#### Element in the abstract syntax tree.

Element in the abstract syntax tree.

#### I/O operations that return immediately.

I/O operations that return immediately.

#### Used in async networking.

Used in async networking.

#### Operations whose results cannot be predicted exactly.

Operations whose results cannot be predicted exactly.

#### Floating point summation order.

floating point summation order

#### Variable in outer (enclosing) scope but not global.

Variable in outer (enclosing) scope but not global.

#### Singleton object representing no value.

Singleton object representing no value.

#### Normalization (Data).

Normalization (Data)

#### Process of standardizing:.

Process of standardizing:

#### Unicode normalization.

Unicode normalization

#### Normalization (Database).

Normalization (Database)

#### Process of structuring relational tables.

Process of structuring relational tables.

#### Special return for dunder methods indicating unsupported operation.

Special return for dunder methods indicating unsupported operation.

#### Python‚Äôs foundational numeric computing library.

Python‚Äôs foundational numeric computing library.

#### JIT compiler for scientific Python using LLVM.

JIT compiler for scientific Python using LLVM.

#### Null Context Manager.

Null Context Manager

#### Context manager that does nothing:.

Context manager that does nothing:

#### From contextlib import nullcontext.

from contextlib import nullcontext

#### Useful for conditionally disabling context managers.

Useful for conditionally disabling context managers.

#### üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections O‚ÄìQ üîµ O Terms Object.

üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections O‚ÄìQ üîµ O Terms Object

#### A Python data entity.

A Python data entity. Everything in Python is an object, including:

#### Ints, strings, tuples.

ints, strings, tuples

#### Object Model (Python Data Model).

Object Model (Python Data Model)

#### Defines how objects behave and interact.

Defines how objects behave and interact.

#### Class and instance dictionaries.

class and instance dictionaries

#### The data model is documented in the official reference.

The data model is documented in the official reference.

#### Object-Oriented Programming (OOP).

Object-Oriented Programming (OOP)

#### Programming paradigm based on classes and objects.

Programming paradigm based on classes and objects.

#### Single & multiple inheritance.

single & multiple inheritance

#### Reusing existing objects instead of creating new ones.

Reusing existing objects instead of creating new ones. Used rarely in Python because GC is fast, but beneficial in high-performance systems.

#### Pattern allowing objects to notify observers.

Pattern allowing objects to notify observers.

#### Custom observer implementation.

custom observer implementation

#### Event-driven frameworks.

event-driven frameworks

#### Behavioral pattern: subject broadcasts changes to observers.

Behavioral pattern: subject broadcasts changes to observers.

#### Integer literal in base 8:.

Integer literal in base 8:

#### Offset-aware Datetime.

Offset-aware Datetime

#### Datetime with timezone info (tzinfo).

Datetime with timezone info (tzinfo).

#### A compact Python statement on one line.

A compact Python statement on one line.

#### X = [f(x) for x in data if x > 0].

x = [f(x) for x in data if x > 0]

#### Object returned by open(...).

Object returned by open(...).

#### Use in context manager:.

Use in context manager:

#### With open(...) as f: ...

with open(...) as f: ...

#### API specification format generated automatically by FastAPI.

API specification format generated automatically by FastAPI.

#### Operator Overloading.

Operator Overloading

#### Implementing arithmetic and other operator behavior via dunders.

Implementing arithmetic and other operator behavior via dunders.

#### Order in which Python evaluates operators.

Order in which Python evaluates operators.

#### Typing.Optional[X] == X | None.

typing.Optional[X] == X | None

#### Optimization (Python).

Optimization (Python)

#### Algorithmic optimization.

algorithmic optimization

#### Avoiding global lookups.

avoiding global lookups

#### Using local variables.

using local variables

#### Using join() over string concatenation.

using join() over string concatenation

#### Using list comprehensions.

using list comprehensions

#### Vectorization (NumPy).

vectorization (NumPy)

#### Dict subclass that maintains insertion order (builtins do this from 3.7+).

Dict subclass that maintains insertion order (builtins do this from 3.7+).

#### Ordering-specific APIs.

ordering-specific APIs

#### Interfaces with operating system:.

Interfaces with operating system:

#### Legacy path utilities.

Legacy path utilities. Prefer pathlib.

#### Out-of-Core Processing.

Out-of-Core Processing

#### Handling datasets too large to fit in memory.

Handling datasets too large to fit in memory.

#### IO buffering managed by Python or C library.

IO buffering managed by Python or C library. Affects realtime output.

#### Redefining a superclass method in a subclass.

Redefining a superclass method in a subclass.

#### Override Decorator (Python 3.12+).

Override Decorator (Python 3.12+)

#### From typing import override.

from typing import override

#### Class Child(Parent): @override def my_method(self): ...

class Child(Parent): @override def my_method(self): ...

#### Using typing overloads to provide multiple call signatures.

Using typing overloads to provide multiple call signatures.

#### @overload def f(x: int) -> int: ...

@overload def f(x: int) -> int: ...

#### This is the largest glossary letter in Python due to:

This is the largest glossary letter in Python due to:

#### Python Packaging (pip, pyproject, wheel).

Python Packaging (pip, pyproject, wheel)

#### Pattern Matching (match-case).

Pattern Matching (match-case)

#### Directory with __init__.py, representing a Python module namespace.

Directory with __init__.py, representing a Python module namespace.

#### Namespace packages may omit __init__.py.

Namespace packages may omit __init__.py.

#### Modern packaging uses:.

Modern packaging uses:

#### PEP 517/518 build isolation.

PEP 517/518 build isolation

#### Python‚Äôs dominant data analysis library.

Python‚Äôs dominant data analysis library.

#### Represents callable parameter lists.

Represents callable parameter lists.

#### From typing import ParamSpec P = ParamSpec("P").

from typing import ParamSpec P = ParamSpec("P")

#### Used when typing decorators.

Used when typing decorators.

#### Via functools.partial:.

Via functools.partial:

#### From functools import partial add5 = partial(add, 5).

from functools import partial add5 = partial(add, 5)

#### Modern path handling library.

Modern path handling library.

#### From pathlib import Path Path("file.txt").read_text().

from pathlib import Path Path("file.txt").read_text()

#### Preferred over os.path.

Preferred over os.path.

#### Structural pattern matching introduced in Python 3.10.

Structural pattern matching introduced in Python 3.10.

#### Match obj: case {"status": 200, "data": d}: ...

match obj: case {"status": 200, "data": d}: ...

#### PEP (Python Enhancement Proposal).

PEP (Python Enhancement Proposal)

#### Design documents for Python.

Design documents for Python.

#### Example: PEP 8 ‚Äî Style Guide PEP 484 ‚Äî Type Hints PEP 622 ‚Äî Pattern Matching.

Example: PEP 8 ‚Äî Style Guide PEP 484 ‚Äî Type Hints PEP 622 ‚Äî Pattern Matching

#### Python‚Äôs official style guide.

Python‚Äôs official style guide.

#### Serialization format for Python objects.

Serialization format for Python objects.

#### WARNING: insecure with untrusted data.

WARNING: insecure with untrusted data.

#### Python imaging library fork (PIL).

Python imaging library fork (PIL).

#### Fast DataFrame library leveraging Rust.

Fast DataFrame library leveraging Rust.

#### Pool (Multiprocessing).

Pool (Multiprocessing)

#### From multiprocessing import Pool.

from multiprocessing import Pool

#### Positional-only Arguments.

Positional-only Arguments

#### Declared with / marker.

Declared with / marker.

#### Def f(a, b, /, c): ...

def f(a, b, /, c): ...

#### Post-init (Dataclass).

Post-init (Dataclass)

#### Method called after auto-generated __init__.

Method called after auto-generated __init__.

#### @dataclass class A: def __post_init__(self): ...

@dataclass class A: def __post_init__(self): ...

#### Pretty printer for nested structures.

Pretty printer for nested structures.

#### Process (Multiprocessing).

Process (Multiprocessing)

#### Separate OS-level process with its own interpreter.

Separate OS-level process with its own interpreter.

#### Structural typing interface.

Structural typing interface.

#### From typing import Protocol class Runner(Protocol): def run(self): ...

from typing import Protocol class Runner(Protocol): def run(self): ...

#### Used instead of abstract base classes for static typing.

Used instead of abstract base classes for static typing.

#### Protobuf (Protocol Buffers).

Protobuf (Protocol Buffers)

#### Binary serialization format used in gRPC.

Binary serialization format used in gRPC.

#### Object controlling access to another object.

Object controlling access to another object.

#### SQLAlchemy lazy loaders.

SQLAlchemy lazy loaders

#### Data validation and serialization framework used by FastAPI.

Data validation and serialization framework used by FastAPI.

#### JSON schema generation.

JSON schema generation

#### PyPI (Python Package Index).

PyPI (Python Package Index)

#### Repository hosting Python packages.

Repository hosting Python packages.

#### Machine learning framework.

Machine learning framework.

#### Modern testing framework.

Modern testing framework.

#### Pytest Fixture Scope.

Pytest Fixture Scope

#### Modify behavior at runtime for tests.

Modify behavior at runtime for tests.

#### Generate multiple tests from data:.

Generate multiple tests from data:

#### @pytest.mark.parametrize("x,y", [(1,2), (3,4)]).

@pytest.mark.parametrize("x,y", [(1,2), (3,4)])

#### Code that follows idiomatic Python style:.

Code that follows idiomatic Python style:

#### Avoids unnecessary classes.

avoids unnecessary classes

#### Time zone handling libraries.

Time zone handling libraries.

#### Zoneinfo is stdlib from Python 3.9+.

zoneinfo is stdlib from Python 3.9+.

#### Distributed processing using Apache Spark with Python API.

Distributed processing using Apache Spark with Python API.

#### Tool for packaging Python apps into standalone executables.

Tool for packaging Python apps into standalone executables.

#### Rust bindings for Python.

Rust bindings for Python.

#### C++ bindings for Python.

C++ bindings for Python.

#### Pyramid (Web Framework).

Pyramid (Web Framework)

#### Legacy but still used in enterprise settings.

Legacy but still used in enterprise settings.

#### Static type checker built in TypeScript (fast alternative to MyPy).

Static type checker built in TypeScript (fast alternative to MyPy).

#### Shorter section, but includes important concepts.

Shorter section, but includes important concepts.

#### Reinforcement learning algorithm (ML).

Reinforcement learning algorithm (ML).

#### Q-Object (Django ORM).

Q-Object (Django ORM)

#### Dynamic query construction object:.

Dynamic query construction object:

#### From django.db.models import Q Q(name="John") | Q(age__lt=30).

from django.db.models import Q Q(name="John") | Q(age__lt=30)

#### Thread abstraction used in Qt framework.

Thread abstraction used in Qt framework.

#### Quadratic Time (O(n¬≤)).

Quadratic Time (O(n¬≤))

#### Performance classification.

Performance classification.

#### Naive string concatenation.

naive string concatenation

#### Qualified Name (__qualname__).

Qualified Name (__qualname__)

#### Fully qualified dotted path of function, including nested context.

Fully qualified dotted path of function, including nested context.

#### Reducing model precision (FP32 ‚Üí INT8) for inference speed.

Reducing model precision (FP32 ‚Üí INT8) for inference speed.

#### Thread-safe FIFO provided by:.

Thread-safe FIFO provided by:

#### Queue.Queue (threading).

queue.Queue (threading)

#### Asyncio.Queue (async).

asyncio.Queue (async)

#### Multiprocessing.Queue (process-safe).

multiprocessing.Queue (process-safe)

#### Selection algorithm used in partition-based operations.

Selection algorithm used in partition-based operations.

#### Python‚Äôs Timsort chooses quicksort-like partitions in worst-case scenarios.

Sorting algorithm. Python‚Äôs Timsort chooses quicksort-like partitions in worst-case scenarios.

#### Consensus requirement in distributed systems ‚Äî relevant to Python-based distributed apps.

Consensus requirement in distributed systems ‚Äî relevant to Python-based distributed apps.

#### State when no tasks remain runnable (asyncio event loop).

State when no tasks remain runnable (asyncio event loop).

#### üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections R‚ÄìT üîµ R Terms Race Condition.

üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections R‚ÄìT üîµ R Terms Race Condition

#### Bug where outcome depends on timing of concurrent operations.

Bug where outcome depends on timing of concurrent operations.

#### Async tasks with shared state.

async tasks with shared state

#### Avoiding shared mutable state.

avoiding shared mutable state

#### Used to trigger an exception.

Used to trigger an exception.

#### Raise ValueError("Invalid!").

raise ValueError("Invalid!")

#### Standard library pseudo-random generator.

Standard library pseudo-random generator.

#### For cryptographic randomness, use:.

For cryptographic randomness, use:

#### Lazy arithmetic sequence type.

Lazy arithmetic sequence type.

#### Efficient because not stored in memory.

Efficient because not stored in memory.

#### Controlling how often a function or API can be called.

Controlling how often a function or API can be called.

#### Prevents escape interpretation:.

Prevents escape interpretation:

#### R"\n" # backslash + n.

r"\n" # backslash + n

#### Reactive Programming.

Reactive Programming

#### Event-driven or observable stream processing.

Event-driven or observable stream processing.

#### Read-Eval-Print Loop (REPL).

Read-Eval-Print Loop (REPL)

#### Interactive Python console.

Interactive Python console.

#### Function calling itself.

Function calling itself.

#### Primary memory management technique in CPython.

Primary memory management technique in CPython.

#### Object freed when refcount hits 0.

Object freed when refcount hits 0.

#### Runtime introspection:.

Runtime introspection:

#### Dir(obj) getattr(obj, "name") inspect.getsource(fn).

dir(obj) getattr(obj, "name") inspect.getsource(fn)

#### Regex / Regular Expressions (re module).

Regex / Regular Expressions (re module)

#### Pattern matching syntax:.

Pattern matching syntax:

#### Import re re.match(r"\d+", "123").

import re re.match(r"\d+", "123")

#### Global or module-level registry of objects.

Global or module-level registry of objects.

#### Using dot-based imports:.

Using dot-based imports:

#### Reload (importlib.reload).

Reload (importlib.reload)

#### Reload a module at runtime.

Reload a module at runtime.

#### Not recommended in production; useful for REPL workflows.

Not recommended in production; useful for REPL workflows.

#### Render (Web Framework Context).

Render (Web Framework Context)

#### Creating output from template:.

Creating output from template:

#### FastAPI response models.

FastAPI response models

#### Separates business logic from persistence.

Separates business logic from persistence.

#### FastAPI + SQLAlchemy systems.

FastAPI + SQLAlchemy systems

#### Framework-dependent representation of incoming HTTP request.

Framework-dependent representation of incoming HTTP request.

#### Words with special meaning:.

Words with special meaning:

#### Prevention: use context managers.

Prevention: use context managers.

#### Type hint for return value:.

Type hint for return value:

#### Exits function and optionally returns a value.

Exits function and optionally returns a value.

#### Returned by reversed(obj).

Returned by reversed(obj).

#### Reentrant Lock (RLock).

Reentrant Lock (RLock)

#### Threading lock that can be acquired multiple times by same thread.

Threading lock that can be acquired multiple times by same thread.

#### Top-level logger of logging system.

Top-level logger of logging system.

#### Configured via decimal context:.

Configured via decimal context:

#### RPC (Remote Procedure Call).

RPC (Remote Procedure Call)

#### Technique for invoking functions over network.

Technique for invoking functions over network.

#### FastAPI RPC patterns.

FastAPI RPC patterns

#### Generic catch-all for unexpected runtime conditions.

Generic catch-all for unexpected runtime conditions.

#### Runtime Introspection.

Runtime Introspection

#### Inspecting objects at runtime.

Inspecting objects at runtime.

#### This is the largest letter in the glossary due to:

This is the largest letter in the glossary due to:

#### Serialization (JSON, YAML, Pickle).

Serialization (JSON, YAML, Pickle)

#### Servers (WSGI, ASGI).

Servers (WSGI, ASGI)

#### Scikit-learn / SciPy.

Scikit-learn / SciPy

#### Serialization formats.

Serialization formats

#### Pattern to safely access attributes:.

Pattern to safely access attributes:

#### Value = obj.attr if obj else None.

value = obj.attr if obj else None

#### Python does NOT have a ?.

Python does NOT have a ?. operator.

#### Single numerical value (non-array).

Single numerical value (non-array).

#### Schema (Pydantic / JSON Schema).

Schema (Pydantic / JSON Schema)

#### Formal structure of data models.

Formal structure of data models.

#### Where variables are visible.

Where variables are visible.

#### Determined lexically.

Determined lexically.

#### Scoped Session (SQLAlchemy).

Scoped Session (SQLAlchemy)

#### Thread-local session registry.

Thread-local session registry.

#### Using Python for procedural, top-level tasks.

Using Python for procedural, top-level tasks.

#### Concurrency primitive limiting number of simultaneous operations.

Concurrency primitive limiting number of simultaneous operations.

#### Threading vs asyncio versions exist.

Threading vs asyncio versions exist.

#### Transforming Python objects into byte/string formats:.

Transforming Python objects into byte/string formats:

#### Server (WSGI / ASGI).

Server (WSGI / ASGI)

#### Stateful interaction between client and server.

Stateful interaction between client and server.

#### aiohttp.ClientSession

aiohttp.ClientSession

#### Transactional database session.

Transactional database session.

#### Unordered collection of unique elements.

Unordered collection of unique elements.

#### Extremely fast membership testing.

Extremely fast membership testing.

#### Set Comprehension {x*x for x in nums}.

Set Comprehension {x*x for x in nums}

#### Copy container but not nested objects:.

Copy container but not nested objects:

#### Memory optimization disabling dynamic attributes:.

Memory optimization disabling dynamic attributes:

#### Class A: __slots__ = ("x", "y").

class A: __slots__ = ("x", "y")

#### Python naming convention: user_profile_image_id.

Python naming convention: user_profile_image_id.

#### Low-level network communication endpoint.

Low-level network communication endpoint.

#### Standard library module: socket.

Standard library module: socket.

#### Python‚Äôs most popular ORM and SQL toolkit.

Python‚Äôs most popular ORM and SQL toolkit.

#### Execution context of a function call.

Execution context of a function call.

#### List of active frames at error time.

List of active frames at error time.

#### Modules included with Python:.

Modules included with Python:

#### Formal model of transitions between states.

Formal model of transitions between states.

#### Object maintaining internal state.

Object maintaining internal state.

#### Method without implicit self or cls.

Method without implicit self or cls.

#### @staticmethod def util(): ...

@staticmethod def util(): ...

#### Python is not statically typed, but typing module offers static type hints.

Python is not statically typed, but typing module offers static type hints.

#### Deduplicating identical immutable strings for optimization.

Deduplicating identical immutable strings for optimization.

#### Enclosed in ' ' or " " or ''' '''.

Enclosed in ' ' or " " or ''' '''.

#### F-strings (modern, fastest).

f-strings (modern, fastest)

#### Running external commands:.

Running external commands:

#### Import subprocess subprocess.run(["ls", "-l"]).

import subprocess subprocess.run(["ls", "-l"])

#### Allows calling parent class methods using MRO.

Allows calling parent class methods using MRO.

#### Internal compiler data structure mapping names to metadata.

Internal compiler data structure mapping names to metadata.

#### Synchronous Function.

Synchronous Function

#### Ordinary function, not using async.

Ordinary function, not using async.

#### Raised when parser rejects code.

Raised when parser rejects code.

#### Used for static analysis.

Used for static analysis.

#### Low-level OS function call.

Low-level OS function call. Python interfaces via:

#### Python has many T-terms due to:.

Python has many T-terms due to:

#### Testing (pytest, unittest).

Testing (pytest, unittest)

#### TaskGroups (asyncio 3.11+).

TaskGroups (asyncio 3.11+)

#### Security vulnerability where untrusted input is used unsafely.

Security vulnerability where untrusted input is used unsafely.

#### Python has tools (Bandit, Semgrep) to detect.

Python has tools (Bandit, Semgrep) to detect.

#### X = a if cond else b.

x = a if cond else b

#### Object replacing real implementation in tests:.

Object replacing real implementation in tests:

#### OS-level lightweight execution unit.

OS-level lightweight execution unit.

#### Python threads are limited by the GIL for CPU-bound tasks, but great for I/O-bound.

Python threads are limited by the GIL for CPU-bound tasks, but great for I/O-bound.

#### Thread pool for concurrency.

Thread pool for concurrency.

#### Standard interface for multi-threading.

Standard interface for multi-threading.

#### Limiting throughput manually or dynamically.

Limiting throughput manually or dynamically.

#### Highly optimized hybrid sorting algorithm used by Python.

Highly optimized hybrid sorting algorithm used by Python.

#### Representation of time (seconds since epoch).

Representation of time (seconds since epoch).

#### Lexical unit produced by tokenizer.

Lexical unit produced by tokenizer.

#### Converts source code ‚Üí tokens.

Converts source code ‚Üí tokens.

#### Python has a full tokenizer in tokenize module.

Python has a full tokenizer in tokenize module.

#### Token Bucket (Rate Limiting).

Token Bucket (Rate Limiting)

#### Algorithm for rate-limiting throughput.

Algorithm for rate-limiting throughput.

#### Configuration format used by pyproject.toml.

Configuration format used by pyproject.toml.

#### Top-level Await (Python 3.11 in REPL / notebooks).

Top-level Await (Python 3.11 in REPL / notebooks)

#### Async code can be awaited at top-level in:.

Async code can be awaited at top-level in:

#### Interactive consoles.

interactive consoles

#### Not allowed in normal .py files.

Not allowed in normal .py files.

#### Error stack printed when an exception occurs.

Error stack printed when an exception occurs.

#### Tracking execution for:.

Tracking execution for:

#### Transactional (DB Context).

Transactional (DB Context)

#### Block of operations executed atomically.

Block of operations executed atomically.

#### Transducer (Functional).

Transducer (Functional)

#### Composed transformation pipelines without intermediate collections.

Composed transformation pipelines without intermediate collections.

#### Supported via itertools chains.

Supported via itertools chains.

#### Transformer Model (ML).

Transformer Model (ML)

#### Neural network architecture used in:.

Neural network architecture used in:

#### Python libraries: PyTorch, TensorFlow.

Python libraries: PyTorch, TensorFlow.

#### Immutable ordered sequence.

Immutable ordered sequence.

#### Every Python object has a type.

Every Python object has a type.

#### Used to name complex types:.

Used to name complex types:

#### From typing import TypeAlias UserId: TypeAlias = int.

from typing import TypeAlias UserId: TypeAlias = int

#### Dictionary with typed keys.

Dictionary with typed keys.

#### Class User(TypedDict): id: int name: str.

class User(TypedDict): id: int name: str

#### Losing type metadata at runtime (Python does this naturally).

Losing type metadata at runtime (Python does this naturally).

#### Used for type narrowing:.

Used for type narrowing:

#### From typing import TypeGuard def is_str(x: object) -> TypeGuard[str]: return isinstance(x, str).

from typing import TypeGuard def is_str(x: object) -> TypeGuard[str]: return isinstance(x, str)

#### Annotation expressing developer intent.

Annotation expressing developer intent.

#### Automatically deducing types.

Automatically deducing types. Python does NOT infer runtime types but type checkers use inference.

#### Generic type placeholder.

Generic type placeholder.

#### TypeChecking (Static).

TypeChecking (Static)

#### üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections U‚ÄìZ üîµ U Terms UDF (User-Defined Function).

üìò APPENDIX C ‚Äî PYTHON GLOSSARY Sections U‚ÄìZ üîµ U Terms UDF (User-Defined Function)

#### Custom function defined by developer.

Custom function defined by developer.

#### UID (Unique Identifier).

UID (Unique Identifier)

#### Unique value used to identify resources.

Unique value used to identify resources.

#### Correlation IDs in logging.

correlation IDs in logging

#### Operator with single operand:.

Operator with single operand:

#### Underscore Placeholder (_).

Underscore Placeholder (_)

#### Internationalization (gettext by convention).

internationalization (gettext by convention)

#### Matching wildcard in match.

matching wildcard in match

#### Standard for text encoding.

Standard for text encoding.

#### Python uses Unicode internally for str.

Python uses Unicode internally for str.

#### Common encoding: UTF-8.

Common encoding: UTF-8.

#### Handling of accented characters.

Handling of accented characters.

#### Python supports via:.

Python supports via:

#### Import unicodedata unicodedata.normalize("NFKD", s).

import unicodedata unicodedata.normalize("NFKD", s)

#### Expanding iterables into variables:.

Expanding iterables into variables:

#### A, *rest = range(10).

a, *rest = range(10)

#### Unpacking Operator (* / **).

Unpacking Operator (* / **)

#### Def f(a, b, c): ..

def f(a, b, c): ... args = [1, 2, 3] f(*args)

#### Deserializing via pickle.load.

Deserializing via pickle.load.

#### Security warning: potential code execution with untrusted data.

Security warning: potential code execution with untrusted data.

#### Python does not have explicit unsigned ints; all ints are arbitrary precision.

Python does not have explicit unsigned ints; all ints are arbitrary precision.

#### Update (Dict Operation).

Update (Dict Operation)

#### Merging two dictionaries:.

Merging two dictionaries:

#### D |= other d.update(other).

d |= other d.update(other)

#### Legacy HTTP requests library.

Legacy HTTP requests library.

#### ASGI server commonly used with FastAPI.

ASGI server commonly used with FastAPI.

#### Server often used with Django.

Server often used with Django.

#### üü¢ V Terms Validation (Data).

üü¢ V Terms Validation (Data)

#### Ensuring data conforms to schema.

Ensuring data conforms to schema.

#### Accepts variable number of args:.

Accepts variable number of args:

#### Applying operations over arrays without Python loops.

Applying operations over arrays without Python loops.

#### Patterns that are dangerous:.

Patterns that are dangerous:

#### Included because they appear across the "Python Bible".

Included because they appear across the "Python Bible".

#### Fixing package versions via:.

Fixing package versions via:

#### Essential for reproducibility.

Essential for reproducibility.

#### Isolated environment containing:.

Isolated environment containing:

#### Traversing nested structures.

traversing nested structures

#### Python usage: ast.NodeVisitor.

Python usage: ast.NodeVisitor.

#### Volatile (Concurrency Concept).

Volatile (Concurrency Concept)

#### Python lacks a volatile keyword.

Python lacks a volatile keyword. Use thread-safe queues instead.

#### VPN (Context: cloud deployments).

VPN (Context: cloud deployments)

#### Often configured for secure remote Python deployments.

Often configured for secure remote Python deployments.

#### (Included for completeness due to devops overlap.).

(Included for completeness due to devops overlap.)

#### Most widely used Python IDE/editor.

Most widely used Python IDE/editor.

#### üü° W Terms WAF (Web Application Framework).

üü° W Terms WAF (Web Application Framework)

#### Waldo (Missing Return Problem).

Waldo (Missing Return Problem)

#### Term referencing missing return in multi-branch function.

Term referencing missing return in multi-branch function.

#### Python static analyzers warn against it.

Python static analyzers warn against it.

#### Warning (warnings module).

Warning (warnings module)

#### Import warnings warnings.warn("deprecated", DeprecationWarning).

import warnings warnings.warn("deprecated", DeprecationWarning)

#### Reference that does not increase reference count.

Reference that does not increase reference count.

#### Circular reference prevention.

circular reference prevention

#### System for building web apps:.

System for building web apps:

#### FastAPI (async, modern).

FastAPI (async, modern)

#### Automated extraction of webpage data.

Automated extraction of webpage data.

#### Requests/async scraping.

requests/async scraping

#### Bidirectional real-time communication.

Bidirectional real-time communication.

#### Modern Python binary package format (.whl).

Modern Python binary package format (.whl).

#### Runs while condition is true.

Runs while condition is true.

#### Significant for indentation.

Significant for indentation.

#### WSGI (Web Server Gateway Interface).

WSGI (Web Server Gateway Interface)

#### Legacy synchronous web interface.

Legacy synchronous web interface.

#### Django (classic mode).

Django (classic mode)

#### Concurrency primitive preventing simultaneous writes.

Concurrency primitive preventing simultaneous writes.

#### WSL (Windows Subsystem for Linux).

WSL (Windows Subsystem for Linux)

#### Popular environment for Python dev on Windows.

Popular environment for Python dev on Windows.

#### (X is a small section but important for ML and data pipelines.).

(X is a small section but important for ML and data pipelines.)

#### Machine learning library used for:.

Machine learning library used for:

#### Python has first-class bindings.

Python has first-class bindings.

#### Markup for hierarchical data.

Markup for hierarchical data.

#### Standard library: xml.etree.ElementTree.

Standard library: xml.etree.ElementTree.

#### Replaced by range in Python 3.

Python 2-only. Replaced by range in Python 3.

#### HTTP header for proxy identification.

HTTP header for proxy identification.

#### Common in Python web servers.

Common in Python web servers.

#### XSS (Cross-Site Scripting).

XSS (Cross-Site Scripting)

#### Security vulnerability due to improper escaping.

Security vulnerability due to improper escaping.

#### Python fixes include:.

Python fixes include:

#### Templating engine auto-escaping (Jinja2).

templating engine auto-escaping (Jinja2)

#### Data serialization format.

Data serialization format.

#### Python library: PyYAML.

Python library: PyYAML.

#### YAGNI ("You Aren‚Äôt Gonna Need It").

YAGNI ("You Aren‚Äôt Gonna Need It")

#### Software engineering principle to avoid over-engineering.

Software engineering principle to avoid over-engineering.

#### Pauses generator and returns value.

Pauses generator and returns value.

#### Def gen(): yield 1 yield 2.

def gen(): yield 1 yield 2

#### Delegates to another generator:.

Delegates to another generator:

#### Yield Statement (Coroutine).

Yield Statement (Coroutine)

#### In async context, used with yield for async generator functions.

In async context, used with yield for async generator functions.

#### Operations along Y-axis (axis=1).

Operations along Y-axis (axis=1).

#### Used in JS environments where Python integrates with frontend tooling.

Used in JS environments where Python integrates with frontend tooling.

#### Y-axis Scaling (ML/Data Engineering).

Y-axis Scaling (ML/Data Engineering)

#### Scaling data vertically; used in plotting libraries.

Scaling data vertically; used in plotting libraries.

#### üü° Z Terms Zero-Based Indexing.

üü° Z Terms Zero-Based Indexing

#### Python indexes start at 0.

Python indexes start at 0.

#### Raises ZeroDivisionError.

Raises ZeroDivisionError.

#### Avoiding memory duplication by using:.

Avoiding memory duplication by using:

#### "7".zfill(3) # "007".

"7".zfill(3) # "007"

#### 1Ô∏è‚É£ builtin function combining iterables:.

1Ô∏è‚É£ builtin function combining iterables:

#### 2Ô∏è‚É£ compression file format.

2Ô∏è‚É£ compression file format.

#### 3Ô∏è‚É£ standard library module zipfile.

3Ô∏è‚É£ standard library module zipfile.

#### Creates executable zip archives for Python apps.

Creates executable zip archives for Python apps.

#### Standard library module for ZIP I/O.

Standard library module for ZIP I/O.

#### Compression library for gzip-like compression.

Compression library for gzip-like compression.

#### High-performance distributed messaging library.

High-performance distributed messaging library.

#### Process that finished but not reaped.

Process that finished but not reaped.

#### Modern timezone support (Python 3.9+).

Modern timezone support (Python 3.9+).

#### Spatial indexing technique used in:.

Spatial indexing technique used in:

#### üìò APPENDIX D ‚Äî PYTHON QUICK REFERENCE.

üìò APPENDIX D ‚Äî PYTHON QUICK REFERENCE

#### D.0 ‚Äî Standard Library Coverage Table.

**D.0 ‚Äî Standard Library Coverage Table**

#### This table shows coverage status for all major standard library modules referenced in this Bible:

This table shows coverage status for all major standard library modules referenced in this Bible:

#### Cross-References: - Chapter 9: Standard Library Essentials (primary coverage) - Chapter 4: Type system modules (typing, abc, enum) - Chapter 6: Fun...

**Cross-References:** - **Chapter 9:** Standard Library Essentials (primary coverage) - **Chapter 4:** Type system modules (typing, abc, enum) - **Chapter 6:** Functional programming modules (functools, itertools, operator) - **Chapter 7:** OOP modules (dataclasses, abc) - **Chapter 13:** Security modules (secrets, hashlib, hmac) - **Chapter 14:** Testing modules (unittest, doctest) - **Chapter 17:** Concurrency modules (threading, multiprocessing, asyncio) - **Chapter 19:** Database modules (sqlite3) - **Chapter 20:** Web modules (http, urllib) - **Appendix H:** GUI modules (tkinter)

#### D.1 ‚Äî Syntax Quick Reference.

D.1 ‚Äî Syntax Quick Reference

#### D.2 ‚Äî Common Operations Cheat Sheet.

D.2 ‚Äî Common Operations Cheat Sheet

#### List Operations:.

**List Operations:**

#### Dictionary Operations:.

**Dictionary Operations:**

#### String Operations:.

**String Operations:**

#### D.3 ‚Äî Type Annotation Cheat Sheet.

D.3 ‚Äî Type Annotation Cheat Sheet

#### Optional & Union:.

**Optional & Union:**

#### D.4 ‚Äî Testing Cheat Sheet.

D.4 ‚Äî Testing Cheat Sheet

#### D.5 ‚Äî Concurrency Decision Tree.

D.5 ‚Äî Concurrency Decision Tree

#### When to use threading vs asyncio vs multiprocessing vs distributed:.

When to use threading vs asyncio vs multiprocessing vs distributed:

#### D.2 ‚Äî I/O Models vs Typical Libraries.

D.2 ‚Äî I/O Models vs Typical Libraries

#### I/O Model Library Use Case Synchronous requests, urllib Simple scripts, CLI tools Asynchronous httpx, aiohttp Web APIs, high concurrency Streaming ...

I/O Model Library Use Case Synchronous requests, urllib Simple scripts, CLI tools Asynchronous httpx, aiohttp Web APIs, high concurrency Streaming httpx.stream, aiohttp Large file downloads WebSockets websockets, aiohttp Real-time communication Database (sync) psycopg2, sqlite3 Traditional apps Database (async) asyncpg, aiosqlite Modern async apps

#### D.3 ‚Äî Web Frameworks vs Use Cases.

D.3 ‚Äî Web Frameworks vs Use Cases

#### Framework Best For Not Ideal For FastAPI APIs, microservices, async Full-stack apps, admin panels Django Full-stack, admin, CMS High-performance AP...

Framework Best For Not Ideal For FastAPI APIs, microservices, async Full-stack apps, admin panels Django Full-stack, admin, CMS High-performance APIs, real-time Flask Small apps, flexibility Large scale, async-heavy Starlette Custom ASGI apps Quick prototyping Tornado WebSockets, long polling Standard CRUD apps

#### D.4 ‚Äî Test Types vs Tools.

D.4 ‚Äî Test Types vs Tools

#### Test Type Tool When to Use Unit tests pytest, unittest Individual functions/classes Integration tests pytest, testcontainers Multiple components E2...

Test Type Tool When to Use Unit tests pytest, unittest Individual functions/classes Integration tests pytest, testcontainers Multiple components E2E tests Playwright, Selenium Full user workflows Property-based hypothesis Edge case discovery Performance locust, pytest-benchmark Load testing, benchmarks Coverage coverage.py Code coverage metrics

#### D.5 ‚Äî "When to Choose X vs Y" Cheat Sheets.

D.5 ‚Äî "When to Choose X vs Y" Cheat Sheets

#### NumPy vs Polars vs pandas:.

NumPy vs Polars vs pandas:

#### NumPy: Numerical arrays, linear algebra, small to medium datasets.

NumPy: Numerical arrays, linear algebra, small to medium datasets

#### Polars: Large datasets, analytical workloads, streaming, >RAM data.

Polars: Large datasets, analytical workloads, streaming, >RAM data

#### Pandas: Data analysis, small to medium datasets, familiar API.

pandas: Data analysis, small to medium datasets, familiar API

#### SQLAlchemy vs raw SQL:.

SQLAlchemy vs raw SQL:

#### SQLAlchemy: ORM benefits, type safety, migrations, complex queries.

SQLAlchemy: ORM benefits, type safety, migrations, complex queries

#### Raw SQL: Performance-critical, complex analytics, existing SQL expertise.

Raw SQL: Performance-critical, complex analytics, existing SQL expertise

#### D.6 ‚Äî Data Processing Decision Tree.

D.6 ‚Äî Data Processing Decision Tree

#### D.7 ‚Äî Package Manager Decision Tree.

D.7 ‚Äî Package Manager Decision Tree

#### Late binding closures.

Late binding closures

#### Iterators & exhaustion.

Iterators & exhaustion

#### Floating point weirdness.

Floating point weirdness

#### Concurrency mistakes.

Concurrency mistakes

#### Error handling mistakes.

Error handling mistakes

#### Object model surprises.

Object model surprises

#### Where it appears in real systems.

Where it appears in real systems

#### Default values are evaluated once at function definition time.

Default values are evaluated once at function definition time.

#### The same list is shared across every call.

The same list is shared across every call.

#### Example: append_to_list(1) ‚Üí [1] append_to_list(2) ‚Üí [1, 2] append_to_list(3) ‚Üí [1, 2, 3].

Example: append_to_list(1) ‚Üí [1] append_to_list(2) ‚Üí [1, 2] append_to_list(3) ‚Üí [1, 2, 3]

#### API parameter defaults.

API parameter defaults

#### Machine learning pipelines.

Machine learning pipelines

#### Python closures capture variables, not values.

Python closures capture variables, not values.

#### Capture value explicitly:.

Capture value explicitly:

#### Funcs = [lambda i=i: i for i in range(3)] [f() for f in funcs] # ‚Üí [0, 1, 2].

funcs = [lambda i=i: i for i in range(3)] [f() for f in funcs] # ‚Üí [0, 1, 2]

#### Real-world mistake locations:.

Real-world mistake locations:

#### List comprehension lambdas.

List comprehension lambdas

#### Loop-generated handlers.

Loop-generated handlers

#### üî• D.3 ‚Äî ITERATOR EXHAUSTION Iterators can only be consumed once.

üî• D.3 ‚Äî ITERATOR EXHAUSTION Iterators can only be consumed once. it = iter([1, 2, 3]) list(it) list(it) # ‚Üí []

#### Why this breaks real code:.

Why this breaks real code:

#### Pandas read_csv(chunksize=...).

Pandas read_csv(chunksize=...)

#### Create new generators.

Create new generators

#### üî• D.4 ‚Äî CIRCULAR IMPORTS The silent killer of Python architecture Scenario:.

üî• D.4 ‚Äî CIRCULAR IMPORTS The silent killer of Python architecture Scenario:

#### A.py imports from b.py b.py imports from a.py.

a.py imports from b.py b.py imports from a.py

#### Partially initialized modules.

Partially initialized modules

#### Runtime errors only on first import (‚ÄúWhy does it work sometimes?‚Äù).

Runtime errors only on first import (‚ÄúWhy does it work sometimes?‚Äù)

#### Move imports inside functions def use_b(): from.

Fixes: 1. Move imports inside functions def use_b(): from . import b

#### Result: list("abc") # TypeError.

Result: list("abc") # TypeError

#### üî• D.6 ‚Äî BOOLEAN TRAPS Dangerous because Python is permissive with truthiness.

üî• D.6 ‚Äî BOOLEAN TRAPS Dangerous because Python is permissive with truthiness. Examples: if []: print("no") # empty list is False if "0": print("yes") # non-empty string is True if 0.00001: print("yes") # small floats are True if None: ... # None is False

#### Common bug locations:.

Common bug locations:

#### Environment variable parsing.

environment variable parsing

#### Optional config fields.

optional config fields

#### If value is None: if value == "": if len(value) == 0:.

if value is None: if value == "": if len(value) == 0:

#### üî• D.7 ‚Äî FLOATING POINT WEIRDNESS Classic example: 0.1 + 0.2 == 0.3.

üî• D.7 ‚Äî FLOATING POINT WEIRDNESS Classic example: 0.1 + 0.2 == 0.3

#### Because floats use binary IEEE-754 representation.

Because floats use binary IEEE-754 representation. Fixes:

#### Use fractions.Fraction.

Use fractions.Fraction

#### Tolerances: math.isclose(a, b, rel_tol=1e-9).

Tolerances: math.isclose(a, b, rel_tol=1e-9)

#### Blocking the Event Loop.

**1. Blocking the Event Loop**

#### Time.sleep() is a blocking call that freezes the entire event loop.

`time.sleep()` is a blocking call that freezes the entire event loop. All other async tasks wait, defeating the purpose of async.

#### Mixing Blocking Libraries with Async.

**2. Mixing Blocking Libraries with Async**

#### Creating Tasks Without Storing References.

**3. Creating Tasks Without Storing References**

#### If the task isn't referenced, Python's garbage collector may clean it up before it completes.

If the task isn't referenced, Python's garbage collector may clean it up before it completes.

#### Forgetting to Await Coroutines.

**4. Forgetting to Await Coroutines**

#### Deadlocks with Locks in Async.

**5. Deadlocks with Locks in Async**

#### Exception Handling in Tasks.

**6. Exception Handling in Tasks**

#### Using asyncio.run() Inside Async Context.

**7. Using `asyncio.run()` Inside Async Context**

#### üéØ When It Bites You:.

**üéØ When It Bites You:**

#### See also: Chapter 17.7 (AsyncIO) for complete async coverage.

**See also:** Chapter 17.7 (AsyncIO) for complete async coverage.

#### The Global Interpreter Lock (GIL) is Python's most misunderstood feature.

**The Global Interpreter Lock (GIL) is Python's most misunderstood feature.**

#### Misconception: "Threads run in parallel in Python.".

**Misconception: "Threads run in parallel in Python."**

#### The GIL allows only one thread to execute Python bytecode at a time.

The GIL allows only one thread to execute Python bytecode at a time. For CPU-bound work, threads actually run **slower** than sequential code due to context switching overhead.

#### When Threads ARE Effective (I/O-Bound):.

**When Threads ARE Effective (I/O-Bound):**

#### GIL Release Points:.

**GIL Release Points:**

#### The GIL is released during: - I/O operations (file, network) - C extension calls (NumPy, Cython) - time.sleep() - Some built-in functions (hash, le...

The GIL is released during: - I/O operations (file, network) - C extension calls (NumPy, Cython) - `time.sleep()` - Some built-in functions (hash, len for built-in types)

#### Assuming Threading Speeds Up CPU Work.

**1. Assuming Threading Speeds Up CPU Work**

#### Race Conditions Despite GIL.

**2. Race Conditions Despite GIL**

#### The GIL doesn't prevent race conditions! It only prevents simultaneous bytecode execution.

The GIL doesn't prevent race conditions! It only prevents simultaneous bytecode execution.

#### Python 3.13+ Free-Threading Mode.

**3. Python 3.13+ Free-Threading Mode**

#### Python 3.13+ (experimental) and 3.14+ (stable) introduce free-threading mode that removes GIL limitations:.

Python 3.13+ (experimental) and 3.14+ (stable) introduce free-threading mode that removes GIL limitations:

#### See also: Chapter 17 (Concurrency) and Chapter 28.7 (GIL Internals) for complete coverage.

**See also:** Chapter 17 (Concurrency) and Chapter 28.7 (GIL Internals) for complete coverage.

#### Type Hints Are Not Enforced at Runtime.

**1. Type Hints Are Not Enforced at Runtime**

#### Any Destroys Type Safety.

**2. `Any` Destroys Type Safety**

#### Mutable Default in TypedDict.

**3. Mutable Default in TypedDict**

#### Generic Type Inference Failures.

**6. Generic Type Inference Failures**

#### Optional vs Union[None, T] Confusion.

**7. `Optional` vs `Union[None, T]` Confusion**

#### 8. Covariant/Contravariant TypeVars

**8. Covariant/Contravariant TypeVars**

#### Assuming type hints catch bugs at runtime - Using Any everywhere defeats the purpose - Protocol mismatches in large codebases - Generic type infere...

- Assuming type hints catch bugs at runtime - Using `Any` everywhere defeats the purpose - Protocol mismatches in large codebases - Generic type inference failures

#### Python's flexibility makes it easy to introduce security vulnerabilities.

**Python's flexibility makes it easy to introduce security vulnerabilities.**

#### Using pickle with Untrusted Data = Code Execution.

**1. Using pickle with Untrusted Data = Code Execution**

#### Pickle deserializes arbitrary Python objects, including function calls.

Pickle deserializes arbitrary Python objects, including function calls. An attacker can execute arbitrary code.

#### Eval/exec with User Input.

**2. eval/exec with User Input**

#### YAML Unsafe Load.

**3. YAML Unsafe Load**

#### 4. Hard-Coded Secrets

**4. Hard-Coded Secrets**

#### SSRF via requests.get(user_input).

**5. SSRF via requests.get(user_input)**

#### SQL Injection with String Concatenation.

**6. SQL Injection with String Concatenation**

#### Path Traversal Vulnerabilities.

**7. Path Traversal Vulnerabilities**

#### 8. Command Injection

**8. Command Injection**

#### Insecure Random Number Generation.

**9. Insecure Random Number Generation**

#### Exposing Internal Errors.

**10. Exposing Internal Errors**

#### Deserializing untrusted data - Executing user-provided code - Exposing sensitive information in error messages - Not validating/sanitizing user inp...

- Deserializing untrusted data - Executing user-provided code - Exposing sensitive information in error messages - Not validating/sanitizing user input - Using weak random number generators for security

#### Python's flexibility can lead to performance bottlenecks if not careful.

**Python's flexibility can lead to performance bottlenecks if not careful.**

#### Repeated String Concatenation with +=.

**1. Repeated String Concatenation with +=**

#### Using List Instead of Set for Membership.

**2. Using List Instead of Set for Membership**

#### Using pandas .apply() Instead of Vectorization.

**3. Using pandas .apply() Instead of Vectorization**

#### Using Python Loops Instead of NumPy.

**4. Using Python Loops Instead of NumPy**

#### Excessive Exception Use.

**5. Excessive Exception Use**

#### 6. Deep Recursion

**6. Deep Recursion**

#### Overuse of Dataclasses When Tuples Suffice.

**7. Overuse of Dataclasses When Tuples Suffice**

#### Many Tiny Function Calls Inside Hot Loops.

**8. Many Tiny Function Calls Inside Hot Loops**

#### Creating Objects in Hot Loops.

**9. Creating Objects in Hot Loops**

#### Not Using Generators for Large Datasets.

**10. Not Using Generators for Large Datasets**

#### Processing large datasets with Python loops - String building in loops - Membership testing on large lists - Not using vectorization for numerical ...

- Processing large datasets with Python loops - String building in loops - Membership testing on large lists - Not using vectorization for numerical work - Creating many small objects in hot paths

#### Performance Checklist:.

**Performance Checklist:**

#### See also: Chapter 12 (Performance & Optimization) for complete coverage.

**See also:** Chapter 12 (Performance & Optimization) for complete coverage.

#### Bare except: Catches Everything.

**1. Bare `except:` Catches Everything**

#### Bare except: catches: - KeyboardInterrupt (Ctrl+C won't work!) - SystemExit (sys.exit() won't work!) - GeneratorExit (generator cleanup fails!) - A...

Bare `except:` catches: - `KeyboardInterrupt` (Ctrl+C won't work!) - `SystemExit` (sys.exit() won't work!) - `GeneratorExit` (generator cleanup fails!) - All exceptions (hides bugs!)

#### Swallowing Exceptions Silently.

**2. Swallowing Exceptions Silently**

#### Exception Chaining Lost.

**3. Exception Chaining Lost**

#### Using except Exception Too Broadly.

**4. Using `except Exception` Too Broadly**

#### Not Cleaning Up Resources.

**5. Not Cleaning Up Resources**

#### Exception in finally Hides Original Exception.

**6. Exception in `finally` Hides Original Exception**

#### Using Exceptions for Control Flow.

**7. Using Exceptions for Control Flow**

#### Not Logging Exceptions.

**8. Not Logging Exceptions**

#### Exception Groups (Python 3.11+).

**9. Exception Groups (Python 3.11+)**

#### Not Using else Clause.

**10. Not Using `else` Clause**

#### Silent failures in production - Ctrl+C not working (bare except) - Resource leaks (files, connections) - Lost exception context - Impossible to deb...

- Silent failures in production - Ctrl+C not working (bare except) - Resource leaks (files, connections) - Lost exception context - Impossible to debug (no logging)

#### See also: Chapter 10 (Error Handling) for complete coverage.

**See also:** Chapter 10 (Error Handling) for complete coverage.

#### üî• D.14 ‚Äî OBJECT MODEL SURPRISES.

üî• D.14 ‚Äî OBJECT MODEL SURPRISES

#### Python's object model has subtle behaviors that surprise even experienced developers.

**Python's object model has subtle behaviors that surprise even experienced developers.**

#### Is vs == - Identity vs Equality.

**1. `is` vs `==` - Identity vs Equality**

#### Is checks identity (same object in memory) - == checks equality (same value) - Small integers (-5 to 256) are cached (implementation detail) - Empt...

- `is` checks **identity** (same object in memory) - `==` checks **equality** (same value) - Small integers (-5 to 256) are cached (implementation detail) - Empty tuples are cached: `() is ()` ‚Üí `True`

#### Mutating a List While Iterating.

**2. Mutating a List While Iterating**

#### Dict View Objects Are Live.

**3. Dict View Objects Are Live**

#### Default Attribute Lookup Uses Class Dict First.

**4. Default Attribute Lookup Uses Class Dict First**

#### Self.count += 1 is equivalent to self.count = self.count + 1.

`self.count += 1` is equivalent to `self.count = self.count + 1`. Python looks up `self.count` (finds class attribute `0`), adds 1, then assigns to `self.count` (creates instance attribute).

#### Else Block Execution Misunderstood.

**5. `for ... else` Block Execution Misunderstood**

#### üîç What else Actually Means:.

üîç **What `else` Actually Means:**

#### The else clause runs only if the loop completes normally (doesn't break).

The `else` clause runs **only if the loop completes normally** (doesn't break). This is counterintuitive!

#### Descriptors Unexpectedly Modifying Behavior.

**6. Descriptors Unexpectedly Modifying Behavior**

#### Descriptors intercept attribute access.

Descriptors intercept attribute access. When you access `obj.attr`, Python calls `Descriptor.__get__()` instead of returning the descriptor object.

#### Inheritance MRO Surprises.

**7. Inheritance MRO Surprises**

#### C3 Linearization requires a consistent Method Resolution Order.

C3 Linearization requires a consistent Method Resolution Order. `G(E, F)` where `E = (A, B)` and `F = (B, A)` creates a conflict.

#### __del__ and Garbage Collection Cycles.

**8. `__del__` and Garbage Collection Cycles**

#### Unicode Normalization Issues.

**9. Unicode Normalization Issues**

#### Time Zone Naive vs Aware Datetime Mixing.

**10. Time Zone Naive vs Aware Datetime Mixing**

#### Comparing objects with is instead of == - Modifying collections during iteration - Assuming for...else works like if...else - Descriptor protocol s...

- Comparing objects with `is` instead of `==` - Modifying collections during iteration - Assuming `for...else` works like `if...else` - Descriptor protocol surprises - MRO conflicts in multiple inheritance - Timezone mixing in datetime operations

#### See also: Chapter 4 (Data Model), Chapter 7 (OOP), Chapter 9.2 (datetime) for complete coverage.

**See also:** Chapter 4 (Data Model), Chapter 7 (OOP), Chapter 9.2 (datetime) for complete coverage.

#### <!-- SSM:PART id="part6" title="Part VI: Appendices" -->.

<!-- SSM:PART id="part6" title="Part VI: Appendices" -->

#### # Part VI: Appendices.

# Part VI: Appendices

#### üìò APPENDIX F ‚Äî DECISION MATRICES.

üìò APPENDIX F ‚Äî DECISION MATRICES

#### This appendix provides decision matrices to help you choose the right tool, approach, or pattern...

This appendix provides decision matrices to help you choose the right tool, approach, or pattern for your specific use case.

#### F.1 Data Structure Selection Matrix.

F.1 Data Structure Selection Matrix

#### F.2 Concurrency Decision Matrix.

F.2 Concurrency Decision Matrix

#### F.3 Testing Framework Decision Matrix.

F.3 Testing Framework Decision Matrix

#### F.4 Package Manager Decision Matrix.

F.4 Package Manager Decision Matrix

#### F.5 Collection Operation Benchmarks (Python 3.12, Reference).

F.5 Collection Operation Benchmarks (Python 3.12, Reference)

#### Key Takeaway: Choose deque for queue operations, set for membership tests, dict for key-value lookup.

**Key Takeaway:** Choose `deque` for queue operations, `set` for membership tests, `dict` for key-value lookup.

#### F.6 Web Framework Decision Matrix.

F.6 Web Framework Decision Matrix

#### üìò APPENDIX H ‚Äî CPYTHON SOURCE CODE TOUR.

üìò APPENDIX H ‚Äî CPYTHON SOURCE CODE TOUR

#### This appendix provides a guided tour of CPython's source code for developers who want to understand...

This appendix provides a guided tour of CPython's source code for developers who want to understand Python's internals at the implementation level.

#### H.1 Key Source Files.

H.1 Key Source Files

#### H.2 How to Read CPython Source.

H.2 How to Read CPython Source

#### Key macros to understand: - Py_INCREF / Py_DECREF ‚Äî reference counting - PyObject_HEAD ‚Äî object header structure - PyAPI_FUNC ‚Äî public C API functi...

2. **Key macros to understand:** - `Py_INCREF` / `Py_DECREF` ‚Äî reference counting - `PyObject_HEAD` ‚Äî object header structure - `PyAPI_FUNC` ‚Äî public C API functions - `PyObject_VAR_HEAD` ‚Äî variable-size objects

#### Useful tools: - gdb for debugging - valgrind for memory checking - perf for performance profiling.

4. **Useful tools:** - `gdb` for debugging - `valgrind` for memory checking - `perf` for performance profiling

#### H.3 Reading the Interpreter Loop.

H.3 Reading the Interpreter Loop

#### The main interpreter loop in Python/ceval.c executes bytecode instructions.

The main interpreter loop in `Python/ceval.c` executes bytecode instructions. Key functions:

#### _PyEval_EvalFrameDefault ‚Äî main evaluation function - _PyEval_EvalFrame ‚Äî frame evaluation entry point - Instruction handlers (e.g., BINARY_ADD, LO...

- `_PyEval_EvalFrameDefault` ‚Äî main evaluation function - `_PyEval_EvalFrame` ‚Äî frame evaluation entry point - Instruction handlers (e.g., `BINARY_ADD`, `LOAD_FAST`)

#### H.4 Object Model Deep Dive.

H.4 Object Model Deep Dive

#### All Python objects inherit from PyObject (defined in Include/object.h):.

All Python objects inherit from `PyObject` (defined in `Include/object.h`):

#### üìò APPENDIX I ‚Äî VERSION MIGRATION GUIDES.

üìò APPENDIX I ‚Äî VERSION MIGRATION GUIDES

#### This appendix provides migration guides for upgrading between Python versions.

This appendix provides migration guides for upgrading between Python versions.

#### I.1 Migrating from 3.9 ‚Üí 3.10.

I.1 Migrating from 3.9 ‚Üí 3.10

#### Breaking Changes: - ‚ö†Ô∏è distutils deprecated (use setuptools) - ‚ö†Ô∏è Some collections aliases removed.

**Breaking Changes:** - ‚ö†Ô∏è `distutils` deprecated (use `setuptools`) - ‚ö†Ô∏è Some `collections` aliases removed

#### Migration Script:.

**Migration Script:**

#### I.2 Migrating from 3.10 ‚Üí 3.11.

I.2 Migrating from 3.10 ‚Üí 3.11

#### Breaking Changes: - ‚ö†Ô∏è asyncio API changes (mostly backward compatible).

**Breaking Changes:** - ‚ö†Ô∏è `asyncio` API changes (mostly backward compatible)

#### I.3 Migrating from 3.11 ‚Üí 3.12.

I.3 Migrating from 3.11 ‚Üí 3.12

#### Breaking Changes: - Minimal breaking changes.

**Breaking Changes:** - Minimal breaking changes

#### I.4 Migrating from 3.12 ‚Üí 3.13.

I.4 Migrating from 3.12 ‚Üí 3.13

#### Breaking Changes: - ‚ö†Ô∏è Some deprecated features removed.

**Breaking Changes:** - ‚ö†Ô∏è Some deprecated features removed

#### I.5 Migrating from 3.13 ‚Üí 3.14.

I.5 Migrating from 3.13 ‚Üí 3.14

#### Breaking Changes: - ‚ö†Ô∏è GIL removal requires code changes for thread-safety.

**Breaking Changes:** - ‚ö†Ô∏è GIL removal requires code changes for thread-safety

#### üìò APPENDIX J ‚Äî PYTHONIC TRANSFORMATIONS.

üìò APPENDIX J ‚Äî PYTHONIC TRANSFORMATIONS

#### This appendix shows common refactoring patterns to make code more Pythonic.

This appendix shows common refactoring patterns to make code more Pythonic.

#### J.1 Loop ‚Üí Comprehension.

J.1 Loop ‚Üí Comprehension

#### When NOT to transform: Complex logic, side effects, debugging needed.

**When NOT to transform:** Complex logic, side effects, debugging needed

#### J.2 Nested Ifs ‚Üí Early Returns.

J.2 Nested Ifs ‚Üí Early Returns

#### J.3 Multiple Returns ‚Üí Match Statement (3.10+).

J.3 Multiple Returns ‚Üí Match Statement (3.10+)

#### J.4 Dictionary Lookup ‚Üí get() with Default.

J.4 Dictionary Lookup ‚Üí get() with Default

#### J.5 String Concatenation ‚Üí join().

J.5 String Concatenation ‚Üí join()

#### üìò APPENDIX K ‚Äî ESSENTIAL PEP INDEX.

üìò APPENDIX K ‚Äî ESSENTIAL PEP INDEX

#### This appendix provides a reference index of essential Python Enhancement Proposals (PEPs) with...

This appendix provides a reference index of essential Python Enhancement Proposals (PEPs) with links and chapter references.

#### K.1 Style & Conventions.

K.1 Style & Conventions

#### K.3 Language Features.

K.3 Language Features

#### K.4 Performance & Internals.

K.4 Performance & Internals

#### üìò APPENDIX G ‚Äî VISUAL DIAGRAMS & FLOWCHARTS.

üìò APPENDIX G ‚Äî VISUAL DIAGRAMS & FLOWCHARTS

#### This appendix contains visual representations of key Python concepts referenced throughout the...

This appendix contains visual representations of key Python concepts referenced throughout the Bible. These diagrams help visualize complex execution flows, data structures, and system architectures.

#### The diagrams in this appendix cover:.

The diagrams in this appendix cover:

#### Execution pipeline (source code to bytecode to execution).

Execution pipeline (source code to bytecode to execution)

#### Import system mechanics.

Import system mechanics

#### Type system relationships.

Type system relationships

#### Memory layout and object structures.

Memory layout and object structures

#### G.2 Execution Pipeline.

G.2 Execution Pipeline

#### G.2.1 Source ‚Üí Bytecode ‚Üí Execution.

G.2.1 Source ‚Üí Bytecode ‚Üí Execution

#### Complete interpreter pipeline flow:.

Complete interpreter pipeline flow:

#### Tokenization: Character stream ‚Üí Token stream.

Tokenization: Character stream ‚Üí Token stream

#### Parsing: Token stream ‚Üí AST (Abstract Syntax Tree).

Parsing: Token stream ‚Üí AST (Abstract Syntax Tree)

#### Compilation: AST ‚Üí Bytecode.

Compilation: AST ‚Üí Bytecode

#### Optimization: Peephole optimizer improves bytecode.

Optimization: Peephole optimizer improves bytecode

#### Code Object: Immutable container for bytecode + metadata.

Code Object: Immutable container for bytecode + metadata

#### Execution: CPython VM interprets bytecode (or JIT compiles it).

Execution: CPython VM interprets bytecode (or JIT compiles it)

#### G.3 Scope & Namespace Resolution.

G.3 Scope & Namespace Resolution

#### G.4.1 Import Machinery Flow.

G.4.1 Import Machinery Flow

#### Complete import system pipeline:.

Complete import system pipeline:

#### Sys.modules acts as a cache (prevents re-importing).

sys.modules acts as a cache (prevents re-importing)

#### Sys.meta_path contains finders (BuiltinImporter, FrozenImporter, PathFinder).

sys.meta_path contains finders (BuiltinImporter, FrozenImporter, PathFinder)

#### ModuleSpec contains all metadata about a module.

ModuleSpec contains all metadata about a module

#### Loaders execute the module code.

Loaders execute the module code

#### Module is stored in sys.modules before execution completes.

Module is stored in sys.modules before execution completes

#### G.5.1 Core Built-in Types.

G.5.1 Core Built-in Types

#### Python's type hierarchy (simplified):.

Python's type hierarchy (simplified):

#### All types inherit from object.

All types inherit from object

#### Type is the metaclass for all classes (classes are instances of type).

type is the metaclass for all classes (classes are instances of type)

#### Built-in types are implemented in C (PyObject structures).

Built-in types are implemented in C (PyObject structures)

#### User-defined classes are instances of type.

User-defined classes are instances of type

#### Special types: NoneType (singleton), NotImplementedType, EllipsisType.

Special types: NoneType (singleton), NotImplementedType, EllipsisType

#### G.6 Object-Oriented Programming.

G.6 Object-Oriented Programming

#### G.6.2 MRO Resolution Path.

G.6.2 MRO Resolution Path

#### Method Resolution Order (MRO) using C3 linearization:.

Method Resolution Order (MRO) using C3 linearization:

#### MRO follows C3 linearization algorithm.

MRO follows C3 linearization algorithm

#### Search order: left to right in MRO list.

Search order: left to right in MRO list

#### First match wins (stops searching).

First match wins (stops searching)

#### Super() uses MRO to find next class in chain.

super() uses MRO to find next class in chain

#### MRO ensures monotonicity (no cycles, consistent ordering).

MRO ensures monotonicity (no cycles, consistent ordering)

#### G.7 Memory Layout (Reference).

G.7 Memory Layout (Reference)

#### G.7.1 PyObject Structure.

G.7.1 PyObject Structure

#### Every Python object in memory:.

Every Python object in memory:

#### All objects start with PyObject header (refcount + type pointer).

All objects start with PyObject header (refcount + type pointer)

#### Reference counting: ob_refcnt tracks how many references exist.

Reference counting: ob_refcnt tracks how many references exist

#### Type pointer: ob_type points to the object's type (class).

Type pointer: ob_type points to the object's type (class)

#### Type-specific data follows the header.

Type-specific data follows the header

#### Memory is managed by obmalloc (small objects) or system malloc (large objects).

Memory is managed by obmalloc (small objects) or system malloc (large objects)

#### Refer to specific chapters for in-depth explanations of each topic.

This appendix provides visual reference for concepts explained in detail throughout the Python Bible. Refer to specific chapters for in-depth explanations of each topic.

#### Last Updated: 2025-11-30.

**Last Updated:** 2025-11-30

#### Use Ctrl+F (or Cmd+F) to search for specific terms.

This index provides quick access to all major topics, concepts, patterns, and examples covered in the Python Bible. Use Ctrl+F (or Cmd+F) to search for specific terms.

#### Abstract Base Classes (ABCs) - Chapter 4.9, Chapter 7.4, Appendix A.4.5 - Abstract Factory Pattern - Appendix A.1.2 - Adapter Pattern - Appendix A....

- **Abstract Base Classes (ABCs)** - Chapter 4.9, Chapter 7.4, Appendix A.4.5 - **Abstract Factory Pattern** - Appendix A.1.2 - **Adapter Pattern** - Appendix A.2.1, Chapter 17.5 - **asyncio** - Chapter 17.3, Chapter 20.13, Appendix F.1 - **Attribute Access** - Chapter 4.8, Chapter 7.5.3, Chapter 17.3 - **Authentication** - Chapter 13.2.2

#### Builder Pattern - Appendix A.1.3 - Bytecode - Chapter 3.5, Appendix G.3.

- **Builder Pattern** - Appendix A.1.3 - **Bytecode** - Chapter 3.5, Appendix G.3

#### Chain of Responsibility - Appendix A.3.1 - Classes - Chapter 7, Chapter 17.2 - Command Pattern - Appendix A.3.2 - Comprehensions - Chapter 5.3, App...

- **Chain of Responsibility** - Appendix A.3.1 - **Classes** - Chapter 7, Chapter 17.2 - **Command Pattern** - Appendix A.3.2 - **Comprehensions** - Chapter 5.3, Appendix F.5 - **Concurrency** - Chapter 17, Appendix F.1 - **Context Managers** - Chapter 10.6, Appendix A.4.1 - **CPython Internals** - Chapter 27, Appendix H

#### Data Classes - Chapter 7.11, Appendix F.5 - Debugging - Chapter 14.5 - Decorators - Chapter 6.3, Chapter 17.4, Appendix A.4.3 - Dependency Injectio...

- **Data Classes** - Chapter 7.11, Appendix F.5 - **Debugging** - Chapter 14.5 - **Decorators** - Chapter 6.3, Chapter 17.4, Appendix A.4.3 - **Dependency Injection** - Chapter 17.5.2 - **Descriptors** - Chapter 7.5.3, Chapter 17.3, Appendix A.4.2 - **Design Patterns** - Chapter 14.6, Chapter 17.5, Appendix A - **Dictionaries** - Chapter 4.4, Chapter 12.2.1

#### Error Handling - Chapter 10, Appendix E - Event-Driven Architecture - Chapter 17.5.3 - Exceptions - Chapter 10.1-10.5.

- **Error Handling** - Chapter 10, Appendix E - **Event-Driven Architecture** - Chapter 17.5.3 - **Exceptions** - Chapter 10.1-10.5

#### Factory Pattern - Appendix A.1.1, Chapter 17.5.5 - FastAPI - Chapter 19, Appendix B.1 - Functions - Chapter 6, Appendix F.5 - Futures - Chapter 17.3.

- **Factory Pattern** - Appendix A.1.1, Chapter 17.5.5 - **FastAPI** - Chapter 19, Appendix B.1 - **Functions** - Chapter 6, Appendix F.5 - **Futures** - Chapter 17.3

#### Generators - Chapter 6.10, Chapter 12.4 - Generics - Chapter 4.11, Appendix F.4 - GIL (Global Interpreter Lock) - Chapter 17.2, Chapter 12.1.

- **Generators** - Chapter 6.10, Chapter 12.4 - **Generics** - Chapter 4.11, Appendix F.4 - **GIL (Global Interpreter Lock)** - Chapter 17.2, Chapter 12.1

#### Hypothesis (Property-Based Testing) - Chapter 14.4.6.

- **Hypothesis (Property-Based Testing)** - Chapter 14.4.6

#### Import System - Chapter 8.2, Chapter 17.5 - Inheritance - Chapter 7.3, Appendix G.6 - Injection Attacks - Chapter 13.2.1 - Iterators - Chapter 6.9,...

- **Import System** - Chapter 8.2, Chapter 17.5 - **Inheritance** - Chapter 7.3, Appendix G.6 - **Injection Attacks** - Chapter 13.2.1 - **Iterators** - Chapter 6.9, Appendix A.3.3

#### JSON - Chapter 9.2, Chapter 13.5.

- **JSON** - Chapter 9.2, Chapter 13.5

#### List Comprehensions - Chapter 5.3, Appendix F.5 - Logging - Chapter 14.5.4, Chapter 13.2.10.

- **List Comprehensions** - Chapter 5.3, Appendix F.5 - **Logging** - Chapter 14.5.4, Chapter 13.2.10

#### Metaclasses - Chapter 17.2, Appendix A.4.4 - Method Resolution Order (MRO) - Chapter 7.3, Appendix G.6 - Mocking - Chapter 14.4.5 - Modules - Chapt...

- **Metaclasses** - Chapter 17.2, Appendix A.4.4 - **Method Resolution Order (MRO)** - Chapter 7.3, Appendix G.6 - **Mocking** - Chapter 14.4.5 - **Modules** - Chapter 8, Chapter 17.5 - **Multiprocessing** - Chapter 17.6, Appendix F.1

#### NumPy - Chapter 12.5, Chapter 21.2.

- **NumPy** - Chapter 12.5, Chapter 21.2

#### Object-Oriented Programming - Chapter 7, Appendix G.6 - Observer Pattern - Appendix A.3.6 - OWASP Top 10 - Chapter 13.2.

- **Object-Oriented Programming** - Chapter 7, Appendix G.6 - **Observer Pattern** - Appendix A.3.6 - **OWASP Top 10** - Chapter 13.2

#### Packaging - Chapter 22, Appendix F.3 - Pattern Matching - Chapter 5.4 - Performance - Chapter 12, Appendix F.1 - PEP Index - Appendix K - pytest - ...

- **Packaging** - Chapter 22, Appendix F.3 - **Pattern Matching** - Chapter 5.4 - **Performance** - Chapter 12, Appendix F.1 - **PEP Index** - Appendix K - **pytest** - Chapter 14.4, Chapter 14.4.4 - **Protocol** - Chapter 4.10, Appendix A.4.5

#### Repository Pattern - Chapter 17.5.1 - RLS (Row Level Security) - Chapter 13.6.

- **Repository Pattern** - Chapter 17.5.1 - **RLS (Row Level Security)** - Chapter 13.6

#### Security - Chapter 13, Appendix E - Singleton Pattern - Appendix A.1.2 - SQL Injection - Chapter 13.2.1 - State Pattern - Appendix A.3.7 - Strategy...

- **Security** - Chapter 13, Appendix E - **Singleton Pattern** - Appendix A.1.2 - **SQL Injection** - Chapter 13.2.1 - **State Pattern** - Appendix A.3.7 - **Strategy Pattern** - Appendix A.3.8, Chapter 17.5.4 - **Structured Logging** - Chapter 14.5.4

#### Testing - Chapter 14, Chapter 14.8 - Threading - Chapter 17.4, Appendix F.1 - Type Hints - Chapter 4, Appendix F.4 - Type System - Chapter 4, Appen...

- **Testing** - Chapter 14, Chapter 14.8 - **Threading** - Chapter 17.4, Appendix F.1 - **Type Hints** - Chapter 4, Appendix F.4 - **Type System** - Chapter 4, Appendix G.5

#### Unit Testing - Chapter 14.4.

- **Unit Testing** - Chapter 14.4

#### Virtual Environments - Chapter 1.4, Chapter 21.2.

- **Virtual Environments** - Chapter 1.4, Chapter 21.2

#### Web Frameworks - Chapter 19, Appendix B.1.

- **Web Frameworks** - Chapter 19, Appendix B.1

#### YAML - Chapter 13.2.1.

- **YAML** - Chapter 13.2.1

#### How to Use This Index:.

**How to Use This Index:**

#### Find a Topic: Use Ctrl+F (Cmd+F) to search for any term 2.

1. **Find a Topic:** Use Ctrl+F (Cmd+F) to search for any term 2. **Navigate:** Click on chapter references to jump to detailed explanations 3. **Cross-Reference:** Many topics appear in multiple chapters (e.g., "Decorators" in Chapter 6.3, Chapter 17.4, and Appendix A.4.3) 4. **Patterns:** Design patterns are cataloged in Appendix A with cross-references to implementation examples

#### Quick Navigation by Goal:.

**Quick Navigation by Goal:**

#### Learning Python Basics: Chapters 1-5 - Functions & OOP: Chapters 6-7 - Advanced Features: Chapters 8-11 - Performance & Security: Chapters 12-13 - ...

- **Learning Python Basics:** Chapters 1-5 - **Functions & OOP:** Chapters 6-7 - **Advanced Features:** Chapters 8-11 - **Performance & Security:** Chapters 12-13 - **Testing & Quality:** Chapter 14 - **Concurrency:** Chapter 17 - **Web Development:** Chapter 19 - **Data Engineering:** Chapter 20 - **Design Patterns:** Chapter 14.6, Chapter 17.5, Appendix A - **CPython Internals:** Chapter 27, Appendix H - **Quick Reference:** Appendices D, F, K


### Important Facts

There should be one‚Äîand preferably only one‚Äîobvious way to do it.

1.6 When You Should (and Shouldn't) Use Python

How Python evaluates expressions (left-to-right, short-circuit rules)

Indentation must be consistent within a block

Offside rule: First non-whitespace column defines block depth

Short-circuit rules:

2.6 Truthiness Rules

shallow copies vs deep copies

2.12 Mutability Rules

Order of calls is always:

Many C extensions assume the GIL and must be audited or ported.

Interpreter lock internal redesign required

Catches misspelled or incorrect overrides.

__repr__ must be unambiguous. __str__ is user-friendly.

1. [ ] What is the difference between `a is b` and `a == b`? Provide an example where they differ. 2. [ ] Explain why `my_list = [1, 2, 3]; another_list = my_list; another_list.append(4)` affects `my_list`. 3. [ ] How would you define a custom class that supports the `len()` built-in function? 4. [ ] When would you use `typing.Protocol` instead of `abc.ABC`? 5. [ ] What is the purpose of `__slots__` and when should you consider using it?

Short-circuiting rules

Python treats truthiness according to Chapter 2 rules.

None is always False

When mutation is required

def process_log(lines): results = [] for line in lines: if not line.strip(): continue obj = eval(line) # never do this in production; for demo only results.append(route(obj)) return results

‚ö† Using eval (never safe) ‚ö† Complex nested comprehensions ‚ö† Misusing else on loops ‚ö† Wrong exception order (broad then narrow) ‚ö† Overusing exceptions for flow control ‚ö† match-case fall-through misunderstanding (it doesn‚Äôt fall through like switch)

Comprehensions are powerful but must remain readable

Callers must supply positional args:

6.5 Scoping Rules (LEGB)

**LEGB Rule Visualization:**

> **Quick Answer:** A decorator is a function that wraps another function. > Use `@decorator` syntax. **Always use `@functools.wraps` to preserve metadata.** > > ```python > from functools import wraps > > def my_decorator(func): > @wraps(func) > def wrapper(*args, **kwargs): > # before > result = func(*args, **kwargs) > # after > return result > return wrapper > ```

Never rely on tail recursion.

‚ö† Late binding closures ‚ö† Forgetting @wraps ‚ö† Using recursion for deep loops ‚ö† Misusing *args (debug difficulty) ‚ö† combining yield with try/finally incorrectly ‚ö† forgetting to close resources (use with) ‚ö† Non-deterministic iteration order pre-3.7

- üéØ **Functions are first-class objects** in Python - store, pass, return them freely - üéØ Use `*args` for variable positional, `**kwargs` for variable keyword arguments - üéØ **LEGB rule** governs scope resolution: Local ‚Üí Enclosing ‚Üí Global ‚Üí Built-in - üéØ **Closures capture variables by reference**, not value (beware late binding!) - üéØ **Always use `@functools.wraps`** in decorators to preserve function metadata - üéØ **Generators are lazy iterators** - use `yield` for memory-efficient data streams - üéØ `functools` & `itertools` are essential for functional programming patterns

Custom __new__ required for immutable types like int, tuple, str.

**Key Rules for __slots__:**

class Derived(Base): __slots__ = ("y",) # Must include parent slots

‚úÖ **Use when:** - Creating many instances (memory-critical) - Fixed attribute set (no dynamic attributes needed) - Performance-sensitive code - Working with data structures (points, vectors, nodes)

1. [ ] What is the difference between a class attribute and an instance attribute? 2. [ ] Can you explain Python's MRO and why it matters for `super()`? 3. [ ] When would you use `@classmethod` vs `@staticmethod`? 4. [ ] How do you implement a custom context manager using `__enter__` and `__exit__`? 5. [ ] What's the difference between `__new__` and `__init__`? 6. [ ] When should you use `@dataclass` vs a regular class?

1. **Easy:** Create a `BankAccount` class with `deposit`, `withdraw`, and `balance` property 2. **Medium:** Implement a `TimedExecution` context manager that prints how long a block took 3. **Medium:** Create a `Temperature` class that allows setting in Celsius but also has a `fahrenheit` property 4. **Hard:** Build a plugin registry using a metaclass that automatically registers subclasses 5. **Hard:** Implement a descriptor that validates an attribute is always positive

**‚ö†Ô∏è CRITICAL:** Always use timezone-aware datetimes in production code. Timezone-naive datetimes cause bugs.

‚ö† **Never mix naive and aware datetimes** ‚Äî raises TypeError ‚ö† **DST (Daylight Saving Time) transitions** ‚Äî some times don't exist or occur twice ‚ö† **Use zoneinfo, not pytz** ‚Äî pytz has different API, zoneinfo is standard library

- ‚úÖ Need `move_to_end()` or `popitem(last=False)` - ‚úÖ Working with Python < 3.7 code - ‚úÖ Need order-aware equality: `OrderedDict([('a', 1), ('b', 2)]) != OrderedDict([('b', 2), ('a', 1)])` - ‚ùå Python 3.7+: Regular `dict` is usually sufficient

- **namedtuple**: ‚úÖ Immutable data, memory-efficient, tuple-like behavior - **dataclass**: ‚úÖ Mutable data, type hints, methods, modern Python (3.7+)

**Always precompile regex patterns for repeated use:**

‚ö† **Catastrophic backtracking** ‚Äî Complex patterns can be extremely slow ‚ö† **ReDoS attacks** ‚Äî Malicious regex can cause denial of service ‚ö† **Always escape special characters** when matching literal text: `re.escape("$100")`

‚ö† **Always use `newline=""` when opening CSV files** ‚Äî prevents extra blank lines ‚ö† **CSV injection attacks** ‚Äî sanitize user input (especially formulas starting with `=`, `+`, `-`, `@`) ‚ö† **Encoding issues** ‚Äî specify encoding explicitly: `open("data.csv", encoding="utf-8")`

‚ö† **XML parsing can be slow for large files** ‚Äî consider streaming parsers for large XML ‚ö† **XML injection (XXE attacks)** ‚Äî never parse untrusted XML without disabling external entity resolution ‚ö† **Use `xml.etree.ElementTree`, not `xml.dom`** ‚Äî ElementTree is faster and simpler

**‚ö†Ô∏è CRITICAL WARNING:** `pickle` is insecure and should NEVER be used with untrusted data. It can execute arbitrary code during unpickling.

‚úÖ **Only for trusted data** ‚Äî Same process, same machine, same user ‚úÖ **Temporary caching** ‚Äî Fast serialization of Python objects ‚úÖ **Inter-process communication** ‚Äî Between trusted processes

The `subprocess` module is the recommended way to run external programs. **Never use `os.system()` or `os.popen()`.**

**Note:** For HTTP requests, use `requests` or `httpx` (third-party). `urllib` is shown here for completeness and when stdlib-only is required.

- ‚úÖ Custom protocols (not HTTP) - ‚úÖ High-performance networking - ‚úÖ Direct TCP/UDP access needed - ‚ùå HTTP requests (use `requests` or `httpx`) - ‚ùå Most web applications (use frameworks)

- ‚úÖ Always use `create_default_context()` for production - ‚úÖ Never disable certificate verification in production - ‚úÖ Use proper certificate validation - ‚ùå Never use `CERT_NONE` in production code

‚ö† pickle security issues ‚ö† incorrect timezone handling ‚ö† regex catastrophic backtracking ‚ö† binary/text mode confusion ‚ö† sys.path modification ‚ö† subprocess shell=True (avoid) ‚ö† encoding mismatches (use UTF-8 explicitly)

pathlib should replace os.path in most cases

> **Quick Answer:** > - **Always catch specific exceptions**, not bare `except:` > - **Use `try/except/else/finally`** for full control > - **Raise with context:** `raise NewError() from original_error` > - **Use context managers (`with`)** for resource cleanup > > ```python > try: > result = risky_operation() > except SpecificError as e: > logger.error(f"Failed: {e}") > raise CustomError("Operation failed") from e > else: > return result # Only runs if no exception > finally: > cleanup() # Always runs > ```

error context propagation

This chapter explores all required concepts thoroughly.

try: risky_operation() except SpecificError: recover() except AnotherError as e: log(e) else: run_if_no_exception() finally: always_run_cleanup()

10.8 Logging Integration (Real-World Required) import logging

cancellations propagate through tasks

must catch exceptions inside tasks

‚ö† ignore exception chaining ‚ö† broad except catching ‚ö† except: pass ‚ö† leaking resources (forgetting finally) ‚ö† retries without backoff ‚ö† mixing exception types improperly ‚ö† not using logger.exception ‚ö† suppressing exceptions incorrectly

retry/backoff required in real-world systems

Presentation Layer (HTTP, CLI, UI) Service Layer (Use cases) Domain Layer (Business rules) Data Layer (DB, external APIs)

Each layer has rules:

Lower layers must NOT import upper layers

Domain layer must NOT depend on frameworks

Services orchestrate domain rules

Use Cases (application-specific business rules)

Chapter 14 covers testing in depth, but architectural rules:

‚ö† designing architecture around frameworks, not domain ‚ö† circular imports from bad folder layouts ‚ö† overusing inheritance ‚ö† leaking database logic into services ‚ö† configuration mixed with business logic ‚ö† DI frameworks adding unnecessary complexity ‚ö† God-classes/modules ‚ö† dynamically importing untrusted plugins ‚ö† mixing sync and async layers incorrectly

Plugin systems should rely on registries/interfaces

Monorepo vs multirepo should be deliberate

> **Quick Answer:** > - **Profile first!** Use `cProfile`, `timeit`, or `py-spy` > - **Use built-ins:** `sum()`, `min()`, `max()` are C-optimized > - **Vectorize with NumPy** for numerical work (100x+ speedups) > - **Use `@lru_cache`** for expensive repeated computations > - **Use generators** for memory-efficient iteration > > ```python > # ‚ùå Slow: Python loop > total = 0 > for x in huge_list: > total += x > > # ‚úÖ Fast: Built-in > total = sum(huge_list) > > # ‚úÖ Fastest: NumPy (for numerical data) > import numpy as np > total = np.sum(np.array(huge_list)) > ```

To optimize Python code, you must understand:

**Prevention Pattern:** Never use `@lru_cache` on methods with mutable `self`. Extract to module-level function or use `functools.cached_property` for instance attributes. 12.3 Profiling Tools (CPU, Wall Time, Memory)

12.4 Common Python Performance Rules ‚úî Rule 1: Avoid Python loops for numeric work

‚úî Rule 2: Prefer list comprehensions over manual loops

‚úî Rule 3: Prefer local variables to globals

‚úî Rule 4: Avoid excessive abstraction in hot paths

‚úî Rule 5: Prefer tuples over lists for fixed data

‚ö†Ô∏è Important: On very small arrays (‚â§1e3 elements), the overhead of NumPy can actually make pure Python faster. Always benchmark your specific use case.

‚úÖ Numerical loops that NumPy can't vectorize ‚úÖ Custom algorithms with complex control flow ‚úÖ Functions called many times (amortizes compilation cost) ‚ùå Functions with Python objects (strings, dicts, etc.) ‚ùå Functions called only once (compilation overhead)

‚úÖ Need maximum performance ‚úÖ Complex algorithms that benefit from static typing ‚úÖ Existing C libraries to wrap ‚ùå Simple operations (NumPy is easier) ‚ùå Rapid prototyping (compilation overhead)

‚úÖ Memory safety without GC overhead ‚úÖ Excellent performance ‚úÖ Modern tooling (cargo, maturin) ‚úÖ Easy to maintain ‚úÖ Can call C libraries safely

‚úÖ CPU-bound tasks that benefit from parallelization ‚úÖ Tasks that can be split into independent chunks ‚úÖ Long-running computations (amortizes process startup cost) ‚ùå Small, quick tasks (overhead > benefit) ‚ùå Tasks requiring frequent communication (IPC overhead)

> **Quick Answer:** > - **Never use `eval()` or `exec()` with user input** > - **Always use parameterized queries** (never string concatenation for SQL) > - **Never use `pickle` with untrusted data** (allows arbitrary code execution) > - **Use `secrets` module** for cryptographic randomness, not `random` > - **Validate and sanitize all input** at system boundaries > > ```python > # ‚ùå DANGEROUS > eval(user_input) # Arbitrary code execution! > f"SELECT * FROM users WHERE id={user_id}" # SQL injection! > pickle.loads(user_data) # Arbitrary code execution! > > # ‚úÖ SAFE > json.loads(user_input) # Safe parsing > cursor.execute("SELECT * FROM users WHERE id=?", (user_id,)) # Parameterized > secrets.token_hex(32) # Secure random > ```

class UserSchema(Schema): name = fields.Str(required=True) age = fields.Int(required=True)

Secrets must never be:

should not be deployed

must not be committed

Never roll your own crypto.

If sandboxing is required, use:

Always hash passwords (bcrypt/argon2)

Error messages must not leak internal data

Testing in Python must address:

required for legacy projects

Coverage is not a goal ‚Äî correctness is.

‚ö† using too many mocks ‚Üí tests lie ‚ö† brittle tests that mirror implementation ‚ö† skipping integration tests ‚Üí hidden failures ‚ö† not isolating the DB state ‚ö† relying on real network in tests ‚ö† test order dependence ‚ö† global state shared between tests ‚ö† mocking time incorrectly

mocks should be used sparingly and correctly

doctest ensures documentation correctness

- `pdb` and `ipdb` are essential for interactive debugging - `breakpoint()` is the modern way to add breakpoints - IDE debugging provides powerful visual debugging - Remote debugging enables production debugging - Structured logging is crucial for production debugging - Performance and memory profilers help find bottlenecks - Always add correlation IDs for distributed systems

17.4 Concurrency Comparison (the famous table) Model Parallel? Best For Worst For Threads ‚ùå (‚â§3.12) / ‚úÖ (3.14 FT) Network IO, HTTP clients, websockets CPU-bound work Multiprocessing ‚úÖ CPU-heavy tasks, ML preprocessing High IPC overhead AsyncIO ‚ùå 100k+ network connections CPU-bound work ThreadPoolExecutor Limited (GIL) mixed I/O tasks heavy CPU work ProcessPoolExecutor Yes batch CPU tasks small tasks (overhead) 17.5 THREADING

Always prefer queues.

‚úÖ CPU-bound tasks (image processing, data analysis, ML preprocessing) ‚úÖ Tasks that benefit from multiple CPU cores ‚úÖ Isolated computations that don't need frequent communication ‚ùå IO-bound tasks (use threading or asyncio instead) ‚ùå Tasks requiring frequent data sharing (high IPC overhead)

**‚ö†Ô∏è Synchronization Required:**

**4. Main Guard Required:**

"Which concurrency model should I use?"

Rule: Use descriptors unless you truly need metaclasses.

18.10.1 Service Boundary Rules

Advanced patterns must be used with caution

19.13 Security Considerations for Databases ‚úî Always use parameterized queries ‚úî Never construct SQL with f-strings ‚úî Validate input (pydantic) ‚úî Manage credentials securely ‚úî Use TLS connections ‚úî Limit permissions per service ‚úî Avoid exposing DB ports 19.14 Mini Example ‚Äî Async CRUD Service async def create_user(session, name: str): user = User(name=name) session.add(user) await session.commit() return user

migrations should be automated with Alembic

never enable CORS="*" in production

observability is a must

Data validation must be explicit

Always distribute wheels when possible.

(Required for microservices)

For microservices, logs must include:

Every service must expose:

Celery / RQ / Dramatiq / custom workers must log:

22.13 Observability Best Practices ‚úî ALWAYS log in JSON ‚úî ALWAYS include IDs (request, correlation, user, trace) ‚úî NEVER log secrets ‚úî keep logs structured, not free text ‚úî use histograms for latency ‚úî set up dashboards ‚úî monitor P50/P95/P99 latencies ‚úî monitor error percentages ‚úî correlate logs ‚Üî metrics ‚Üî traces 22.14 Anti-Patterns

Structured JSON logs are required

Rule: Configuration should be stored in the environment.

23.2.1 Required vs Optional Variables DATABASE_URL = os.environ["DATABASE_URL"] # required LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO") # optional

Secrets should never be stored:

secrets must never be committed

scripts should load config from a central module

apiVersion: batch/v1 kind: CronJob metadata: name: cleanup spec: schedule: "0 * * * *" jobTemplate: spec: template: spec: containers: - name: worker image: myapp:latest args: ["python", "scripts/cleanup.py"] restartPolicy: OnFailure

Background tasks should not handle heavy workloads

Task queues must be idempotent

Distributed cron should be done in Kubernetes or Airflow

This topic matters because **clean docstrings directly improve maintainability, correctness, API usability, and LLM comprehension.**

**Try This:** Write Google-style docstrings for a class you created earlier in Chapter 7 (Classes & OOP). Your docstring must include:

## **30.2.2 Docstring Coverage Rules**

All public-facing objects must have docstrings:

Private objects (prefixed with `_`) are exempt but should still be documented when their behavior is non-trivial.

## **30.2.4 Optional Policy Integration**

For organizations using Policy-as-Code frameworks:

## **30.4.2 Prefer Correct Patterns**

**Never include sensitive information in docstrings:**

- Docstrings define **what** your code does‚Äînot **how** - Google-style is the recommended standard for modern Python projects - Always document Args, Returns, Raises, and provide examples where helpful - Good docstrings greatly improve IDE usability and LLM understanding - Enterprise projects require coverage enforcement and style consistency - Keep docstrings synchronized with code during refactoring - Never include sensitive information in docstrings - Use doctest examples to create executable documentation

distributed tracing required

Rule: Each microservice owns its data.

26.13 High Availability Patterns Required for Python production services:

Python services must handle SIGTERM:

Rules that say: this statement transforms the state into that state.

Logic rules for proving correctness.

**State Transition Rules:**

**Evaluation Rules (Inference Rules):**

The LEGB rule describes name resolution:

**Inference Rule Form:**

**Closure Creation Rule:**

**Closure Application Rule:**

**Type Inference Rules:**

if none found ‚Üí propagate to top level

propagating constraints

exceptions propagate via stack unwinding

how exceptions propagate in native code

Exception propagation is implemented by:

You should assume CPython unless you have a strong reason to choose something else.

‚úÖ Direct Java ecosystem integration (libraries, tools, app servers) ‚úÖ No GIL (uses JVM threading model) ‚úÖ Mature for Python 2.7 workloads

For new JVM + Python projects: - ‚úÖ **Use GraalPy** (Python 3.11+, active development, better performance) - ‚úÖ **Use CPython + JPype** (if you need strict CPython compatibility) - ‚ùå **Avoid Jython** for new projects

- Python implementation targeting .NET CLR (Common Language Runtime) - Written in C# - Direct access to .NET libraries (no marshalling overhead) - Can be embedded in .NET applications

‚úÖ Enterprise .NET shops needing Python scripting ‚úÖ Integration with WPF / WinForms / ASP.NET ‚úÖ Scripting for .NET applications ‚úÖ When you need tight .NET interop without C API

For .NET + Python interop: - ‚úÖ **CPython + pythonnet**: Mature, supports Python 3.x, good performance - ‚úÖ **GraalPy + .NET interop**: If you're already using GraalVM - ‚úÖ **Embed CPython**: Most flexible, best library support

‚úÖ Data science workloads (NumPy, SciPy compatibility improving) ‚úÖ Enterprise JVM applications needing Python scripting ‚úÖ Polyglot applications (Python + Java + JavaScript in one process) ‚úÖ High-performance numerical code

‚ö†Ô∏è **C-extension support**: Improving but not 100% compatible (use cffi when possible) ‚ö†Ô∏è **Ecosystem**: Smaller than CPython (but growing) ‚ö†Ô∏è **Best fit**: When you're already using GraalVM/JVM ecosystem ‚úÖ **Excellent**: For new polyglot projects on JVM

‚úÖ JVM-based applications needing Python ‚úÖ Polyglot projects (Python + Java + other languages) ‚úÖ Data science on JVM infrastructure ‚úÖ When you need better performance than CPython for pure Python code ‚ùå Not ideal: Heavy C-extension dependencies (NumPy/SciPy support improving)

‚úÖ Drop-in CPython replacement for performance ‚úÖ Web applications (Django, Flask) ‚úÖ Pure Python workloads ‚úÖ When you need better performance but can't use PyPy

‚úÖ Specific microthreading requirements ‚úÖ Legacy Stackless codebases ‚ùå **Not recommended** for new projects (use asyncio instead)

‚úÖ Educational projects ‚úÖ Embedded Python in Rust applications ‚úÖ WebAssembly Python (experimental) ‚ùå Not for production applications

‚úÖ CPython by default

‚úÖ Consider GraalPy if you‚Äôre in JVM world and want max performance

‚úÖ GraalPy on GraalVM

‚úÖ IronPython for certain scenarios

‚úÖ MicroPython or CircuitPython MicroPython +2 Raspberry Pi +2

audit, constrain, correct, and sanitize AI-generated code

Policy / safety layer

29.3.4 ‚Äî DO: Always Validate AI Code with Linters

incorrect method names

29.4.1 ‚Äî Typical AI Mistakes üö® 1. Incorrect imports from pandas import Dataframe # wrong: DataFrame

A cleanup agent should perform these checks automatically:

Check async await correctness

29.5.1 ‚Äî Architecture of a Python Agent Agent ‚îú‚îÄ‚îÄ Planner ‚îú‚îÄ‚îÄ Memory ‚îú‚îÄ‚îÄ Tools (Python functions) ‚îú‚îÄ‚îÄ Policy / Rules ‚îú‚îÄ‚îÄ LLM ‚îî‚îÄ‚îÄ Environment

tools = [ { "type": "function", "function": { "name": "add", "parameters": { "type": "object", "properties": { "a": {"type": "integer"}, "b": {"type": "integer"}, }, "required": ["a", "b"], }, }, } ]

29.8 ‚Äî Tips, Tricks & Patterns for AI-Powered Python 29.8.1 ‚Äî Never let AI mutate architecture unintentionally

29.8.2 ‚Äî Always ask for explanations of choices

29.8.3 ‚Äî Use multi-step generation for correctness

29.8.5 ‚Äî But ALWAYS validate with CI

AI does not enforce linters. Your CI must.

Clean code rules must be enforced automatically

AI code must be validated, tested, and refactored

Shows correct usage, anti-patterns, pitfalls

‚úÖ **Prefer Instead: Dependency Injection**

‚úÖ **Prefer: Simple Functions or Dicts**

Useful when state is required.

‚úÖ **Prefer: Explicit Dependencies**

This is not a shallow glossary. This appendix is designed as the canonical, authoritative dictionary for all terminology used throughout the Python Bible ‚Äî covering:

Entry function for AWS serverless execution. Always def handler(event, context):.

completing required work before exit

A set of rules defining how Python objects behave.

Asynchronous tasks require special handling to propagate exceptions.

Exceptions propagate upward through:

Rules that define how iterables and iterators work.

Parameter that must be passed by keyword, declared after *.

Cache eviction policy:

Subclass must be usable wherever superclass is expected.

Extension system allowing customization of static type rules.

Rules defining how shapes match when performing elementwise operations.

Ensures method correctly overrides a parent method.

Code that behaves correctly with multiple threads.

**Legend:** - ‚úÖ **Fully covered:** Complete explanation with examples - ‚ö†Ô∏è **Partially covered:** Basic explanation, may need more detail - ‚≠êÔ∏è **Skipped:** Intentionally minimal or specialized coverage

üî• D.1 ‚Äî MUTABLE DEFAULT ARGUMENTS The #1 Python bug of all time ‚ùå Incorrect def append_to_list(value, lst=[]): lst.append(value) return lst

‚úÖ Correct def append_to_list(value, lst=None): if lst is None: lst = [] lst.append(value) return lst

üî• D.2 ‚Äî LATE BINDING IN CLOSURES ‚ÄúWhy does my lambda use the last value?!‚Äù ‚ùå Incorrect funcs = [lambda: i for i in range(3)] [f() for f in funcs] # ‚Üí [2, 2, 2]

2. Extract shared logic to a third module 3. Avoid running module-level code üî• D.5 ‚Äî VARIABLE SHADOWING (BUILTINS & OUTER SCOPE) ‚ùå Incorrect list = [1, 2, 3] # destroys built-in list()

Correct: items = [1, 2, 3]

- Web servers (FastAPI, Starlette) with blocking database calls - Background tasks that use blocking libraries - Task cancellation not properly handled - Exception propagation in fire-and-forget tasks

‚ùå **Incorrect Understanding:**

‚úÖ **Correct: Use Multiprocessing for CPU-Bound Work**

‚ùå **Incorrect Assumption:**

Type hints are **documentation only** at runtime. They don't prevent incorrect types from being passed.

‚úÖ **Correct: Use Runtime Validation**

**5. Using Protocol Incorrectly**

‚úÖ **Correct Understanding:**

‚ùå **Incorrect (O(n¬≤) complexity):**

‚úÖ **Correct (O(n) complexity):**

‚ùå **Incorrect (O(n) lookup):**

‚úÖ **Correct (O(1) lookup):**

‚ùå **Incorrect (slow):**

‚úÖ **Correct (fast):**

‚ùå **Incorrect (stack overflow risk):**

‚ùå **Incorrect (memory overhead):**

‚úÖ **Correct (memory efficient):**

‚ùå **Incorrect (function call overhead):**

‚ùå **Incorrect (memory intensive):**

- ‚úÖ Use sets/dicts for membership (not lists) - ‚úÖ Use list comprehensions (faster than loops) - ‚úÖ Use NumPy for numerical work - ‚úÖ Use generators for large datasets - ‚úÖ Avoid exceptions in hot paths - ‚úÖ Use __slots__ for memory-critical classes - ‚úÖ Profile before optimizing (see Chapter 12.3)

‚ùå **Incorrect (old pattern):**

‚úÖ **Correct (Python 3.11+):**

- ‚úÖ Always catch specific exceptions - ‚úÖ Always log exceptions with context - ‚úÖ Use `except Exception`, not bare `except:` - ‚úÖ Use context managers for cleanup - ‚úÖ Preserve exception chains with `from` - ‚úÖ Use `else` and `finally` appropriately

‚úÖ **Correct Usage:**

‚ùå **Incorrect (undefined behavior):**

**New Features to Adopt:** - ‚úÖ Pattern matching (`match`/`case`) - ‚úÖ Union types: `int | str` instead of `Union[int, str]` - ‚úÖ Parenthesized context managers - ‚úÖ Better error messages

**New Features:** - ‚úÖ Exception groups and `except*` - ‚úÖ `Self` type - ‚úÖ `variadic generics` (PEP 646) - ‚úÖ Performance improvements (10-60% faster)

**New Features:** - ‚úÖ Type parameter syntax: `def func[T](x: T) -> T` - ‚úÖ F-string improvements (nested quotes) - ‚úÖ `@override` decorator - ‚úÖ Improved error messages

**New Features:** - ‚úÖ Experimental JIT compiler - ‚úÖ Improved `asyncio` performance - ‚úÖ Better error messages

**New Features:** - ‚úÖ Optional free-threading (`--disable-gil`) - ‚úÖ Performance improvements

G.3.1 LEGB Rule Visualization

Python's name resolution follows the LEGB rule (Local ‚Üí Enclosing ‚Üí Global ‚Üí Built-in):


### Code Patterns

flowchart TD
    Start([Start Learning Python]) --> Beginner[Beginner Path<br/>Ch. 1 ‚Üí Ch. 2 ‚Üí Ch. 4 ‚Üí Ch. 5 ‚Üí Ch. 6 ‚Üí Ch. 7<br/>Intro, Syntax, Types, Control, Functions, OOP<br/>Focus: Core language, basic data structures, functions]
    
    Beginner --> Intermediate[Intermediate Path<br/>Ch. 8 ‚Üí Ch. 9 ‚Üí Ch. 10 ‚Üí Ch. 11 ‚Üí Ch. 14<br/>Modules, Stdlib, Errors, Arch, Testing<br/>Focus: Project structure, error handling, testing]
    
    Intermediate --> Advanced[Advanced Path<br/>Ch. 12 ‚Üí Ch. 13 ‚Üí Ch. 17 ‚Üí Ch. 18 ‚Üí Ch. 20<br/>Perf, Security, Concurrency, Meta, Web<br/>Focus: Performance, security, async, metaprogramming]
    
    Advanced --> Specialist{Choose Specialist Path}
    
    Specialist -->|Systems Programming| Systems[Ch. 27 Internals<br/>‚Üí Ch. 28 Implementations]
    Specialist -->|Backend Development| Backend[Ch. 20 Web<br/>‚Üí Ch. 21 Data<br/>‚Üí Ch. 22 Eng]
    Specialist -->|Performance Engineering| Perf[Ch. 12 Perf<br/>‚Üí Ch. 27 Internals<br/>‚Üí Ch. 28 PyPy]
    Specialist -->|Architecture & Design| Arch[Ch. 11 Arch<br/>‚Üí Ch. 18 Meta<br/>‚Üí Appendix A Patterns]

flowchart TD
    Source[Source Code<br/>hello.py] --> Tokenization[1. TOKENIZATION<br/>Tokenizer converts characters ‚Üí tokens<br/>Example: def ‚Üí NAME, ( ‚Üí LPAR, x ‚Üí NAME]
    
    Tokenization --> Parsing[2. PARSING PEG Parser<br/>Tokens ‚Üí Abstract Syntax Tree AST<br/>Example: FunctionDef name='greet', args=[...]]
    
    Parsing --> ASTOpt[3. AST OPTIMIZATION<br/>Constant folding, dead code elimination<br/>Example: 2 + 3 ‚Üí 5 compile-time]
    
    ASTOpt --> Bytecode[4. BYTECODE COMPILATION<br/>AST ‚Üí Bytecode instructions<br/>Example: LOAD_FAST, CALL_FUNCTION, RETURN_VALUE]
    
    Bytecode --> CodeObj[5. CODE OBJECT CREATION<br/>Bytecode + metadata ‚Üí code object<br/>Stored in: __pycache__/hello.cpython-313.pyc]
    
    CodeObj --> Execution[6. EXECUTION CPython VM]
    
    Execution --> Tier0[Tier 0: Baseline Interpreter 3.11+<br/>Standard bytecode execution]
    
    Tier0 -->|hot code detected| Tier1[Tier 1: Adaptive Interpreter 3.11+<br/>Specialized opcodes<br/>Type-specific optimizations]
    
    Tier1 -->|very hot code, 3.13+| Tier2[Tier 2: JIT Compiler 3.13+ experimental<br/>Copy-and-patch JIT<br/>Native machine code]
    
    Tier0 --> Runtime[Runtime Execution<br/>Frame objects, stack, namespaces]
    Tier1 --> Runtime
    Tier2 --> Runtime
    
    style Source fill:#e1f5ff
    style Runtime fill:#fff4e1
    style Tier0 fill:#ffe1f5
    style Tier1 fill:#e1ffe1
    style Tier2 fill:#ffe1e1

# hello.py
def greet(name: str) -> str:
    """Return a personalized greeting."""
    return f"Hello, {name}!"

if __name__ == "__main__":
    print(greet("Python"))
    # Output: Hello, Python!

def greet(name: str, title: str = "") -> str:
    """Return a personalized greeting with optional title."""
    if title:
        return f"Hello, {title} {name}!"
    return f"Hello, {name}!"

print(greet("Smith", "Dr."))
# Output: Hello, Dr. Smith!

from typing import Optional

def format_greeting(name: str, age: Optional[int] = None) -> str:
    """Format a personalized greeting with type safety."""
    if age is None:
        return f"Hello, {name}!"
    return f"Hello, {name}! You are {age} years old."

print(format_greeting("Alice", 30))

flowchart TD
    Source[Source Code<br/>hello.py] --> Tokenization[1. TOKENIZATION<br/>Tokenizer converts characters ‚Üí tokens<br/>Example: def ‚Üí NAME, ( ‚Üí LPAR, x ‚Üí NAME]
    
    Tokenization --> Parsing[2. PARSING PEG Parser<br/>Tokens ‚Üí Abstract Syntax Tree AST<br/>Example: FunctionDef name='greet', args=[...]]
    
    Parsing --> ASTOpt[3. AST OPTIMIZATION<br/>Constant folding, dead code elimination<br/>Example: 2 + 3 ‚Üí 5 compile-time]
    
    ASTOpt --> Bytecode[4. BYTECODE COMPILATION<br/>AST ‚Üí Bytecode instructions<br/>Example: LOAD_FAST, CALL_FUNCTION, RETURN_VALUE]
    
    Bytecode --> ByteOpt[5. BYTECODE OPTIMIZATION Peephole<br/>Dead jump removal, constant tuple building<br/>Example: JUMP_IF_FALSE ‚Üí removed if always true]
    
    ByteOpt --> CodeObj[6. CODE OBJECT CREATION<br/>Bytecode + metadata ‚Üí code object<br/>Stored in: __pycache__/hello.cpython-313.pyc]
    
    CodeObj --> Execution[7. EXECUTION CPython VM]
    
    Execution --> Tier0[Tier 0: Baseline Interpreter<br/>Standard bytecode execution]
    
    Tier0 -->|hot code detected| Tier1[Tier 1: Adaptive Interpreter 3.11+<br/>Specialized opcodes<br/>Type-specific optimizations]
    
    Tier1 -->|very hot code, 3.13+| Tier2[Tier 2: JIT Compiler 3.13+ experimental<br/>Copy-and-patch JIT<br/>Native machine code]
    
    Tier0 --> Runtime[Runtime Execution<br/>Frame objects, stack, namespaces]
    Tier1 --> Runtime
    Tier2 --> Runtime
    
    style Source fill:#e1f5ff
    style Runtime fill:#fff4e1
    style Tier0 fill:#ffe1f5
    style Tier1 fill:#e1ffe1
    style Tier2 fill:#ffe1e1

def add(a, b):
    return a + b

import tokenize
from io import BytesIO

code = b"def add(a, b):\n    return a + b"
for token in tokenize.tokenize(BytesIO(code).readline):
    print(f"{token.type:15} {token.string:20} {token.start} ‚Üí {token.end}")

import ast

tree = ast.parse("def add(a, b):\n    return a + b")
print(ast.dump(tree, indent=2))

import dis

def add(a, b):
    return a + b

dis.dis(add)

import dis

flowchart TD
    Start[import mymodule] --> Step1[STEP 1: Check sys.modules cache<br/>if 'mymodule' in sys.modules:<br/>    return sys.modules['mymodule']  # Already loaded]
    
    Step1 -->|found| Return[Return cached module]
    Step1 -->|not found| Step2[STEP 2: Iterate sys.meta_path finders]
    
    Step2 --> Finder1[1. BuiltinImporter<br/>Checks built-in modules<br/>Examples: sys, builtins]
    
    Finder1 -->|not found| Finder2[2. FrozenImporter<br/>Checks frozen modules<br/>Examples: _frozen_importlib]
    
    Finder2 -->|not found| Finder3[3. PathFinder<br/>Searches sys.path<br/>Uses SourceFileLoader, etc.]
    
    Finder3 -->|finder returns ModuleSpec| Step3[STEP 3: Create ModuleSpec<br/>spec = ModuleSpec(<br/>    name='mymodule',<br/>    loader=SourceFileLoader...,<br/>    origin='/path/to/mymodule.py',<br/>    submodule_search_locations=None<br/>)]
    
    Step3 --> Step4[STEP 4: Loader.exec_module spec]
    
    Step4 --> Loader1[SourceFileLoader:<br/>1. Read .py file<br/>2. Compile to bytecode<br/>3. Execute bytecode<br/>4. Create module object]
    
    Step4 --> Loader2[ExtensionFileLoader:<br/>1. Load .so/.pyd file<br/>2. Initialize module]
    
    Step4 --> Loader3[NamespaceLoader:<br/>1. Create namespace package<br/>2. Set __path__]
    
    Loader1 --> Step5[STEP 5: Store in sys.modules<br/>sys.modules['mymodule'] = module_object]
    Loader2 --> Step5
    Loader3 --> Step5
    
    Step5 --> Step6[STEP 6: Module code executed<br/>Top-level code runs<br/>Functions/classes defined<br/>Module-level variables assigned]
    
    Step6 --> Return
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style Step3 fill:#fff4e1
    style Step4 fill:#ffe1e1
    style Step5 fill:#e1f5ff
    style Step6 fill:#ffe1f5
    style Return fill:#e1ffe1

print("util imported")
x = 10
y = 20

def helper():
    return "helper function"

import sys
import util

import util  # No "util imported" printed again

import util as util2
print(f"Same object: {util is util2}")

import sys

import util  # "util imported" printed again

flowchart TD
    Start([Function Call: inner]) --> Local[1. LOCAL SCOPE L<br/>def inner:<br/>    x = local ‚Üê Check here first<br/>    print x<br/><br/>If found ‚Üí use it, STOP<br/>If not found ‚Üí continue to Enclosing]
    
    Local -->|not found| Enclosing[2. ENCLOSING SCOPE E<br/>def outer:<br/>    x = enclosing ‚Üê Check here<br/>    def inner:<br/>        print x  # uses enclosing<br/>    return inner<br/><br/>If found ‚Üí use it, STOP<br/>If not found ‚Üí continue to Global]
    
    Enclosing -->|not found| Global[3. GLOBAL SCOPE G<br/>x = global ‚Üê Module-level<br/><br/>def outer:<br/>    def inner:<br/>        print x  # uses global<br/><br/>If found ‚Üí use it, STOP<br/>If not found ‚Üí continue to Built-in]
    
    Global -->|not found| Builtin[4. BUILT-IN SCOPE B<br/>Built-in names len, str, int, etc.<br/><br/>import builtins<br/>print builtins.__dict__<br/><br/>If found ‚Üí use it<br/>If not found ‚Üí NameError]
    
    Local -->|found| Stop1[Use Local Value]
    Enclosing -->|found| Stop2[Use Enclosing Value]
    Global -->|found| Stop3[Use Global Value]
    Builtin -->|found| Stop4[Use Built-in Value]
    Builtin -->|not found| Error[NameError]
    
    style Local fill:#e1f5ff
    style Enclosing fill:#ffe1f5
    style Global fill:#e1ffe1
    style Builtin fill:#fff4e1
    style Error fill:#ffe1e1

class Calculator:
    def add(self, a: int, b: int) -> int:
        return a + b

calc = Calculator()
print(calc.add(2, 3))

class Point:
    def __init__(self, x, y):
        self.x = x
        self.y = y

p = Point(1, 2)
# Each instance has __dict__: ~240 bytes overhead
# Can add arbitrary attributes: p.z = 3

class Point:
    __slots__ = ("x", "y")
    
    def __init__(self, x, y):
        self.x = x
        self.y = y

p = Point(1, 2)
# No __dict__: ~56 bytes per instance (4-5√ó memory savings)
# Cannot add arbitrary attributes: p.z = 3  # AttributeError

import sys

class RegularPoint:
    def __init__(self, x, y):
        self.x = x
        self.y = y

class SlottedPoint:
    __slots__ = ("x", "y")
    
    def __init__(self, x, y):
        self.x = x
        self.y = y

import sys
from dataclasses import dataclass

@dataclass
class RegularUser:
    id: int
    name: str

@dataclass(slots=True)
class SlottedUser:
    id: int
    name: str

regular = RegularUser(1, "Alice")
slotted = SlottedUser(1, "Alice")

print(f"Regular: {sys.getsizeof(regular)} bytes")
print(f"Slotted: {sys.getsizeof(slotted)} bytes")
# Typical: Regular ~240 bytes, Slotted ~56 bytes

class A:
    def method(self):
        return "A"

class B:
    def method(self):
        return "B"

class C(A, B):
    pass

class D(B, A):
    pass

print(C.__mro__)

flowchart TD
    Start[import mymodule] --> Step1[1. Check sys.modules cache<br/>Already imported?]
    
    Step1 -->|found| Return[Return cached module]
    Step1 -->|not found| Step2[2. Iterate sys.meta_path finders<br/>BuiltinImporter<br/>FrozenImporter<br/>PathFinder]
    
    Step2 -->|finder returns spec| Step3[3. ModuleSpec created<br/>name, loader, origin<br/>submodule_search_locations]
    
    Step3 --> Step4[4. Loader.exec_module spec<br/>SourceFileLoader<br/>ExtensionFileLoader<br/>NamespaceLoader]
    
    Step4 --> Step5[5. Module added to sys.modules<br/>6. Module code executed]
    
    Step5 --> Return
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style Step3 fill:#fff4e1
    style Step4 fill:#ffe1e1
    style Step5 fill:#e1f5ff
    style Return fill:#e1ffe1

import sys
import importlib.util

spec = importlib.util.find_spec("json")
print(f"JSON module origin: {spec.origin}")

import shutil

import shutil
from pathlib import Path
from datetime import datetime

def backup_directory(source: Path, backup_dir: Path = Path("backups")):
    """Create timestamped backup of directory."""
    backup_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    archive_name = f"{source.name}_{timestamp}"
    shutil.make_archive(
        str(backup_dir / archive_name),
        "zip",
        source.parent,
        source.name
    )
    print(f"Backup created: {archive_name}.zip")

backup_directory(Path("my_project"))

import tempfile

import os

fd, path = tempfile.mkstemp(suffix='.txt', prefix='data_')
try:
    with os.fdopen(fd, 'w') as f:
        f.write("secure temporary data")

import tempfile
import os
from pathlib import Path

def process_with_temp_file(data: str) -> str:
    """Process data in a secure temporary file."""
    fd, path = tempfile.mkstemp(suffix='.txt', text=True)
    try:
        with os.fdopen(fd, 'w') as f:
            f.write(data)

from datetime import datetime, timedelta, date, time

from datetime import datetime
from zoneinfo import ZoneInfo

from datetime import datetime
from zoneinfo import ZoneInfo

def schedule_event(local_time: str, timezone: str, event_name: str):
    """Schedule event in local timezone, convert to UTC."""

dt = datetime.fromisoformat("2025-01-27T14:30:45")
dt_tz = datetime.fromisoformat("2025-01-27T14:30:45-05:00")  # With timezone

from datetime import datetime, timedelta

def date_range(start: str, end: str, step_days: int = 1):
    """Generate dates in range."""
    start_dt = datetime.strptime(start, "%Y-%m-%d")
    end_dt = datetime.strptime(end, "%Y-%m-%d")
    current = start_dt
    
    while current <= end_dt:
        yield current.date()
        current += timedelta(days=step_days)

# Generate all dates in January 2025
for date in date_range("2025-01-01", "2025-01-31"):
    print(date.strftime("%A, %B %d, %Y"))

from collections import Counter

from collections import Counter

def analyze_errors(log_file: str):
    """Count error types in log file."""
    errors = []
    with open(log_file) as f:
        for line in f:
            if "ERROR" in line:
                # Extract error type (simplified)
                error_type = line.split("ERROR")[1].split(":")[0].strip()
                errors.append(error_type)
    
    error_counts = Counter(errors)
    return error_counts.most_common(5)

# Usage
top_errors = analyze_errors("app.log")
for error, count in top_errors:
    print(f"{error}: {count}")

from collections import defaultdict

groups = defaultdict(list)
groups["a"].append(1)  # No KeyError, list created automatically
groups["a"].append(2)
print(groups)  # defaultdict(<class 'list'>, {'a': [1, 2]})

counts = defaultdict(int)
counts["apple"] += 1  # No KeyError
counts["banana"] += 1
print(counts)  # defaultdict(<class 'int'>, {'apple': 1, 'banana': 1})

def default_factory():
    return {"count": 0, "items": []}

dd_custom = defaultdict(default_factory)
dd_custom["group"]["count"] += 1

from collections import deque

right = q.pop()        # Remove from right: 2
left = q.popleft()     # Remove from left: 0
print(q)  # deque([1])

from collections import deque
import time

from collections import deque

def sliding_window(iterable, window_size: int):
    """Yield sliding windows of size window_size."""
    window = deque(maxlen=window_size)
    for item in iterable:
        window.append(item)
        if len(window) == window_size:
            yield tuple(window)

# Usage
data = [1, 2, 3, 4, 5, 6, 7]
for window in sliding_window(data, 3):
    print(window)
# (1, 2, 3)
# (2, 3, 4)
# (3, 4, 5)
# (4, 5, 6)
# (5, 6, 7)

from collections import OrderedDict

from collections import ChainMap

config = ChainMap(env_config, file_config, defaults)

print(config["host"])   # "prod.example.com" (from env_config)
print(config["port"])   # 9000 (from file_config)
print(config["debug"])  # True (from file_config)

import os
from collections import ChainMap

from collections import ChainMap
import json

def load_config():
    """Load configuration with precedence: env > file > defaults."""

env_config = {}  # Would load from os.environ
    
    return ChainMap(env_config, file_config, defaults)

config = load_config()
print(config["theme"])  # Uses file_config or defaults

from collections import namedtuple

from dataclasses import dataclass

@dataclass
class Point:
    x: int
    y: int
    
    def distance(self, other: "Point") -> float:
        """Calculate distance to another point."""
        return ((self.x - other.x) ** 2 + (self.y - other.y) ** 2) ** 0.5

p1 = Point(1, 2)
p2 = Point(4, 6)
print(p1.distance(p2))  # 5.0

from collections import namedtuple
from dataclasses import dataclass

@dataclass
class PointDC:
    x: int
    y: int

p2 = PointDC(1, 2)
p2.x = 3  # OK: can modify
print(p2)  # PointDC(x=3, y=2)

import re

def replacer(match):
    return match.group(0).upper()

text = "hello world"
new_text = re.sub(r"\w+", replacer, text)
print(new_text)  # "HELLO WORLD"

import re
import time

text = "The number is 42"
pattern_str = r"\d+"
pattern_compiled = re.compile(pattern_str)

import re

log_line = "[2025-11-30 14:30:45] ERROR: Database connection failed (code: 5001)"

import string

from string import Template

import string
import secrets

def generate_password(length: int = 16) -> str:
    """Generate secure random password."""
    alphabet = string.ascii_letters + string.digits + string.punctuation
    return ''.join(secrets.choice(alphabet) for _ in range(length))

password = generate_password(20)
print(password)

import textwrap

long_text = "This is a very long line of text that needs to be wrapped to fit within a certain width for better readability."

import textwrap

def format_docstring(text: str, width: int = 72) -> str:
    """Format docstring with proper indentation."""

import difflib

text1 = "Hello world\nPython is great"
text2 = "Hello Python\nPython is awesome"

diff = difflib.unified_diff(
    text1.splitlines(keepends=True),
    text2.splitlines(keepends=True),
    fromfile='old.txt',
    tofile='new.txt',
    lineterm=''
)
print(''.join(diff))

diff = difflib.context_diff(
    text1.splitlines(keepends=True),
    text2.splitlines(keepends=True),
    fromfile='old.txt',
    tofile='new.txt'
)
print(''.join(diff))

diff = difflib.HtmlDiff()
html_diff = diff.make_file(
    text1.splitlines(),
    text2.splitlines(),
    fromdesc='Old Version',
    todesc='New Version'
)

import difflib

def show_diff(old_text: str, new_text: str):
    """Show unified diff between two texts."""
    diff = difflib.unified_diff(
        old_text.splitlines(keepends=True),
        new_text.splitlines(keepends=True),
        lineterm='',
        n=3  # Context lines
    )
    for line in diff:
        if line.startswith('+'):
            print(f"\033[92m{line}\033[0m", end='')  # Green for additions
        elif line.startswith('-'):
            print(f"\033[91m{line}\033[0m", end='')  # Red for deletions
        else:
            print(line, end='')

old = "Hello world\nPython"
new = "Hello Python\nPython 3.12"
show_diff(old, new)

import json

class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

def person_encoder(obj):
    if isinstance(obj, Person):
        return {"name": obj.name, "age": obj.age}
    raise TypeError(f"Object of type {type(obj)} is not JSON serializable")

person = Person("Alice", 30)
json_str = json.dumps(person, default=person_encoder)
print(json_str)  # '{"name": "Alice", "age": 30}'

def person_decoder(dct):
    if "name" in dct and "age" in dct:
        return Person(dct["name"], dct["age"])
    return dct

data = json.loads(json_str, object_hook=person_decoder)
print(type(data))  # <class '__main__.Person'>

import json

def safe_json_loads(text: str):
    """Safely parse JSON with error handling."""
    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        print(f"JSON decode error: {e}")
        print(f"Error at line {e.lineno}, column {e.colno}")
        return None

result = safe_json_loads('{"invalid": json}')

import json
from pathlib import Path

class ConfigManager:
    def __init__(self, config_path: Path):
        self.config_path = config_path
        self.config = self.load()
    
    def load(self) -> dict:
        """Load configuration from JSON file."""
        if self.config_path.exists():
            with open(self.config_path) as f:
                return json.load(f)
        return {}
    
    def save(self):
        """Save configuration to JSON file."""
        with open(self.config_path, "w") as f:
            json.dump(self.config, f, indent=2)
    
    def get(self, key: str, default=None):
        """Get configuration value."""
        return self.config.get(key, default)
    
    def set(self, key: str, value):
        """Set configuration value."""
        self.config[key] = value
        self.save()

config = ConfigManager(Path("config.json"))
config.set("theme", "dark")
print(config.get("theme"))  # "dark"

import csv

import csv
from typing import List, Dict

def read_csv_safe(filename: str) -> List[Dict[str, str]]:
    """Read CSV with error handling and validation."""
    rows = []
    with open(filename, "r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        for i, row in enumerate(reader, start=2):  # Start at 2 (header is row 1)
            try:

import configparser

import configparser
from pathlib import Path

class AppConfig:
    def __init__(self, config_path: Path):
        self.cfg = configparser.ConfigParser()
        self.cfg.read(config_path)
        self.validate()
    
    def validate(self):
        """Validate required configuration."""
        required = {
            "database": ["host", "port", "name"],
            "app": ["debug", "log_level"]
        }
        for section, keys in required.items():
            if not self.cfg.has_section(section):
                raise ValueError(f"Missing section: {section}")
            for key in keys:
                if not self.cfg.has_option(section, key):
                    raise ValueError(f"Missing option: {section}.{key}")
    
    @property
    def db_host(self):
        return self.cfg.get("database", "host")
    
    @property
    def db_port(self):
        return self.cfg.getint("database", "port")
    
    @property
    def debug(self):
        return self.cfg.getboolean("app", "debug")

config = AppConfig(Path("settings.ini"))
print(f"Database: {config.db_host}:{config.db_port}")

import xml.etree.ElementTree as ET

xml_str = "<root><item>Value</item></root>"
root = ET.fromstring(xml_str)

import xml.etree.ElementTree as ET

def transform_xml(input_file: str, output_file: str):
    """Transform XML structure."""
    tree = ET.parse(input_file)
    root = tree.getroot()

import pickle

import json
data = {"name": "Alice", "age": 30}
json_str = json.dumps(data)  # Safe, human-readable

import msgpack  # Third-party
packed = msgpack.packb(data)

import pickle
import hashlib
from pathlib import Path

class SafePickleCache:
    """Safe pickle-based cache with validation."""
    
    def __init__(self, cache_dir: Path):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(exist_ok=True)
    
    def _get_cache_path(self, key: str) -> Path:
        """Get cache file path for key."""
        key_hash = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{key_hash}.pkl"
    
    def get(self, key: str):
        """Get cached object."""
        cache_path = self._get_cache_path(key)
        if cache_path.exists():
            try:
                with open(cache_path, "rb") as f:
                    return pickle.load(f)
            except Exception as e:
                print(f"Cache read error: {e}")
                cache_path.unlink()  # Remove corrupted cache
        return None
    
    def set(self, key: str, value):
        """Cache object."""
        cache_path = self._get_cache_path(key)
        try:
            with open(cache_path, "wb") as f:
                pickle.dump(value, f, protocol=pickle.HIGHEST_PROTOCOL)
        except Exception as e:
            print(f"Cache write error: {e}")

import subprocess

import subprocess
from typing import List, Optional

def run_command_safe(
    command: List[str],
    timeout: Optional[float] = None,
    cwd: Optional[str] = None
) -> tuple[int, str, str]:
    """Safely run command and return (returncode, stdout, stderr)."""
    try:
        result = subprocess.run(
            command,
            capture_output=True,
            text=True,
            timeout=timeout,
            cwd=cwd,
            check=False  # Don't raise on error
        )
        return result.returncode, result.stdout, result.stderr
    except subprocess.TimeoutExpired as e:
        return -1, "", f"Command timed out after {timeout}s"
    except Exception as e:
        return -1, "", str(e)

# Usage
returncode, stdout, stderr = run_command_safe(["ls", "-l"], timeout=5.0)
if returncode == 0:
    print(stdout)
else:
    print(f"Error: {stderr}")

import sys
x = [1, 2, 3, 4, 5]
print(sys.getsizeof(x))  # Size in bytes

import sys
x = [1, 2, 3]
print(sys.getrefcount(x))  # Number of references

import sys
with open("output.txt", "w") as f:
    sys.stdout = f
    print("This goes to file")
sys.stdout = sys.__stdout__  # Restore

from contextlib import redirect_stdout
with open("output.txt", "w") as f:
    with redirect_stdout(f):
        print("This goes to file")

import sys

def parse_args():
    """Simple argument parser."""
    if len(sys.argv) < 2:
        print("Usage: script.py <command> [args...]")
        sys.exit(1)
    
    command = sys.argv[1]
    args = sys.argv[2:]
    
    if command == "hello":
        name = args[0] if args else "World"
        print(f"Hello, {name}!")
    elif command == "version":
        print(f"Python {sys.version}")
    else:
        print(f"Unknown command: {command}")
        sys.exit(1)

parse_args()

import os

import os.path

import os
from pathlib import Path

def find_files(directory: str, extension: str) -> list[str]:
    """Find all files with given extension."""
    files = []
    for root, dirs, filenames in os.walk(directory):
        for filename in filenames:
            if filename.endswith(extension):
                full_path = os.path.join(root, filename)
                files.append(full_path)
    return files

# Usage
py_files = find_files(".", ".py")
for file in py_files:
    print(file)

import signal
import sys

def signal_handler(signum, frame):
    """Handle interrupt signal."""
    print("\nInterrupted! Cleaning up...")

import signal

class TimeoutError(Exception):
    pass

def timeout_handler(signum, frame):
    raise TimeoutError("Operation timed out")

def with_timeout(seconds: int):
    """Decorator for function timeout."""
    def decorator(func):
        def wrapper(*args, **kwargs):
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(seconds)
            try:
                result = func(*args, **kwargs)
            finally:
                signal.alarm(0)  # Cancel alarm
            return result
        return wrapper
    return decorator

@with_timeout(5)
def slow_operation():
    import time
    time.sleep(10)  # Will timeout

try:
    slow_operation()
except TimeoutError:
    print("Operation timed out")

import signal
import sys
import time

class GracefulShutdown:
    def __init__(self):
        self.shutdown_requested = False
        signal.signal(signal.SIGINT, self._handler)
        signal.signal(signal.SIGTERM, self._handler)
    
    def _handler(self, signum, frame):
        print(f"\nReceived signal {signum}, shutting down gracefully...")
        self.shutdown_requested = True
    
    def should_continue(self):
        return not self.shutdown_requested

shutdown = GracefulShutdown()

# Main loop
while shutdown.should_continue():
    print("Working...")
    time.sleep(1)
    # Do work, check shutdown.should_continue() periodically

print("Shutdown complete")

from urllib.request import urlopen, Request
from urllib.parse import urlencode, quote

from urllib.parse import urlparse, urljoin, quote, unquote

from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError
from urllib.parse import urlencode

def http_get(url: str, headers: dict = None) -> tuple[int, bytes]:
    """Simple GET request with error handling."""
    try:
        req = Request(url)
        if headers:
            for key, value in headers.items():
                req.add_header(key, value)
        
        with urlopen(req, timeout=10) as response:
            return response.status, response.read()
    except HTTPError as e:
        return e.code, e.read()
    except URLError as e:
        raise ConnectionError(f"Failed to connect: {e.reason}")

status, data = http_get("https://example.com")
print(f"Status: {status}")
print(f"Data: {data[:100]}...")

import socket

server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
server.bind(("localhost", 8080))
server.listen(5)

print("Server listening on port 8080")

while True:
    client, addr = server.accept()
    print(f"Connection from {addr}")
    
    with client:
        data = client.recv(1024)
        if data:
            client.sendall(b"Echo: " + data)

import socket
import threading

def handle_client(client, addr):
    """Handle client connection."""
    with client:
        print(f"Client connected: {addr}")
        while True:
            data = client.recv(1024)
            if not data:
                break
            client.sendall(b"Echo: " + data)
    print(f"Client disconnected: {addr}")

def start_server(host="localhost", port=8080):
    """Start echo server."""
    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server.bind((host, port))
    server.listen(5)
    
    print(f"Server listening on {host}:{port}")
    
    while True:
        client, addr = server.accept()
        thread = threading.Thread(target=handle_client, args=(client, addr))
        thread.start()

# start_server()  # Uncomment to run

import ssl
import socket

import ssl
import socket
from urllib.request import urlopen

def secure_get(url: str) -> bytes:
    """Secure HTTPS GET with proper certificate validation."""
    ctx = ssl.create_default_context()

from urllib.parse import urlparse
    parsed = urlparse(url)

import zipfile

import zipfile
from pathlib import Path
from datetime import datetime

def create_backup(source_dir: Path, backup_path: Path):
    """Create timestamped ZIP backup of directory."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = backup_path / f"backup_{timestamp}.zip"
    
    with zipfile.ZipFile(backup_file, "w", zipfile.ZIP_DEFLATED) as z:
        for file in source_dir.rglob("*"):
            if file.is_file():
                arcname = file.relative_to(source_dir)
                z.write(file, arcname)
    
    print(f"Backup created: {backup_file}")
    return backup_file

backup = create_backup(Path("my_project"), Path("backups"))

import tarfile

import tarfile
from pathlib import Path

def create_tar_filtered(source_dir: Path, output: Path, exclude_patterns: list[str]):
    """Create TAR excluding certain patterns."""
    def filter_func(tarinfo):
        """Filter out excluded patterns."""
        for pattern in exclude_patterns:
            if pattern in tarinfo.name:
                return None
        return tarinfo
    
    with tarfile.open(output, "w:gz") as t:
        t.add(source_dir, arcname=source_dir.name, filter=filter_func)

create_tar_filtered(
    Path("project"),
    Path("project.tar.gz"),
    exclude_patterns=[".git", "__pycache__", ".pyc"]
)

import gzip

import gzip
from pathlib import Path

def compress_logs(log_dir: Path, keep_original: bool = False):
    """Compress all .log files in directory."""
    for log_file in log_dir.glob("*.log"):
        gz_file = log_file.with_suffix(".log.gz")
        
        with open(log_file, "rb") as f_in:
            with gzip.open(gz_file, "wb") as f_out:
                f_out.writelines(f_in)
        
        if not keep_original:
            log_file.unlink()
        
        print(f"Compressed: {log_file.name} -> {gz_file.name}")

compress_logs(Path("logs"))

import logging

import logging
from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler

import logging

logger = logging.getLogger(__name__)

class ContextFilter(logging.Filter):
    def filter(self, record):
        record.request_id = getattr(record, "request_id", "unknown")
        return True

logger.addFilter(ContextFilter())

import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path

def setup_logging(log_dir: Path, app_name: str = "app"):
    """Setup production-ready logging."""
    log_dir.mkdir(exist_ok=True)
    log_file = log_dir / f"{app_name}.log"
    
    # Configure root logger
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - [%(request_id)s] - %(message)s',
        handlers=[
            logging.StreamHandler(),
            RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5)
        ]
    )
    
    return logging.getLogger(app_name)

logger = setup_logging(Path("logs"), "myapp")
logger.info("Application started")

from pprint import pprint

data = {
    "users": [
        {"name": "Alice", "age": 30, "city": "New York"},
        {"name": "Bob", "age": 25, "city": "London"},
    ],
    "metadata": {"version": "1.0", "count": 2}
}

from pprint import pprint, pformat

def debug_print(data, label="Data"):
    """Pretty print with label."""
    print(f"\n{label}:")
    print("=" * 50)
    pprint(data, width=80, indent=2)
    print("=" * 50)

# Usage
debug_print({"key": "value"}, "Configuration")

import traceback

try:
    1 / 0
except Exception:

import traceback
import sys

def format_exception(e: Exception) -> str:
    """Format exception with full context."""
    exc_type, exc_value, exc_tb = sys.exc_info()
    tb_lines = traceback.format_exception(exc_type, exc_value, exc_tb)
    return ''.join(tb_lines)

try:
    risky_operation()
except Exception as e:
    error_msg = format_exception(e)
    logger.error(f"Operation failed:\n{error_msg}")

import traceback
import logging

logger = logging.getLogger(__name__)

def log_exception(func):
    """Decorator to log exceptions with full traceback."""
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(
                f"Exception in {func.__name__}:\n{traceback.format_exc()}"
            )
            raise
    return wrapper

@log_exception
def risky_function():
    1 / 0

risky_function()

import inspect

def example(a: int, b: str = "default", *args, **kwargs) -> str:
    """Example function."""
    pass

print(sig.return_annotation)  # <class 'str'>

import inspect

class MyClass:
    def method(self):
        pass

import inspect

def debug_function():
    # Get current frame
    frame = inspect.currentframe()
    print(f"Function: {frame.f_code.co_name}")
    print(f"File: {frame.f_code.co_filename}")
    print(f"Line: {frame.f_lineno}")
    print(f"Locals: {frame.f_locals}")

debug_function()

import inspect

def inspect_function(func):
    """Inspect function and print details."""
    sig = inspect.signature(func)
    doc = inspect.getdoc(func)
    source = inspect.getsource(func)
    
    print(f"Function: {func.__name__}")
    print(f"Signature: {sig}")
    print(f"Docstring: {doc}")
    print(f"Source:\n{source}")

def example(a: int, b: str) -> str:
    """Example function."""
    return f"{a}: {b}"

inspect_function(example)

# ‚ùå WRONG: Cache grows unbounded
class Service:
    @lru_cache(maxsize=256)
    def process(self, data: str) -> dict:
        # 'self' is part of cache key ‚Üí unique per instance
        return expensive_computation(data)

# ‚úÖ CORRECT: Module-level function with hashable args
@lru_cache(maxsize=256)
def _process_impl(data: str) -> dict:
    return expensive_computation(data)

class Service:
    def process(self, data: str) -> dict:
        return _process_impl(data)

import tracemalloc

import tracemalloc
import sys

def process_data():
    """Simulate memory-intensive operation."""

import tracemalloc

def create_objects():
    """Function that might leak memory."""
    objects = []
    for i in range(1000):
        objects.append([0] * 10000)
    return objects

import tracemalloc

tracemalloc.start()

from contextlib import contextmanager
import tracemalloc

@contextmanager
def trace_memory():
    """Context manager for memory tracing."""
    tracemalloc.start()
    snapshot1 = tracemalloc.take_snapshot()
    try:
        yield
    finally:
        snapshot2 = tracemalloc.take_snapshot()
        top_stats = snapshot2.compare_to(snapshot1, 'lineno')
        
        print("Memory allocations:")
        for stat in top_stats[:5]:
            print(stat)
        
        tracemalloc.stop()

# Usage
with trace_memory():
    result = process_data()

import tracemalloc

def my_function():
    # Your code here
    data = [i**2 for i in range(100_000)]
    return sum(data)

tracemalloc.start()
result = my_function()
snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

print("Memory usage by line:")
for stat in top_stats[:5]:
    print(f"{stat.filename}:{stat.lineno}: {stat.size / 1024:.2f} KB")

tracemalloc.stop()

import time
import numpy as np
from typing import Callable

def benchmark(func: Callable, *args, iterations: int = 5) -> float:
    """Run function multiple times and return average time."""
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        func(*args)
        times.append(time.perf_counter() - start)
    return sum(times) / len(times)

def python_loop(n: int):
    return [i * 2 for i in range(n)]

def numpy_vectorized(n: int):
    return (np.arange(n) * 2).tolist()

def numpy_inplace(n: int):
    arr = np.arange(n, dtype=np.float64)
    arr *= 2
    return arr

import time
import numpy as np

def python_loop(n):
    return [i * 2 for i in range(n)]

def numpy_vectorized(n):
    return (np.arange(n) * 2).tolist()

n = 1_000_000
start = time.perf_counter()
python_loop(n)
py_time = time.perf_counter() - start

start = time.perf_counter()
numpy_vectorized(n)
np_time = time.perf_counter() - start

print(f"Python: {py_time:.4f}s, NumPy: {np_time:.4f}s")
print(f"Speedup: {py_time / np_time:.1f}√ó")
# Output: Python: 0.1234s, NumPy: 0.0045s
# Output: Speedup: 27.4√ó

import numpy as np
import time

from numba import njit
import numpy as np

@njit
def fast_sum(arr):
    """JIT-compiled function."""
    total = 0.0
    for i in range(len(arr)):
        total += arr[i]
    return total

import numpy as np
import time
from numba import njit

def python_sum(arr):
    """Pure Python sum."""
    total = 0.0
    for i in range(len(arr)):
        total += arr[i]
    return total

@njit
def numba_sum(arr):
    """Numba JIT-compiled sum."""
    total = 0.0
    for i in range(len(arr)):
        total += arr[i]
    return total

def numpy_sum(arr):
    """NumPy vectorized sum."""
    return np.sum(arr)

from numba import njit
import numpy as np

@njit
def custom_filter(arr, threshold):
    """Custom filtering algorithm (hard to vectorize)."""
    result = []
    for i in range(len(arr)):
        if arr[i] > threshold:
            result.append(arr[i] * 2)
        elif arr[i] < -threshold:
            result.append(arr[i] * -2)
    return np.array(result)

# Much faster than pure Python version
arr = np.random.randn(1_000_000)
filtered = custom_filter(arr, 0.5)

def python_sum(arr):
    total = 0.0
    for x in arr:
        total += x
    return total

from multiprocessing import Pool
from concurrent.futures import ProcessPoolExecutor
import time

def cpu_task(n: int) -> int:
    """CPU-intensive task."""
    return sum(i * i for i in range(n))

@pytest.fixture(scope="session")
def db():
    """Database connection shared across all tests."""
    conn = create_connection()
    yield conn
    conn.close()

@pytest.fixture(scope="function")
def transaction(db):
    """Fresh transaction for each test."""
    trans = db.begin()
    yield trans
    trans.rollback()

@pytest.fixture(params=["sqlite", "postgresql", "mysql"])
def database(request):
    return create_database(request.param)

def test_query(database):
    assert database.query("SELECT 1") == 1

@pytest.fixture
def config():
    return {"api_url": "https://api.example.com"}

@pytest.fixture
def client(config):  # Depends on config
    return APIClient(config["api_url"])

def test_api_call(client):
    assert client.get("/status") == 200

@pytest.fixture(autouse=True)
def reset_state():
    """Automatically runs before every test."""
    clear_cache()
    yield
    cleanup()

@pytest.mark.slow
def test_expensive_operation():

@pytest.mark.parametrize("input,expected", [
    ("hello", "HELLO"),
    ("world", "WORLD"),
    ("", ""),
])
def test_uppercase(input, expected):
    assert input.upper() == expected

# Multiple parameters
@pytest.mark.parametrize("a", [1, 2])
@pytest.mark.parametrize("b", [3, 4])
def test_multiply(a, b):
    assert a * b in [3, 4, 6, 8]

def test_division_by_zero():
    with pytest.raises(ZeroDivisionError) as exc_info:
        divide(10, 0)
    
    assert str(exc_info.value) == "division by zero"

# Match exception message
with pytest.raises(ValueError, match="invalid input"):
    process_data(None)

from unittest.mock import patch

@patch('module.expensive_function')
def test_with_mock(mock_func):
    mock_func.return_value = "mocked"
    result = my_function()
    assert result == "mocked"
    mock_func.assert_called_once()

# Context manager
def test_with_context():
    with patch('module.api_call') as mock_api:
        mock_api.return_value = {"status": "ok"}
        result = process_api()
        assert result["status"] == "ok"

import pytest

def test_with_pytest_mock(mocker):
    mock_func = mocker.patch('module.expensive_function')
    mock_func.return_value = 42
    
    result = my_function()
    assert result == 42
    mock_func.assert_called_once()

from unittest.mock import AsyncMock

@pytest.mark.asyncio
async def test_async_function():
    mock_client = AsyncMock()
    mock_client.fetch.return_value = {"data": "test"}
    
    result = await my_async_function(mock_client)
    assert result == {"data": "test"}

from hypothesis import given, strategies as st

@given(st.integers(), st.integers())
def test_add_commutative(a, b):
    """Addition is commutative."""
    assert add(a, b) == add(b, a)

@given(st.lists(st.integers()))
def test_reverse_twice_is_identity(lst):
    """Reversing twice returns original."""
    assert reverse(reverse(lst)) == lst

from hypothesis import given, strategies as st

@given(st.emails())
def test_email_validation(email):
    assert is_valid_email(email)

# Composite strategies
@given(st.lists(st.integers(min_value=1, max_value=100), min_size=1))
def test_sum_positive(numbers):
    assert sum(numbers) > 0

@pytest.fixture(scope="session")
def test_db():
    """Create test database."""
    db = create_test_database()
    yield db
    db.drop_all()

@pytest.fixture
def db_session(test_db):
    """Fresh session for each test."""
    session = test_db.session()
    yield session
    session.rollback()
    session.close()

def test_user_creation(db_session):
    user = User(name="Test")
    db_session.add(user)
    db_session.commit()
    assert user.id is not None

from fastapi.testclient import TestClient

@pytest.fixture
def client():
    return TestClient(app)

def test_get_users(client):
    response = client.get("/users")
    assert response.status_code == 200
    assert len(response.json()) > 0

# tests/conftest.py
import pytest

@pytest.fixture(scope="session")
def database():
    return create_test_db()

@pytest.fixture
def sample_user():
    return User(name="Test", email="test@example.com")

import pdb

def divide(a, b):
    pdb.set_trace()  # Breakpoint
    return a / b

result = divide(10, 2)

def process_data(data):
    breakpoint()  # Modern way (calls pdb.set_trace())
    return data.upper()

import ipdb

def complex_function():
    ipdb.set_trace()  # Enhanced breakpoint
    # ... your code ...

import debugpy

def main():
    result = process_data()
    return result

import logging
import json
from datetime import datetime

class StructuredLogger:
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s %(name)s %(levelname)s %(message)s'
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.DEBUG)
    
    def debug(self, event: str, **kwargs):
        self.logger.debug(json.dumps({
            "event": event,
            "timestamp": datetime.utcnow().isoformat(),
            **kwargs
        }))

import structlog

logger = structlog.get_logger()

def process_order(order_id: str):
    logger.info("order.processing", order_id=order_id)
    try:
        result = validate_order(order_id)
        logger.info("order.validated", order_id=order_id, valid=result)
    except Exception as e:
        logger.error("order.failed", order_id=order_id, error=str(e))
        raise

import uuid
import logging

class CorrelationFilter(logging.Filter):
    def filter(self, record):
        record.correlation_id = getattr(
            record, 'correlation_id', str(uuid.uuid4())
        )
        return True

logger = logging.getLogger()
logger.addFilter(CorrelationFilter())

import cProfile
import pstats

def profile_function():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # Your code
    result = slow_function()
    
    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # Top 20 functions

# Install: pip install line_profiler

@profile  # Decorator for line_profiler
def slow_function():
    total = 0
    for i in range(1000000):
        total += i ** 2
    return total

# Install: pip install memory-profiler

@profile
def memory_intensive():
    data = [i for i in range(1000000)]
    return sum(data)

def debug_print(*args, **kwargs):
    """Print with context."""
    import inspect
    frame = inspect.currentframe().f_back
    print(f"[{frame.filename}:{frame.lineno}]", *args, **kwargs)

def process_data(data):
    assert data is not None, "Data cannot be None"
    assert len(data) > 0, "Data cannot be empty"
    # ... processing ...

from multiprocessing import Process
import os

def compute(name: str, data: list[int]):
    """CPU-intensive task."""
    print(f"Process {name} (PID: {os.getpid()}) processing {len(data)} items")
    result = sum(x * x for x in data)
    print(f"Process {name} result: {result}")
    return result

if __name__ == "__main__":

from multiprocessing import Process, Queue
import time

def worker(name: str, queue: Queue):
    """Worker process that sends results back."""
    for i in range(5):
        result = f"{name}: Task {i} completed"
        queue.put(result)
        time.sleep(0.1)
    queue.put(None)  # Sentinel value

if __name__ == "__main__":
    queue = Queue()

from multiprocessing import Process
from pathlib import Path

def process_file(file_path: Path):
    """Process a single file."""
    print(f"Processing {file_path.name}")

from concurrent.futures import ProcessPoolExecutor, as_completed
import time

def expensive_computation(n: int) -> int:
    """CPU-intensive computation."""
    result = sum(i * i for i in range(n))
    return result

if __name__ == "__main__":
    data = [1000000, 2000000, 3000000, 4000000, 5000000]

def risky_computation(n: int) -> int:
    """May raise exception."""
    if n < 0:
        raise ValueError("Negative number")
    return n * n

with ProcessPoolExecutor() as executor:
    futures = [executor.submit(risky_computation, n) for n in [-1, 2, 3]]
    
    for future in as_completed(futures):
        try:
            result = future.result()
            print(f"Success: {result}")
        except ValueError as e:
            print(f"Error: {e}")

import time
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor

def cpu_task(n: int) -> int:
    """CPU-bound task."""
    return sum(i * i for i in range(n))

data = list(range(1000, 5000, 100))

from concurrent.futures import ProcessPoolExecutor
from pathlib import Path
from PIL import Image

def process_image(image_path: Path) -> Path:
    """Process single image (CPU-intensive)."""
    img = Image.open(image_path)
    # Resize and apply filters
    img = img.resize((800, 600))
    img = img.filter(Image.Filter.SHARPEN)
    output_path = image_path.parent / f"processed_{image_path.name}"
    img.save(output_path)
    return output_path

if __name__ == "__main__":
    images = list(Path("photos").glob("*.jpg"))
    
    with ProcessPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(process_image, images))
    
    print(f"Processed {len(results)} images")

from multiprocessing import Process, Value, Array
import time

def increment_counter(counter: Value, lock):
    """Increment shared counter."""
    for _ in range(100000):
        with lock:
            counter.value += 1

if __name__ == "__main__":

from multiprocessing import Process, Array

def square_array(arr: Array, start: int, end: int):
    """Square elements in range."""
    for i in range(start, end):
        arr[i] = arr[i] * arr[i]

if __name__ == "__main__":

# ‚ùå WRONG: Race condition
counter = Value('i', 0)
def bad_increment():
    counter.value += 1  # Not atomic!

# ‚úÖ CORRECT: Use lock
from multiprocessing import Lock

lock = Lock()
def good_increment():
    with lock:
        counter.value += 1

from multiprocessing import Process, Array, Lock
import math

def compute_row(arr: Array, row: int, cols: int, lock: Lock):
    """Compute values for one row."""
    for col in range(cols):
        index = row * cols + col
        with lock:
            arr[index] = math.sin(row) * math.cos(col)

if __name__ == "__main__":
    rows, cols = 1000, 1000
    shared_matrix = Array('d', [0.0] * (rows * cols))
    lock = Lock()

from multiprocessing import Manager, Process

def worker(shared_dict: dict, shared_list: list):
    """Worker that modifies shared objects."""
    shared_dict['count'] = shared_dict.get('count', 0) + 1
    shared_list.append(os.getpid())

if __name__ == "__main__":
    manager = Manager()
    shared_dict = manager.dict()
    shared_list = manager.list()
    
    # Start workers
    processes = [
        Process(target=worker, args=(shared_dict, shared_list))
        for _ in range(5)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print(f"Dict: {dict(shared_dict)}")
    print(f"List: {list(shared_list)}")

from multiprocessing import Manager, Process

def update_stats(stats):
    """Update statistics."""
    stats.processed += 1
    stats.total_time += 0.5

if __name__ == "__main__":
    manager = Manager()
    stats = manager.Namespace()
    stats.processed = 0
    stats.total_time = 0.0
    
    processes = [
        Process(target=update_stats, args=(stats,))
        for _ in range(10)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print(f"Processed: {stats.processed}")
    print(f"Total time: {stats.total_time}")

from multiprocessing import Manager, Process
import time

def worker(task_queue: 'Queue', result_dict: dict, worker_id: int):
    """Worker process."""
    while True:
        task = task_queue.get()
        if task is None:  # Sentinel
            break

large_data = [list(range(10000)) for _ in range(1000)]

def process(data):
    return sum(sum(row) for row in data)

def process_by_index(start_idx, end_idx):

# ‚ùå BAD: Many small tasks
def tiny_task(x):
    return x * 2

# Process startup overhead > task time
with ProcessPoolExecutor() as executor:
    results = list(executor.map(tiny_task, range(100)))  # Slow!

# ‚úÖ BETTER: Batch small tasks
def batch_task(batch):
    return [x * 2 for x in batch]

batches = [list(range(i, i+100)) for i in range(0, 1000, 100)]
with ProcessPoolExecutor() as executor:
    results = list(executor.map(batch_task, batches))

# ‚ùå BAD: Lambdas can't be pickled
with ProcessPoolExecutor() as executor:
    results = executor.map(lambda x: x * 2, data)  # Error!

# ‚úÖ CORRECT: Use named functions
def double(x):
    return x * 2

with ProcessPoolExecutor() as executor:
    results = executor.map(double, data)

# ‚ùå BAD: Trying to share unpicklable objects
class Unpicklable:
    def __init__(self):
        self.lock = threading.Lock()  # Can't pickle locks!

# ‚úÖ CORRECT: Use Manager or shared memory
manager = Manager()
shared_obj = manager.Namespace()

import multiprocessing
multiprocessing.set_start_method('spawn')  # Must be called once, early

from multiprocessing import Process, Queue
import multiprocessing

if __name__ == "__main__":
    multiprocessing.set_start_method('spawn')  # Portable
    
    def worker(q: Queue):
        """Worker that processes tasks."""
        while True:
            task = q.get()
            if task is None:
                break

from multiprocessing import Process, Pipe

def worker(conn):
    """Worker with bidirectional communication."""
    while True:
        msg = conn.recv()
        if msg == "STOP":
            break
        result = process(msg)
        conn.send(result)
    conn.close()

if __name__ == "__main__":
    parent_conn, child_conn = Pipe()
    p = Process(target=worker, args=(child_conn,))
    p.start()
    
    # Send and receive
    parent_conn.send("task1")
    result = parent_conn.recv()
    print(result)
    
    parent_conn.send("STOP")
    p.join()

from multiprocessing import Process, Queue
import time

def producer(queue: Queue):
    """Produce items."""
    for i in range(10):
        queue.put(f"Item {i}")
        time.sleep(0.1)
    queue.put(None)  # Sentinel

def consumer(queue: Queue):
    """Consume items."""
    while True:
        item = queue.get()
        if item is None:
            break
        print(f"Consumed: {item}")

if __name__ == "__main__":
    queue = Queue()
    
    p1 = Process(target=producer, args=(queue,))
    p2 = Process(target=consumer, args=(queue,))
    
    p1.start()
    p2.start()
    
    p1.join()
    p2.join()

from multiprocessing import Process, Queue
from typing import List

def stage1(input_queue: Queue, output_queue: Queue):
    """First stage: Load and filter."""
    while True:
        item = input_queue.get()
        if item is None:
            output_queue.put(None)
            break
        if item > 0:  # Filter
            output_queue.put(item * 2)

def stage2(input_queue: Queue, output_queue: Queue):
    """Second stage: Transform."""
    while True:
        item = input_queue.get()
        if item is None:
            output_queue.put(None)
            break
        output_queue.put(item ** 2)

def stage3(input_queue: Queue, results: List):
    """Third stage: Collect results."""
    while True:
        item = input_queue.get()
        if item is None:
            break
        results.append(item)

if __name__ == "__main__":
    q1, q2, q3 = Queue(), Queue(), Queue()
    results = []
    
    # Create pipeline
    p1 = Process(target=stage1, args=(q1, q2))
    p2 = Process(target=stage2, args=(q2, q3))
    p3 = Process(target=stage3, args=(q3, results))
    
    p1.start()
    p2.start()
    p3.start()
    
    # Feed data
    for i in range(-5, 10):
        q1.put(i)
    q1.put(None)
    
    p1.join()
    p2.join()
    p3.join()
    
    print(f"Results: {results}")

from abc import ABC, abstractmethod
from typing import Optional, List

class UserRepository(ABC):
    @abstractmethod
    def get_by_id(self, user_id: int) -> Optional[dict]:
        """Get user by ID."""
        pass
    
    @abstractmethod
    def save(self, user: dict) -> dict:
        """Save user."""
        pass

class SQLUserRepository(UserRepository):
    def __init__(self, db_connection):
        self.db = db_connection
    
    def get_by_id(self, user_id: int) -> Optional[dict]:
        cursor = self.db.execute("SELECT * FROM users WHERE id=?", (user_id,))
        row = cursor.fetchone()
        return dict(row) if row else None
    
    def save(self, user: dict) -> dict:

pass

class InMemoryUserRepository(UserRepository):
    def __init__(self):
        self._users = {}
    
    def get_by_id(self, user_id: int) -> Optional[dict]:
        return self._users.get(user_id)
    
    def save(self, user: dict) -> dict:
        self._users[user["id"]] = user
        return user

class UserService:
    def __init__(self, repository: UserRepository):
        self.repo = repository
    
    def get_user(self, user_id: int) -> Optional[dict]:
        return self.repo.get_by_id(user_id)

from typing import Protocol

class IDatabase(Protocol):
    def execute(self, query: str, params: tuple) -> dict: ...

class Database:
    def execute(self, query: str, params: tuple) -> dict:

return {"result": "data"}

class Service:
    def __init__(self, db: IDatabase):
        self.db = db
    
    def process(self):
        return self.db.execute("SELECT * FROM data", ())

from dependency_injector import containers, providers

class Container(containers.DeclarativeContainer):
    db = providers.Singleton(Database)
    service = providers.Factory(Service, db=db)

container = Container()
service = container.service()

from typing import Callable, Dict, List
from dataclasses import dataclass
from enum import Enum

class EventType(Enum):
    USER_CREATED = "user_created"
    ORDER_PLACED = "order_placed"

@dataclass
class Event:
    event_type: EventType
    payload: dict

class EventBus:
    def __init__(self):
        self._handlers: Dict[EventType, List[Callable]] = {}
    
    def subscribe(self, event_type: EventType, handler: Callable[[Event], None]):
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)
    
    def publish(self, event: Event):
        handlers = self._handlers.get(event.event_type, [])
        for handler in handlers:
            handler(event)

# Usage
bus = EventBus()

def send_welcome_email(event: Event):
    print(f"Sending welcome email to {event.payload['email']}")

def log_event(event: Event):
    print(f"Logging event: {event.event_type.value}")

bus.subscribe(EventType.USER_CREATED, send_welcome_email)
bus.subscribe(EventType.USER_CREATED, log_event)

bus.publish(Event(
    event_type=EventType.USER_CREATED,
    payload={"email": "user@example.com"}
))

from typing import Callable

def federal_tax(amount: float) -> float:
    return amount * 0.25

def state_tax(amount: float) -> float:
    return amount * 0.05

def calculate_total(amount: float, tax_strategy: Callable[[float], float]) -> float:
    return amount + tax_strategy(amount)

# Usage
total1 = calculate_total(100, federal_tax)  # 125.0
total2 = calculate_total(100, state_tax)   # 105.0

class Dog:
    def speak(self): return "Woof!"

class Cat:
    def speak(self): return "Meow!"

def create_animal(animal_type: str):
    animals = {"dog": Dog, "cat": Cat}
    return animals[animal_type]()

class Animal:
    @classmethod
    def create(cls, animal_type: str):
        return cls._create(animal_type)
    
    @staticmethod
    def _create(animal_type: str):
        animals = {"dog": Dog, "cat": Cat}
        return animals[animal_type]()

from fastapi import FastAPI

app = FastAPI()

@app.get("/users/{user_id}")
async def get_user(user_id: int):

from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class UserResponse(BaseModel):
    id: int
    name: str

@app.get("/users/{user_id}", response_model=UserResponse)
async def get_user(user_id: int):
    return UserResponse(id=user_id, name="Alice")
    # Output: {"id": 1, "name": "Alice"}

from fastapi import FastAPI, Depends
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from pydantic import BaseModel

app = FastAPI()
engine = create_async_engine("postgresql+asyncpg://...")
SessionLocal = async_sessionmaker(engine, expire_on_commit=False)

class UserResponse(BaseModel):
    id: int
    name: str

async def get_db():
    async with SessionLocal() as session:
        yield session

@app.get("/users/{user_id}", response_model=UserResponse)
async def get_user(user_id: int, db: AsyncSession = Depends(get_db)):

flowchart TD
    APIService[API Service] -->|enqueue job| MessageBus[Message Bus<br/>Redis/Kafka]
    
    MessageBus -->|deliver message| WorkerCluster[Worker Cluster<br/>Celery / Dramatiq / RQ]
    
    WorkerCluster --> Worker1[Worker1]
    WorkerCluster --> Worker2[Worker2]
    
    style APIService fill:#e1f5ff
    style MessageBus fill:#ffe1f5
    style WorkerCluster fill:#e1ffe1
    style Worker1 fill:#fff4e1
    style Worker2 fill:#ffe1e1

def greet(name: str) -> str:
    """Return a greeting message for the given name."""
    return f"Hello, {name}!"

# ‚úÖ CORRECT: Google-style docstring
def scale(x: float, factor: float) -> float:
    """Scale a numeric value by a given factor.

    Args:
        x: Input value.
        factor: The number to multiply by.

    Returns:
        The scaled result.
    """
    return x * factor

# ‚úÖ CORRECT: NumPy-style docstring
def scale(x, factor):
    """
    Scale a numeric value.

    Parameters
    ----------
    x : float
        Input value to be scaled.
    factor : float
        Scaling factor to apply.

    Returns
    -------
    float
        The scaled result.
    """
    return x * factor

# ‚úÖ CORRECT: Sphinx/RST style docstring
def scale(x, factor):
    """
    Scale a numeric value.

    :param x: Input value.
    :type x: float
    :param factor: Scale factor.
    :type factor: float
    :returns: Scaled result.
    :rtype: float
    """
    return x * factor

# ‚úÖ CORRECT: Class docstring with attributes
class RateLimiter:
    """Token-bucket rate limiter with adjustable burst window.

    Attributes:
        rate: Tokens added per second.
        burst: Extra capacity available during spikes.
        tokens: Current token count.
    """

    def __init__(self, rate: float, burst: int):
        """Initialize the rate limiter.

        Args:
            rate: Tokens per second.
            burst: Maximum burst capacity.
        """
        self.rate = rate
        self.burst = burst
        self.tokens = burst

# ‚úÖ CORRECT: Function with comprehensive docstring
def login_user(username: str, password: str) -> bool:
    """Authenticate a user against the credentials database.

    Args:
        username: The user's login name.
        password: Raw password input.

    Returns:
        True if the user is authenticated; otherwise False.

    Raises:
        AuthenticationError: If credentials are invalid.
        DatabaseError: If the database is unavailable.
    """
    # Implementation here
    pass

# ‚úÖ CORRECT: Async function docstring
async def fetch_user(uid: str) -> dict:
    """Fetch a user record asynchronously from the database.

    Args:
        uid: Unique user identifier.

    Returns:
        Dictionary containing user data with keys: id, name, email.

    Raises:
        UserNotFoundError: If the user does not exist.
    """
    # Implementation here
    pass

# ‚úÖ CORRECT: Generator docstring
def read_lines(path: str):
    """Yield lines lazily from a file.

    Args:
        path: Path to the text file.

    Yields:
        str: Each line from the file with trailing whitespace stripped.

    Raises:
        FileNotFoundError: If the file does not exist.
        PermissionError: If the file cannot be read.
    """
    with open(path) as f:
        for line in f:
            yield line.rstrip()

# ‚úÖ CORRECT: Property docstring
class User:
    """User account representation."""

    def __init__(self, first: str, last: str):
        self._first = first
        self._last = last

    @property
    def full_name(self) -> str:
        """Return the user's full name.

        Returns:
            Concatenated first and last name separated by a space.
        """
        return f"{self._first} {self._last}"

# ‚úÖ CORRECT: Public function with docstring
def process_payment(amount: float, currency: str) -> bool:
    """Process a payment transaction."""
    return _validate_and_charge(amount, currency)

# ‚úÖ CORRECT: Private function can skip docstring for simple cases
def _validate_and_charge(amount: float, currency: str) -> bool:
    # Implementation
    return True

# ‚úÖ CORRECT: OPA policy for docstring enforcement
package python.docstrings

deny[msg] {
  fn := input.functions[_]
  fn.public == true
  not fn.has_docstring
  msg := sprintf("Missing docstring: %s", [fn.name])
}

deny[msg] {
  cls := input.classes[_]
  cls.public == true
  not cls.has_docstring
  msg := sprintf("Missing class docstring: %s", [cls.name])
}

# ‚úÖ CORRECT: Detailed return type documentation
def parse_config(path: str) -> dict[str, Any]:
    """Parse a YAML configuration file.

    Args:
        path: Path to the YAML configuration file.

    Returns:
        Dictionary containing parsed configuration with structure:
        {
            "database": {
                "host": str,
                "port": int,
                "credentials": dict
            },
            "logging": {
                "level": str,
                "handlers": list[str]
            }
        }

    Raises:
        FileNotFoundError: If the configuration file does not exist.
        YAMLError: If the file contains invalid YAML syntax.
    """
    pass

# ‚úÖ CORRECT: Generic function with type variable documentation
from typing import TypeVar, Callable

T = TypeVar('T')

def retry(func: Callable[[], T], max_attempts: int = 3) -> T:
    """Retry a function until it succeeds or max attempts is reached.

    Type Parameters:
        T: The return type of the function being retried.

    Args:
        func: Zero-argument callable to retry.
        max_attempts: Maximum number of retry attempts.

    Returns:
        The result of the successful function call.

    Raises:
        MaxRetriesExceeded: If all retry attempts fail.
    """
    pass

# ‚úÖ CORRECT: Context manager documentation
from contextlib import contextmanager

@contextmanager
def database_transaction():
    """Context manager for database transactions with automatic rollback.

    Yields:
        Database connection with an open transaction.

    Examples:
        >>> with database_transaction() as conn:
        ...     conn.execute("INSERT INTO users VALUES (?, ?)", ("alice", 30))
        ...     # Transaction commits on successful exit

        >>> with database_transaction() as conn:
        ...     conn.execute("INSERT INTO users VALUES (?, ?)", ("bob", 25))
        ...     raise ValueError("Oops")
        ...     # Transaction rolls back on exception
    """
    pass

# ‚úÖ CORRECT: Decorator documentation
from functools import wraps
from typing import Callable, TypeVar, ParamSpec

P = ParamSpec('P')
T = TypeVar('T')

def memoize(func: Callable[P, T]) -> Callable[P, T]:
    """Decorator that caches function results based on arguments.

    Args:
        func: Function to memoize. Must have hashable arguments.

    Returns:
        Wrapped function with caching behavior.

    Examples:
        >>> @memoize
        ... def fibonacci(n: int) -> int:
        ...     if n < 2:
        ...         return n
        ...     return fibonacci(n-1) + fibonacci(n-2)
    """
    cache = {}
    
    @wraps(func)
    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
        key = (args, tuple(sorted(kwargs.items())))
        if key not in cache:
            cache[key] = func(*args, **kwargs)
        return cache[key]
    
    return wrapper

# ‚ùå INCORRECT: Provides no useful information
def process_data(data):
    """Process data."""
    pass

# ‚ùå INCORRECT: Just repeats what the name already says
def add(x, y):
    """Add function."""
    return x + y

# ‚ùå INCORRECT: Missing Raises section
def parse_int(value: str) -> int:
    """Convert a string to an integer."""
    return int(value)  # Can raise ValueError!

# ‚ùå INCORRECT: Describes how instead of what
def authenticate(user: str, pwd: str) -> bool:
    """Check password by computing SHA256 hash and comparing with database.
    
    Uses the hashlib library to compute the hash, then queries the users
    table in PostgreSQL using SQLAlchemy ORM.
    """
    pass

# ‚úÖ CORRECT: Clear, complete, focused on contract
def parse_int(value: str) -> int:
    """Convert a string to an integer.

    Args:
        value: String representation of an integer.

    Returns:
        The integer value.

    Raises:
        ValueError: If the string cannot be converted to an integer.
    """
    return int(value)

# ‚úÖ CORRECT: Describes behavior, not implementation
def authenticate(user: str, pwd: str) -> bool:
    """Verify user credentials against stored credentials.

    Args:
        user: Username to authenticate.
        pwd: Password to verify.

    Returns:
        True if credentials are valid; False otherwise.

    Raises:
        DatabaseError: If credential verification fails due to database issues.
    """
    pass

# ‚ùå INCORRECT: Exposes internal implementation details
def fetch_user(uid: str) -> dict:
    """Fetch user from database.
    
    Raises:
        psycopg2.OperationalError: If PostgreSQL connection fails.
        redis.ConnectionError: If Redis cache is unavailable.
    """
    pass

# ‚úÖ CORRECT: Public API uses abstracted exceptions
def fetch_user(uid: str) -> dict:
    """Fetch user from database.
    
    Raises:
        DatabaseError: If user data cannot be retrieved.
        UserNotFoundError: If the user does not exist.
    """
    pass

# ‚ùå INCORRECT: Docstring doesn't match signature
def process_order(order_id: str, priority: bool = False) -> dict:
    """Process an order.
    
    Args:
        order_id: Order identifier.
        expedite: Whether to expedite shipping.  # ‚ùå Wrong parameter name!
    """
    pass

# ‚ùå INCORRECT: States the obvious
def get_name(self) -> str:
    """Get the name.
    
    Returns:
        str: The name.
    """
    return self._name

# ‚úÖ CORRECT: Adds value
def get_name(self) -> str:
    """Return the user's display name.
    
    Returns:
        Full name if available; otherwise username.
    """
    return self._full_name or self._username

# ‚úÖ CORRECT: Sphinx-compatible docstring
def calculate_tax(amount: float, rate: float) -> float:
    """Calculate tax on a given amount.

    Args:
        amount: Pre-tax amount in dollars.
        rate: Tax rate as a decimal (e.g., 0.08 for 8%).

    Returns:
        Tax amount in dollars.

    Examples:
        >>> calculate_tax(100.0, 0.08)
        8.0
        >>> calculate_tax(50.0, 0.10)
        5.0
    """
    return amount * rate

# ‚úÖ CORRECT: Doctest examples in docstring
def factorial(n: int) -> int:
    """Calculate factorial of n.

    Args:
        n: Non-negative integer.

    Returns:
        Factorial of n.

    Raises:
        ValueError: If n is negative.

    Examples:
        >>> factorial(0)
        1
        >>> factorial(5)
        120
        >>> factorial(-1)
        Traceback (most recent call last):
            ...
        ValueError: n must be non-negative
    """
    if n < 0:
        raise ValueError("n must be non-negative")
    if n == 0:
        return 1
    return n * factorial(n - 1)

# ‚úÖ CORRECT: Docstring consistent with type hints
def divide(x: float, y: float) -> float:
    """Divide x by y.

    Args:
        x: Numerator.
        y: Denominator.

    Returns:
        Result of division.

    Raises:
        ZeroDivisionError: If y is zero.
    """
    if y == 0:
        raise ZeroDivisionError("Cannot divide by zero")
    return x / y

State = (Env, Stack, Heap, IP, Exception, Tasks)

where:
  Env = Env_global √ó Env_local √ó Env_enclosing  (environment chain)
  Stack = [Frame‚ÇÅ, Frame‚ÇÇ, ..., Frame‚Çô]  (call stack, Frame = (code, locals, IP))
  Heap = {ref ‚Ü¶ Object}  (object store, ref ‚àà Address)
  IP = instruction pointer (bytecode offset)
  Exception = None | (exc_type, exc_value, exc_tb)
  Tasks = {task_id ‚Ü¶ CoroutineState}  (for asyncio)

State = (Env, Stack, Heap, IP, Exception)

where:
  Env = {name ‚Ü¶ reference}  (environment mapping names to heap references)
  Stack = [Frame‚ÇÅ, Frame‚ÇÇ, ...]  (call stack)
  Heap = {ref ‚Ü¶ Object}  (object store)
  IP = instruction pointer
  Exception = None | (ExceptionType, value, traceback)

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-FunDef]
Env' = {x ‚Ü¶ v | x ‚àà free_vars(fun_body) ‚àß x ‚àà dom(Env)}
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®def outer(x): ... def inner(y): return x + y, Env‚ü© 
  ‚Üí ‚ü®closure(inner_code, Env' = {x ‚Ü¶ Env[x]}), Env‚ü©

def outer(x):
    def inner(y):
        return x + y
    return inner

# Formal representation:
# outer_code = Œªx. (Œªy. x + y)
# When outer(5) is called:
#   Env_captured = {x ‚Ü¶ 5}
#   Returns: closure(inner_code, {x ‚Ü¶ 5})
# When closure(3) is called:
#   Env_new = {x ‚Ü¶ 5, y ‚Ü¶ 3}
#   Evaluates: x + y ‚Üí 5 + 3 ‚Üí 8

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Var]
x : œÑ ‚àà Œì
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ x : œÑ

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Int]
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ n : int    (for integer literal n)

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Str]
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ s : str    (for string literal s)

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Fun]
Œì, x : œÑ‚ÇÅ ‚ä¢ body : œÑ‚ÇÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ (Œªx: œÑ‚ÇÅ. body) : œÑ‚ÇÅ ‚Üí œÑ‚ÇÇ

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-App]
Œì ‚ä¢ f : œÑ‚ÇÅ ‚Üí œÑ‚ÇÇ    Œì ‚ä¢ arg : œÑ‚ÇÅ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ f(arg) : œÑ‚ÇÇ

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Union]
Œì ‚ä¢ e : œÑ‚ÇÅ    or    Œì ‚ä¢ e : œÑ‚ÇÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ e : œÑ‚ÇÅ | œÑ‚ÇÇ

Set = {x‚ÇÅ, x‚ÇÇ, ..., x‚Çô}    (unordered, unique)

Map = {k‚ÇÅ ‚Ü¶ v‚ÇÅ, k‚ÇÇ ‚Ü¶ v‚ÇÇ, ...}    (key-value pairs)

Sequence = [v‚ÇÅ, v‚ÇÇ, ..., v‚Çô]    (ordered, indexed)

Iterable = {obj | obj has __iter__()}

Iterator = {obj | obj has __next__() ‚àß obj ‚àà Iterable}

from typing import List, Dict, Any, Callable
from dataclasses import dataclass
from enum import Enum
import json

class AgentRole(Enum):
    ARCHITECT = "architect"
    REVIEWER = "reviewer"
    TESTER = "tester"
    REFACTORER = "refactorer"
    SECURITY = "security"
    DOCS = "documentation"

@dataclass
class AgentMessage:
    role: AgentRole
    content: str
    metadata: Dict[str, Any]

class BaseAgent:
    """Base class for all agents."""
    
    def __init__(self, role: AgentRole, llm_client, tools: List[Callable]):
        self.role = role
        self.llm_client = llm_client
        self.tools = {tool.__name__: tool for tool in tools}
        self.memory: List[AgentMessage] = []
    
    def execute(self, task: str, context: Dict[str, Any]) -> AgentMessage:
        """Execute agent task and return message."""

result = self._process(task, context)
        message = AgentMessage(
            role=self.role,
            content=result,
            metadata=context
        )
        self.memory.append(message)
        return message
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        """Override in subclasses."""
        raise NotImplementedError

class ArchitectAgent(BaseAgent):
    """Proposes system design and architecture."""
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        prompt = f"""
        As an architect agent, analyze the following task and propose a design:
        
        Task: {task}
        Context: {json.dumps(context, indent=2)}
        
        Provide:
        1. Architecture proposal
        2. Component breakdown
        3. Dependencies
        4. File structure
        """

return f"Architecture proposal for: {task}"

class ReviewerAgent(BaseAgent):
    """Reviews code for patterns and compliance."""
    
    def __init__(self, *args, rules: List[str], **kwargs):
        super().__init__(*args, **kwargs)
        self.rules = rules
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        code = context.get("code", "")
        violations = []

for rule in self.rules:
            if self._violates_rule(code, rule):
                violations.append(rule)
        
        if violations:
            return f"Review failed. Violations: {violations}"
        return "Review passed. Code complies with patterns."

    def _violates_rule(self, code: str, rule: str) -> bool:
        """Check if code violates rule."""

return False

class TesterAgent(BaseAgent):
    """Generates tests for code."""
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        code = context.get("code", "")
        test_code = f"""

import pytest

def test_basic_functionality():

pass

def test_edge_cases():

pass
"""
        return test_code

class SecurityAgent(BaseAgent):
    """Checks for security anti-patterns."""
    
    SECURITY_PATTERNS = [
        "subprocess.run",
        "eval(",
        "exec(",
        "pickle.loads",
        "yaml.load(",
    ]
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        code = context.get("code", "")
        issues = []
        
        for pattern in self.SECURITY_PATTERNS:
            if pattern in code:
                issues.append(f"Security risk: {pattern}")
        
        if issues:
            return f"Security issues found: {issues}"
        return "Security check passed."

class MultiAgentOrchestrator:
    """Coordinates multiple agents."""
    
    def __init__(self, agents: List[BaseAgent]):
        self.agents = {agent.role: agent for agent in agents}
        self.shared_memory: List[AgentMessage] = []
    
    def execute_workflow(self, task: str) -> Dict[AgentRole, str]:
        """Execute multi-agent workflow."""
        results = {}

if "failed" in review_result.content.lower():
            refactor_result = self.agents[AgentRole.REFACTORER].execute(
                "Refactor code", {"code": code, "issues": review_result.content}
            )
            results[AgentRole.REFACTORER] = refactor_result.content
        
        return results
    
    def _generate_code(self, task: str, design: str) -> str:
        """Generate code based on design (simplified)."""
        return f"# Generated code for: {task}\n# Design: {design}"

from typing import List, Dict, Any
from dataclasses import dataclass

@dataclass
class ReActStep:
    thought: str
    action: str
    action_input: Dict[str, Any]
    observation: str

class ReActAgent:
    """ReAct pattern agent: reasons before acting."""
    
    def __init__(self, llm_client, tools: Dict[str, Callable], max_steps: int = 10):
        self.llm_client = llm_client
        self.tools = tools
        self.max_steps = max_steps
        self.steps: List[ReActStep] = []
    
    def execute(self, task: str) -> str:
        """Execute task using ReAct pattern."""
        observation = f"Task: {task}"
        
        for step_num in range(self.max_steps):

self.steps.append(ReActStep(
                thought=thought,
                action=action,
                action_input=action_input,
                observation=observation
            ))
        
        return "Max steps reached. Task incomplete."
    
    def _think(self, observation: str, history: List[ReActStep]) -> str:
        """Generate reasoning thought."""

return f"Analyzing: {observation}"
    
    def _decide_action(self, thought: str) -> tuple[str, Dict[str, Any]]:
        """Decide next action based on thought."""

return "FINISH", {}
    
    def _extract_answer(self, thought: str) -> str:
        """Extract final answer from thought."""
        return thought

def read_file(path: str) -> str:
    """Read file content."""
    with open(path, 'r') as f:
        return f.read()

def write_file(path: str, content: str) -> None:
    """Write file content."""
    with open(path, 'w') as f:
        f.write(content)

agent = ReActAgent(
    llm_client=None,
    tools={"read_file": read_file, "write_file": write_file}
)

result = agent.execute("Read config.json and update the version field")

from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import Tool
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

def search_codebase(query: str) -> str:
    """Search codebase for patterns."""

return f"Found: {query}"

def run_tests() -> str:
    """Run test suite."""

llm = ChatOpenAI(model="gpt-4o", temperature=0)
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code review agent. Use tools to analyze code."),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

agent = create_openai_tools_agent(llm, tools, prompt)
executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

from crewai import Agent, Task, Crew
from crewai_tools import FileReadTool, DirectoryReadTool

class CodeCleanupAgent:
    """Multi-agent system for code cleanup."""
    
    def __init__(self):
        self.agents = {
            "analyzer": self._analyze_code,
            "refactorer": self._refactor_code,
            "validator": self._validate_code,
        }
    
    def cleanup(self, code: str) -> str:
        """Clean up code using agent pipeline."""

if self.agents["validator"](cleaned):
            return cleaned
        else:
            return code  # Return original if validation fails
    
    def _analyze_code(self, code: str) -> List[str]:
        """Analyze code for issues."""
        issues = []
        if "import *" in code:
            issues.append("wildcard_import")
        if "eval(" in code:
            issues.append("eval_usage")
        return issues
    
    def _refactor_code(self, code: str, issues: List[str]) -> str:
        """Refactor code to fix issues."""

return code
    
    def _validate_code(self, code: str) -> bool:
        """Validate refactored code."""

from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import json
import sqlite3
from pathlib import Path

@dataclass
class ToolResult:
    success: bool
    result: Any
    error: Optional[str] = None

class PythonToolAgent:
    """Agent with real Python tools for file I/O, DB access, etc."""
    
    def __init__(self, llm_client, db_path: str = "agent.db"):
        self.llm_client = llm_client
        self.db_path = db_path
        self.tools = {
            "read_file": self._read_file,
            "write_file": self._write_file,
            "list_directory": self._list_directory,
            "query_database": self._query_database,
            "execute_sql": self._execute_sql,
            "search_files": self._search_files,
            "run_command": self._run_command_safe,
        }
    
    def _read_file(self, path: str) -> ToolResult:
        """Read file content safely."""
        try:
            file_path = Path(path)
            if not file_path.exists():
                return ToolResult(False, None, f"File not found: {path}")
            if not file_path.is_file():
                return ToolResult(False, None, f"Not a file: {path}")

if not str(file_path.resolve()).startswith(str(Path.cwd().resolve())):
                return ToolResult(False, None, "Path traversal not allowed")
            
            content = file_path.read_text(encoding='utf-8')
            return ToolResult(True, content)
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _write_file(self, path: str, content: str, mode: str = "w") -> ToolResult:
        """Write file content safely."""
        try:
            file_path = Path(path)

if not str(file_path.resolve()).startswith(str(Path.cwd().resolve())):
                return ToolResult(False, None, "Path traversal not allowed")
            
            file_path.parent.mkdir(parents=True, exist_ok=True)
            file_path.write_text(content, encoding='utf-8')
            return ToolResult(True, f"Written {len(content)} bytes to {path}")
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _list_directory(self, path: str = ".") -> ToolResult:
        """List directory contents."""
        try:
            dir_path = Path(path)
            if not dir_path.exists():
                return ToolResult(False, None, f"Directory not found: {path}")
            if not dir_path.is_dir():
                return ToolResult(False, None, f"Not a directory: {path}")
            
            items = {
                "files": [str(p) for p in dir_path.iterdir() if p.is_file()],
                "directories": [str(p) for p in dir_path.iterdir() if p.is_dir()],
            }
            return ToolResult(True, items)
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _query_database(self, query: str, params: Dict[str, Any] = None) -> ToolResult:
        """Execute SELECT query safely."""
        try:
            if not query.strip().upper().startswith("SELECT"):
                return ToolResult(False, None, "Only SELECT queries allowed")
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            results = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description] if cursor.description else []
            
            conn.close()
            
            return ToolResult(True, {
                "columns": columns,
                "rows": results,
                "count": len(results)
            })
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _execute_sql(self, query: str, params: Dict[str, Any] = None) -> ToolResult:
        """Execute write SQL (with approval)."""

try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            conn.commit()
            affected = cursor.rowcount
            conn.close()
            
            return ToolResult(True, f"Query executed. Rows affected: {affected}")
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _search_files(self, pattern: str, directory: str = ".") -> ToolResult:
        """Search for files matching pattern."""
        try:
            dir_path = Path(directory)
            matches = list(dir_path.rglob(pattern))
            return ToolResult(True, [str(m) for m in matches])
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _run_command_safe(self, command: str) -> ToolResult:
        """Run command with restrictions."""

ALLOWED_COMMANDS = ["ls", "pwd", "cat", "grep"]
        
        parts = command.split()
        if not parts or parts[0] not in ALLOWED_COMMANDS:
            return ToolResult(False, None, f"Command not allowed: {parts[0] if parts else 'empty'}")
        
        import subprocess
        try:
            result = subprocess.run(
                command.split(),
                capture_output=True,
                text=True,
                timeout=5,
                cwd=Path.cwd()
            )
            return ToolResult(
                True,
                {
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode
                }
            )
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def execute_with_tools(self, task: str) -> str:
        """Execute task using available tools."""

file_path = "config.json"  # In real implementation, extract from task
            result = self._read_file(file_path)
            if result.success:
                return f"File content: {result.result[:100]}..."
            else:
                return f"Error: {result.error}"
        
        return "Task completed"

from typing import Callable, Optional
from enum import Enum
import time
import logging

class ErrorType(Enum):
    RATE_LIMIT = "rate_limit"
    TIMEOUT = "timeout"
    INVALID_RESPONSE = "invalid_response"
    TOOL_ERROR = "tool_error"
    NETWORK_ERROR = "network_error"

class RetryStrategy:
    """Configurable retry strategies."""
    
    @staticmethod
    def exponential_backoff(max_retries: int = 3, base_delay: float = 1.0):
        """Exponential backoff retry."""
        def retry(func: Callable, *args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise
                    delay = base_delay * (2 ** attempt)
                    time.sleep(delay)
                    logging.warning(f"Retry {attempt + 1}/{max_retries} after {delay}s")
        return retry
    
    @staticmethod
    def circuit_breaker(threshold: int = 5, timeout: float = 60.0):
        """Circuit breaker pattern."""
        failures = 0
        last_failure_time = 0
        
        def wrapper(func: Callable, *args, **kwargs):
            nonlocal failures, last_failure_time

failures = 0
            
            try:
                result = func(*args, **kwargs)
                failures = 0  # Reset on success
                return result
            except Exception as e:
                failures += 1
                last_failure_time = time.time()
                raise
        return wrapper

class ResilientAgent:
    """Agent with error recovery mechanisms."""
    
    def __init__(self, llm_client, tools: Dict[str, Callable]):
        self.llm_client = llm_client
        self.tools = tools
        self.retry_strategy = RetryStrategy.exponential_backoff(max_retries=3)
        self.circuit_breaker = RetryStrategy.circuit_breaker(threshold=5)
    
    def execute_with_recovery(self, task: str) -> str:
        """Execute with automatic error recovery."""

if error_type == ErrorType.RATE_LIMIT:
                return self._handle_rate_limit(task)
            elif error_type == ErrorType.TIMEOUT:
                return self._handle_timeout(task)
            elif error_type == ErrorType.INVALID_RESPONSE:
                return self._handle_invalid_response(task)
            elif error_type == ErrorType.TOOL_ERROR:
                return self._handle_tool_error(task, e)
            else:
                return self._handle_generic_error(task, e)
    
    def _execute_primary(self, task: str) -> str:
        """Primary execution path."""

return self.retry_strategy(self._call_llm, task)
    
    def _call_llm(self, task: str) -> str:
        """Call LLM (simplified)."""

if "fail" in task.lower():
            raise Exception("Simulated LLM failure")
        return f"Result for: {task}"
    
    def _classify_error(self, error: Exception) -> ErrorType:
        """Classify error type."""
        error_str = str(error).lower()
        if "rate limit" in error_str or "429" in error_str:
            return ErrorType.RATE_LIMIT
        elif "timeout" in error_str:
            return ErrorType.TIMEOUT
        elif "invalid" in error_str or "parse" in error_str:
            return ErrorType.INVALID_RESPONSE
        else:
            return ErrorType.NETWORK_ERROR
    
    def _handle_rate_limit(self, task: str) -> str:
        """Handle rate limit errors."""
        logging.info("Rate limit hit, waiting and retrying...")
        time.sleep(60)  # Wait 1 minute
        return self._execute_primary(task)
    
    def _handle_timeout(self, task: str) -> str:
        """Handle timeout errors."""
        logging.info("Timeout occurred, retrying with shorter context...")

simplified_task = task[:100]  # Truncate
        return self._execute_primary(simplified_task)
    
    def _handle_invalid_response(self, task: str) -> str:
        """Handle invalid LLM responses."""
        logging.info("Invalid response, requesting structured output...")

structured_task = f"{task}\n\nRespond in JSON format only."
        return self._execute_primary(structured_task)
    
    def _handle_tool_error(self, task: str, error: Exception) -> str:
        """Handle tool execution errors."""
        logging.warning(f"Tool error: {error}")

return f"Task partially completed. Tool error: {error}"
    
    def _handle_generic_error(self, task: str, error: Exception) -> str:
        """Handle generic errors."""
        logging.error(f"Unrecoverable error: {error}")
        return f"Task failed: {error}"

from functools import lru_cache
from typing import List, Dict, Any
import hashlib
import json
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class CacheEntry:
    result: str
    timestamp: datetime
    cost: float
    tokens_used: int

class CostOptimizedAgent:
    """Agent optimized for cost and latency."""
    
    def __init__(self, llm_client, cache_ttl: timedelta = timedelta(hours=24)):
        self.llm_client = llm_client
        self.cache: Dict[str, CacheEntry] = {}
        self.cache_ttl = cache_ttl
        self.total_cost = 0.0
        self.total_tokens = 0
    
    def _cache_key(self, task: str, context: Dict[str, Any] = None) -> str:
        """Generate cache key from task and context."""
        key_data = {"task": task, "context": context or {}}
        key_str = json.dumps(key_data, sort_keys=True)
        return hashlib.sha256(key_str.encode()).hexdigest()
    
    def execute_cached(self, task: str, context: Dict[str, Any] = None) -> str:
        """Execute with caching."""
        cache_key = self._cache_key(task, context)

self.cache[cache_key] = CacheEntry(
            result=result,
            timestamp=datetime.now(),
            cost=cost,
            tokens_used=tokens
        )
        
        self.total_cost += cost
        self.total_tokens += tokens
        
        return result
    
    def batch_execute(self, tasks: List[str]) -> List[str]:
        """Execute multiple tasks in a single LLM call."""

cost_per_task = cost / len(tasks)
        tokens_per_task = tokens / len(tasks)
        
        logging.info(f"Batch execution: {len(tasks)} tasks, "
                    f"{cost:.4f} total cost ({cost_per_task:.4f} per task)")
        
        return results
    
    def _call_llm_with_metrics(self, prompt: str) -> tuple[str, float, int]:
        """Call LLM and track metrics."""

tokens = len(prompt.split()) * 1.3  # Rough estimate
        cost = tokens * 0.000002  # Example: $0.002 per 1K tokens
        
        result = f"Response to: {prompt[:50]}"
        return result, cost, int(tokens)
    
    def get_cost_summary(self) -> Dict[str, Any]:
        """Get cost and usage summary."""
        return {
            "total_cost": self.total_cost,
            "total_tokens": self.total_tokens,
            "cache_size": len(self.cache),
            "cache_hit_rate": self._calculate_cache_hit_rate(),
        }
    
    def _calculate_cache_hit_rate(self) -> float:
        """Calculate cache hit rate (simplified)."""

class CodeReviewAgent(CostOptimizedAgent):
    """Code review agent with cost optimization."""
    
    def review_file(self, file_path: str) -> Dict[str, Any]:
        """Review a file with caching."""
        with open(file_path, 'r') as f:
            code = f.read()
        
        # Use cached execution
        review = self.execute_cached(
            f"Review this Python code for issues:\n\n{code}",
            context={"file": file_path}
        )
        
        return {
            "file": file_path,
            "review": review,
            "cached": self._was_cached(file_path, code)
        }
    
    def _was_cached(self, file_path: str, code: str) -> bool:
        """Check if review was cached."""
        cache_key = self._cache_key(
            f"Review code: {code}",
            context={"file": file_path}
        )
        return cache_key in self.cache

from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import Tool, StructuredTool
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
from langchain.callbacks import StreamingStdOutCallbackHandler
from pydantic import BaseModel, Field

class CodeReviewInput(BaseModel):
    file_path: str = Field(description="Path to the file to review")
    rules: list[str] = Field(default=[], description="Specific rules to check")

def review_code(file_path: str, rules: list[str] = None) -> str:
    """Review Python code for quality issues."""
    with open(file_path, 'r') as f:
        code = f.read()
    
    issues = []
    if "import *" in code:
        issues.append("Wildcard import detected")
    if "eval(" in code:
        issues.append("eval() usage detected")
    
    return f"Review complete. Issues: {issues}" if issues else "No issues found"

review_tool = StructuredTool.from_function(
    func=review_code,
    name="review_code",
    description="Review Python code for quality and security issues",
    args_schema=CodeReviewInput
)

llm = ChatOpenAI(model="gpt-4o", temperature=0, streaming=True)
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a code review agent. Use tools to analyze code.
    Always explain your reasoning before using tools.
    Provide actionable feedback."""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

agent = create_openai_tools_agent(llm, [review_tool], prompt)
executor = AgentExecutor(
    agent=agent,
    tools=[review_tool],
    memory=memory,
    verbose=True,
    max_iterations=5,
    handle_parsing_errors=True
)

from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chains import ConversationalRetrievalChain

embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_texts(
    texts=["Code patterns", "Architecture docs"],
    embedding=embeddings
)

qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever(),
    memory=memory,
    verbose=True
)

result = qa_chain({"question": "How do we handle authentication?"})

from llama_index import VectorStoreIndex, ServiceContext
from llama_index.llms import OpenAI
from llama_index.tools import FunctionTool
from llama_index.agent import ReActAgent
from llama_index.query_engine import RetrieverQueryEngine

llm = OpenAI(model="gpt-4", temperature=0)
service_context = ServiceContext.from_defaults(llm=llm)

from llama_index import SimpleDirectoryReader
documents = SimpleDirectoryReader("src").load_data()

index = VectorStoreIndex.from_documents(documents, service_context=service_context)

def search_codebase(query: str) -> str:
    """Search codebase for patterns."""
    query_engine = index.as_query_engine()
    response = query_engine.query(query)
    return str(response)

def analyze_dependencies(file_path: str) -> str:
    """Analyze dependencies for a file."""

tools = [
    FunctionTool.from_defaults(fn=search_codebase),
    FunctionTool.from_defaults(fn=analyze_dependencies),
]

agent = ReActAgent.from_tools(
    tools=tools,
    llm=llm,
    verbose=True
)

from llama_index.tools import ToolMetadata
from llama_index.agent import OpenAIAgent

class CodebaseTool:
    """Custom tool for codebase operations."""
    
    def __init__(self, codebase_path: str):
        self.codebase_path = codebase_path
    
    def read_file(self, file_path: str) -> str:
        """Read file from codebase."""
        full_path = f"{self.codebase_path}/{file_path}"
        with open(full_path, 'r') as f:
            return f.read()
    
    def list_files(self, directory: str = ".") -> list[str]:
        """List files in directory."""
        import os
        full_path = f"{self.codebase_path}/{directory}"
        return os.listdir(full_path)

from llama_index.tools import FunctionTool

read_file_tool = FunctionTool.from_defaults(
    fn=codebase_tool.read_file,
    name="read_file",
    description="Read a file from the codebase"
)

list_files_tool = FunctionTool.from_defaults(
    fn=codebase_tool.list_files,
    name="list_files",
    description="List files in a directory"
)

agent = OpenAIAgent.from_tools(
    [read_file_tool, list_files_tool],
    verbose=True
)

import hashlib
from pathlib import Path

class SnapshotTester:
    """Test AI-generated code against snapshots."""
    
    def __init__(self, snapshot_dir: Path = Path("snapshots")):
        self.snapshot_dir = snapshot_dir
        self.snapshot_dir.mkdir(exist_ok=True)
    
    def test_generated_code(self, task: str, generated_code: str) -> bool:
        """Test generated code against snapshot."""
        snapshot_path = self.snapshot_dir / f"{self._hash_task(task)}.py"
        
        if snapshot_path.exists():

snapshot_path.write_text(generated_code)
            print(f"Created snapshot: {snapshot_path}")
            return True
    
    def _hash_task(self, task: str) -> str:
        """Generate hash for task."""
        return hashlib.sha256(task.encode()).hexdigest()[:16]

tester = SnapshotTester()
tester.test_generated_code(
    "Create user authentication",
    "def authenticate(): pass"
)

import ast
import inspect

class BehavioralTester:
    """Test that generated functions obey invariants."""
    
    def test_function(self, code: str, invariants: list[callable]) -> bool:
        """Test function against invariants."""
        try:

for invariant in invariants:
                if not invariant(func):
                    return False
            
            return True
        except Exception as e:
            print(f"Behavioral test failed: {e}")
            return False
    
    def _extract_function_name(self, tree: ast.AST) -> str:
        """Extract function name from AST."""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                return node.name
        raise ValueError("No function found")

def invariant_no_side_effects(func):
    """Check that function has no side effects."""

return True

tester = BehavioralTester()
tester.test_function(
    "def add(a, b): return a + b",
    [invariant_no_side_effects]
)

import subprocess
from pathlib import Path

class CodeQualityChecker:
    """Run linting and type checking on generated code."""
    
    def check(self, code: str, output_file: Path = Path("temp_code.py")) -> dict:
        """Check code quality."""
        # Write code to temp file
        output_file.write_text(code)
        
        results = {
            "ruff": self._run_ruff(output_file),
            "mypy": self._run_mypy(output_file),
            "pytest": self._run_pytest(output_file),
        }
        
        # Cleanup
        output_file.unlink()
        
        return results
    
    def _run_ruff(self, file_path: Path) -> dict:
        """Run ruff linter."""
        try:
            result = subprocess.run(
                ["ruff", "check", str(file_path)],
                capture_output=True,
                text=True
            )
            return {
                "success": result.returncode == 0,
                "output": result.stdout
            }
        except FileNotFoundError:
            return {"success": False, "output": "ruff not installed"}
    
    def _run_mypy(self, file_path: Path) -> dict:
        """Run mypy type checker."""
        try:
            result = subprocess.run(
                ["mypy", "--strict", str(file_path)],
                capture_output=True,
                text=True
            )
            return {
                "success": result.returncode == 0,
                "output": result.stdout
            }
        except FileNotFoundError:
            return {"success": False, "output": "mypy not installed"}
    
    def _run_pytest(self, file_path: Path) -> dict:
        """Run pytest."""
        try:
            result = subprocess.run(
                ["pytest", str(file_path), "-q"],
                capture_output=True,
                text=True
            )
            return {
                "success": result.returncode == 0,
                "output": result.stdout
            }
        except FileNotFoundError:
            return {"success": False, "output": "pytest not installed"}

# Usage
checker = CodeQualityChecker()
results = checker.check("def add(a: int, b: int) -> int: return a + b")
print(results)

import random
import json

class AdversarialTester:
    """Test code robustness against adversarial inputs."""
    
    def test_robustness(self, func: callable, test_cases: list) -> dict:
        """Test function with adversarial inputs."""
        results = {
            "passed": 0,
            "failed": 0,
            "errors": []
        }
        
        for test_case in test_cases:
            try:
                result = func(*test_case["args"], **test_case["kwargs"])
                results["passed"] += 1
            except Exception as e:
                results["failed"] += 1
                results["errors"].append({
                    "test_case": test_case,
                    "error": str(e)
                })
        
        return results
    
    def generate_adversarial_inputs(self) -> list:
        """Generate adversarial test inputs."""
        return [
            {"args": [], "kwargs": {}},  # Empty input
            {"args": [None], "kwargs": {}},  # None input
            {"args": [""], "kwargs": {}},  # Empty string
            {"args": [{}], "kwargs": {}},  # Empty dict
            {"args": [1e10], "kwargs": {}},  # Large number
            {"args": ["<script>alert('xss')</script>"], "kwargs": {}},  # XSS attempt
            {"args": [json.dumps({"malformed": True})], "kwargs": {}},  # Malformed JSON
        ]

def example_func(data: str) -> str:
    """Example function to test."""
    return data.upper()

tester = AdversarialTester()
test_cases = tester.generate_adversarial_inputs()
results = tester.test_robustness(example_func, test_cases)
print(f"Passed: {results['passed']}, Failed: {results['failed']}")

import config
print(config.API_URL)  # Single source of truth

class DatabaseConnection:
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:  # Thread-safe
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.connection = self._connect()
            self._initialized = True
    
    def _connect(self):

import threading
from typing import Any

class SingletonMeta(type):
    _instances: dict[type, Any] = {}
    _lock = threading.Lock()
    
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            with cls._lock:
                if cls not in cls._instances:
                    cls._instances[cls] = super().__call__(*args, **kwargs)
        return cls._instances[cls]

class Logger(metaclass=SingletonMeta):
    def __init__(self):
        self.logs = []
    
    def log(self, message: str):
        self.logs.append(message)
        print(message)

# Usage
logger1 = Logger()
logger2 = Logger()
assert logger1 is logger2
logger1.log("Test")
assert len(logger2.logs) == 1  # Shared state

import config
config.settings["debug"] = True  # Side effect!

import config
print(config.settings["debug"])  # True - unexpected!

@dataclass
class Config:
    api_url: str
    timeout: int
    debug: bool = False

def create_app(config: Config):

def create_parser(kind: str):
    match kind:
        case "json": return JSONParser()
        case "yaml": return YAMLParser()
        case "xml": return XMLParser()
        case _: raise ValueError(f"Unknown parser: {kind}")

# Usage
parser = create_parser("json")
data = parser.parse(text)

PARSERS: dict[str, type[Parser]] = {
    "json": JSONParser,
    "yaml": YAMLParser,
    "xml": XMLParser,
}

def create_parser(kind: str) -> Parser:
    parser_class = PARSERS.get(kind)
    if parser_class is None:
        raise ValueError(f"Unknown parser: {kind}")
    return parser_class()

# Usage
parser = create_parser("json")

from typing import Protocol

class Parser(Protocol):
    def parse(self, text: str) -> dict: ...

class ParserFactory(Protocol):
    def create(self) -> Parser: ...

class JSONParserFactory:
    def create(self) -> Parser:
        return JSONParser()

class YAMLParserFactory:
    def create(self) -> Parser:
        return YAMLParser()

# Usage
factory: ParserFactory = JSONParserFactory()
parser = factory.create()

from typing import Protocol
from dataclasses import dataclass

@dataclass
class DatabaseConfig:
    host: str
    port: int
    database: str

class Database(Protocol):
    def connect(self) -> None: ...
    def query(self, sql: str) -> list[dict]: ...

class PostgreSQLDatabase:
    def __init__(self, config: DatabaseConfig):
        self.config = config
    
    def connect(self) -> None:

pass
    
    def query(self, sql: str) -> list[dict]:

return []

class MySQLDatabase:
    def __init__(self, config: DatabaseConfig):
        self.config = config
    
    def connect(self) -> None:
        pass
    
    def query(self, sql: str) -> list[dict]:
        return []

def create_database(db_type: str, config: DatabaseConfig) -> Database:
    factories = {
        "postgresql": PostgreSQLDatabase,
        "mysql": MySQLDatabase,
    }
    
    factory = factories.get(db_type)
    if factory is None:
        raise ValueError(f"Unknown database type: {db_type}")
    
    return factory(config)

class AbstractFactory(ABC):
    @abstractmethod
    def create(self): ...

class ConcreteFactory(AbstractFactory):
    def create(self):
        return ConcreteProduct()

def create_product():
    return ConcreteProduct()

# GOOD: Simple and Pythonic
PRODUCTS = {
    "type_a": ProductA,
    "type_b": ProductB,
}

def create_product(product_type: str):
    return PRODUCTS[product_type]()

from typing import Callable, Any, TypeVar
from enum import Enum

T = TypeVar("T")

class Lifecycle(Enum):
    SINGLETON = "singleton"
    TRANSIENT = "transient"
    SCOPED = "scoped"

class Container:
    def __init__(self):
        self._providers: dict[str, Callable[[], Any]] = {}
        self._lifecycles: dict[str, Lifecycle] = {}
        self._singletons: dict[str, Any] = {}
        self._scoped: dict[str, dict[str, Any]] = {}
    
    def register(
        self,
        name: str,
        provider: Callable[[], T],
        lifecycle: Lifecycle = Lifecycle.TRANSIENT
    ) -> None:
        self._providers[name] = provider
        self._lifecycles[name] = lifecycle
    
    def resolve(self, name: str, scope_id: str | None = None) -> Any:
        if name not in self._providers:
            raise ValueError(f"Service '{name}' not registered")
        
        lifecycle = self._lifecycles[name]
        
        if lifecycle == Lifecycle.SINGLETON:
            if name not in self._singletons:
                self._singletons[name] = self._providers[name]()
            return self._singletons[name]
        
        elif lifecycle == Lifecycle.SCOPED:
            if scope_id is None:
                raise ValueError("Scope ID required for scoped services")
            if scope_id not in self._scoped:
                self._scoped[scope_id] = {}
            if name not in self._scoped[scope_id]:
                self._scoped[scope_id][name] = self._providers[name]()
            return self._scoped[scope_id][name]
        
        else:  # TRANSIENT
            return self._providers[name]()
    
    def clear_scope(self, scope_id: str) -> None:
        """Clear all scoped instances for a scope."""
        if scope_id in self._scoped:
            del self._scoped[scope_id]

# Usage
container = Container()

# Register services
container.register("database", lambda: create_db_connection(), Lifecycle.SINGLETON)
container.register("logger", lambda: Logger(), Lifecycle.SINGLETON)
container.register("user_service", lambda: UserService(
    container.resolve("database"),
    container.resolve("logger")
), Lifecycle.TRANSIENT)

# Resolve
db = container.resolve("database")
user_service = container.resolve("user_service")

from typing import Protocol
from dataclasses import dataclass

class Database(Protocol):
    def query(self, sql: str) -> list[dict]: ...

class Logger(Protocol):
    def log(self, message: str) -> None: ...

@dataclass
class UserService:
    db: Database
    logger: Logger
    
    def get_user(self, user_id: int) -> dict | None:
        self.logger.log(f"Fetching user {user_id}")
        results = self.db.query(f"SELECT * FROM users WHERE id = {user_id}")
        return results[0] if results else None

def create_user_service(db: Database, logger: Logger) -> UserService:
    return UserService(db=db, logger=logger)

import inspect
from typing import get_type_hints

class AutoContainer:
    def __init__(self):
        self._services: dict[type, Any] = {}
        self._factories: dict[type, Callable] = {}
    
    def register_singleton(self, service_type: type, instance: Any) -> None:
        self._services[service_type] = instance
    
    def register_factory(self, service_type: type, factory: Callable) -> None:
        self._factories[service_type] = factory
    
    def resolve(self, service_type: type) -> Any:
        if service_type in self._services:
            return self._services[service_type]
        
        if service_type in self._factories:
            factory = self._factories[service_type]

# BAD: Hard to test, tight coupling
import database
import logger

class UserService:
    def get_user(self, user_id: int):
        logger.log(f"Fetching {user_id}")  # Global dependency
        return database.query(f"SELECT * FROM users WHERE id = {user_id}")

# GOOD: Testable, explicit dependencies
class UserService:
    def __init__(self, db: Database, logger: Logger):
        self.db = db
        self.logger = logger
    
    def get_user(self, user_id: int):
        self.logger.log(f"Fetching {user_id}")
        return self.db.query(f"SELECT * FROM users WHERE id = {user_id}")

def greet(name: str) -> str:
    return f"Hello, {name}!"

class User:
    def __init__(self, name: str):
        self.name = name

def process(data: list[int]) -> dict[str, int]:
    return {"count": len(data)}

# Variable arguments
def func(*args: int, **kwargs: str) -> None:
    pass

# Callable
from typing import Callable
handler: Callable[[int, str], bool] = my_func

from typing import TypeVar, Generic

T = TypeVar("T")

class Container(Generic[T]):
    def __init__(self, value: T):
        self.value = value

from typing import Protocol

class Drawable(Protocol):
    def draw(self) -> None: ...

def render(obj: Drawable) -> None:
    obj.draw()

def test_function():
    assert add(1, 2) == 3

@pytest.mark.parametrize("a,b,expected", [(1,2,3), (0,5,5)])
def test_add(a, b, expected):
    assert add(a, b) == expected

@pytest.fixture
def data():
    return [1, 2, 3]

def test_process(data):
    assert len(data) == 3

from unittest.mock import Mock, patch

# Mock object
mock = Mock()
mock.method.return_value = 42

# Patch
@patch('module.function')
def test_with_patch(mock_func):
    mock_func.return_value = "mocked"
    result = my_function()

import asyncio
import time

async def slow():
    time.sleep(3)  # BLOCKS entire event loop!
    return "done"

async def main():
    await slow()  # All other tasks wait
    print("finished")

import asyncio

async def slow():
    await asyncio.sleep(3)  # Non-blocking
    return "done"

async def main():
    await slow()
    print("finished")

import requests  # Blocking library
import asyncio

async def fetch_data():
    response = requests.get("https://api.example.com")  # BLOCKS!
    return response.json()

import httpx  # Async HTTP client
import asyncio

async def fetch_data():
    async with httpx.AsyncClient() as client:
        response = await client.get("https://api.example.com")
        return response.json()

async def background_task():
    await asyncio.sleep(10)
    print("Task completed")

async def main():
    asyncio.create_task(background_task())  # Task may be garbage collected!
    await asyncio.sleep(1)  # Main exits before task completes

async def main():
    task = asyncio.create_task(background_task())

async def fetch():
    return {"data": "value"}

async def main():
    result = fetch()  # Returns coroutine object, not result!
    print(result)  # <coroutine object fetch at 0x...>

async def main():
    result = await fetch()  # Actually execute coroutine
    print(result)  # {'data': 'value'}

import asyncio

lock = asyncio.Lock()

async def task1():
    async with lock:
        await asyncio.sleep(1)
        async with lock:  # DEADLOCK! (reentrant lock needed)
            pass

async def main():
    await task1()  # Hangs forever

lock = asyncio.Lock()

async def task1():
    async with lock:
        await asyncio.sleep(1)
        # Don't acquire same lock again, or use asyncio's reentrant lock
        pass

async def failing_task():
    raise ValueError("Error!")

async def main():
    task = asyncio.create_task(failing_task())
    # Exception is silently swallowed!
    await asyncio.sleep(1)

async def main():
    task = asyncio.create_task(failing_task())
    try:
        await task
    except ValueError as e:
        print(f"Task failed: {e}")

async def inner():
    await asyncio.sleep(1)

async def outer():
    asyncio.run(inner())  # ERROR: Cannot call run() from running event loop

async def outer():
    await inner()  # Just await directly

import threading

def cpu_bound_task(n):
    total = 0
    for i in range(n):
        total += i * i
    return total

import multiprocessing

def cpu_bound_task(n):
    total = 0
    for i in range(n):
        total += i * i
    return total

if __name__ == "__main__":
    with multiprocessing.Pool() as pool:
        results = pool.map(cpu_bound_task, [10_000_000, 10_000_000])
    # Actually runs in parallel across CPU cores

import threading
import requests

def fetch_url(url):
    response = requests.get(url)  # I/O operation releases GIL
    return response.status_code

threads = [
    threading.Thread(target=fetch_url, args=(url,))
    for url in urls
]

for t in threads:
    t.start()
for t in threads:
    t.join()

# Threads work well here because I/O releases GIL

# This is SLOWER than sequential!
threads = [threading.Thread(target=heavy_computation) for _ in range(4)]
for t in threads:
    t.start()
for t in threads:
    t.join()

counter = 0

def increment():
    global counter
    for _ in range(100_000):
        counter += 1  # NOT atomic! Race condition possible

threads = [threading.Thread(target=increment) for _ in range(10)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print(counter)  # May be < 1_000_000 due to race conditions

import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100_000):
        with lock:
            counter += 1  # Atomic operation

def add(a: int, b: int) -> int:
    return a + b

result = add("hello", "world")  # No error at runtime!
print(result)  # "helloworld" (works, but wrong type)

from typing import assert_type

def add(a: int, b: int) -> int:
    assert_type(a, int)  # Runtime check (Python 3.13+)
    assert_type(b, int)
    return a + b

from pydantic import validate_call

@validate_call
def add(a: int, b: int) -> int:
    return a + b

from typing import Any

def process(data: Any) -> Any:
    return data.anything()  # Type checker can't help

result: Any = process(123)
result.foo.bar.baz  # No type errors, but runtime error!

from typing import Protocol

class Processable(Protocol):
    def process(self) -> str: ...

def process(data: Processable) -> str:
    return data.process()  # Type-safe

from typing import TypedDict

class Config(TypedDict):
    items: list[str]

def create_config(items: list[str] = []) -> Config:  # Mutable default!
    return {"items": items}

config1 = create_config()
config2 = create_config()
config1["items"].append("x")
print(config2["items"])  # ['x'] - shared list!

def create_config(items: list[str] | None = None) -> Config:
    if items is None:
        items = []
    return {"items": items}

from typing import TypeVar

T = TypeVar("T", bound=int)  # Too restrictive

def identity(x: T) -> T:
    return x

identity("hello")  # Type error, but maybe you wanted str support

T = TypeVar("T")  # Unconstrained

def identity(x: T) -> T:
    return x

identity("hello")  # Works
identity(42)  # Works

from typing import Protocol

class Drawable(Protocol):
    def draw(self) -> None: ...

class Circle:
    def draw(self, color: str) -> None:  # Extra parameter!
        print(f"Drawing circle in {color}")

def render(obj: Drawable):
    obj.draw()  # Type error: draw() signature doesn't match

circle = Circle()
render(circle)  # Runtime error: missing argument

class Circle:
    def draw(self, color: str = "black") -> None:  # Default parameter
        print(f"Drawing circle in {color}")

def render(obj: Drawable):
    obj.draw()  # Works: default parameter satisfies protocol

from typing import TypeVar, Generic

T = TypeVar("T")

class Container(Generic[T]):
    def __init__(self, value: T):
        self.value = value

def get_value(container: Container) -> int:  # Missing type parameter!
    return container.value  # Type checker can't infer T

def get_value(container: Container[int]) -> int:
    return container.value  # Type-safe

from typing import Optional

def process(data: Optional[str]) -> str:
    return data.upper()  # Type error: data might be None

def process(data: Optional[str]) -> str:
    if data is None:
        return ""
    return data.upper()  # Type checker knows data is str here

from typing import TypeVar, Generic

T = TypeVar("T")

class Box(Generic[T]):
    def put(self, item: T) -> None: ...
    def get(self) -> T: ...

def put_string(box: Box[str]) -> None:
    box.put("hello")

string_box: Box[str] = Box()
any_box: Box[object] = string_box  # Type error: Box is invariant
put_string(any_box)  # Would allow putting non-string!

from typing import TypeVar, Generic

T_co = TypeVar("T_co", covariant=True)

class ReadOnlyBox(Generic[T_co]):
    def get(self) -> T_co: ...

import ast

user_code = input("Enter expression: ")

import os

API_KEY = os.getenv("API_KEY")  # From environment
DATABASE_PASSWORD = os.getenv("DATABASE_PASSWORD")

from dotenv import load_dotenv
load_dotenv()

import requests
from urllib.parse import urlparse

def safe_get(url: str):
    parsed = urlparse(url)

import sqlite3

user_id = input("Enter user ID: ")
query = f"SELECT * FROM users WHERE id = {user_id}"  # SQL INJECTION!

import sqlite3

user_id = input("Enter user ID: ")
query = "SELECT * FROM users WHERE id = ?"  # Parameterized query
cursor.execute(query, (user_id,))  # Safe: parameters are escaped

from sqlalchemy import text
result = session.execute(text("SELECT * FROM users WHERE id = :id"), {"id": user_id})

from pathlib import Path

filename = input("Enter filename: ")
file_path = Path("data") / filename  # Base directory
file_path = file_path.resolve()

import subprocess
import shlex

user_input = input("Enter filename: ")

from fastapi import FastAPI

app = FastAPI()

@app.get("/users/{user_id}")
def get_user(user_id: str):
    try:
        user = db.get_user(user_id)
    except Exception as e:
        return {"error": str(e)}  # Exposes internal details!

# Error might reveal: "Database connection failed: password='secret'"

@app.get("/users/{user_id}")
def get_user(user_id: str):
    try:
        user = db.get_user(user_id)
        return {"user": user}
    except UserNotFound:
        raise HTTPException(status_code=404, detail="User not found")
    except Exception:

import time

data = list(range(1_000_000))

start = time.perf_counter()
result = [x * 2 for x in data]  # Python loop
print(f"Time: {time.perf_counter() - start:.4f}s")
# Typical: 0.1250s

def find_item(items, target):
    try:
        return items.index(target)
    except ValueError:
        return -1

def find_item(items, target):
    if target in items:  # Fast membership check
        return items.index(target)
    return -1

def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n - 1)  # Deep recursion

factorial(10000)  # RecursionError: maximum recursion depth exceeded

def factorial(n):
    result = 1
    for i in range(2, n + 1):  # Iterative
        result *= i
    return result

# Or use tail recursion optimization (if available)
from functools import lru_cache

@lru_cache(maxsize=None)
def factorial_cached(n):
    if n <= 1:
        return 1
    return n * factorial_cached(n - 1)

from dataclasses import dataclass

@dataclass
class Point:
    x: int
    y: int

points = [Point(i, i) for i in range(1_000_000)]
# Each Point: ~240 bytes (with __dict__)
# Total: ~240 MB

@dataclass(slots=True)
class Point:
    x: int
    y: int

def add_one(x):
    return x + 1

def process(data):
    result = []
    for item in data:  # 1M iterations
        result.append(add_one(item))  # 1M function calls
    return result

def process(data):

import numpy as np
result = np.array(data) + 1  # Vectorized

import time

timestamps = [time.time() for _ in range(1_000_000)]  # Floats, not objects

def read_all_lines(filepath):
    with open(filepath) as f:
        return f.readlines()  # Loads entire file into memory

lines = read_all_lines("huge_file.txt")  # May run out of memory

def read_lines(filepath):
    with open(filepath) as f:
        yield from f  # Generator: one line at a time

for line in read_lines("huge_file.txt"):  # Memory efficient
    process(line)

def process_file(filename):
    try:
        with open(filename) as f:
            return f.read()
    except:
        pass  # Silent failure - user has no idea what went wrong
    return None

def process_file(filename):
    try:
        with open(filename) as f:
            return f.read()
    except FileNotFoundError:
        logger.error(f"File not found: {filename}")
        raise  # Re-raise or return appropriate value
    except PermissionError:
        logger.error(f"Permission denied: {filename}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error: {e}", exc_info=True)
        raise  # Don't hide unexpected errors

try:
    result = 1 / 0
except ZeroDivisionError as e:
    raise ValueError("Invalid input") from e  # Preserves chain

def find_user(users, user_id):
    try:
        return next(u for u in users if u.id == user_id)
    except StopIteration:
        return None  # Exception for control flow - slow!

def find_user(users, user_id):
    for user in users:
        if user.id == user_id:
            return user
    return None  # Normal control flow

def process_items(items):
    errors = []
    for item in items:
        try:
            process_item(item)
        except Exception as e:
            errors.append(e)
    
    if errors:
        raise ExceptionGroup("Processing failed", errors)  # Preserves all tracebacks

class Counter:
    count = 0  # Class attribute
    
    def increment(self):
        self.count += 1  # Creates instance attribute!

c1 = Counter()
c2 = Counter()

c1.increment()
print(c1.count)  # 1 (instance attribute)
print(c2.count)  # 0 (class attribute)
print(Counter.count)  # 0 (class attribute unchanged)

class Counter:
    count = 0
    
    def increment(self):
        Counter.count += 1  # Explicitly modify class attribute

class Counter:
    def __init__(self):
        self.count = 0  # Instance attribute
    
    def increment(self):
        self.count += 1

class Descriptor:
    def __get__(self, obj, objtype=None):
        return "getter called"
    
    def __set__(self, obj, value):
        print(f"setter called with {value}")

class MyClass:
    attr = Descriptor()  # Descriptor instance

obj = MyClass()
print(obj.attr)  # "getter called" - not the Descriptor object!
obj.attr = 42  # "setter called with 42"

# Descriptors are how @property works internally
class Temperature:
    def __init__(self):
        self._celsius = 0
    
    @property
    def celsius(self):
        return self._celsius
    
    @celsius.setter
    def celsius(self, value):
        self._celsius = value

temp = Temperature()
temp.celsius = 25  # Calls setter
print(temp.celsius)  # Calls getter

class A:
    def method(self):
        return "A"

class B:
    def method(self):
        return "B"

class C(A, B):
    pass

class D(B, A):
    pass

c = C()
print(c.method())  # "A" - A comes first in MRO

d = D()
print(d.method())  # "B" - B comes first in MRO

class E(A, B):
    pass

class F(B, A):
    pass

class G(E, F):  # TypeError: Cannot create consistent MRO!
    pass

print(C.__mro__)  # (<class 'C'>, <class 'A'>, <class 'B'>, <class 'object'>)
print(D.__mro__)  # (<class 'D'>, <class 'B'>, <class 'A'>, <class 'object'>)

class Base:
    def method(self):
        return "Base"

class A(Base):
    pass

class B(Base):
    pass

class C(A, B):  # OK - both inherit from Base
    pass

class Node:
    def __init__(self, value):
        self.value = value
        self.parent = None
        self.children = []
    
    def __del__(self):
        print(f"Deleting {self.value}")

# Create cycle
parent = Node("parent")
child = Node("child")
parent.children.append(child)
child.parent = parent

del parent
del child
# __del__ may not be called immediately due to cycle!

import weakref

class Node:
    def __init__(self, value):
        self.value = value
        self._parent = None
        self.children = []
    
    @property
    def parent(self):
        return self._parent() if self._parent else None
    
    @parent.setter
    def parent(self, value):
        self._parent = weakref.ref(value) if value else None

# Or break cycles explicitly
def cleanup_node(node):
    node.parent = None
    node.children.clear()

from datetime import datetime

naive = datetime(2025, 1, 1, 12, 0)  # No timezone
aware = datetime(2025, 1, 1, 12, 0, tzinfo=timezone.utc)

from datetime import datetime, timezone

result = [item.value for item in items if item.is_valid()]

def process(data):
    if data is not None:
        if data.is_valid():
            if data.has_permission():
                return data.process()
    return None

def process(data):
    if data is None:
        return None
    if not data.is_valid():
        return None
    if not data.has_permission():
        return None
    return data.process()

def get_status_message(status):
    if status == "pending":
        return "Waiting for approval"
    elif status == "approved":
        return "Request approved"
    elif status == "rejected":
        return "Request rejected"
    else:
        return "Unknown status"

def get_status_message(status):
    match status:
        case "pending":
            return "Waiting for approval"
        case "approved":
            return "Request approved"
        case "rejected":
            return "Request rejected"
        case _:
            return "Unknown status"

x = "global"

def outer():
    x = "enclosing"
    
    def inner():
        x = "local"
        print(x)  # Output: "local" (L found first)
    
    inner()

outer()

flowchart TD
    Start[import mymodule] --> Step1[STEP 1: Check sys.modules cache<br/>if 'mymodule' in sys.modules:<br/>    return sys.modules['mymodule']  # Already loaded]
    
    Step1 -->|not found| Step2[STEP 2: Iterate sys.meta_path finders]
    
    Step2 --> Finder1[1. BuiltinImporter<br/>Checks built-in modules<br/>Examples: sys, builtins]
    
    Finder1 -->|not found| Finder2[2. FrozenImporter<br/>Checks frozen modules<br/>Examples: _frozen_importlib]
    
    Finder2 -->|not found| Finder3[3. PathFinder<br/>Searches sys.path<br/>Uses SourceFileLoader, etc.]
    
    Finder3 -->|finder returns ModuleSpec| Step3[STEP 3: Create ModuleSpec<br/>spec = ModuleSpec(<br/>    name='mymodule',<br/>    loader=SourceFileLoader...,<br/>    origin='/path/to/mymodule.py',<br/>    submodule_search_locations=None<br/>)]
    
    Step3 --> Step4[STEP 4: Loader.exec_module spec]
    
    Step4 --> Loader1[SourceFileLoader:<br/>1. Read .py file<br/>2. Compile to bytecode<br/>3. Execute bytecode<br/>4. Create module object]
    
    Step4 --> Loader2[ExtensionFileLoader:<br/>1. Load .so/.pyd file<br/>2. Initialize module]
    
    Step4 --> Loader3[NamespaceLoader:<br/>1. Create namespace package<br/>2. Set __path__]
    
    Loader1 --> Step5[STEP 5: Store in sys.modules<br/>sys.modules['mymodule'] = module_object]
    Loader2 --> Step5
    Loader3 --> Step5
    
    Step5 --> Step6[STEP 6: Module code executed<br/>Top-level code runs<br/>Functions/classes defined<br/>Module-level variables assigned]
    
    Step6 --> Return[Return module object]
    
    Step1 -->|found| Return
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style Step3 fill:#fff4e1
    style Step4 fill:#ffe1e1
    style Step5 fill:#e1f5ff
    style Step6 fill:#ffe1f5
    style Return fill:#e1ffe1

import sys

class RegularPoint:
    def __init__(self, x, y):
        self.x = x
        self.y = y

class SlottedPoint:
    __slots__ = ("x", "y")
    
    def __init__(self, x, y):
        self.x = x
        self.y = y

# Create 1 million instances
regular_points = [RegularPoint(i, i) for i in range(1_000_000)]
slotted_points = [SlottedPoint(i, i) for i in range(1_000_000)]

# Memory usage (approximate)
regular_size = sys.getsizeof(regular_points[0]) * 1_000_000
slotted_size = sys.getsizeof(slotted_points[0]) * 1_000_000

print(f"Regular: ~{regular_size / 1024 / 1024:.1f} MB")
print(f"Slotted: ~{slotted_size / 1024 / 1024:.1f} MB")
print(f"Savings: ~{(1 - slotted_size/regular_size) * 100:.1f}%")

# Typical Results:
# Regular: ~240.0 MB
# Slotted: ~56.0 MB
# Savings: ~76.7%

# Application configuration with precedence
import os
from collections import ChainMap

# Default configuration
defaults = {
    "database_url": "sqlite:///app.db",
    "log_level": "INFO",
    "max_connections": 10,
}

# File-based configuration (loaded from config file)
file_config = {
    "log_level": "DEBUG",
    "max_connections": 20,
}

# Environment variable overrides
env_config = {
    key.replace("APP_", "").lower(): value
    for key, value in os.environ.items()
    if key.startswith("APP_")
}

# Final configuration (env > file > defaults)
config = ChainMap(env_config, file_config, defaults)

import tracemalloc

# Start tracing
tracemalloc.start()

# Run your workload
data = [i**2 for i in range(100_000)]
result = sum(data)

# Get current memory usage
current, peak = tracemalloc.get_traced_memory()
print(f"Current: {current / 1024 / 1024:.2f} MB")
print(f"Peak: {peak / 1024 / 1024:.2f} MB")

# Stop tracing
tracemalloc.stop()

import tracemalloc
import sys

def process_data():
    """Simulate memory-intensive operation."""
    # Allocate large list
    data = [list(range(1000)) for _ in range(1000)]
    
    # Process data
    result = sum(len(item) for item in data)
    
    return result

# Start tracing
tracemalloc.start()

# Run workload
result = process_data()

# Get snapshot
snapshot = tracemalloc.take_snapshot()

# Get top 10 memory allocations
top_stats = snapshot.statistics('lineno')

print("Top 10 memory allocations:")
for index, stat in enumerate(top_stats[:10], 1):
    print(f"{index}. {stat}")

# Get traceback for specific allocation
print("\nTraceback for largest allocation:")
top_stat = top_stats[0]
for line in top_stat.traceback.format():
    print(line)

# Stop tracing
tracemalloc.stop()

import time
import numpy as np
from typing import Callable

def benchmark(func: Callable, *args, iterations: int = 5) -> float:
    """Run function multiple times and return average time."""
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        func(*args)
        times.append(time.perf_counter() - start)
    return sum(times) / len(times)

# Test functions
def python_loop(n: int):
    return [i * 2 for i in range(n)]

def numpy_vectorized(n: int):
    return (np.arange(n) * 2).tolist()

def numpy_inplace(n: int):
    arr = np.arange(n, dtype=np.float64)
    arr *= 2
    return arr

# Benchmark different sizes
sizes = [1_000, 10_000, 100_000, 1_000_000, 10_000_000]

print("Array Size | Python Loop | NumPy (tolist) | NumPy (inplace) | Speedup")
print("-" * 75)

for n in sizes:
    py_time = benchmark(python_loop, n)
    np_time = benchmark(numpy_vectorized, n)
    np_inplace_time = benchmark(numpy_inplace, n)
    
    speedup = py_time / np_inplace_time
    
    print(f"{n:>10,} | {py_time:>10.4f}s | {np_time:>13.4f}s | "
          f"{np_inplace_time:>15.4f}s | {speedup:>6.1f}√ó")

# Typical Results (Python 3.12, NumPy 1.26):
# Array Size | Python Loop | NumPy (tolist) | NumPy (inplace) | Speedup
# ---------------------------------------------------------------------------
#      1,000 |     0.0001s |         0.0002s |         0.0000s |    2.5√ó
#     10,000 |     0.0012s |         0.0003s |         0.0000s |   12.0√ó
#    100,000 |     0.0125s |         0.0021s |         0.0001s |  125.0√ó
#  1,000,000 |     0.1250s |         0.0180s |         0.0008s |  156.3√ó
# 10,000,000 |     1.2500s |         0.1800s |         0.0080s |  156.3√ó

from multiprocessing import Pool
from concurrent.futures import ProcessPoolExecutor
import time

def cpu_task(n: int) -> int:
    """CPU-intensive task."""
    return sum(i * i for i in range(n))

# Single process
start = time.perf_counter()
results = [cpu_task(1_000_000) for _ in range(8)]
single_time = time.perf_counter() - start

# Multiprocessing (4 cores)
start = time.perf_counter()
with ProcessPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(cpu_task, [1_000_000] * 8))
multi_time = time.perf_counter() - start

print(f"Single process: {single_time:.2f}s")
print(f"4 processes:    {multi_time:.2f}s")
print(f"Speedup:        {single_time/multi_time:.2f}√ó")

# Typical Results (4-core CPU):
# Single process: 8.00s
# 4 processes:    2.50s (3.2√ó speedup, not 4√ó due to overhead)

from concurrent.futures import ProcessPoolExecutor, as_completed
import time

def expensive_computation(n: int) -> int:
    """CPU-intensive computation."""
    result = sum(i * i for i in range(n))
    return result

if __name__ == "__main__":
    data = [1000000, 2000000, 3000000, 4000000, 5000000]
    
    # Process pool with automatic cleanup
    with ProcessPoolExecutor(max_workers=4) as executor:
        # Submit tasks
        futures = [executor.submit(expensive_computation, n) for n in data]
        
        # Get results as they complete
        for future in as_completed(futures):
            result = future.result()
            print(f"Result: {result}")

from multiprocessing import Process, Value, Array
import time

def increment_counter(counter: Value, lock):
    """Increment shared counter."""
    for _ in range(100000):
        with lock:
            counter.value += 1

if __name__ == "__main__":
    # Shared integer (Value)
    counter = Value('i', 0)  # 'i' = integer type
    lock = multiprocessing.Lock()
    
    # Create processes
    processes = [
        Process(target=increment_counter, args=(counter, lock))
        for _ in range(4)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print(f"Final counter value: {counter.value}")  # Should be 400000

from multiprocessing import Process, Array, Lock
import math

def compute_row(arr: Array, row: int, cols: int, lock: Lock):
    """Compute values for one row."""
    for col in range(cols):
        index = row * cols + col
        with lock:
            arr[index] = math.sin(row) * math.cos(col)

if __name__ == "__main__":
    rows, cols = 1000, 1000
    shared_matrix = Array('d', [0.0] * (rows * cols))
    lock = Lock()
    
    # Process each row in parallel
    processes = [
        Process(target=compute_row, args=(shared_matrix, r, cols, lock))
        for r in range(rows)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    # Access results
    result = [shared_matrix[i] for i in range(rows * cols)]
    print(f"Computed {len(result)} values")

from multiprocessing import Manager, Process
import time

def worker(task_queue: 'Queue', result_dict: dict, worker_id: int):
    """Worker process."""
    while True:
        task = task_queue.get()
        if task is None:  # Sentinel
            break
        
        # Process task
        result = task * 2
        result_dict[task] = result
        print(f"Worker {worker_id} processed task {task}")

if __name__ == "__main__":
    manager = Manager()
    task_queue = manager.Queue()
    result_dict = manager.dict()
    
    # Add tasks
    for i in range(20):
        task_queue.put(i)
    
    # Add sentinels
    num_workers = 4
    for _ in range(num_workers):
        task_queue.put(None)
    
    # Start workers
    workers = [
        Process(target=worker, args=(task_queue, result_dict, i))
        for i in range(num_workers)
    ]
    
    for w in workers:
        w.start()
    for w in workers:
        w.join()
    
    print(f"Results: {dict(result_dict)}")

# ‚ùå BAD: Large objects passed to processes
large_data = [list(range(10000)) for _ in range(1000)]

def process(data):
    return sum(sum(row) for row in data)

# Each process receives full copy ‚Üí huge memory usage
with ProcessPoolExecutor() as executor:
    results = executor.map(process, [large_data] * 10)

# ‚úÖ BETTER: Pass indices or file paths
def process_by_index(start_idx, end_idx):
    # Load data in process
    data = load_data_slice(start_idx, end_idx)
    return process(data)

from typing import List, Dict, Any, Callable
from dataclasses import dataclass
from enum import Enum
import json

class AgentRole(Enum):
    ARCHITECT = "architect"
    REVIEWER = "reviewer"
    TESTER = "tester"
    REFACTORER = "refactorer"
    SECURITY = "security"
    DOCS = "documentation"

@dataclass
class AgentMessage:
    role: AgentRole
    content: str
    metadata: Dict[str, Any]

class BaseAgent:
    """Base class for all agents."""
    
    def __init__(self, role: AgentRole, llm_client, tools: List[Callable]):
        self.role = role
        self.llm_client = llm_client
        self.tools = {tool.__name__: tool for tool in tools}
        self.memory: List[AgentMessage] = []
    
    def execute(self, task: str, context: Dict[str, Any]) -> AgentMessage:
        """Execute agent task and return message."""
        # Agent-specific logic here
        result = self._process(task, context)
        message = AgentMessage(
            role=self.role,
            content=result,
            metadata=context
        )
        self.memory.append(message)
        return message
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        """Override in subclasses."""
        raise NotImplementedError

class ArchitectAgent(BaseAgent):
    """Proposes system design and architecture."""
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        prompt = f"""
        As an architect agent, analyze the following task and propose a design:
        
        Task: {task}
        Context: {json.dumps(context, indent=2)}
        
        Provide:
        1. Architecture proposal
        2. Component breakdown
        3. Dependencies
        4. File structure
        """
        # In real implementation, call LLM
        return f"Architecture proposal for: {task}"

class ReviewerAgent(BaseAgent):
    """Reviews code for patterns and compliance."""
    
    def __init__(self, *args, rules: List[str], **kwargs):
        super().__init__(*args, **kwargs)
        self.rules = rules
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        code = context.get("code", "")
        violations = []
        
        # Check against rules
        for rule in self.rules:
            if self._violates_rule(code, rule):
                violations.append(rule)
        
        if violations:
            return f"Review failed. Violations: {violations}"
        return "Review passed. Code complies with patterns."

    def _violates_rule(self, code: str, rule: str) -> bool:
        """Check if code violates rule."""
        # Simplified - real implementation would use AST analysis
        return False

class TesterAgent(BaseAgent):
    """Generates tests for code."""
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        code = context.get("code", "")
        test_code = f"""
# Generated tests for: {task}
import pytest

def test_basic_functionality():
    # Test implementation
    pass

def test_edge_cases():
    # Edge case tests
    pass
"""
        return test_code

class SecurityAgent(BaseAgent):
    """Checks for security anti-patterns."""
    
    SECURITY_PATTERNS = [
        "subprocess.run",
        "eval(",
        "exec(",
        "pickle.loads",
        "yaml.load(",
    ]
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        code = context.get("code", "")
        issues = []
        
        for pattern in self.SECURITY_PATTERNS:
            if pattern in code:
                issues.append(f"Security risk: {pattern}")
        
        if issues:
            return f"Security issues found: {issues}"
        return "Security check passed."

class MultiAgentOrchestrator:
    """Coordinates multiple agents."""
    
    def __init__(self, agents: List[BaseAgent]):
        self.agents = {agent.role: agent for agent in agents}
        self.shared_memory: List[AgentMessage] = []
    
    def execute_workflow(self, task: str) -> Dict[AgentRole, str]:
        """Execute multi-agent workflow."""
        results = {}
        
        # Step 1: Architect proposes design
        arch_result = self.agents[AgentRole.ARCHITECT].execute(
            task, {"phase": "design"}
        )
        results[AgentRole.ARCHITECT] = arch_result.content
        self.shared_memory.append(arch_result)
        
        # Step 2: Generate code (simplified)
        code = self._generate_code(task, arch_result.content)
        
        # Step 3: Reviewer checks patterns
        review_result = self.agents[AgentRole.REVIEWER].execute(
            "Review code", {"code": code, "task": task}
        )
        results[AgentRole.REVIEWER] = review_result.content
        
        # Step 4: Security check
        security_result = self.agents[AgentRole.SECURITY].execute(
            "Security audit", {"code": code}
        )
        results[AgentRole.SECURITY] = security_result.content
        
        # Step 5: Tester generates tests
        test_result = self.agents[AgentRole.TESTER].execute(
            "Generate tests", {"code": code, "task": task}
        )
        results[AgentRole.TESTER] = test_result.content
        
        # Step 6: Refactor if needed
        if "failed" in review_result.content.lower():
            refactor_result = self.agents[AgentRole.REFACTORER].execute(
                "Refactor code", {"code": code, "issues": review_result.content}
            )
            results[AgentRole.REFACTORER] = refactor_result.content
        
        return results
    
    def _generate_code(self, task: str, design: str) -> str:
        """Generate code based on design (simplified)."""
        return f"# Generated code for: {task}\n# Design: {design}"

# Usage
orchestrator = MultiAgentOrchestrator([
    ArchitectAgent(AgentRole.ARCHITECT, llm_client=None, tools=[]),
    ReviewerAgent(AgentRole.REVIEWER, llm_client=None, tools=[], 
                  rules=["no_global_state", "type_hints_required"]),
    TesterAgent(AgentRole.TESTER, llm_client=None, tools=[]),
    SecurityAgent(AgentRole.SECURITY, llm_client=None, tools=[]),
])

results = orchestrator.execute_workflow("Create user authentication system")
for role, result in results.items():
    print(f"{role.value}: {result}")

from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import json
import sqlite3
from pathlib import Path

@dataclass
class ToolResult:
    success: bool
    result: Any
    error: Optional[str] = None

class PythonToolAgent:
    """Agent with real Python tools for file I/O, DB access, etc."""
    
    def __init__(self, llm_client, db_path: str = "agent.db"):
        self.llm_client = llm_client
        self.db_path = db_path
        self.tools = {
            "read_file": self._read_file,
            "write_file": self._write_file,
            "list_directory": self._list_directory,
            "query_database": self._query_database,
            "execute_sql": self._execute_sql,
            "search_files": self._search_files,
            "run_command": self._run_command_safe,
        }
    
    def _read_file(self, path: str) -> ToolResult:
        """Read file content safely."""
        try:
            file_path = Path(path)
            if not file_path.exists():
                return ToolResult(False, None, f"File not found: {path}")
            if not file_path.is_file():
                return ToolResult(False, None, f"Not a file: {path}")
            # Security: prevent reading outside allowed directories
            if not str(file_path.resolve()).startswith(str(Path.cwd().resolve())):
                return ToolResult(False, None, "Path traversal not allowed")
            
            content = file_path.read_text(encoding='utf-8')
            return ToolResult(True, content)
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _write_file(self, path: str, content: str, mode: str = "w") -> ToolResult:
        """Write file content safely."""
        try:
            file_path = Path(path)
            # Security: prevent writing outside allowed directories
            if not str(file_path.resolve()).startswith(str(Path.cwd().resolve())):
                return ToolResult(False, None, "Path traversal not allowed")
            
            file_path.parent.mkdir(parents=True, exist_ok=True)
            file_path.write_text(content, encoding='utf-8')
            return ToolResult(True, f"Written {len(content)} bytes to {path}")
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _list_directory(self, path: str = ".") -> ToolResult:
        """List directory contents."""
        try:
            dir_path = Path(path)
            if not dir_path.exists():
                return ToolResult(False, None, f"Directory not found: {path}")
            if not dir_path.is_dir():
                return ToolResult(False, None, f"Not a directory: {path}")
            
            items = {
                "files": [str(p) for p in dir_path.iterdir() if p.is_file()],
                "directories": [str(p) for p in dir_path.iterdir() if p.is_dir()],
            }
            return ToolResult(True, items)
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _query_database(self, query: str, params: Dict[str, Any] = None) -> ToolResult:
        """Execute SELECT query safely."""
        try:
            if not query.strip().upper().startswith("SELECT"):
                return ToolResult(False, None, "Only SELECT queries allowed")
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            results = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description] if cursor.description else []
            
            conn.close()
            
            return ToolResult(True, {
                "columns": columns,
                "rows": results,
                "count": len(results)
            })
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _execute_sql(self, query: str, params: Dict[str, Any] = None) -> ToolResult:
        """Execute write SQL (with approval)."""
        # In production, require approval for write operations
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            conn.commit()
            affected = cursor.rowcount
            conn.close()
            
            return ToolResult(True, f"Query executed. Rows affected: {affected}")
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _search_files(self, pattern: str, directory: str = ".") -> ToolResult:
        """Search for files matching pattern."""
        try:
            dir_path = Path(directory)
            matches = list(dir_path.rglob(pattern))
            return ToolResult(True, [str(m) for m in matches])
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _run_command_safe(self, command: str) -> ToolResult:
        """Run command with restrictions."""
        # Whitelist of allowed commands
        ALLOWED_COMMANDS = ["ls", "pwd", "cat", "grep"]
        
        parts = command.split()
        if not parts or parts[0] not in ALLOWED_COMMANDS:
            return ToolResult(False, None, f"Command not allowed: {parts[0] if parts else 'empty'}")
        
        import subprocess
        try:
            result = subprocess.run(
                command.split(),
                capture_output=True,
                text=True,
                timeout=5,
                cwd=Path.cwd()
            )
            return ToolResult(
                True,
                {
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode
                }
            )
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def execute_with_tools(self, task: str) -> str:
        """Execute task using available tools."""
        # In real implementation, use LLM to decide which tools to call
        # This is a simplified version
        
        # Example: "Read config.json and update the database"
        if "read" in task.lower() and "file" in task.lower():
            # Extract file path (simplified)
            file_path = "config.json"  # In real implementation, extract from task
            result = self._read_file(file_path)
            if result.success:
                return f"File content: {result.result[:100]}..."
            else:
                return f"Error: {result.error}"
        
        return "Task completed"

# Usage
agent = PythonToolAgent(llm_client=None, db_path="app.db")
result = agent.execute_with_tools("Read config.json and show database schema")

from functools import lru_cache
from typing import List, Dict, Any
import hashlib
import json
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class CacheEntry:
    result: str
    timestamp: datetime
    cost: float
    tokens_used: int

class CostOptimizedAgent:
    """Agent optimized for cost and latency."""
    
    def __init__(self, llm_client, cache_ttl: timedelta = timedelta(hours=24)):
        self.llm_client = llm_client
        self.cache: Dict[str, CacheEntry] = {}
        self.cache_ttl = cache_ttl
        self.total_cost = 0.0
        self.total_tokens = 0
    
    def _cache_key(self, task: str, context: Dict[str, Any] = None) -> str:
        """Generate cache key from task and context."""
        key_data = {"task": task, "context": context or {}}
        key_str = json.dumps(key_data, sort_keys=True)
        return hashlib.sha256(key_str.encode()).hexdigest()
    
    def execute_cached(self, task: str, context: Dict[str, Any] = None) -> str:
        """Execute with caching."""
        cache_key = self._cache_key(task, context)
        
        # Check cache
        if cache_key in self.cache:
            entry = self.cache[cache_key]
            if datetime.now() - entry.timestamp < self.cache_ttl:
                logging.info(f"Cache hit for: {task[:50]}")
                return entry.result
        
        # Cache miss - call LLM
        result, cost, tokens = self._call_llm_with_metrics(task)
        
        # Store in cache
        self.cache[cache_key] = CacheEntry(
            result=result,
            timestamp=datetime.now(),
            cost=cost,
            tokens_used=tokens
        )
        
        self.total_cost += cost
        self.total_tokens += tokens
        
        return result
    
    def batch_execute(self, tasks: List[str]) -> List[str]:
        """Execute multiple tasks in a single LLM call."""
        # Combine tasks into single prompt
        combined_prompt = "\n\n".join([
            f"Task {i+1}: {task}" for i, task in enumerate(tasks)
        ])
        
        # Single LLM call
        result, cost, tokens = self._call_llm_with_metrics(combined_prompt)
        
        # Parse results (simplified - real implementation needs structured parsing)
        results = result.split("\n\n")
        
        # Cost per task
        cost_per_task = cost / len(tasks)
        tokens_per_task = tokens / len(tasks)
        
        logging.info(f"Batch execution: {len(tasks)} tasks, "
                    f"{cost:.4f} total cost ({cost_per_task:.4f} per task)")
        
        return results
    
    def _call_llm_with_metrics(self, prompt: str) -> tuple[str, float, int]:
        """Call LLM and track metrics."""
        # In real implementation:
        # - Call actual LLM
        # - Extract token usage from response
        # - Calculate cost based on model pricing
        
        # Simplified metrics
        tokens = len(prompt.split()) * 1.3  # Rough estimate
        cost = tokens * 0.000002  # Example: $0.002 per 1K tokens
        
        result = f"Response to: {prompt[:50]}"
        return result, cost, int(tokens)
    
    def get_cost_summary(self) -> Dict[str, Any]:
        """Get cost and usage summary."""
        return {
            "total_cost": self.total_cost,
            "total_tokens": self.total_tokens,
            "cache_size": len(self.cache),
            "cache_hit_rate": self._calculate_cache_hit_rate(),
        }
    
    def _calculate_cache_hit_rate(self) -> float:
        """Calculate cache hit rate (simplified)."""
        # In real implementation, track hits/misses
        return 0.0

# Usage
agent = CostOptimizedAgent(llm_client=None)

# Single execution (cached)
result1 = agent.execute_cached("Analyze code quality")

# Batch execution (cost-efficient)
tasks = [
    "Review function A",
    "Review function B",
    "Review function C",
]
results = agent.batch_execute(tasks)

# Cost summary
summary = agent.get_cost_summary()
print(f"Total cost: ${summary['total_cost']:.4f}")
print(f"Total tokens: {summary['total_tokens']:,}")

# Variables
x = 10
name: str = "Python"  # Type annotation

# Functions
def greet(name: str) -> str:
    return f"Hello, {name}!"

# Classes
class User:
    def __init__(self, name: str):
        self.name = name

# Conditionals
if condition:
    do_something()
elif other_condition:
    do_other()
else:
    do_default()

# Loops
for item in items:
    process(item)

while condition:
    do_work()

# Comprehensions
[x**2 for x in range(10)]  # List
{x: x**2 for x in range(10)}  # Dict
{x**2 for x in range(10)}  # Set
(x**2 for x in range(10))  # Generator

# Exception Handling
try:
    risky_operation()
except SpecificError as e:
    handle_error(e)
except Exception as e:
    handle_generic(e)
else:
    no_exception()
finally:
    always_run()

def find_item(items, target):
    if target in items:  # Fast membership check
        return items.index(target)
    return -1

# Or use dict for O(1) lookup
item_dict = {item: idx for idx, item in enumerate(large_list)}
idx = item_dict.get(target, -1)

# Use tuples for simple data
points = [(i, i) for i in range(1_000_000)]
# Each tuple: ~48 bytes
# Total: ~48 MB (5√ó savings)

# Or use __slots__ if you need a class
@dataclass(slots=True)
class Point:
    x: int
    y: int
# Each Point: ~56 bytes (4√ó savings vs regular dataclass)

def process(data):
    # Inline operation or use list comprehension (faster)
    return [x + 1 for x in data]  # No function call overhead

# Or use NumPy for large arrays
import numpy as np
result = np.array(data) + 1  # Vectorized

# Batch creation or use simpler types
import time

timestamps = [time.time() for _ in range(1_000_000)]  # Floats, not objects
# Or create once and reuse if possible
now = datetime.now()
timestamps = [now] * 1_000_000

# Option 1: Iterate over copy
for item in items[:]:  # Slice creates copy
    if item % 2 == 0:
        items.remove(item)

# Option 2: Build new list
items = [item for item in items if item % 2 != 0]

# Option 3: Iterate backwards
for i in range(len(items) - 1, -1, -1):
    if items[i] % 2 == 0:
        del items[i]

This pattern is industry-standard.

20.13 Enterprise Design Patterns for Async Web Apps
20.13.1 Pattern: API Layer ‚Üí Service Layer ‚Üí Repo Layer
[API] ‚Üí [Service] ‚Üí [Repository] ‚Üí [DB]

20.13.2 Pattern: Request-Scoped DB Sessions

20.13.3 Pattern: Message-Driven Integrations

22.8 Deployment Patterns
22.8.1 Pattern: Single-Container Microservice
Client ‚Üí Load Balancer ‚Üí API Container ‚Üí DB

22.8.2 Pattern: Multi-Container Application

22.8.3 Pattern: Serverless Deployment

> **Quick Answer:**  
> - A docstring is a string literal placed as the first statement in a module, class, or function.  
> - It defines the public contract of your API and is consumed by IDEs, Sphinx, inspect(), doctest, and LLM/RAG systems.  
>
> **Example ‚Äî Correct Pattern:**  
> ```python
> # ‚úÖ Correct docstring pattern
> def add(x: int, y: int) -> int:
>     """Add two integers and return their sum."""
>     return x + y
> ```  
>
> **Estimated time:** 2‚Äì3 hours  
> **When you need this:** Any time you define a public API, library, or maintain internal tooling.

29.4.2 ‚Äî Pattern-Based Cleanup Pass

ReAct (Reasoning + Acting) is a powerful pattern for tool-using agents:

‚ùå **Anti-Pattern: Global State Mutation**

‚ùå **Anti-Pattern: Over-Complicated Factory**

‚ùå **Anti-Pattern: Global Dependencies**

OOP design pattern that converts one interface into another.

Pattern for passing dependencies explicitly.

A design pattern that provides a simplified interface to a complex subsystem.

Pattern to prevent code from executing on import.

Behavioral pattern: subject broadcasts changes to observers.

Pattern to safely access attributes:

This appendix provides decision matrices to help you choose the right tool, approach, or pattern for your specific use case.


### Common Pitfalls & Anti-Patterns

#### [MEDIUM] üéØ "I want to write production Python in 2 weeks" 1.

**üéØ "I want to write production Python in 2 weeks"** 1. Chapter 1 (Introduction) ‚Üí 2 hours 2. Chapter 2 (Syntax) ‚Üí 4 hours 3. Chapter 6 (Functions) ‚Üí 3 hours 4. Chapter 10 (Error Handling) ‚Üí 2 hours 5. Appendix E (Pitfalls) ‚Üí 2 hours 6. Chapter 14 (Testing) ‚Üí 3 hours **Total: ~16 hours**

#### [MEDIUM] üéØ "I'm optimizing Python performance" 1.

**üéØ "I'm optimizing Python performance"** 1. Chapter 3 (Execution Model) ‚Üí 3 hours 2. Chapter 12 (Performance Engineering) ‚Üí 5 hours 3. Chapter 17 (Concurrency) ‚Üí 4 hours 4. Appendix E, Section D.9 (GIL Traps) ‚Üí 1 hour **Total: ~13 hours**

#### [MEDIUM] 1.9 Common Beginner Pitfalls (Preview).

1.9 Common Beginner Pitfalls (Preview)

#### [MEDIUM] Subtle pitfalls around mutability, aliasing, copying.

Subtle pitfalls around mutability, aliasing, copying

#### [MEDIUM] 2.17 Pitfalls & Warnings.

2.17 Pitfalls & Warnings

#### [MEDIUM] 3.18 Pitfalls & Warnings.

3.18 Pitfalls & Warnings

#### [MEDIUM] 4.3.3 Mutability Table Type Mutable? int ‚ùå float ‚ùå str ‚ùå tuple ‚ùå (but may contain mutable values) bytes ‚ùå bool ‚ùå list ‚úîÔ∏è dict ‚úîÔ∏è set ‚úîÔ∏è bytearray ‚úî...

4.3.3 Mutability Table Type Mutable? int ‚ùå float ‚ùå str ‚ùå tuple ‚ùå (but may contain mutable values) bytes ‚ùå bool ‚ùå list ‚úîÔ∏è dict ‚úîÔ∏è set ‚úîÔ∏è bytearray ‚úîÔ∏è custom classes (default) ‚úîÔ∏è ‚ö† Pitfall: Mutable Defaults def f(x=[]): # bad x.append(1) return x

#### [MEDIUM] 4.12 Type System Pitfalls.

4.12 Type System Pitfalls

#### [MEDIUM] 5.9 Pitfalls & Warnings.

5.9 Pitfalls & Warnings

#### [MEDIUM] Add(1, 2) # OK add(a=1, b=2) # ‚ùå.

add(1, 2) # OK add(a=1, b=2) # ‚ùå

#### [MEDIUM] 6.16 Pitfalls & Warnings.

6.16 Pitfalls & Warnings

#### [MEDIUM] ‚ùå Avoid when: - Need dynamic attributes - Using multiple inheritance with classes that don't have slots - Need weak references (unless __weakref__ ...

‚ùå **Avoid when:** - Need dynamic attributes - Using multiple inheritance with classes that don't have slots - Need weak references (unless `__weakref__` in slots`) - Prototyping or frequently changing attribute set

#### [MEDIUM] 7.17 Pitfalls & Warnings.

7.17 Pitfalls & Warnings

#### [MEDIUM] 8.14 Pitfalls & Warnings.

8.14 Pitfalls & Warnings

#### [MEDIUM] 9.13 Pitfalls & Warnings.

9.13 Pitfalls & Warnings

#### [MEDIUM] Exception Appropriate When ValueError wrong value given TypeError wrong argument type KeyError missing dict key IndexError index out of range ZeroD...

Exception Appropriate When ValueError wrong value given TypeError wrong argument type KeyError missing dict key IndexError index out of range ZeroDivisionError division by zero RuntimeError unspecified runtime failure FileNotFoundError missing file PermissionError filesystem access denied TimeoutError timeout exceeded AssertionError debugging checks (not for business logic) 10.6 Custom Exceptions

#### [MEDIUM] 10.10 Error Handling Anti-Patterns.

10.10 Error Handling Anti-Patterns

#### [MEDIUM] 10.17 Pitfalls & Warnings.

10.17 Pitfalls & Warnings

#### [MEDIUM] 11.17 Pitfalls & Warnings.

11.17 Pitfalls & Warnings

#### [MEDIUM] 12.16 Pitfalls & Warnings.

12.16 Pitfalls & Warnings

#### [MEDIUM] 13.4.2 dotenv pitfalls.

13.4.2 dotenv pitfalls

#### [MEDIUM] ‚ùå pickle ‚ùå shelve ‚ùå marshal ‚ùå PyYAML load().

‚ùå pickle ‚ùå shelve ‚ùå marshal ‚ùå PyYAML load()

#### [MEDIUM] 13.12 Secure API Design 1.

13.12 Secure API Design 1. Input validation (pydantic) 2. Authentication (JWT, OAuth2) 3. Authorization (RBAC, ABAC) 4. Rate limiting 5. Logging & auditing 6. Safe error messages (no stack traces) 7. CORS limits 8. HTTPS only 13.13 Secure Web Development Anti-Patterns

#### [MEDIUM] ‚ùå manual SQL queries ‚ùå storing plaintext passwords ‚ùå trusting user-supplied IDs ‚ùå rendering raw HTML ‚ùå returning internal error messages ‚ùå disablin...

‚ùå manual SQL queries ‚ùå storing plaintext passwords ‚ùå trusting user-supplied IDs ‚ùå rendering raw HTML ‚ùå returning internal error messages ‚ùå disabling SSL verification ‚ùå using "pickle" for sessions

#### [MEDIUM] 13.16 Pitfalls & Warnings.

13.16 Pitfalls & Warnings

#### [MEDIUM] 14.17 Pitfalls & Warnings.

14.17 Pitfalls & Warnings

#### [MEDIUM] 16.6 Dockerization for Python Applications 16.6.1 Base Python Image Pitfalls.

16.6 Dockerization for Python Applications 16.6.1 Base Python Image Pitfalls

#### [MEDIUM] ‚ùå python:latest ‚ùå python:3.12-slim with no pinned version.

‚ùå python:latest ‚ùå python:3.12-slim with no pinned version

#### [MEDIUM] 16.13 Pitfalls & Warnings.

16.13 Pitfalls & Warnings

#### [MEDIUM] 17.6.5 Multiprocessing Pitfalls: Common Mistakes.

17.6.5 Multiprocessing Pitfalls: Common Mistakes

#### [MEDIUM] Try This: Avoid common pitfalls:.

**Try This:** Avoid common pitfalls:

#### [MEDIUM] 17.16 Pitfalls & Warnings.

17.16 Pitfalls & Warnings

#### [MEDIUM] 18.2.3 Metaclass Anti-Patterns.

18.2.3 Metaclass Anti-Patterns

#### [MEDIUM] 18.15 Pitfalls & Warnings.

18.15 Pitfalls & Warnings

#### [MEDIUM] Cur.execute(f"SELECT * FROM users WHERE id={user_id}") # ‚ùå SQL injection.

cur.execute(f"SELECT * FROM users WHERE id={user_id}") # ‚ùå SQL injection

#### [MEDIUM] 20.16 Pitfalls & Warnings.

20.16 Pitfalls & Warnings

#### [MEDIUM] C = Consumer({"bootstrap.servers": "localhost"}) c.subscribe(["events"]) msg = c.poll(1.0).

c = Consumer({"bootstrap.servers": "localhost"}) c.subscribe(["events"]) msg = c.poll(1.0)

#### [MEDIUM] 21.16 Pitfalls & Warnings.

21.16 Pitfalls & Warnings

#### [MEDIUM] C = Consumer({ "bootstrap.servers": "localhost", "group.id": "mygroup", }) c.subscribe(["events"]).

c = Consumer({ "bootstrap.servers": "localhost", "group.id": "mygroup", }) c.subscribe(["events"])

#### [MEDIUM] Avoid anti-patterns like long-running sync tasks in APIs.

Avoid anti-patterns like long-running sync tasks in APIs

#### [MEDIUM] How docstrings work at the compiler and runtime level - The differences between Google, NumPy, and Sphinx/RST styles - How to document modules, cla...

- How docstrings work at the compiler and runtime level - The differences between Google, NumPy, and Sphinx/RST styles - How to document modules, classes, functions, async functions, and generators - Enterprise-level governance for docstring quality and CI enforcement - Pitfalls, anti-patterns, war stories, and best practices

#### [MEDIUM] # 30.4 Pitfalls & Warnings.

# **30.4 Pitfalls & Warnings**

#### [MEDIUM] ## 30.4.1 Anti-Patterns.

## **30.4.1 Anti-Patterns**

#### [MEDIUM] ‚ùå Do not write vague docstrings:.

‚ùå **Do not write vague docstrings:**

#### [MEDIUM] ‚ùå Do not restate the function name:.

‚ùå **Do not restate the function name:**

#### [MEDIUM] ‚ùå Do not omit exceptions:.

‚ùå **Do not omit exceptions:**

#### [MEDIUM] ‚ùå Do not include implementation details:.

‚ùå **Do not include implementation details:**

#### [MEDIUM] ‚ùå API keys, tokens, or credentials - ‚ùå Internal server names or infrastructure details - ‚ùå Security algorithms or salt values - ‚ùå Database schemas ...

- ‚ùå API keys, tokens, or credentials - ‚ùå Internal server names or infrastructure details - ‚ùå Security algorithms or salt values - ‚ùå Database schemas with security implications

#### [MEDIUM] ## 30.4.4 Common Pitfalls.

## **30.4.4 Common Pitfalls**

#### [MEDIUM] 26.15 Deployment Anti-Patterns.

26.15 Deployment Anti-Patterns

#### [MEDIUM] Avoid anti-patterns early.

avoid anti-patterns early

#### [MEDIUM] ‚ùå Python 2.7 only (Python 2 EOL was 2020) ‚ùå No Python 3 support (experimental only) ‚ùå Minimal active development ‚ùå Declining community.

‚ùå **Python 2.7 only** (Python 2 EOL was 2020) ‚ùå **No Python 3 support** (experimental only) ‚ùå Minimal active development ‚ùå Declining community

#### [MEDIUM] ‚ùå Python 3 support is experimental (not production-ready) ‚ùå Smaller ecosystem than CPython ‚ùå Limited third-party library support ‚ùå Performance may ...

‚ùå **Python 3 support is experimental** (not production-ready) ‚ùå Smaller ecosystem than CPython ‚ùå Limited third-party library support ‚ùå Performance may lag CPython for some workloads

#### [MEDIUM] ‚ùå Not production-ready (missing features, compatibility issues) ‚ùå Limited standard library support ‚ùå Performance may lag CPython (not optimized yet).

‚ùå **Not production-ready** (missing features, compatibility issues) ‚ùå Limited standard library support ‚ùå Performance may lag CPython (not optimized yet)

#### [MEDIUM] 29.11 Anti-Patterns & Gotchas.

29.11 Anti-Patterns & Gotchas

#### [MEDIUM] Wrong async/sync mixing async def foo(): time.sleep(2) # blocks event loop.

üö® 4. Wrong async/sync mixing async def foo(): time.sleep(2) # blocks event loop

#### [MEDIUM] Gotchas, warnings, and anti-patterns.

Gotchas, warnings, and anti-patterns

#### [MEDIUM] A.1 Singleton Pattern üîß Use With Caution (Common Anti-Pattern).

A.1 Singleton Pattern üîß Use With Caution (Common Anti-Pattern)

#### [MEDIUM] ‚ùå Anti-Pattern: Global State Mutation.

‚ùå **Anti-Pattern: Global State Mutation**

#### [MEDIUM] ‚ùå Anti-Pattern: Over-Complicated Factory.

‚ùå **Anti-Pattern: Over-Complicated Factory**

#### [MEDIUM] ‚ùå Anti-Pattern: Global Dependencies.

‚ùå **Anti-Pattern: Global Dependencies**

#### [MEDIUM] A.17 Anti-Patterns & Warnings ‚ùå Overusing OOP patterns in Python.

A.17 Anti-Patterns & Warnings ‚ùå Overusing OOP patterns in Python

#### [MEDIUM] ‚ùå Factories where simple callables suffice ‚ùå Strategy classes instead of functions.

‚ùå Factories where simple callables suffice ‚ùå Strategy classes instead of functions

#### [MEDIUM] ‚ùå Excessive class hierarchies.

‚ùå Excessive class hierarchies

#### [MEDIUM] Callback Hell (Anti-pattern).

Callback Hell (Anti-pattern)

#### [MEDIUM] Venomous Patterns (Anti-patterns).

Venomous Patterns (Anti-patterns)

#### [MEDIUM] üìò APPENDIX E ‚Äî COMMON GOTCHAS & PITFALLS A Comprehensive Guide to Python‚Äôs Most Dangerous Mistakes.

üìò APPENDIX E ‚Äî COMMON GOTCHAS & PITFALLS A Comprehensive Guide to Python‚Äôs Most Dangerous Mistakes

#### [MEDIUM] Python is easy to write but has deep semantic traps that bite developers at all levels.

Python is easy to write but has deep semantic traps that bite developers at all levels. This appendix covers all major categories of pitfalls:

#### [MEDIUM] Boolean trap patterns.

Boolean trap patterns

#### [MEDIUM] Each pitfall includes:.

Each pitfall includes:

#### [MEDIUM] üî• D.8 ‚Äî ASYNC PITFALLS.

üî• D.8 ‚Äî ASYNC PITFALLS

#### [MEDIUM] The async/await model is powerful but has subtle traps that can deadlock or degrade performance.

**The async/await model is powerful but has subtle traps that can deadlock or degrade performance.**

#### [MEDIUM] üî• D.9 ‚Äî GIL & CONCURRENCY TRAPS.

üî• D.9 ‚Äî GIL & CONCURRENCY TRAPS

#### [MEDIUM] Assuming threading speeds up numerical computations - Not using locks because "GIL prevents races" (wrong!) - Using threads for CPU-bound work inst...

- Assuming threading speeds up numerical computations - Not using locks because "GIL prevents races" (wrong!) - Using threads for CPU-bound work instead of multiprocessing - Not understanding when GIL is released

#### [MEDIUM] üî• D.10 ‚Äî TYPING PITFALLS.

üî• D.10 ‚Äî TYPING PITFALLS

#### [MEDIUM] Python's type system is optional and has subtle traps.

**Python's type system is optional and has subtle traps.**

#### [MEDIUM] Wrong TypeVar Constraints.

**4. Wrong TypeVar Constraints**

#### [MEDIUM] See also: Chapter 4 (Type System) for complete typing coverage.

**See also:** Chapter 4 (Type System) for complete typing coverage. üî• D.11 ‚Äî SECURITY PITFALLS

#### [MEDIUM] ‚ùå CRITICAL SECURITY RISK:.

‚ùå **CRITICAL SECURITY RISK:**

#### [MEDIUM] See also: Chapter 13 (Security) for comprehensive security coverage.

**See also:** Chapter 13 (Security) for comprehensive security coverage. üî• D.12 ‚Äî PERFORMANCE TRAPS

#### [MEDIUM] üî• D.13 ‚Äî ERROR HANDLING PITFALLS.

üî• D.13 ‚Äî ERROR HANDLING PITFALLS

#### [MEDIUM] Python's exception handling is powerful but has dangerous traps.

**Python's exception handling is powerful but has dangerous traps.**

#### [MEDIUM] ‚ùå CRITICAL MISTAKE:.

‚ùå **CRITICAL MISTAKE:**

#### [MEDIUM] ‚ùå Common Confusion:.

‚ùå **Common Confusion:**

#### [MEDIUM] ‚ùå Surprising Behavior:.

‚ùå **Surprising Behavior:**

#### [MEDIUM] ‚ùå Common Misunderstanding:.

‚ùå **Common Misunderstanding:**

#### [LOW] 1.6 When You Should (and Shouldn't) Use Python

1.6 When You Should (and Shouldn't) Use Python

Solution: (and Shouldn't) Use Python

**Solution:**

(and Shouldn't) Use Python

#### [LOW] ‚ùå Less Ideal

‚ùå Less Ideal

#### [LOW] 1. Mutable default arguments

1. Mutable default arguments
2. Closing files improperly
3. Misusing is vs ==
4. Modifying lists while iterating
5. Shadowing built-in names
6. Forgetting virtual environments
7. Using Python lists fo

#### [LOW] float	‚ùå

float	‚ùå
str	‚ùå
tuple	‚ùå (but may contain mutable values)
bytes	‚ùå
bool	‚ùå
list	‚úîÔ∏è
dict	‚úîÔ∏è
set	‚úîÔ∏è
bytearray	‚úîÔ∏è
custom classes (default)	‚úîÔ∏è
‚ö† Pitfall: Mutable Defaults
def f(x=[]):   # bad
    x.append(1)
    return x

#### [LOW] add(1, 2)   # OK

add(1, 2)   # OK
add(a=1, b=2)  #

#### [MEDIUM] ‚ö† Late binding closures

‚ö† Late binding closures
‚ö† Forgetting @wraps
‚ö† Using recursion for deep loops
‚ö† Misusing *args (debug difficulty)
‚ö† combining yield with try/finally incorrectly
‚ö† forgetting to close resources (use with)
‚ö† Non-deterministic iteration order pre-3.7

Solution: with)
‚ö† Non-deterministic iteration order pre-3.7

**Solution:**

with)

#### [LOW] **Avoid when:**

**Avoid when:**
- Need dynamic attributes
- Using multiple inheritance with classes that don't have slots
- Need weak references (unless `__weakref__` in slots`)
- Prototyping or frequently changing attribute set

#### [LOW] Python 3.7+: Regular `dict` is usually sufficient

Python 3.7+: Regular `dict` is usually sufficient

Solution: Need `move_to_end()` or `popitem(last=False)`
- ‚úÖ Working with Python < 3.7 code
- ‚úÖ Need order-aware equality: `OrderedDict([('a', 1), ('b', 2)]) != OrderedDict([('b', 2), ('a', 1)])`
- ‚ùå Python 3.7+: Regular `dict` is usually sufficient

**Solution:**

Need `move_to_end()` or `popitem(last=False)`

#### [MEDIUM] HTTP requests (use `requests` or `httpx`)

HTTP requests (use `requests` or `httpx`)
- ‚ùå Most web applications (use frameworks)

Solution: Custom protocols (not HTTP)
- ‚úÖ High-performance networking
- ‚úÖ Direct TCP/UDP access needed
- ‚ùå HTTP requests (use `requests` or `httpx`)
- ‚ùå Most web applications (use frameworks)

**Solution:**

Custom protocols (not HTTP)

#### [LOW] disable certificate verification in production

disable certificate verification in production

Solution: Always use `create_default_context()` for production
- ‚úÖ Never disable certificate verification in production
- ‚úÖ Use proper certificate validation
- ‚ùå Never use `CERT_NONE` in production code

**Solution:**

Always use `create_default_context()` for production

#### [MEDIUM] ‚ö† ignore exception chaining

‚ö† ignore exception chaining
‚ö† broad except catching
‚ö† except: pass
‚ö† leaking resources (forgetting finally)
‚ö† retries without backoff
‚ö† mixing exception types improperly
‚ö† not using logger.exception
‚ö† suppressing exceptions incorrectly

#### [LOW] Lower layers must NOT import upper layers

Lower layers must NOT import upper layers

#### [LOW] Domain layer must NOT depend on frameworks

Domain layer must NOT depend on frameworks

#### [MEDIUM] ‚ö† designing architecture around frameworks, not domain

‚ö† designing architecture around frameworks, not domain
‚ö† circular imports from bad folder layouts
‚ö† overusing inheritance
‚ö† leaking database logic into services
‚ö† configuration mixed with business logic
‚ö† DI frameworks adding unnecessary complexity
‚ö† God-classes/modules
‚ö† dynamically importing untrusted plugins
‚ö† mixing sync and async layers incorrectly

#### [MEDIUM] Slow: Python loop

Slow: Python loop
> total = 0
> for x in huge_list:
>     total += x
> 
> #

Solution: Fast: Built-in
> total = sum(huge_list)
> 
> # ‚úÖ Fastest: NumPy (for numerical data)
> import numpy as np
> total = np.sum(np.array(huge_list))
> ```

**Solution:**

Fast: Built-in

#### [LOW] Functions with Python objects (strings, dicts, etc.)

Functions with Python objects (strings, dicts, etc.)
‚ùå Functions called only once (compilation overhead)

Solution: Numerical loops that NumPy can't vectorize
‚úÖ Custom algorithms with complex control flow
‚úÖ Functions called many times (amortizes compilation cost)

**Solution:**

Numerical loops that NumPy can't vectorize

#### [MEDIUM] Simple operations (NumPy is easier)

Simple operations (NumPy is easier)
‚ùå Rapid prototyping (compilation overhead)

Solution: Need maximum performance
‚úÖ Complex algorithms that benefit from static typing
‚úÖ Existing C libraries to wrap

**Solution:**

Need maximum performance

#### [LOW] Small, quick tasks (overhead > benefit)

Small, quick tasks (overhead > benefit)
‚ùå Tasks requiring frequent communication (IPC overhead)

Solution: CPU-bound tasks that benefit from parallelization
‚úÖ Tasks that can be split into independent chunks
‚úÖ Long-running computations (amortizes process startup cost)

**Solution:**

CPU-bound tasks that benefit from parallelization

#### [HIGH] use `eval()` or `exec()` with user input**

use `eval()` or `exec()` with user input**

Solution: SAFE
> json.loads(user_input)  # Safe parsing
> cursor.execute("SELECT * FROM users WHERE id=?", (user_id,))  # Parameterized
> secrets.token_hex(32)  # Secure random
> ```

**Solution:**

SAFE

#### [LOW] should not be deployed

should not be deployed

Solution: not be deployed

**Solution:**

not be deployed

#### [LOW] must not be committed

must not be committed

Solution: should be encrypted

**Solution:**

should be encrypted

#### [LOW] pickle

pickle
‚ùå shelve
‚ùå marshal
‚ùå PyYAML load()

Solution: 13.6 Secure Filesystem & Path Handling
13.6.1 Use pathlib to prevent path traversal
def safe_join(base: Path, user_path: str) -> Path:
    resolved = (base / user_path).resolve()
    if base not in resolved.parents:
        raise ValueError("Traversal attempt")
    return resolved

**Solution:**

13.6 Secure Filesystem & Path Handling

#### [LOW] using user input in file paths directly

using user input in file paths directly

Solution: input in file paths directly
13.7 Rate Limiting & Abuse Prevention

**Solution:**

input in file paths directly

#### [MEDIUM] manual SQL queries

manual SQL queries
‚ùå storing plaintext passwords
‚ùå trusting user-supplied IDs
‚ùå rendering raw HTML
‚ùå returning internal error messages
‚ùå disabling SSL verification
‚ùå using "pickle" for sessions

Solution: using "pickle" for sessions

**Solution:**

using "pickle" for sessions

#### [MEDIUM] Error messages must not leak internal data

Error messages must not leak internal data

#### [MEDIUM] ‚ö† using too many mocks ‚Üí tests lie

‚ö† using too many mocks ‚Üí tests lie
‚ö† brittle tests that mirror implementation
‚ö† skipping integration tests ‚Üí hidden failures
‚ö† not isolating the DB state
‚ö† relying on real network in tests
‚ö† test order dependence
‚ö† global state shared between tests
‚ö† mocking time incorrectly

#### [LOW] python:latest

python:latest
‚ùå python:3.12-slim with no pinned version

Solution: 16.6.2 Multi-Stage Build Example
FROM python:3.12-slim as builder
WORKDIR /app
COPY pyproject.toml .
RUN pip install --user poetry
COPY . .
RUN poetry build

**Solution:**

16.6.2 Multi-Stage Build Example

#### [LOW] 17.4 Concurrency Comparison (the famous table)

17.4 Concurrency Comparison (the famous table)
Model	Parallel

Solution: (3.14 FT)	Network IO, HTTP clients, websockets	CPU-bound work
Multiprocessing	‚úÖ	CPU-heavy tasks, ML preprocessing	High IPC overhead
AsyncIO	‚ùå	100k+ network connections	CPU-bound work
ThreadPoolExecutor	Limited (GIL)	mixed I/O tasks	heavy CPU work
ProcessPoolExecutor	Yes	batch CPU tasks	small tasks (overhead)
17.5 THREADING

**Solution:**

(3.14 FT)	Network IO, HTTP clients, websockets	CPU-bound work

#### [LOW] need frequent communication

need frequent communication

Solution: CPU-bound tasks (image processing, data analysis, ML preprocessing)
‚úÖ Tasks that benefit from multiple CPU cores
‚úÖ Isolated computations that don't need frequent communication

**Solution:**

CPU-bound tasks (image processing, data analysis, ML preprocessing)

#### [HIGH] cur.execute(f"SELECT * FROM users WHERE id={user_id}")  #

cur.execute(f"SELECT * FROM users WHERE id={user_id}")  #

Solution: SQL injection

**Solution:**

SQL injection

#### [LOW] handle heavy workloads

handle heavy workloads

Solution: not handle heavy workloads

**Solution:**

not handle heavy workloads

#### [LOW] **Do not write vague docstrings:**

**Do not write vague docstrings:**

Solution: # ‚ùå INCORRECT: Provides no useful information
def process_data(data):
    """Process data."""
    pass

**Solution:**

# ‚ùå INCORRECT: Provides no useful information

#### [LOW] **Do not restate the function name:**

**Do not restate the function name:**

Solution: # ‚ùå INCORRECT: Just repeats what the name already says
def add(x, y):
    """Add function."""
    return x + y

**Solution:**

# ‚ùå INCORRECT: Just repeats what the name already says

#### [LOW] **Do not omit exceptions:**

**Do not omit exceptions:**

Solution: # ‚ùå INCORRECT: Missing Raises section
def parse_int(value: str) -> int:
    """Convert a string to an integer."""
    return int(value)  # Can raise ValueError!

**Solution:**

# ‚ùå INCORRECT: Missing Raises section

#### [LOW] **Do not include implementation details:**

**Do not include implementation details:**

Solution: # ‚ùå INCORRECT: Describes how instead of what
def authenticate(user: str, pwd: str) -> bool:
    """Check password by computing SHA256 hash and comparing with database.
    
    Uses the hashlib library to compute the hash, then queries the users
    table in PostgreSQL using SQLAlchemy ORM.
    """
    pass

**Solution:**

# ‚ùå INCORRECT: Describes how instead of what

#### [HIGH] API keys, tokens, or credentials

API keys, tokens, or credentials  
- ‚ùå Internal server names or infrastructure details  
- ‚ùå Security algorithms or salt values  
- ‚ùå Database schemas with security implications

Solution: # ‚ùå INCORRECT: Exposes internal implementation details
def fetch_user(uid: str) -> dict:
    """Fetch user from database.
    
    Raises:
        psycopg2.OperationalError: If PostgreSQL connection fails.
        redis.ConnectionError: If Redis cache is unavailable.
    """
    pass

# ‚úÖ CORRECT: Public API uses abstracted exceptions
def fetch_user(uid: str) -> dict:
    """Fetch user from database.
    
    Raises:
        DatabaseError: If user data cannot be retrieved.
        UserNotFoundError: If the user does not exist.
    """
    pass

**Solution:**

# ‚ùå INCORRECT: Exposes internal implementation details

#### [LOW] **Python 2.7 only** (Python 2 EOL was 2020)

**Python 2.7 only** (Python 2 EOL was 2020)
‚ùå **No Python 3 support** (experimental only)
‚ùå Minimal active development
‚ùå Declining community

Solution: For new JVM + Python projects:
- ‚úÖ **Use GraalPy** (Python 3.11+, active development, better performance)
- ‚úÖ **Use CPython + JPype** (if you need strict CPython compatibility)
- ‚ùå **Avoid Jython** for new projects

**Solution:**

For new JVM + Python projects:

#### [MEDIUM] Jython** for new projects

Jython** for new projects

Solution: **Use GraalPy** (Python 3.11+, active development, better performance)
- ‚úÖ **Use CPython + JPype** (if you need strict CPython compatibility)
- ‚ùå **Avoid Jython** for new projects

**Solution:**

**Use GraalPy** (Python 3.11+, active development, better performance)

#### [MEDIUM] **Python 3 support is experimental** (not production-ready)

**Python 3 support is experimental** (not production-ready)
‚ùå Smaller ecosystem than CPython
‚ùå Limited third-party library support
‚ùå Performance may lag CPython for some workloads

Solution: For .NET + Python interop:
- ‚úÖ **CPython + pythonnet**: Mature, supports Python 3.x, good performance
- ‚úÖ **GraalPy + .NET interop**: If you're already using GraalVM
- ‚úÖ **Embed CPython**: Most flexible, best library support

**Solution:**

For .NET + Python interop:

#### [MEDIUM] Not ideal: Heavy C-extension dependencies (NumPy/SciPy support improving)

Not ideal: Heavy C-extension dependencies (NumPy/SciPy support improving)

Solution: JVM-based applications needing Python
‚úÖ Polyglot projects (Python + Java + other languages)
‚úÖ Data science on JVM infrastructure
‚úÖ When you need better performance than CPython for pure Python code

**Solution:**

JVM-based applications needing Python

#### [LOW] **Not recommended** for new projects (use asyncio instead)

**Not recommended** for new projects (use asyncio instead)

Solution: Specific microthreading requirements
‚úÖ Legacy Stackless codebases

**Solution:**

Specific microthreading requirements

#### [MEDIUM] **Not production-ready** (missing features, compatibility issues)

**Not production-ready** (missing features, compatibility issues)
‚ùå Limited standard library support
‚ùå Performance may lag CPython (not optimized yet)

Solution: **Use Cases:**

**Solution:**

**Use Cases:**

#### [LOW] Not for production applications

Not for production applications

Solution: Educational projects
‚úÖ Embedded Python in Rust applications
‚úÖ WebAssembly Python (experimental)

**Solution:**

Educational projects

#### [MEDIUM] incorrect method names

incorrect method names

#### [LOW] A.1 Singleton Pattern

A.1 Singleton Pattern
üîß Use With Caution (Common Anti-Pattern)

Solution: With Caution (Common Anti-Pattern)

**Solution:**

With Caution (Common Anti-Pattern)

#### [LOW] **Anti-Pattern: Global State Mutation**

**Anti-Pattern: Global State Mutation**

Solution: ‚úÖ **Prefer Instead: Dependency Injection**

**Solution:**

‚úÖ **Prefer Instead: Dependency Injection**

#### [LOW] **Anti-Pattern: Over-Complicated Factory**

**Anti-Pattern: Over-Complicated Factory**

Solution: ‚úÖ **Prefer: Simple Functions or Dicts**

**Solution:**

‚úÖ **Prefer: Simple Functions or Dicts**

#### [LOW] **Anti-Pattern: Global Dependencies**

**Anti-Pattern: Global Dependencies**

Solution: # BAD: Hard to test, tight coupling
import database
import logger

class UserService:
    def get_user(self, user_id: int):
        logger.log(f"Fetching {user_id}")  # Global dependency
        return database.query(f"SELECT * FROM users WHERE id = {user_id}")

**Solution:**

# BAD: Hard to test, tight coupling

#### [LOW] Overusing OOP patterns in Python

Overusing OOP patterns in Python

Solution: Functional & simpler solutions often work better.

**Solution:**

Functional & simpler solutions often work better.

#### [LOW] ‚ùå Singleton misuse

‚ùå Singleton misuse

Solution: ‚ùå Factories where simple callables suffice
‚ùå Strategy classes instead of functions

**Solution:**

‚ùå Factories where simple callables suffice

#### [LOW] Factories where simple callables suffice

Factories where simple callables suffice
‚ùå Strategy classes instead of functions

Solution: of functions

**Solution:**

of functions

#### [LOW] Excessive class hierarchies

Excessive class hierarchies

#### [LOW] Common pitfall.

Common pitfall.

#### [LOW] Callback Hell (Anti-pattern)

Callback Hell (Anti-pattern)

#### [LOW] Default Argument Gotcha (Mutable Defaults)

Default Argument Gotcha (Mutable Defaults)

#### [LOW] Python pitfall:

Python pitfall:

#### [LOW] Boolean trap patterns

Boolean trap patterns

#### [LOW] Each pitfall includes:

Each pitfall includes:

Solution: Incorrect example

**Solution:**

Incorrect example

#### [MEDIUM] def append_to_list(value, lst=[]):

def append_to_list(value, lst=[]):
    lst.append(value)
    return lst

#### [MEDIUM] funcs = [lambda: i for i in range(3)]

funcs = [lambda: i for i in range(3)]
[f() for f in funcs]  # ‚Üí [2, 2, 2]

Solution: Incorrect
funcs = [lambda: i for i in range(3)]
[f() for f in funcs]  # ‚Üí [2, 2, 2]

Rationale: does my lambda use the last value?!‚Äù
‚ùå Incorrect
funcs = [lambda: i for i in range(3)]
[f() for f in funcs]  # ‚Üí [2, 2, 2]

**Solution:**

Incorrect

#### [MEDIUM] running module-level code

running module-level code

Solution: Correct:
items = [1, 2, 3]

**Solution:**

Correct:

#### [MEDIUM] ‚ùå **Incorrect:**

‚ùå **Incorrect:**

#### [MEDIUM] ‚ùå **Incorrect:**

‚ùå **Incorrect:**

Solution: ‚úÖ **Correct:**

**Solution:**

‚úÖ **Correct:**

#### [MEDIUM] **Incorrect Understanding:**

**Incorrect Understanding:**

#### [MEDIUM] **Incorrect Assumption:**

**Incorrect Assumption:**

Solution: Type hints are **documentation only** at runtime. They don't prevent incorrect types from being passed.

**Solution:**

Type hints are **documentation only** at runtime. They don't prevent incorrect types from being passed.

#### [MEDIUM] **5. Using Protocol Incorrectly**

**5. Using Protocol Incorrectly**

Solution: ‚ùå **Incorrect:**

**Solution:**

‚ùå **Incorrect:**

#### [MEDIUM] **Incorrect Understanding:**

**Incorrect Understanding:**

Solution: ‚úÖ **Correct:**

**Solution:**

‚úÖ **Correct:**

#### [MEDIUM] ‚ùå **Incorrect:**

‚ùå **Incorrect:**

Solution: ‚úÖ **Correct Understanding:**

**Solution:**

‚úÖ **Correct Understanding:**

#### [HIGH] **CRITICAL SECURITY RISK:**

**CRITICAL SECURITY RISK:**

Solution: import pickle

# NEVER do this with user input!
user_data = input("Enter data: ")
obj = pickle.loads(user_data)  # CODE EXECUTION VULNERABILITY!

# Attacker can send: b'\x80\x03cbuiltins\neval\nq\x00X\x10\x00\x00\x00__import__("os").system("rm -rf /")\nq\x01\x85q\x02Rq\x03.'

**Solution:**

import pickle

#### [HIGH] **CRITICAL SECURITY RISK:**

**CRITICAL SECURITY RISK:**

Solution: user_code = input("Enter expression: ")
result = eval(user_code)  # CODE EXECUTION!

# Attacker can send: "__import__('os').system('rm -rf /')"

**Solution:**

user_code = input("Enter expression: ")

#### [HIGH] **CRITICAL SECURITY RISK:**

**CRITICAL SECURITY RISK:**

Solution: import sqlite3

user_id = input("Enter user ID: ")
query = f"SELECT * FROM users WHERE id = {user_id}"  # SQL INJECTION!

# Attacker can send: "1 OR 1=1; DROP TABLE users;--"
cursor.execute(query)

**Solution:**

import sqlite3

#### [HIGH] **CRITICAL SECURITY RISK:**

**CRITICAL SECURITY RISK:**

Solution: import subprocess

user_input = input("Enter command: ")
subprocess.run(f"ls {user_input}", shell=True)  # COMMAND INJECTION!

# Attacker can send: "; rm -rf /"

**Solution:**

import subprocess

#### [MEDIUM] ‚ùå **Incorrect:**

‚ùå **Incorrect:**

Solution: from fastapi import FastAPI

app = FastAPI()

@app.get("/users/{user_id}")
def get_user(user_id: str):
    try:
        user = db.get_user(user_id)
    except Exception as e:
        return {"error": str(e)}  # Exposes internal details!

# Error might reveal: "Database connection failed: password='secret'"

**Solution:**

from fastapi import FastAPI

#### [MEDIUM] **Incorrect (O(n¬≤) complexity):**

**Incorrect (O(n¬≤) complexity):**

Solution: ‚úÖ **Correct (O(n) complexity):**

**Solution:**

‚úÖ **Correct (O(n) complexity):**

#### [MEDIUM] **Incorrect (O(n) lookup):**

**Incorrect (O(n) lookup):**

Solution: ‚úÖ **Correct (O(1) lookup):**

**Solution:**

‚úÖ **Correct (O(1) lookup):**

#### [MEDIUM] **Incorrect (slow):**

**Incorrect (slow):**

Solution: import pandas as pd

df = pd.DataFrame({"x": range(1_000_000), "y": range(1_000_000)})

# .apply() uses Python loops internally
df["sum"] = df.apply(lambda row: row["x"] + row["y"], axis=1)  # SLOW!

**Solution:**

import pandas as pd

#### [MEDIUM] **Incorrect (slow):**

**Incorrect (slow):**

Solution: ‚úÖ **Correct (fast):**

**Solution:**

‚úÖ **Correct (fast):**

#### [MEDIUM] **Incorrect (slow):**

**Incorrect (slow):**

Solution: ‚úÖ **Correct:**

**Solution:**

‚úÖ **Correct:**

#### [MEDIUM] **Incorrect (stack overflow risk):**

**Incorrect (stack overflow risk):**

Solution: ‚úÖ **Correct:**

**Solution:**

‚úÖ **Correct:**

#### [MEDIUM] **Incorrect (memory overhead):**

**Incorrect (memory overhead):**

Solution: ‚úÖ **Correct (memory efficient):**

**Solution:**

‚úÖ **Correct (memory efficient):**

#### [MEDIUM] **Incorrect (function call overhead):**

**Incorrect (function call overhead):**

Solution: ‚úÖ **Correct:**

**Solution:**

‚úÖ **Correct:**

#### [MEDIUM] **Incorrect (memory intensive):**

**Incorrect (memory intensive):**

Solution: ‚úÖ **Correct:**

**Solution:**

‚úÖ **Correct:**

#### [LOW] **CRITICAL MISTAKE:**

**CRITICAL MISTAKE:**

#### [MEDIUM] ‚ùå **Incorrect:**

‚ùå **Incorrect:**

Solution: def process_file(filename):
    try:
        with open(filename) as f:
            return f.read()
    except:
        pass  # Silent failure - user has no idea what went wrong
    return None

**Solution:**

def process_file(filename):

#### [MEDIUM] ‚ùå **Incorrect:**

‚ùå **Incorrect:**

Solution: try:
    user_id = int(input("Enter ID: "))
    user = db.get_user(user_id)
except Exception:  # Too broad - catches everything
    print("Error occurred")

**Solution:**

try:

#### [MEDIUM] **Incorrect (slow):**

**Incorrect (slow):**

Solution: def find_user(users, user_id):
    try:
        return next(u for u in users if u.id == user_id)
    except StopIteration:
        return None  # Exception for control flow - slow!

**Solution:**

def find_user(users, user_id):

#### [MEDIUM] **Incorrect (old pattern):**

**Incorrect (old pattern):**

Solution: ‚úÖ **Correct (Python 3.11+):**

**Solution:**

‚úÖ **Correct (Python 3.11+):**

#### [LOW] **Common Confusion:**

**Common Confusion:**

#### [MEDIUM] **Incorrect (undefined behavior):**

**Incorrect (undefined behavior):**

Solution: ‚úÖ **Correct:**

**Solution:**

‚úÖ **Correct:**

#### [LOW] **Surprising Behavior:**

**Surprising Behavior:**

Solution: ‚úÖ **Correct Understanding:**

**Solution:**

‚úÖ **Correct Understanding:**

#### [LOW] **Surprising Behavior:**

**Surprising Behavior:**

#### [LOW] **Common Misunderstanding:**

**Common Misunderstanding:**

Solution: The `else` clause runs **only if the loop completes normally** (doesn't break). This is counterintuitive!

**Solution:**

The `else` clause runs **only if the loop completes normally** (doesn't break). This is counterintuitive!

#### [LOW] **Surprising Behavior:**

**Surprising Behavior:**

Solution: Descriptors intercept attribute access. When you access `obj.attr`, Python calls `Descriptor.__get__()` instead of returning the descriptor object.

**Solution:**

Descriptors intercept attribute access. When you access `obj.attr`, Python calls `Descriptor.__get__()` instead of returning the descriptor object.

#### [LOW] **Surprising Behavior:**

**Surprising Behavior:**

Solution: C3 Linearization requires a consistent Method Resolution Order. `G(E, F)` where `E = (A, B)` and `F = (B, A)` creates a conflict.

**Solution:**

C3 Linearization requires a consistent Method Resolution Order. `G(E, F)` where `E = (A, B)` and `F = (B, A)` creates a conflict.

#### [LOW] **Surprising Behavior:**

**Surprising Behavior:**

Solution: ‚úÖ **Correct:**

**Solution:**

‚úÖ **Correct:**


### Additional Content

#### Example

python hello.py
# Output: Hello, Python!

#### Example

name = "Alice"
age = 30
message = "Hello, %s! You are %d years old." % (name, age)
print(message)
# Output: Hello, Alice! You are 30 years old.

#### Example

name = "Alice"
age = 30
message = "Hello, {}! You are {} years old.".format(name, age)

#### Example

message = "Hello, {name}! You are {age} years old.".format(name=name, age=age)
print(message)

#### Example

name = "Alice"
age = 30
message = f"Hello, {name}! You are {age} years old."
print(message)

#### Example

::: example
id: CODE-6c9c7d64819d1dfc
chapter: GLOBAL
language: python
role: example
tags: []
explanation: With expressions:
confidence: 0.9
digest: 86fffaec87f9685109bdb214bea434d55744fa84ba843f7c8b92e1c945c37a98
symbol_refs: [message]
semantic_role: example
embedding_hint_importance: medium
embedding_hint_scope: local
embedding_hint_chunk: auto

#### Example

print(format_greeting("Bob"))

#### Example

NAME            def                  (1, 0) ‚Üí (1, 3)
NAME            add                  (1, 4) ‚Üí (1, 7)
OP              (                    (1, 7) ‚Üí (1, 8)
NAME            a                    (1, 8) ‚Üí (1, 9)
OP              ,                    (1, 9) ‚Üí (1, 10)
NAME            b                    (1, 10) ‚Üí (1, 11)
OP              )                    (1, 11) ‚Üí (1, 12)
OP              :                    (1, 12) ‚Üí (1, 13)
NEWLINE         \n                   (1, 13) ‚Üí (1, 14)
INDENT          \n    \n             (2, 0) ‚Üí (2, 4)
NAME            return               (2, 4) ‚Üí (2, 10)
NAME            a                    (2, 11) ‚Üí (2, 12)
OP              +                    (2, 13) ‚Üí (2, 14)
NAME            b                    (2, 15) ‚Üí (2, 16)
NEWLINE         \n                   (2, 16) ‚Üí (2, 17)
DEDENT          \n                   (3, 0) ‚Üí (3, 0)
ENDMARKER       \n                   (3, 0) ‚Üí (3, 0)

#### Example

Module(
  body=[
    FunctionDef(
      name='add',
      args=arguments(
        posonlyargs=[],
        args=[
          arg(arg='a'),
          arg(arg='b')
        ],
        kwonlyargs=[],
        kw_defaults=[],
        defaults=[]
      ),
      body=[
        Return(
          value=BinOp(
            left=Name(id='a', ctx=Load()),
            op=Add(),
            right=Name(id='b', ctx=Load())
          )
        )
      ],
      decorator_list=[]
    )
  ]
)

#### Example

2           0 LOAD_FAST                0 (a)
              2 LOAD_FAST                1 (b)
              4 BINARY_ADD
              6 RETURN_VALUE

#### Example

dis.dis(lambda x: x + 1)      # Simple addition
dis.dis(lambda x: x * 2)      # Multiplication
dis.dis(lambda x: x if x > 0 else 0)  # Conditional

#### Example

print(f"util in sys.modules: {'util' in sys.modules}")

#### Example

cached_util = sys.modules['util']
print(f"Direct access: {cached_util.x}")

#### Example

print(f"All same: {util is util2 is cached_util}")

#### Example

util imported
util in sys.modules: True
Same object: True
Direct access: 10
All same: True

#### Example

if 'util' in sys.modules:
    del sys.modules['util']

#### Example

graph TD
    Object[object base class] --> Type[type metaclass]
    Object --> Exception[Exception]
    Object --> BaseException[BaseException]
    
    Type --> Class[class instances]
    
    Exception --> ValueError[ValueError]
    Exception --> KeyError[KeyError]
    
    BaseException --> KeyboardInterrupt[KeyboardInterrupt]
    
    Class --> BuiltInTypes[Built-in Types]
    
    BuiltInTypes --> Numeric[Numeric Types:<br/>int, float, complex, bool]
    BuiltInTypes --> Sequence[Sequence Types:<br/>str, list, tuple, bytes,<br/>bytearray, range]
    BuiltInTypes --> Mapping[Mapping Types:<br/>dict]
    BuiltInTypes --> Set[Set Types:<br/>set, frozenset]
    BuiltInTypes --> Callable[Callable Types:<br/>function, method, builtin]
    BuiltInTypes --> Iterator[Iterator Types:<br/>iterator, generator]
    BuiltInTypes --> Other[Other Types:<br/>NoneType, type,<br/>generator, coroutine]
    
    style Object fill:#e1f5ff
    style Type fill:#ffe1f5
    style BuiltInTypes fill:#e1ffe1

#### Example

bound_method = calc.add
print(bound_method(4, 5))

#### Example

unbound_method = Calculator.add
print(unbound_method(calc, 6, 7))

#### Example

regular_points = [RegularPoint(i, i) for i in range(1_000_000)]
slotted_points = [SlottedPoint(i, i) for i in range(1_000_000)]

#### Example

regular_size = sys.getsizeof(regular_points[0]) * 1_000_000
slotted_size = sys.getsizeof(slotted_points[0]) * 1_000_000

print(f"Regular: ~{regular_size / 1024 / 1024:.1f} MB")
print(f"Slotted: ~{slotted_size / 1024 / 1024:.1f} MB")
print(f"Savings: ~{(1 - slotted_size/regular_size) * 100:.1f}%")

#### Example

graph TD
    Object[object] --> A[A]
    Object --> B[B]
    
    A --> C[C]
    B --> C
    
    C --> MRO[MRO Resolution for: C A, B<br/><br/>Step 1: Build inheritance graph<br/>Step 2: C3 Linearization<br/>MRO C = C + merge<br/>    MRO A,<br/>    MRO B,<br/>    A, B<br/><br/>Result: C, A, B, object]
    
    style Object fill:#e1f5ff
    style C fill:#ffe1f5
    style MRO fill:#e1ffe1

#### Example

flowchart TD
    Start[obj.method] --> Step1[1. Check type obj.__mro__<br/>C, A, B, object]
    
    Step1 --> Step2[2. Search in order:<br/>C.__dict__['method']?<br/>A.__dict__['method']?<br/>B.__dict__['method']?<br/>object.__dict__['method']?]
    
    Step2 --> Step3[3. First match wins<br/>stops at first found]
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style Step3 fill:#fff4e1

#### Example

print(D.__mro__)

#### Example

c = C()
print(c.method())

#### Example

d = D()
print(d.method())

#### Example

graph TD
    Object[object] --> A[A]
    Object --> B[B]
    
    A --> C[C]
    B --> C
    
    C --> D[D]
    C --> E[E]
    
    D --> F[F]
    E --> F
    
    F --> MRO[MRO Calculation for F:<br/>F.__mro__ = F + merge<br/>MRO D: D, C, A, object<br/>MRO E: E, C, B, object<br/>Direct parents: D, E<br/><br/>Step-by-step merge:<br/>1. Take D ‚Üí keep D<br/>2. Remove D, take E ‚Üí keep E<br/>3. Take C ‚Üí keep C<br/>4. Continue: A, B, object<br/><br/>Final MRO: F, D, E, C, A, B, object]
    
    style Object fill:#e1f5ff
    style F fill:#ffe1f5
    style MRO fill:#e1ffe1

#### Example

flowchart TD
    Start[obj.method] --> Step1[1. Get type obj.__mro__<br/>Example: F, D, E, C, A, B, object]
    
    Step1 --> Step2[2. Search in MRO order left to right]
    
    Step2 --> CheckF[Check F.__dict__['method']?<br/>‚Üí Not found]
    
    CheckF --> CheckD[Check D.__dict__['method']?<br/>‚Üí Not found]
    
    CheckD --> CheckE[Check E.__dict__['method']?<br/>‚Üí Not found]
    
    CheckE --> CheckC[Check C.__dict__['method']?<br/>‚Üí FOUND!]
    
    CheckC --> Step3[3. Return method bound to obj<br/>STOP searching first match wins]
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style CheckC fill:#fff4e1
    style Step3 fill:#ffe1e1

#### Example

print(f"Modules loaded: {len(sys.modules)}")

#### Example

print(f"Meta path finders: {len(sys.meta_path)}")
for finder in sys.meta_path:
    print(f"  - {type(finder).__name__}")

#### Example

shutil.copy("source.txt", "dest.txt")  # Copies file, preserves permissions
shutil.copy2("source.txt", "dest.txt")  # Also preserves metadata (timestamps)

#### Example

shutil.copytree("src_dir", "dest_dir", dirs_exist_ok=True)  # Python 3.8+

#### Example

# Move/rename file or directory
shutil.move("old_name.txt", "new_name.txt")
shutil.move("source_dir", "dest_dir")  # Moves entire directory

#### Example

# Remove directory tree (destructive, no undo!)
shutil.rmtree("directory_to_remove", ignore_errors=True)  # ignore_errors prevents exceptions

#### Example

shutil.make_archive("backup", "zip", "myfolder")

#### Example

# Extract archive
shutil.unpack_archive("backup.zip", "extract_to/")

#### Example

# Get disk space statistics
total, used, free = shutil.disk_usage("/")
print(f"Total: {total // (1024**3)} GB")
print(f"Used: {used // (1024**3)} GB")
print(f"Free: {free // (1024**3)} GB")

#### Example

# Find executable in PATH
python_path = shutil.which("python3")
print(python_path)  # /usr/bin/python3

#### Example

with tempfile.TemporaryFile(mode='w+') as f:
    f.write("temporary data")
    f.seek(0)
    print(f.read())

#### Example

with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:
    f.write("data")
    temp_name = f.name  # Keep name for later use

#### Example

with tempfile.TemporaryDirectory() as tmpdir:
    print(f"Working in: {tmpdir}")

#### Example

temp_file = Path(tmpdir) / "data.txt"
    temp_file.write_text("temporary content")

#### Example

tmpdir = tempfile.gettempdir()  # /tmp on Unix, %TEMP% on Windows

#### Example

user_tmp = tempfile.gettempdir()

#### Example

temp_name = tempfile.mktemp(suffix='.txt')  # Deprecated, use NamedTemporaryFile

#### Example

with open(path) as f:
        print(f.read())
finally:
    os.unlink(path)  # Always clean up

#### Example

# Create temporary file with specific permissions (Unix)
import stat

fd, path = tempfile.mkstemp()
os.chmod(path, stat.S_IRUSR | stat.S_IWUSR)  # 0600: user read/write only

#### Example

with open(path) as f:
            result = f.read().upper()  # Example: uppercase transformation
        return result
    finally:
        os.unlink(path)  # Always clean up

result = process_with_temp_file("hello world")
print(result)  # HELLO WORLD

#### Example

now = datetime.now()
print(now)  # 2025-11-30 14:30:45.123456

#### Example

dt = datetime(2025, 1, 27, 14, 30, 45)
print(dt)  # 2025-11-30 14:30:45

#### Example

tomorrow = now + timedelta(days=1)
next_week = now + timedelta(weeks=1)
in_2_hours = now + timedelta(hours=2)

#### Example

diff = tomorrow - now
print(diff.total_seconds())  # 86400.0 seconds

#### Example

# Extract components
dt = datetime.now()
print(dt.year)      # 2025
print(dt.month)     # 1
print(dt.day)       # 27
print(dt.hour)      # 14
print(dt.minute)    # 30
print(dt.second)    # 45
print(dt.microsecond)  # 123456
print(dt.weekday())    # 0 (Monday = 0, Sunday = 6)
print(dt.isoweekday()) # 1 (Monday = 1, Sunday = 7)

#### Example

d = date(2025, 1, 27)
print(d)  # 2025-11-30

#### Example

t = time(14, 30, 45)
print(t)  # 14:30:45

#### Example

dt = datetime.combine(d, t)
print(dt)  # 2025-11-30 14:30:45

#### Example

delta = timedelta(days=5, hours=3, minutes=30, seconds=15)
print(delta)  # 5 days, 3:30:15

#### Example

print(delta.days)         # 5
print(delta.seconds)      # 12615 (hours*3600 + minutes*60 + seconds)
print(delta.total_seconds())  # 447615.0

#### Example

dt1 = datetime(2025, 1, 1)
dt2 = datetime(2025, 1, 10)
diff = dt2 - dt1
print(diff.days)  # 9

#### Example

dt_ny = datetime.now(ZoneInfo("America/New_York"))
dt_utc = datetime.now(ZoneInfo("UTC"))
dt_tokyo = datetime.now(ZoneInfo("Asia/Tokyo"))

#### Example

dt_utc = dt_ny.astimezone(ZoneInfo("UTC"))
print(f"NY: {dt_ny}")
print(f"UTC: {dt_utc}")

#### Example

naive = datetime(2025, 1, 27, 14, 30)
aware = naive.replace(tzinfo=ZoneInfo("America/New_York"))

#### Example

aware = datetime(2025, 1, 27, 14, 30, tzinfo=ZoneInfo("America/New_York"))

#### Example

utc = ZoneInfo("UTC")

#### Example

eastern = ZoneInfo("America/New_York")
pacific = ZoneInfo("America/Los_Angeles")
central = ZoneInfo("America/Chicago")

#### Example

london = ZoneInfo("Europe/London")
paris = ZoneInfo("Europe/Paris")
berlin = ZoneInfo("Europe/Berlin")

#### Example

tokyo = ZoneInfo("Asia/Tokyo")
beijing = ZoneInfo("Asia/Shanghai")

#### Example

dt_ny = datetime.now(ZoneInfo("America/New_York"))
dt_utc = dt_ny.astimezone(ZoneInfo("UTC"))
dt_tokyo = dt_ny.astimezone(ZoneInfo("Asia/Tokyo"))

#### Example

print(f"NY:    {dt_ny}")
print(f"UTC:   {dt_utc}")
print(f"Tokyo: {dt_tokyo}")

#### Example

dt_local = datetime.strptime(local_time, "%Y-%m-%d %H:%M")
    dt_local = dt_local.replace(tzinfo=ZoneInfo(timezone))

#### Example

dt_utc = dt_local.astimezone(ZoneInfo("UTC"))
    
    print(f"Event: {event_name}")
    print(f"Local ({timezone}): {dt_local}")
    print(f"UTC: {dt_utc}")
    return dt_utc

#### Example

utc_time = schedule_event(
    "2025-11-30 14:00",
    "America/New_York",
    "Team Meeting"
)

#### Example

dt = datetime.strptime("2025-11-30", "%Y-%m-%d")
dt = datetime.strptime("Jan 27, 2025 2:30 PM", "%b %d, %Y %I:%M %p")

#### Example

dt = datetime.now()

#### Example

iso_str = dt.isoformat()
print(iso_str)  # 2025-01-27T14:30:45.123456

#### Example

formatted = dt.strftime("%Y-%m-%d")
formatted = dt.strftime("%B %d, %Y")  # January 27, 2025
formatted = dt.strftime("%A, %B %d, %Y at %I:%M %p")  # Monday, January 27, 2025 at 02:30 PM

#### Example

# Using strftime for readable output
dt = datetime.now()
print(dt.strftime("%A, %B %d, %Y"))  # Monday, January 27, 2025
print(dt.strftime("%I:%M %p"))        # 02:30 PM
print(dt.strftime("%Y-%m-%d %H:%M:%S"))  # 2025-11-30 14:30:45

#### Example

c = Counter("banana")
print(c)  # Counter({'a': 3, 'n': 2, 'b': 1})

#### Example

words = ["apple", "banana", "apple", "cherry", "banana", "apple"]
word_count = Counter(words)
print(word_count)  # Counter({'apple': 3, 'banana': 2, 'cherry': 1})

#### Example

c = Counter("banana")

#### Example

print(c['a'])      # 3
print(c['z'])      # 0 (doesn't raise KeyError)

#### Example

print(c.most_common(2))  # [('a', 3), ('n', 2)]

#### Example

c.update("apple")  # Add more items
print(c)  # Counter({'a': 4, 'n': 2, 'b': 1, 'p': 2, 'l': 1, 'e': 1})

#### Example

c1 = Counter("ab")
c2 = Counter("bc")
print(c1 + c2)  # Counter({'b': 2, 'a': 1, 'c': 1})
print(c1 - c2)  # Counter({'a': 1}) (negative counts removed)

#### Example

text = "the quick brown fox jumps over the lazy dog"
words = text.split()
word_freq = Counter(words)
print(word_freq.most_common(3))  # [('the', 2), ('quick', 1), ('brown', 1)]

#### Example

data = [1, 2, 3, 1, 2, 1, 3, 3, 3]
counter = Counter(data)
top_2 = counter.most_common(2)
print(top_2)  # [(3, 4), (1, 3)]

#### Example

dd_list = defaultdict(list)
dd_list["key"].append("value")

#### Example

dd_int = defaultdict(int)
dd_int["count"] += 1

#### Example

dd_set = defaultdict(set)
dd_set["tags"].add("python")

#### Example

dd_dict = defaultdict(dict)
dd_dict["user"]["name"] = "Alice"

#### Example

# Group items by category
items = [
    ("fruit", "apple"),
    ("fruit", "banana"),
    ("vegetable", "carrot"),
    ("fruit", "cherry"),
    ("vegetable", "broccoli"),
]

grouped = defaultdict(list)
for category, item in items:
    grouped[category].append(item)

print(grouped)
# defaultdict(<class 'list'>, {
#     'fruit': ['apple', 'banana', 'cherry'],
#     'vegetable': ['carrot', 'broccoli']
# })

#### Example

from collections import defaultdict

users = [
    {"name": "Alice", "dept": "Engineering"},
    {"name": "Bob", "dept": "Sales"},
    {"name": "Charlie", "dept": "Engineering"},
    {"name": "Diana", "dept": "Marketing"},
]

dept_users = defaultdict(list)
for user in users:
    dept_users[user["dept"]].append(user["name"])

for dept, names in dept_users.items():
    print(f"{dept}: {', '.join(names)}")

#### Example

q = deque()
q.append(1)        # Add to right
q.append(2)
q.appendleft(0)    # Add to left
print(q)  # deque([0, 1, 2])

#### Example

# Use as queue (FIFO)
queue = deque()
queue.append("first")   # Enqueue
queue.append("second")
queue.append("third")

while queue:
    item = queue.popleft()  # Dequeue
    print(item)
# Output: first, second, third

#### Example

# Use as stack (LIFO)
stack = deque()
stack.append("first")    # Push
stack.append("second")
stack.append("third")

while stack:
    item = stack.pop()   # Pop
    print(item)
# Output: third, second, first

#### Example

# Bounded deque (maxlen)
d = deque(maxlen=3)
d.append(1)
d.append(2)
d.append(3)
d.append(4)  # Automatically removes leftmost item
print(d)  # deque([2, 3, 4], maxlen=3)

#### Example

q_deque = deque(range(1000000))
start = time.perf_counter()
while q_deque:
    q_deque.popleft()
deque_time = time.perf_counter() - start

#### Example

q_list = list(range(1000000))
start = time.perf_counter()
while q_list:
    q_list.pop(0)  # Very slow!
list_time = time.perf_counter() - start

print(f"deque: {deque_time:.4f}s")
print(f"list:  {list_time:.4f}s")  # Much slower!

#### Example

od = OrderedDict()
od['first'] = 1
od['second'] = 2
od['third'] = 3
print(list(od.keys()))  # ['first', 'second', 'third']

#### Example

od.move_to_end('first')
print(list(od.keys()))  # ['second', 'third', 'first']

#### Example

first = od.popitem(last=False)
print(first)  # ('second', 2)

#### Example

defaults = {"host": "localhost", "port": 8080}
file_config = {"port": 9000, "debug": True}
env_config = {"host": "prod.example.com"}

#### Example

defaults = {
    "database_url": "sqlite:///app.db",
    "log_level": "INFO",
    "max_connections": 10,
}

#### Example

file_config = {
    "log_level": "DEBUG",
    "max_connections": 20,
}

#### Example

env_config = {
    key.replace("APP_", "").lower(): value
    for key, value in os.environ.items()
    if key.startswith("APP_")
}

#### Example

config = ChainMap(env_config, file_config, defaults)

#### Example

defaults = {"theme": "light", "language": "en"}

#### Example

try:
        with open("config.json") as f:
            file_config = json.load(f)
    except FileNotFoundError:
        file_config = {}

#### Example

Point = namedtuple("Point", "x y")
p = Point(1, 2)
print(p.x, p.y)  # 1 2
print(p)  # Point(x=1, y=2)

#### Example

Person = namedtuple("Person", "name age", defaults=["Unknown", 0])
p1 = Person("Alice")
p2 = Person("Bob", 30)

#### Example

PointNT = namedtuple("Point", "x y")
p1 = PointNT(1, 2)

#### Example

text = "Age 42 years old"
m = re.search(r"\d+", text)
if m:
    print(m.group())  # "42"
    print(m.start())  # 4
    print(m.end())    # 6

#### Example

m = re.match(r"Age", text)  # Matches only at start
if m:
    print(m.group())  # "Age"

#### Example

numbers = re.findall(r"\d+", "I have 3 cats and 2 dogs")
print(numbers)  # ['3', '2']

#### Example

for m in re.finditer(r"\d+", "I have 3 cats and 2 dogs"):
    print(f"{m.group()} at {m.start()}-{m.end()}")

#### Example

text = "John Doe, age 42"
m = re.search(r"(\w+) (\w+), age (\d+)", text)
if m:
    print(m.group(0))  # Full match: "John Doe, age 42"
    print(m.group(1))  # First group: "John"
    print(m.group(2))  # Second group: "Doe"
    print(m.group(3))  # Third group: "42"
    print(m.groups())  # All groups: ('John', 'Doe', '42')

#### Example

m = re.search(r"(?P<first>\w+) (?P<last>\w+), age (?P<age>\d+)", text)
if m:
    print(m.group('first'))  # "John"
    print(m.group('last'))   # "Doe"
    print(m.group('age'))    # "42"
    print(m.groupdict())     # {'first': 'John', 'last': 'Doe', 'age': '42'}

#### Example

email_pattern = r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}"
emails = re.findall(email_pattern, "Contact: alice@example.com or bob@test.org")

#### Example

phone_pattern = r"\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}"
phones = re.findall(phone_pattern, "Call 555-1234 or (555) 987-6543")

#### Example

url_pattern = r"https?://[^\s]+"
urls = re.findall(url_pattern, "Visit https://example.com for more info")

#### Example

text = "Hello World"
new_text = re.sub(r"World", "Python", text)
print(new_text)  # "Hello Python"

#### Example

text = "2025-11-30"
new_text = re.sub(r"(\d{4})-(\d{2})-(\d{2})", r"\3/\2/\1", text)
print(new_text)  # "27/01/2025" (US format)

#### Example

text = "Hello WORLD"
m = re.search(r"world", text, re.IGNORECASE)
print(m.group())  # "WORLD"

#### Example

text = "Line 1\nLine 2\nLine 3"
matches = re.findall(r"^Line", text, re.MULTILINE)
print(matches)  # ['Line', 'Line', 'Line']

#### Example

text = "Start\nEnd"
m = re.search(r"Start.*End", text, re.DOTALL)
print(m.group())  # "Start\nEnd"

#### Example

pattern = re.compile(r"""
    \d{3}      # Area code
    -          # Separator
    \d{3}      # Exchange
    -          # Separator
    \d{4}      # Number
""", re.VERBOSE)

#### Example

pattern = re.compile(r"\d+")

#### Example

for text in large_text_list:
    m = pattern.search(text)
    if m:
        print(m.group())

#### Example

pattern = re.compile(r"(\w+)@(\w+\.\w+)", re.IGNORECASE)
m = pattern.search("Contact: alice@example.com")
if m:
    print(m.groups())  # ('alice', 'example.com')

#### Example

start = time.perf_counter()
for _ in range(1000000):
    re.search(pattern_str, text)
uncompiled_time = time.perf_counter() - start

#### Example

start = time.perf_counter()
for _ in range(1000000):
    pattern_compiled.search(text)
compiled_time = time.perf_counter() - start

print(f"Uncompiled: {uncompiled_time:.4f}s")
print(f"Compiled:   {compiled_time:.4f}s")
print(f"Speedup:    {uncompiled_time/compiled_time:.1f}x")

#### Example

text = "Python3 Python2"
matches = re.findall(r"Python(?=\d)", text)
print(matches)  # ['Python', 'Python'] (matches Python before digit)

#### Example

matches = re.findall(r"Python(?!\d)", text)
print(matches)  # [] (no Python without digit)

#### Example

text = "$100 and ‚Ç¨50"
matches = re.findall(r"(?<=\$)\d+", text)
print(matches)  # ['100'] (number after $)

#### Example

matches = re.findall(r"(?<!\$)\d+", text)
print(matches)  # ['50'] (number not after $)

#### Example

text = "abc123 def456"

#### Example

matches = re.findall(r"(?:\w+)(\d+)", text)
print(matches)  # ['123', '456']

#### Example

text = "<tag>content</tag><tag>more</tag>"

#### Example

greedy = re.findall(r"<tag>.*</tag>", text)
print(greedy)  # ['<tag>content</tag><tag>more</tag>'] (one match)

#### Example

non_greedy = re.findall(r"<tag>.*?</tag>", text)
print(non_greedy)  # ['<tag>content</tag>', '<tag>more</tag>'] (two matches)

#### Example

pattern = re.compile(r"""
    \[(?P<timestamp>.*?)\]     # Timestamp in brackets
    \s+
    (?P<level>\w+)            # Log level
    :\s+
    (?P<message>.*?)          # Message
    \s*
    \(code:\s*(?P<code>\d+)\) # Optional error code
""", re.VERBOSE)

m = pattern.search(log_line)
if m:
    print(f"Time: {m.group('timestamp')}")
    print(f"Level: {m.group('level')}")
    print(f"Message: {m.group('message')}")
    print(f"Code: {m.group('code')}")

#### Example

print(string.ascii_letters)  # 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
print(string.ascii_lowercase)  # 'abcdefghijklmnopqrstuvwxyz'
print(string.ascii_uppercase)  # 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
print(string.digits)  # '0123456789'
print(string.hexdigits)  # '0123456789abcdefABCDEF'
print(string.octdigits)  # '01234567'
print(string.punctuation)  # '!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~'
print(string.whitespace)  # ' \t\n\r\x0b\x0c'
print(string.printable)  # All printable ASCII characters

#### Example

t = Template('Hello, $name! You have $count messages.')
result = t.substitute(name='Alice', count=5)
print(result)  # "Hello, Alice! You have 5 messages."

#### Example

result = t.safe_substitute(name='Bob')  # count missing
print(result)  # "Hello, Bob! You have $count messages."

#### Example

from string import Formatter

f = Formatter()
# Custom formatting logic
result = f.format("{name:>10} {age:03d}", name="Alice", age=5)
print(result)  # "     Alice 005"

#### Example

wrapped = textwrap.wrap(long_text, width=40)
for line in wrapped:
    print(line)

#### Example

filled = textwrap.fill(long_text, width=40)
print(filled)

#### Example

text = "This is a paragraph that needs indentation."
indented = textwrap.fill(
    text,
    width=30,
    initial_indent="  ",      # First line indent
    subsequent_indent="    "   # Subsequent lines indent
)
print(indented)

#### Example

text = "Line 1\n\nLine 2"
preserved = textwrap.fill(text, width=20, replace_whitespace=False)
print(preserved)

#### Example

# Remove common leading whitespace
text = """
    This is indented.
    So is this.
    And this too.
"""
dedented = textwrap.dedent(text)
print(dedented)
# This is indented.
# So is this.
# And this too.

#### Example

# Truncate text to fit width
long_text = "This is a very long text that needs to be shortened."
short = textwrap.shorten(long_text, width=30, placeholder="...")
print(short)  # "This is a very long..."

#### Example

text = textwrap.dedent(text).strip()

#### Example

return textwrap.fill(text, width=width, initial_indent="    ", subsequent_indent="    ")

doc = """
    This is a long docstring that explains
    what the function does in detail.
    It should be properly formatted.
"""
print(format_docstring(doc))

#### Example

s1 = ['apple', 'banana', 'cherry']
s2 = ['apple', 'berry', 'cherry']

matcher = difflib.SequenceMatcher(None, s1, s2)
ratio = matcher.ratio()
print(f"Similarity: {ratio:.2%}")  # Similarity: 66.67%

#### Example

for tag, i1, i2, j1, j2 in matcher.get_opcodes():
    print(f"{tag:7} s1[{i1}:{i2}] -> s2[{j1}:{j2}]")

#### Example

# Find closest matches
words = ['apple', 'banana', 'cherry', 'date']
target = 'appel'  # Typo for 'apple'

matches = difflib.get_close_matches(target, words, n=2, cutoff=0.6)
print(matches)  # ['apple'] (closest match)

#### Example

with open('diff.html', 'w') as f:
    f.write(html_diff)

#### Example

json_str = '{"name": "Alice", "age": 30, "city": "New York"}'
data = json.loads(json_str)
print(data["name"])  # "Alice"

#### Example

data = {"name": "Alice", "age": 30, "city": "New York"}
json_str = json.dumps(data)
print(json_str)  # '{"name": "Alice", "age": 30, "city": "New York"}'

#### Example

json_str = json.dumps(data, indent=2)
print(json_str)

#### Example

with open("data.json") as f:
    data = json.load(f)

#### Example

data = {"users": [{"name": "Alice"}, {"name": "Bob"}]}
with open("output.json", "w") as f:
    json.dump(data, f, indent=2)

#### Example

with open("data.csv") as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)  # Each row is a list

#### Example

with open("data.csv") as f:
    reader = csv.DictReader(f)
    for row in reader:
        print(row["name"], row["age"])  # Access by column name

#### Example

data = [
    ["Name", "Age", "City"],
    ["Alice", "30", "New York"],
    ["Bob", "25", "London"],
]

with open("output.csv", "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerows(data)

#### Example

fieldnames = ["name", "age", "city"]
data = [
    {"name": "Alice", "age": "30", "city": "New York"},
    {"name": "Bob", "age": "25", "city": "London"},
]

with open("output.csv", "w", newline="") as f:
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(data)

#### Example

with open("data.tsv") as f:
    reader = csv.reader(f, delimiter="\t")  # Tab-separated

#### Example

with open("data.csv") as f:
    reader = csv.reader(f, quoting=csv.QUOTE_NONNUMERIC)

#### Example

with open("data.csv") as f:
    reader = csv.reader(f, skipinitialspace=True)

#### Example

with open("data.csv", newline="") as f:  # Always use newline="" in Python 3
    reader = csv.reader(f)

#### Example

if not row.get("name") or not row.get("age"):
                    print(f"Warning: Row {i} missing required fields, skipping")
                    continue
                rows.append(row)
            except Exception as e:
                print(f"Error processing row {i}: {e}")
                continue
    return rows

data = read_csv_safe("users.csv")
for row in data:
    print(f"{row['name']}: {row['age']}")

#### Example

cfg = configparser.ConfigParser()

#### Example

cfg.read("settings.ini")

#### Example

db_host = cfg.get("database", "host")
db_port = cfg.getint("database", "port")  # Auto-convert to int
debug = cfg.getboolean("app", "debug")     # Auto-convert to bool

#### Example

cfg["database"] = {
    "host": "localhost",
    "port": "5432",
    "name": "mydb"
}
cfg["app"] = {
    "debug": "true",
    "log_level": "INFO"
}

with open("settings.ini", "w") as f:
    cfg.write(f)

#### Example

[database]
host = localhost
port = 5432
name = mydb

[app]
debug = true
log_level = INFO
timeout = 30.5

#### Example

db_host = cfg.get("database", "host", fallback="localhost")

#### Example

if cfg.has_section("database"):
    if cfg.has_option("database", "host"):
        host = cfg.get("database", "host")

#### Example

for section in cfg.sections():
    print(f"Section: {section}")
    for key, value in cfg.items(section):
        print(f"  {key} = {value}")

#### Example

tree = ET.parse("data.xml")
root = tree.getroot()

#### Example

for child in root:
    print(child.tag, child.text)

#### Example

items = root.findall("item")
for item in items:
    print(item.text)

#### Example

item = root.find("item")
if item is not None:
    print(item.text)

#### Example

root = ET.Element("users")
user1 = ET.SubElement(root, "user")
user1.set("id", "1")
name1 = ET.SubElement(user1, "name")
name1.text = "Alice"
age1 = ET.SubElement(user1, "age")
age1.text = "30"

#### Example

xml_str = ET.tostring(root, encoding="unicode")
print(xml_str)

#### Example

tree = ET.ElementTree(root)
tree.write("output.xml", encoding="utf-8", xml_declaration=True)

#### Example

items = root.findall(".//item")  # Find all 'item' elements anywhere

#### Example

items = root.findall(".//item[@id='1']")  # Items with id="1"

#### Example

for elem in root.iter():
    print(elem.tag, elem.text)

#### Example

new_root = ET.Element("transformed")
    for item in root.findall("item"):
        new_item = ET.SubElement(new_root, "entry")
        new_item.set("value", item.text)

#### Example

new_tree = ET.ElementTree(new_root)
    new_tree.write(output_file, encoding="utf-8", xml_declaration=True)

transform_xml("input.xml", "output.xml")

#### Example

data = {"name": "Alice", "items": [1, 2, 3]}
pickled = pickle.dumps(data)

#### Example

unpickled = pickle.loads(pickled)
print(unpickled)  # {'name': 'Alice', 'items': [1, 2, 3]}

#### Example

with open("data.pkl", "wb") as f:
    pickle.dump(data, f)

with open("data.pkl", "rb") as f:
    loaded = pickle.load(f)

#### Example

# Use highest protocol for efficiency (Python 3.8+)
pickled = pickle.dumps(data, protocol=pickle.HIGHEST_PROTOCOL)

# Protocol 5 (Python 3.8+) supports out-of-band data for large objects

#### Example

cache = SafePickleCache(Path(".cache"))
cache.set("user_data", {"name": "Alice"})
data = cache.get("user_data")

#### Example

result = subprocess.run(
    ["ls", "-l"],
    capture_output=True,
    text=True,
    check=True
)
print(result.stdout)
print(result.returncode)  # 0 for success

#### Example

result = subprocess.run(["echo", "Hello"], text=True)

#### Example

try:
    result = subprocess.run(
        ["command", "args"],
        capture_output=True,
        text=True,
        check=True  # Raises CalledProcessError on non-zero exit
    )
except subprocess.CalledProcessError as e:
    print(f"Command failed: {e}")
    print(f"Return code: {e.returncode}")
    print(f"Error output: {e.stderr}")

#### Example

result = subprocess.run(
    ["ls"],
    cwd="/tmp",
    capture_output=True,
    text=True
)

#### Example

env = {"PATH": "/usr/bin", "LANG": "en_US.UTF-8"}
result = subprocess.run(
    ["command"],
    env=env,
    capture_output=True,
    text=True
)

#### Example

try:
    result = subprocess.run(
        ["slow_command"],
        timeout=5.0,  # Seconds
        capture_output=True,
        text=True
    )
except subprocess.TimeoutExpired:
    print("Command timed out")

#### Example

result = subprocess.run(
    ["grep", "pattern"],
    input="line1\nline2\npattern\nline4",
    capture_output=True,
    text=True
)

#### Example

process = subprocess.Popen(
    ["command"],
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
    text=True
)

#### Example

for line in process.stdout:
    print(line.strip())

#### Example

process.wait()
if process.returncode != 0:
    error = process.stderr.read()
    print(f"Error: {error}")

#### Example

# ‚ùå NEVER DO THIS (shell injection vulnerability)
subprocess.run(f"rm {user_input}", shell=True)  # DANGEROUS!

# ‚úÖ ALWAYS DO THIS (safe)
subprocess.run(["rm", user_input])  # Safe: user_input is single argument

# ‚ùå NEVER use shell=True with user input
subprocess.run(f"ls {user_dir}", shell=True)  # DANGEROUS!

# ‚úÖ Use list form
subprocess.run(["ls", user_dir])  # Safe

#### Example

print(sys.argv)  # ['script.py', 'arg1', 'arg2']
if len(sys.argv) > 1:
    first_arg = sys.argv[1]

#### Example

sys.exit(0)   # Success
sys.exit(1)   # General error
sys.exit(2)   # Misuse of command

#### Example

raise SystemExit(1)

#### Example

sys.path.insert(0, "/custom/module/path")

#### Example

print(sys.path)

#### Example

print(sys.version)      # Detailed version info
print(sys.version_info) # (3, 12, 0, 'final', 0)

#### Example

print(sys.platform)     # 'linux', 'win32', 'darwin'

#### Example

print(sys.executable)   # Path to Python interpreter

#### Example

print(sys.byteorder)   # 'little' or 'big'

#### Example

print(sys.getrecursionlimit())  # Default: 1000
sys.setrecursionlimit(2000)     # Change limit (use carefully!)

#### Example

home = os.getenv("HOME")
path = os.getenv("PATH", "/usr/bin")  # With default

#### Example

os.environ["MY_VAR"] = "value"

#### Example

for key, value in os.environ.items():
    print(f"{key}={value}")

#### Example

cwd = os.getcwd()
os.chdir("/tmp")  # Change directory

#### Example

files = os.listdir(".")
for file in files:
    print(file)

#### Example

os.makedirs("path/to/dir", exist_ok=True)
os.rmdir("empty_dir")  # Only removes empty directories
os.removedirs("path/to/dir")  # Removes empty parent dirs too

#### Example

os.rename("old.txt", "new.txt")
os.remove("file.txt")
os.link("source", "hardlink")  # Create hard link
os.symlink("source", "symlink")  # Create symbolic link

#### Example

path = os.path.join("dir", "subdir", "file.txt")

#### Example

dirname, filename = os.path.split("/path/to/file.txt")
basename = os.path.basename("/path/to/file.txt")
dirname = os.path.dirname("/path/to/file.txt")

#### Example

name, ext = os.path.splitext("file.txt")  # ("file", ".txt")

#### Example

abs_path = os.path.abspath("relative/path")

#### Example

if os.path.exists("file.txt"):
    if os.path.isfile("file.txt"):
        print("It's a file")
    elif os.path.isdir("file.txt"):
        print("It's a directory")

#### Example

pid = os.getpid()
print(f"Process ID: {pid}")

#### Example

ppid = os.getppid()
print(f"Parent PID: {ppid}")

#### Example

uid = os.getuid()  # Current user ID
gid = os.getgid()  # Current group ID

#### Example

mode = os.stat("file.txt").st_mode
print(oct(mode))  # Permission bits

#### Example

os.chmod("file.txt", 0o755)  # rwxr-xr-x

#### Example

os.chown("file.txt", uid, gid)

#### Example

sys.exit(0)

#### Example

signal.signal(signal.SIGINT, signal_handler)

#### Example

signal.signal(signal.SIGTERM, signal_handler)

#### Example

while True:

#### Example

pass

#### Example

signal.signal(signal.SIGINT, handler)

#### Example

signal.signal(signal.SIGTERM, handler)

#### Example

signal.signal(signal.SIGHUP, handler)

#### Example

signal.signal(signal.SIGALRM, handler)

#### Example

with urlopen("https://example.com") as response:
    data = response.read()
    print(data.decode('utf-8'))

#### Example

req = Request("https://api.example.com/data")
req.add_header("User-Agent", "MyApp/1.0")
req.add_header("Authorization", "Bearer token123")

with urlopen(req) as response:
    data = response.read()

#### Example

data = urlencode({"key": "value"}).encode()
req = Request("https://api.example.com/submit", data=data)
req.add_header("Content-Type", "application/x-www-form-urlencoded")

with urlopen(req) as response:
    result = response.read()

#### Example

url = "https://example.com/path?query=value#fragment"
parsed = urlparse(url)
print(parsed.scheme)    # "https"
print(parsed.netloc)    # "example.com"
print(parsed.path)      # "/path"
print(parsed.query)     # "query=value"
print(parsed.fragment)  # "fragment"

#### Example

base = "https://example.com/api/"
relative = "users/123"
full_url = urljoin(base, relative)
print(full_url)  # "https://example.com/api/users/123"

#### Example

encoded = quote("hello world")
print(encoded)  # "hello%20world"

decoded = unquote("hello%20world")
print(decoded)  # "hello world"

#### Example

from urllib.request import urlopen
from urllib.error import URLError, HTTPError

try:
    with urlopen("https://example.com") as response:
        data = response.read()
except HTTPError as e:
    print(f"HTTP Error {e.code}: {e.reason}")
except URLError as e:
    print(f"URL Error: {e.reason}")

#### Example

s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

#### Example

s.connect(("example.com", 80))

#### Example

s.sendall(b"GET / HTTP/1.1\r\nHost: example.com\r\n\r\n")

#### Example

data = s.recv(4096)
print(data.decode())

#### Example

s.close()

#### Example

with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
    s.connect(("example.com", 80))
    s.sendall(b"GET / HTTP/1.1\r\nHost: example.com\r\n\r\n")
    data = s.recv(4096)
    print(data.decode())

#### Example

# UDP client
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
sock.sendto(b"Hello", ("example.com", 53))
data, addr = sock.recvfrom(1024)
sock.close()

#### Example

ctx = ssl.create_default_context()

#### Example

sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
secure_sock = ctx.wrap_socket(sock, server_hostname="example.com")
secure_sock.connect(("example.com", 443))

#### Example

secure_sock.sendall(b"GET / HTTP/1.1\r\nHost: example.com\r\n\r\n")
response = secure_sock.recv(4096)
print(response.decode())

secure_sock.close()

#### Example

ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE  # ‚ö†Ô∏è DANGEROUS!

#### Example

ctx = ssl.create_default_context()
ctx.load_verify_locations("/path/to/ca-bundle.crt")

#### Example

ctx.load_cert_chain("client.crt", "client.key")

#### Example

sock = socket.create_connection((parsed.hostname, 443))
    secure_sock = ctx.wrap_socket(sock, server_hostname=parsed.hostname)
    
    try:

#### Example

request = f"GET {parsed.path or '/'} HTTP/1.1\r\nHost: {parsed.hostname}\r\n\r\n"
        secure_sock.sendall(request.encode())

#### Example

response = secure_sock.recv(4096)
        return response
    finally:
        secure_sock.close()

#### Example

response = secure_get("https://example.com")
print(response.decode()[:200])

#### Example

with zipfile.ZipFile("archive.zip") as z:
    print(z.namelist())  # List of file names
    print(z.infolist())  # List of ZipInfo objects

#### Example

z.extractall("extract_to/")

#### Example

z.extract("file.txt", "extract_to/")

#### Example

content = z.read("file.txt")
    print(content.decode('utf-8'))

#### Example

with zipfile.ZipFile("output.zip", "w", zipfile.ZIP_DEFLATED) as z:
    z.write("file1.txt")
    z.write("file2.txt", "renamed.txt")  # Rename in archive
    z.writestr("data.txt", "Content as string")

#### Example

with zipfile.ZipFile("archive.zip", "w", zipfile.ZIP_STORED) as z:

#### Example

z.write("file.txt")

with zipfile.ZipFile("archive.zip", "w", zipfile.ZIP_DEFLATED) as z:

#### Example

z.write("file.txt")

with zipfile.ZipFile("archive.zip", "w", zipfile.ZIP_BZIP2) as z:

#### Example

z.write("file.txt")

with zipfile.ZipFile("archive.zip", "w", zipfile.ZIP_LZMA) as z:

#### Example

z.write("file.txt")

#### Example

with zipfile.ZipFile("secure.zip", "w") as z:
    z.write("file.txt", pwd=b"password123")

#### Example

with zipfile.ZipFile("secure.zip") as z:
    z.extractall(pwd=b"password123")

#### Example

with tarfile.open("data.tar.gz", "r:gz") as t:
    t.extractall("extract_to/")

#### Example

for member in t.getmembers():
        print(f"{member.name} ({member.size} bytes)")

#### Example

with tarfile.open("data.tar", "r") as t:      # Uncompressed
    t.extractall()

with tarfile.open("data.tar.gz", "r:gz") as t:  # Gzip
    t.extractall()

with tarfile.open("data.tar.bz2", "r:bz2") as t:  # Bzip2
    t.extractall()

with tarfile.open("data.tar.xz", "r:xz") as t:  # XZ
    t.extractall()

#### Example

with tarfile.open("output.tar.gz", "w:gz") as t:
    t.add("file1.txt")
    t.add("file2.txt", arcname="renamed.txt")  # Rename in archive
    t.add("directory/", recursive=True)  # Add directory

#### Example

with tarfile.open("archive.tar", "w") as t:      # Uncompressed
    t.add("file.txt")

with tarfile.open("archive.tar.gz", "w:gz") as t:  # Gzip (common)
    t.add("file.txt")

with tarfile.open("archive.tar.bz2", "w:bz2") as t:  # Bzip2
    t.add("file.txt")

#### Example

with open("file.txt", "rb") as f_in:
    with gzip.open("file.txt.gz", "wb") as f_out:
        f_out.writelines(f_in)

#### Example

with gzip.open("file.txt.gz", "rb") as f_in:
    with open("file.txt", "wb") as f_out:
        f_out.writelines(f_in)

#### Example

with gzip.open("file.txt.gz", "rt") as f:
    text = f.read()
    print(text)

#### Example

with gzip.open("file.txt.gz", "wb", compresslevel=9) as f:
    f.write(b"data")

#### Example

import bz2

# Compress
with open("file.txt", "rb") as f_in:
    with bz2.open("file.txt.bz2", "wb") as f_out:
        f_out.writelines(f_in)

# Decompress
with bz2.open("file.txt.bz2", "rb") as f:
    data = f.read()

#### Example

import lzma

# Compress
with open("file.txt", "rb") as f_in:
    with lzma.open("file.txt.xz", "wb") as f_out:
        f_out.writelines(f_in)

# Decompress
with lzma.open("file.txt.xz", "rb") as f:
    data = f.read()

#### Example

import gzip
import bz2
import lzma

data = b"x" * 1000000  # 1MB of data

# Gzip
with gzip.open("test.gz", "wb") as f:
    f.write(data)
gz_size = Path("test.gz").stat().st_size

# Bzip2
with bz2.open("test.bz2", "wb") as f:
    f.write(data)
bz2_size = Path("test.bz2").stat().st_size

# LZMA
with lzma.open("test.xz", "wb") as f:
    f.write(data)
xz_size = Path("test.xz").stat().st_size

print(f"Original: 1,000,000 bytes")
print(f"Gzip:     {gz_size:,} bytes")
print(f"Bzip2:    {bz2_size:,} bytes")
print(f"LZMA:     {xz_size:,} bytes")

#### Example

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

logger = logging.getLogger(__name__)

#### Example

logger.debug("Debug message")      # Not shown (level=INFO)
logger.info("Info message")        # Shown
logger.warning("Warning message")   # Shown
logger.error("Error message")       # Shown
logger.critical("Critical message") # Shown

#### Example

logger = logging.getLogger("myapp")
logger.setLevel(logging.DEBUG)

#### Example

console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_format = logging.Formatter('%(levelname)s - %(message)s')
console_handler.setFormatter(console_format)

#### Example

file_handler = RotatingFileHandler(
    "app.log",
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5
)
file_handler.setLevel(logging.DEBUG)
file_format = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
file_handler.setFormatter(file_format)

#### Example

logger.addHandler(console_handler)
logger.addHandler(file_handler)

#### Example

logger.info("Application started")
logger.error("An error occurred", exc_info=True)  # Include traceback

#### Example

logger.info("Processing request", extra={
    "user_id": 123,
    "request_id": "abc-123",
    "endpoint": "/api/users"
})

#### Example

pprint(data)

#### Example

pprint(data, width=40, indent=2, depth=2)

#### Example

traceback.print_exc()

#### Example

tb_str = traceback.format_exc()
    print(f"Traceback:\n{tb_str}")

#### Example

exc_type, exc_value, exc_tb = sys.exc_info()
    tb_lines = traceback.format_exception(exc_type, exc_value, exc_tb)
    print(''.join(tb_lines))

#### Example

sig = inspect.signature(example)
print(sig)  # (a: int, b: str = 'default', *args, **kwargs) -> str

#### Example

for name, param in sig.parameters.items():
    print(f"{name}: {param.annotation} = {param.default}")

#### Example

source = inspect.getsource(example)
print(source)

#### Example

file = inspect.getfile(example)
line = inspect.getsourcelines(example)[1]
print(f"Defined in {file}:{line}")

#### Example

members = inspect.getmembers(MyClass)
for name, value in members:
    print(f"{name}: {type(value)}")

#### Example

print(inspect.iscallable(MyClass))  # True

#### Example

print(inspect.getmro(MyClass))  # MRO tuple

#### Example

tracemalloc.start()

#### Example

data = [i**2 for i in range(100_000)]
result = sum(data)

#### Example

current, peak = tracemalloc.get_traced_memory()
print(f"Current: {current / 1024 / 1024:.2f} MB")
print(f"Peak: {peak / 1024 / 1024:.2f} MB")

#### Example

tracemalloc.stop()

#### Example

data = [list(range(1000)) for _ in range(1000)]

#### Example

result = sum(len(item) for item in data)
    
    return result

#### Example

result = process_data()

#### Example

snapshot = tracemalloc.take_snapshot()

#### Example

top_stats = snapshot.statistics('lineno')

print("Top 10 memory allocations:")
for index, stat in enumerate(top_stats[:10], 1):
    print(f"{index}. {stat}")

#### Example

print("\nTraceback for largest allocation:")
top_stat = top_stats[0]
for line in top_stat.traceback.format():
    print(line)

#### Example

Top 10 memory allocations:
1. <frozen importlib._bootstrap>:538: 8.2 MB
2. /path/to/script.py:5: 7.6 MB
3. <frozen importlib._bootstrap_external>:883: 2.1 MB
...

Traceback for largest allocation:
  File "/path/to/script.py", line 5
    data = [list(range(1000)) for _ in range(1000)]

#### Example

snapshot1 = tracemalloc.take_snapshot()

#### Example

for _ in range(10):
    create_objects()

#### Example

snapshot2 = tracemalloc.take_snapshot()

#### Example

top_stats = snapshot2.compare_to(snapshot1, 'lineno')

print("Top 10 differences:")
for stat in top_stats[:10]:
    print(stat)

tracemalloc.stop()

#### Example

data = process_large_dataset()

snapshot = tracemalloc.take_snapshot()

#### Example

filtered = snapshot.filter_traces([
    tracemalloc.Filter(True, __file__),  # Only current file
])

top_stats = filtered.statistics('lineno')
print("Memory allocations in current file:")
for stat in top_stats[:5]:
    print(stat)

tracemalloc.stop()

#### Example

class Point:
    __slots__ = ("x", "y")

#### Example

sizes = [1_000, 10_000, 100_000, 1_000_000, 10_000_000]

print("Array Size | Python Loop | NumPy (tolist) | NumPy (inplace) | Speedup")
print("-" * 75)

for n in sizes:
    py_time = benchmark(python_loop, n)
    np_time = benchmark(numpy_vectorized, n)
    np_inplace_time = benchmark(numpy_inplace, n)
    
    speedup = py_time / np_inplace_time
    
    print(f"{n:>10,} | {py_time:>10.4f}s | {np_time:>13.4f}s | "
          f"{np_inplace_time:>15.4f}s | {speedup:>6.1f}√ó")

#### Example

sizes = [100, 500, 1000, 2000]

print("Matrix Size | NumPy (optimized) | Pure Python (estimated)")
print("-" * 60)

for n in sizes:

#### Example

a = np.random.rand(n, n)
    b = np.random.rand(n, n)
    
    start = time.perf_counter()
    c = np.dot(a, b)
    np_time = time.perf_counter() - start

#### Example

estimated_py_time = (n ** 3) * 1e-8
    
    speedup = estimated_py_time / np_time if np_time > 0 else float('inf')
    
    print(f"{n:>10}√ó{n:<3} | {np_time:>18.4f}s | {estimated_py_time:>25.1f}s "
          f"({speedup:.0f}√ó faster)")

#### Example

arr = np.arange(1_000_000, dtype=np.float64)
result = fast_sum(arr)  # Compilation overhead on first call

#### Example

result = fast_sum(arr)  # Fast!

#### Example

arr = np.arange(10_000_000, dtype=np.float64)

#### Example

start = time.perf_counter()
python_sum(arr)
py_time = time.perf_counter() - start

#### Example

start = time.perf_counter()
numpy_sum(arr)
np_time = time.perf_counter() - start

#### Example

numba_sum(arr)  # Warmup
start = time.perf_counter()
numba_sum(arr)
nb_time = time.perf_counter() - start

print(f"Python: {py_time:.4f}s")
print(f"NumPy:  {np_time:.4f}s ({py_time/np_time:.1f}√ó faster)")
print(f"Numba:  {nb_time:.4f}s ({py_time/nb_time:.1f}√ó faster)")

#### Example

# math_ops.pyx
cpdef int add(int x, int y):
    return x + y

cpdef double fast_sum(double[:] arr):
    cdef double total = 0.0
    cdef int i
    for i in range(len(arr)):
        total += arr[i]
    return total

#### Example

// src/lib.rs
use pyo3::prelude::*;

#[pyfunction]
fn fast_sum(py: Python, arr: &PyArray1<f64>) -> PyResult<f64> {
    let array = unsafe { arr.as_array() };
    Ok(array.sum())
}

#[pymodule]
fn my_ext(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(fast_sum, m)?)?;
    Ok(())
}

#### Example

# After building Rust extension: import my_ext
# result = my_ext.fast_sum(arr)

# Typical Results:
# Python:  0.8500s (1.0√ó baseline)
# NumPy:   0.0020s (425√ó faster)
# Rust:    0.0008s (1063√ó faster)

#### Example

pip install maturin

#### Example

maturin init --name my_ext

#### Example

maturin develop

#### Example

start = time.perf_counter()
results = [cpu_task(1_000_000) for _ in range(8)]
single_time = time.perf_counter() - start

#### Example

start = time.perf_counter()
with ProcessPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(cpu_task, [1_000_000] * 8))
multi_time = time.perf_counter() - start

print(f"Single process: {single_time:.2f}s")
print(f"4 processes:    {multi_time:.2f}s")
print(f"Speedup:        {single_time/multi_time:.2f}√ó")

#### Example

username = request.form['username']
cur.execute(f"SELECT * FROM users WHERE name='{username}'")

#### Example

cur.execute("SELECT * FROM users WHERE name=?", (username,))

#### Example

cur.execute("SELECT * FROM users WHERE name=:name", {"name": username})

#### Example

# ‚úÖ SAFE: SQLAlchemy ORM (automatic parameterization)
user = session.query(User).filter(User.name == username).first()

# ‚úÖ SAFE: SQLAlchemy Core with parameters
stmt = select(User).where(User.name == bindparam('name'))
result = session.execute(stmt, {'name': username})

#### Example

# ‚ùå VULNERABLE
os.system(f"rm -rf {user_input}")  # Command injection!

# ‚úÖ SAFE: Use subprocess without shell
subprocess.run(['rm', '-rf', user_input], check=True)

# ‚úÖ SAFE: Validate input first
if not user_input.isalnum():
    raise ValueError("Invalid input")
subprocess.run(['command', user_input])

#### Example

# ‚ùå VULNERABLE: Jinja2 autoescape off
template = jinja2.Template(user_input, autoescape=False)

# ‚úÖ SAFE: Autoescape enabled (default)
template = jinja2.Template(user_input)  # autoescape=True by default

# ‚úÖ SAFE: Sandboxed rendering
from jinja2.sandbox import SandboxedEnvironment
env = SandboxedEnvironment()
template = env.from_string(user_input)

#### Example

data = yaml.load(user_input)  # Can execute arbitrary code!

#### Example

data = yaml.safe_load(user_input)  # Only loads basic types

#### Example

[pytest]
markers =
    slow: marks tests as slow
    integration: marks tests as integration tests
    unit: marks tests as unit tests

#### Example

from unittest.mock import Mock, MagicMock

# Basic mock
mock_obj = Mock()
mock_obj.method.return_value = 42
assert mock_obj.method() == 42

# Verify calls
mock_obj.method.assert_called_once()
mock_obj.method.assert_called_with(1, 2, key="value")

#### Example

pip install coverage pytest-cov

#### Example

pytest --cov=src --cov-report=html

#### Example

pytest --cov=src --cov-report=term-missing

#### Example

pytest --cov=src --cov-report=xml

#### Example

[run]
source = src
omit = 
    */tests/*
    */venv/*
    */migrations/*

[report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError

#### Example

# pytest.ini or pyproject.toml
[tool.pytest.ini_options]
addopts = "--cov=src --cov-fail-under=80"

#### Example

tests/
  conftest.py          # Shared fixtures
  unit/
    test_models.py
    test_utils.py
  integration/
    test_api.py
    test_database.py
  e2e/
    test_workflows.py

#### Example

PYTHONBREAKPOINT=0 python script.py

#### Example

PYTHONBREAKPOINT=ipdb.set_trace python script.py

#### Example

pip install ipdb

#### Example

{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Python: FastAPI",
            "type": "debugpy",
            "request": "launch",
            "module": "uvicorn",
            "args": ["main:app", "--reload"],
            "jinja": true,
            "justMyCode": false
        }
    ]
}

#### Example

debugpy.listen(5678)
print("Waiting for debugger to attach...")
debugpy.wait_for_client()  # Optional: wait for connection

#### Example

{
    "name": "Python: Remote Attach",
    "type": "debugpy",
    "request": "attach",
    "connect": {
        "host": "localhost",
        "port": 5678
    },
    "pathMappings": [
        {
            "localRoot": "${workspaceFolder}",
            "remoteRoot": "/app"
        }
    ]
}

#### Example

import logging

# Development
logging.basicConfig(level=logging.DEBUG)

# Production
logging.basicConfig(level=logging.INFO)

#### Example

kernprof -l -v script.py

#### Example

import tracemalloc

tracemalloc.start()

# Your code
data = process_large_dataset()

snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

print("Top 10 memory allocations:")
for stat in top_stats[:10]:
    print(stat)

#### Example

python -m memory_profiler script.py

#### Example

p1 = Process(target=compute, args=("Worker-1", range(1000000)))
    p2 = Process(target=compute, args=("Worker-2", range(1000000, 2000000)))

#### Example

p1.start()
    p2.start()

#### Example

p1.join()
    p2.join()
    
    print("All processes completed")

#### Example

p = Process(target=worker, args=("Worker", queue))
    p.start()

#### Example

while True:
        result = queue.get()
        if result is None:
            break
        print(result)
    
    p.join()

#### Example

p = Process(target=compute, args=("test",))

#### Example

print(p.name)        # Process name
print(p.pid)         # Process ID (None before start)
print(p.is_alive())  # Check if running
print(p.daemon)      # Daemon flag

#### Example

p.start()
p.join(timeout=5.0)  # Wait with timeout

#### Example

if p.is_alive():
    p.terminate()
    p.join()

#### Example

data = file_path.read_text()
    result = len(data.split())
    return result

if __name__ == "__main__":
    files = list(Path("data").glob("*.txt"))
    processes = []

#### Example

for file_path in files:
        p = Process(target=process_file, args=(file_path,))
        p.start()
        processes.append(p)

#### Example

for p in processes:
        p.join()
    
    print("All files processed")

#### Example

with ProcessPoolExecutor(max_workers=4) as executor:

#### Example

futures = [executor.submit(expensive_computation, n) for n in data]

#### Example

for future in as_completed(futures):
            result = future.result()
            print(f"Result: {result}")

#### Example

with ProcessPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(expensive_computation, data))
    print(results)

#### Example

try:
    with ProcessPoolExecutor() as executor:
        results = list(executor.map(
            expensive_computation,
            data,
            timeout=30.0  # Total timeout for all tasks
        ))
except TimeoutError:
    print("Some tasks timed out")

#### Example

start = time.perf_counter()
with ThreadPoolExecutor(max_workers=4) as executor:
    list(executor.map(cpu_task, data))
thread_time = time.perf_counter() - start

#### Example

start = time.perf_counter()
with ProcessPoolExecutor(max_workers=4) as executor:
    list(executor.map(cpu_task, data))
process_time = time.perf_counter() - start

print(f"ThreadPool: {thread_time:.2f}s")
print(f"ProcessPool: {process_time:.2f}s")
print(f"Speedup: {thread_time/process_time:.2f}x")

#### Example

counter = Value('i', 0)  # 'i' = integer type
    lock = multiprocessing.Lock()

#### Example

processes = [
        Process(target=increment_counter, args=(counter, lock))
        for _ in range(4)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print(f"Final counter value: {counter.value}")  # Should be 400000

#### Example

shared_arr = Array('i', [1, 2, 3, 4, 5, 6, 7, 8])

#### Example

p1 = Process(target=square_array, args=(shared_arr, 0, 4))
    p2 = Process(target=square_array, args=(shared_arr, 4, 8))
    
    p1.start()
    p2.start()
    p1.join()
    p2.join()
    
    print(list(shared_arr))  # [1, 4, 9, 16, 25, 36, 49, 64]

#### Example

'i'  # signed int (32-bit)
'f'  # float (32-bit)
'd'  # double/float (64-bit)
'c'  # char (1-byte)
'b'  # signed char
'B'  # unsigned char
'h'  # short
'H'  # unsigned short
'l'  # long
'L'  # unsigned long
'q'  # long long
'Q'  # unsigned long long

#### Example

arr = Array('f', [1.0, 2.0, 3.0])  # Float array
val = Value('d', 3.14159)           # Double precision float

#### Example

processes = [
        Process(target=compute_row, args=(shared_matrix, r, cols, lock))
        for r in range(rows)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()

#### Example

result = [shared_matrix[i] for i in range(rows * cols)]
    print(f"Computed {len(result)} values")

#### Example

manager = Manager()

# Available types
shared_dict = manager.dict()
shared_list = manager.list()
shared_namespace = manager.Namespace()
shared_queue = manager.Queue()
shared_lock = manager.Lock()
shared_event = manager.Event()
shared_semaphore = manager.Semaphore(5)
shared_barrier = manager.Barrier(4)

#### Example

result = task * 2
        result_dict[task] = result
        print(f"Worker {worker_id} processed task {task}")

if __name__ == "__main__":
    manager = Manager()
    task_queue = manager.Queue()
    result_dict = manager.dict()

#### Example

for i in range(20):
        task_queue.put(i)

#### Example

num_workers = 4
    for _ in range(num_workers):
        task_queue.put(None)

#### Example

workers = [
        Process(target=worker, args=(task_queue, result_dict, i))
        for i in range(num_workers)
    ]
    
    for w in workers:
        w.start()
    for w in workers:
        w.join()
    
    print(f"Results: {dict(result_dict)}")

#### Example

with ProcessPoolExecutor() as executor:
    results = executor.map(process, [large_data] * 10)

#### Example

data = load_data_slice(start_idx, end_idx)
    return process(data)

#### Example

# ‚ùå BAD: Without main guard (Windows/spawn mode)
p = Process(target=worker)
p.start()  # May re-import module, causing infinite loop!

# ‚úÖ CORRECT: Always guard
if __name__ == "__main__":
    p = Process(target=worker)
    p.start()
    p.join()

#### Example

print(multiprocessing.get_start_method())  # 'fork', 'spawn', or 'forkserver'

#### Example

result = expensive_computation(task)
            print(f"Processed: {result}")
    
    queue = Queue()
    p = Process(target=worker, args=(queue,))
    p.start()

#### Example

for task in range(10):
        queue.put(task)
    queue.put(None)  # Sentinel
    
    p.join()

#### Example

service = UserService(InMemoryUserRepository())

#### Example

service = UserService(SQLUserRepository(db))

#### Example

service = Service(Database())

#### Example

return {"id": user_id, "name": "Alice"}

#### Example

return UserResponse(id=user_id, name="Alice")

#### Example

docstring ::= STRING_LITERAL
suite ::= docstring? statement*

#### Example

print(greet.__doc__)  # Returns: "Return a greeting message for the given name."

#### Example

flowchart LR
    A[Docstring in Source File] --> B[Python Runtime __doc__]
    B --> C[inspect.getdoc]
    C --> D[LSP Server / Editor]
    D --> E[IDE Tooltip Docs]
    B --> F[Sphinx / MkDocs Generators]
    B --> G[Doctest Runner]
    B --> H[LLM / RAG Processing Layer]

#### Example

# ‚úÖ CORRECT: Module-level docstring
"""Authentication utilities for login and password validation.

This module provides core authentication functionality including
user credential validation, session management, and token generation.
"""

import hashlib
import secrets

#### Example

print(YourClass.__doc__)
print(YourClass.method.__doc__)

#### Example

# ‚úÖ CORRECT: GitHub Actions workflow for docstring linting
- name: Docstring Lint
  run: |
    pip install pydocstyle
    pydocstyle src/

#### Example

# .pydocstyle.ini
[pydocstyle]
convention = google
add-ignore = D100,D104
match-dir = (?!tests)[^\.].*

#### Example

# ‚úÖ CORRECT: Docstring coverage enforcement
- name: Check Docstring Coverage
  run: |
    pip install interrogate
    interrogate src/ --fail-under 95 --verbose

#### Example

# conf.py
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.napoleon',  # Enables Google/NumPy style parsing
    'sphinx.ext.doctest',
]

napoleon_google_docstring = True
napoleon_numpy_docstring = False

#### Example

python -m doctest mymodule.py -v

#### Example

python -m pytest --doctest-modules

#### Example

‚ü®stmt, œÉ‚ü© ‚Üí œÉ'    (statement transforms state)

or

‚ü®expr, œÉ‚ü© ‚Üí ‚ü®v, œÉ'‚ü©    (expression evaluates to value, may modify state)

#### Example

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-Assign]
‚ü®expr, œÉ‚ü© ‚Üí ‚ü®v, œÉ'‚ü©    œÉ'[name ‚Ü¶ v] = œÉ''
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name = expr, œÉ‚ü© ‚Üí œÉ''

#### Example

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-App]
‚ü®g(), œÉ‚ü© ‚Üí v‚ÇÅ    ‚ü®h(), œÉ'‚ü© ‚Üí v‚ÇÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®f(g(), h()), œÉ‚ü© ‚Üí ‚ü®f(v‚ÇÅ, v‚ÇÇ), œÉ''‚ü©

#### Example

Step 1: ‚ü®g(), œÉ‚ü© ‚Üí v‚ÇÅ
Step 2: ‚ü®h(), œÉ‚ü© ‚Üí v‚ÇÇ  
Step 3: ‚ü®f(v‚ÇÅ, v‚ÇÇ), œÉ‚ü© ‚Üí result

Final: ‚ü®f(g(), h()), œÉ‚ü© ‚Üí result

#### Example

resolve(name, Env) = 
  if name ‚àà dom(Env_local):
    Env_local[name]
  else if name ‚àà dom(Env_enclosing):
    Env_enclosing[name]
  else if name ‚àà dom(Env_global):
    Env_global[name]
  else if name ‚àà dom(Builtins):
    Builtins[name]
  else:
    NameError

#### Example

Env = Env_local ‚äé Env_enclosing ‚äé Env_global ‚äé Builtins

where ‚äé denotes environment union (with precedence: local > enclosing > global > builtins)

#### Example

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Local]
name ‚àà dom(Env_local)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí Env_local[name]

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Enclosing]
name ‚àâ dom(Env_local)    name ‚àà dom(Env_enclosing)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí Env_enclosing[name]

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Global]
name ‚àâ dom(Env_local ‚à™ Env_enclosing)    name ‚àà dom(Env_global)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí Env_global[name]

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Builtin]
name ‚àâ dom(Env_local ‚à™ Env_enclosing ‚à™ Env_global)    name ‚àà dom(Builtins)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí Builtins[name]

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Error]
name ‚àâ dom(Env_local ‚à™ Env_enclosing ‚à™ Env_global ‚à™ Builtins)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí NameError("name 'name' is not defined")

#### Example

Closure = (code, Env_captured)

where:
  code = function body (AST or bytecode)
  Env_captured = {free_var ‚Ü¶ reference}  (free variables from enclosing scope)

#### Example

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-ClosureApp]
‚ü®closure(code, Env_captured), Env‚ü© ‚Üí fun_obj
‚ü®arg, Env‚ü© ‚Üí v
Env_new = Env_captured ‚à™ {param ‚Ü¶ v}  (extend with argument)
‚ü®code, Env_new‚ü© ‚Üí result
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®closure(code, Env_captured)(arg), Env‚ü© ‚Üí result

#### Example

Typing Judgment: Œì ‚ä¢ e : œÑ

where:
  Œì = {x‚ÇÅ : œÑ‚ÇÅ, x‚ÇÇ : œÑ‚ÇÇ, ...}  (typing environment)
  e = expression
  œÑ = type

#### Example

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-Eq]
‚ü®obj.__eq__(other), œÉ‚ü© ‚Üí ‚ü®True, œÉ'‚ü©    or    ‚ü®False, œÉ'‚ü©
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®obj == other, œÉ‚ü© ‚Üí ‚ü®obj.__eq__(other), œÉ‚ü©

Properties:
  - Reflexive: ‚àÄx. x == x
  - Symmetric: x == y ‚ü∫ y == x
  - Transitive: (x == y) ‚àß (y == z) ‚üπ (x == z)
  - Not guaranteed: objects may violate these (bad practice)

#### Example

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-Lt]
‚ü®obj.__lt__(other), œÉ‚ü© ‚Üí ‚ü®True, œÉ'‚ü©    or    ‚ü®False, œÉ'‚ü©
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®obj < other, œÉ‚ü© ‚Üí ‚ü®obj.__lt__(other), œÉ‚ü©

Properties:
  - Partial: Not all objects are comparable
  - If comparable: must satisfy transitivity, antisymmetry
  - TypeError raised if objects are not comparable

#### Example

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-Hash]
‚ü®obj.__hash__(), œÉ‚ü© ‚Üí ‚ü®h, œÉ'‚ü©    h ‚àà ‚Ñ§
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®hash(obj), œÉ‚ü© ‚Üí ‚ü®h, œÉ'‚ü©

Invariant (for hashable objects):
  obj‚ÇÅ == obj‚ÇÇ ‚üπ hash(obj‚ÇÅ) == hash(obj‚ÇÇ)
  
Violation raises TypeError at runtime.

#### Example

graph TD
    Arena[Arena 256 KiB or 1 MiB] --> Pool0[Pool 0 4 KiB<br/>Block, Block, Block, ...]
    Arena --> Pool1[Pool 1 4 KiB<br/>...]
    Arena --> PoolN[Pool N 4 KiB<br/>...]
    
    Pool0 --> Blocks0[Blocks organized by size class<br/>8, 16, 24, 32, ... up to 512 bytes]
    Pool1 --> Blocks1[Blocks organized by size class]
    PoolN --> BlocksN[Blocks organized by size class]
    
    style Arena fill:#e1f5ff
    style Pool0 fill:#ffe1f5
    style Pool1 fill:#e1ffe1
    style PoolN fill:#fff4e1

#### Example

PYTHONMALLOCSTATS=1 python script.py

#### Example

PYTHONMALLOC=debug python script.py

#### Example

PYTHONMALLOC=malloc python script.py

#### Example

if hasattr(sys, 'getallocatedblocks'):
    blocks = sys.getallocatedblocks()
    print(f"Allocated blocks: {blocks}")

#### Example

flowchart TD
    Orchestrator[Orchestrator] --> Architect[Architect]
    Orchestrator --> Reviewer[Reviewer]
    Orchestrator --> Tester[Tester]
    
    Architect --> Refactorer[Refactorer]
    Reviewer --> Security[Security]
    Tester --> Docs[Docs]
    
    Refactorer --> SharedMemory[Shared Memory<br/>Vector Store, Context]
    Security --> SharedMemory
    Docs --> SharedMemory
    
    style Orchestrator fill:#e1f5ff
    style SharedMemory fill:#fff4e1

#### Example

arch_result = self.agents[AgentRole.ARCHITECT].execute(
            task, {"phase": "design"}
        )
        results[AgentRole.ARCHITECT] = arch_result.content
        self.shared_memory.append(arch_result)

#### Example

code = self._generate_code(task, arch_result.content)

#### Example

review_result = self.agents[AgentRole.REVIEWER].execute(
            "Review code", {"code": code, "task": task}
        )
        results[AgentRole.REVIEWER] = review_result.content

#### Example

security_result = self.agents[AgentRole.SECURITY].execute(
            "Security audit", {"code": code}
        )
        results[AgentRole.SECURITY] = security_result.content

#### Example

test_result = self.agents[AgentRole.TESTER].execute(
            "Generate tests", {"code": code, "task": task}
        )
        results[AgentRole.TESTER] = test_result.content

#### Example

orchestrator = MultiAgentOrchestrator([
    ArchitectAgent(AgentRole.ARCHITECT, llm_client=None, tools=[]),
    ReviewerAgent(AgentRole.REVIEWER, llm_client=None, tools=[], 
                  rules=["no_global_state", "type_hints_required"]),
    TesterAgent(AgentRole.TESTER, llm_client=None, tools=[]),
    SecurityAgent(AgentRole.SECURITY, llm_client=None, tools=[]),
])

results = orchestrator.execute_workflow("Create user authentication system")
for role, result in results.items():
    print(f"{role.value}: {result}")

#### Example

thought = self._think(observation, self.steps)

#### Example

action, action_input = self._decide_action(thought)
            
            if action == "FINISH":
                return self._extract_answer(thought)

#### Example

if action in self.tools:
                observation = str(self.tools[action](**action_input))
            else:
                observation = f"Unknown action: {action}"

#### Example

return "Tests passed"

tools = [
    Tool(name="search_codebase", func=search_codebase, 
         description="Search codebase for code patterns"),
    Tool(name="run_tests", func=run_tests,
         description="Run the test suite"),
]

#### Example

result = executor.invoke({"input": "Review the authentication module"})

#### Example

architect = Agent(
    role="Software Architect",
    goal="Design scalable Python systems",
    backstory="Expert in Python architecture and design patterns",
    tools=[DirectoryReadTool()],
    verbose=True
)

reviewer = Agent(
    role="Code Reviewer",
    goal="Ensure code quality and pattern compliance",
    backstory="Strict reviewer enforcing best practices",
    tools=[FileReadTool()],
    verbose=True
)

tester = Agent(
    role="Test Engineer",
    goal="Generate comprehensive test coverage",
    backstory="Expert in Python testing frameworks",
    verbose=True
)

#### Example

design_task = Task(
    description="Design a user authentication system",
    agent=architect,
    expected_output="Architecture document with component breakdown"
)

review_task = Task(
    description="Review the authentication implementation",
    agent=reviewer,
    expected_output="Review report with violations and recommendations"
)

test_task = Task(
    description="Generate tests for authentication",
    agent=tester,
    expected_output="Test suite with unit and integration tests"
)

#### Example

crew = Crew(
    agents=[architect, reviewer, tester],
    tasks=[design_task, review_task, test_task],
    verbose=True
)

#### Example

result = crew.kickoff()

#### Example

issues = self.agents["analyzer"](code)

#### Example

cleaned = self.agents["refactorer"](code, issues)

#### Example

return True

#### Example

if "read" in task.lower() and "file" in task.lower():

#### Example

agent = PythonToolAgent(llm_client=None, db_path="app.db")
result = agent.execute_with_tools("Read config.json and show database schema")

#### Example

if failures >= threshold:
                if time.time() - last_failure_time < timeout:
                    raise Exception("Circuit breaker is OPEN")
                else:

#### Example

try:
            return self._execute_primary(task)
        except Exception as e:
            error_type = self._classify_error(e)

#### Example

agent = ResilientAgent(llm_client=None, tools={})
result = agent.execute_with_recovery("Process user data")

#### Example

if cache_key in self.cache:
            entry = self.cache[cache_key]
            if datetime.now() - entry.timestamp < self.cache_ttl:
                logging.info(f"Cache hit for: {task[:50]}")
                return entry.result

#### Example

result, cost, tokens = self._call_llm_with_metrics(task)

#### Example

combined_prompt = "\n\n".join([
            f"Task {i+1}: {task}" for i, task in enumerate(tasks)
        ])

#### Example

result, cost, tokens = self._call_llm_with_metrics(combined_prompt)

#### Example

results = result.split("\n\n")

#### Example

return 0.0

#### Example

agent = CostOptimizedAgent(llm_client=None)

#### Example

result1 = agent.execute_cached("Analyze code quality")

#### Example

tasks = [
    "Review function A",
    "Review function B",
    "Review function C",
]
results = agent.batch_execute(tasks)

#### Example

summary = agent.get_cost_summary()
print(f"Total cost: ${summary['total_cost']:.4f}")
print(f"Total tokens: {summary['total_tokens']:,}")

#### Example

result = executor.invoke(
    {"input": "Review the authentication module in src/auth.py"},
    config={"callbacks": [StreamingStdOutCallbackHandler()]}
)

#### Example

memory = ConversationSummaryBufferMemory(
    llm=llm,
    max_token_limit=2000,
    return_messages=True
)

#### Example

return f"Dependencies for {file_path}"

#### Example

response = agent.chat("Find all authentication-related code")

#### Example

codebase_tool = CodebaseTool("src")

#### Example

response = agent.chat("Read the main.py file and list all Python files in src/")

#### Example

expected = snapshot_path.read_text()
            if generated_code.strip() == expected.strip():
                return True
            else:
                print(f"Snapshot mismatch for: {task}")
                return False
        else:

#### Example

tree = ast.parse(code)
            exec(compile(tree, "<string>", "exec"))

#### Example

func_name = self._extract_function_name(tree)
            func = locals()[func_name]

#### Example

API_URL = "https://example.com"
TIMEOUT = 30
DEBUG = False

#### Example

return create_connection()

#### Example

db1 = DatabaseConnection()
db2 = DatabaseConnection()
assert db1 is db2  # Same instance

#### Example

settings = {"debug": False}

#### Example

if config.debug:
        enable_debug_mode()
    return app

#### Example

config = Config(api_url="https://api.example.com", timeout=30)
app = create_app(config)  # Explicit dependency

#### Example

config = DatabaseConfig(host="localhost", port=5432, database="mydb")
db = create_database("postgresql", config)
db.connect()

#### Example

db = create_database()
logger = create_logger()
user_service = create_user_service(db, logger)  # Explicit dependencies

#### Example

sig = inspect.signature(factory)
            kwargs = {}
            for param_name, param in sig.parameters.items():
                if param.annotation != inspect.Parameter.empty:
                    kwargs[param_name] = self.resolve(param.annotation)
            return factory(**kwargs)
        
        raise ValueError(f"Service {service_type} not registered")

#### Example

container = AutoContainer()
container.register_singleton(Database, create_database())
container.register_factory(Logger, create_logger)
container.register_factory(UserService, UserService)

user_service = container.resolve(UserService)  # Auto-wired!

#### Example

x = 10
name: str = "Python"  # Type annotation

#### Example

if condition:
    do_something()
elif other_condition:
    do_other()
else:
    do_default()

#### Example

for item in items:
    process(item)

while condition:
    do_work()

#### Example

[x**2 for x in range(10)]  # List
{x: x**2 for x in range(10)}  # Dict
{x**2 for x in range(10)}  # Set
(x**2 for x in range(10))  # Generator

#### Example

try:
    risky_operation()
except SpecificError as e:
    handle_error(e)
except Exception as e:
    handle_generic(e)
else:
    no_exception()
finally:
    always_run()

#### Example

lst = [1, 2, 3]
lst.append(4)        # Add to end
lst.insert(0, 0)     # Insert at index
lst.extend([5, 6])   # Extend with iterable
lst.pop()            # Remove and return last
lst.pop(0)           # Remove and return at index
lst.remove(1)       # Remove first occurrence
lst.index(2)         # Find index
lst.count(2)         # Count occurrences
lst.sort()           # Sort in place
sorted(lst)          # Return sorted copy
lst.reverse()        # Reverse in place
lst[::-1]            # Return reversed copy

#### Example

d = {"a": 1, "b": 2}
d["c"] = 3           # Add/update
d.get("d", 0)        # Get with default
d.pop("a")           # Remove and return
d.keys()             # View of keys
d.values()           # View of values
d.items()            # View of items
d.update({"e": 5})   # Update with dict

#### Example

s = "hello"
s.upper()            # "HELLO"
s.lower()            # "hello"
s.strip()            # Remove whitespace
s.split(",")         # Split into list
",".join(items)      # Join list
s.startswith("h")    # True
s.endswith("o")      # True
s.replace("l", "L")  # "heLLo"
f"{s} world"         # f-string

#### Example

x: int = 42
name: str = "Python"
is_active: bool = True
items: list[int] = [1, 2, 3]
data: dict[str, int] = {"a": 1}
options: set[str] = {"a", "b"}

#### Example

from typing import Optional, Union

value: Optional[int] = None
value: int | None = None  # 3.10+

result: Union[int, str] = 42
result: int | str = 42  # 3.10+

#### Example

with pytest.raises(ValueError):
    raise ValueError("error")

#### Example

pytest --cov=src --cov-fail-under=80

#### Example

I/O-bound, many connections ‚Üí asyncio
CPU-bound, single machine ‚Üí multiprocessing
CPU-bound, distributed ‚Üí Celery / Dask
Mixed I/O + CPU ‚Üí ThreadPoolExecutor + ProcessPoolExecutor
Free-threading available (3.13+) ‚Üí threading for CPU-bound

#### Example

Small dataset (<1GB) ‚Üí pandas
Large dataset (>1GB) ‚Üí Polars or Dask
Streaming data ‚Üí Polars lazy or Dask
ML/AI workloads ‚Üí NumPy, PyTorch, TensorFlow
Time series ‚Üí pandas, Polars

#### Example

New project ‚Üí uv
Legacy project ‚Üí pip + pip-tools
Poetry ecosystem ‚Üí Poetry
Enterprise ‚Üí pip + requirements.txt

#### Example

await asyncio.sleep(1)
    await task  # Wait for completion

#### Example

thread1 = threading.Thread(target=cpu_bound_task, args=(10_000_000,))
thread2 = threading.Thread(target=cpu_bound_task, args=(10_000_000,))

thread1.start()
thread2.start()
thread1.join()
thread2.join()

#### Example

# Use multiprocessing for CPU-bound
with multiprocessing.Pool(processes=4) as pool:
    pool.map(heavy_computation, data)

#### Example

# Python 3.14+ with --disable-gil flag
# Threads can actually run CPU-bound code in parallel!

#### Example

CPU-bound work?
‚îú‚îÄ Yes ‚Üí Use multiprocessing or C extensions
‚îî‚îÄ No (I/O-bound) ‚Üí Use threading or asyncio

#### Example

str_box: ReadOnlyBox[str] = ReadOnlyBox()
obj_box: ReadOnlyBox[object] = str_box  # Covariant: safe

#### Example

user_data = input("Enter data: ")
obj = pickle.loads(user_data)  # CODE EXECUTION VULNERABILITY!

#### Example

import json  # Safe alternative

user_data = input("Enter data: ")
obj = json.loads(user_data)  # Safe: only deserializes JSON data structures

#### Example

user_code = input("Enter expression: ")
result = eval(user_code)  # CODE EXECUTION!

# Attacker can send: "__import__('os').system('rm -rf /')"

#### Example

tree = ast.parse(user_code, mode='eval')
result = eval(compile(tree, '<string>', 'eval'), {"__builtins__": {}})

#### Example

import yaml

with open("config.yaml", "r") as f:
    data = yaml.load(f)  # UNSAFE! Can execute arbitrary code

# Malicious YAML:
# !!python/object/apply:os.system ["rm -rf /"]

#### Example

import yaml

with open("config.yaml", "r") as f:
    data = yaml.safe_load(f)  # Safe: only loads basic data structures

#### Example

# config.py
API_KEY = "sk_live_1234567890abcdef"  # COMMITTED TO GIT!
DATABASE_PASSWORD = "password123"

#### Example

import requests

url = input("Enter URL: ")
response = requests.get(url)  # SSRF vulnerability!

# Attacker can send: "http://localhost:8080/admin" or "file:///etc/passwd"

#### Example

allowed_hosts = {"api.example.com", "cdn.example.com"}
    
    if parsed.hostname not in allowed_hosts:
        raise ValueError("URL not allowed")

#### Example

if parsed.hostname in ["localhost", "127.0.0.1", "0.0.0.0"]:
        raise ValueError("Private IPs not allowed")
    
    return requests.get(url)

#### Example

cursor.execute(query)

#### Example

filename = input("Enter filename: ")
with open(filename, "r") as f:  # Path traversal!
    content = f.read()

# Attacker can send: "../../../etc/passwd"

#### Example

if not str(file_path).startswith(str(Path("data").resolve())):
    raise ValueError("Path traversal detected")

with open(file_path, "r") as f:
    content = f.read()

#### Example

import subprocess

user_input = input("Enter command: ")
subprocess.run(f"ls {user_input}", shell=True)  # COMMAND INJECTION!

# Attacker can send: "; rm -rf /"

#### Example

subprocess.run(["ls", user_input])  # Safe: no shell interpretation

#### Example

sanitized = shlex.quote(user_input)
subprocess.run(f"ls {sanitized}", shell=True)

#### Example

import random

token = "".join(random.choices("abcdefghijklmnopqrstuvwxyz", k=32))
# Predictable! Not cryptographically secure

#### Example

import secrets

token = secrets.token_urlsafe(32)  # Cryptographically secure
# Or
token = "".join(secrets.choice("abcdefghijklmnopqrstuvwxyz") for _ in range(32))

#### Example

logger.error("Internal error", exc_info=True)

#### Example

raise HTTPException(status_code=500, detail="Internal server error")

#### Example

result = ""
for i in range(100_000):
    result += str(i)  # Creates new string each time!

# Each += creates a new string object, copying all previous characters
# Time complexity: O(n¬≤)

#### Example

parts = []
for i in range(100_000):
    parts.append(str(i))
result = "".join(parts)  # Single allocation

#### Example

result = "".join(str(i) for i in range(100_000))

#### Example

items = [1, 2, 3, 4, 5, ..., 1_000_000]  # List

if 999_999 in items:  # O(n) - scans entire list
    print("Found")

#### Example

items = {1, 2, 3, 4, 5, ..., 1_000_000}  # Set

if 999_999 in items:  # O(1) - hash table lookup
    print("Found")

#### Example

import pandas as pd

df = pd.DataFrame({"x": range(1_000_000), "y": range(1_000_000)})

# .apply() uses Python loops internally
df["sum"] = df.apply(lambda row: row["x"] + row["y"], axis=1)  # SLOW!

#### Example

df["sum"] = df["x"] + df["y"]  # 100√ó faster!

#### Example

df["sum"] = df["x"].add(df["y"])  # Still vectorized

#### Example

import numpy as np
import time

data = np.arange(1_000_000)

start = time.perf_counter()
result = data * 2  # NumPy vectorization
print(f"Time: {time.perf_counter() - start:.4f}s")
# Typical: 0.0008s (156√ó faster!)

#### Example

for target in search_list:
    idx = find_item(large_list, target)  # Exception on every miss

#### Example

item_dict = {item: idx for idx, item in enumerate(large_list)}
idx = item_dict.get(target, -1)

#### Example

points = [(i, i) for i in range(1_000_000)]

#### Example

return [x + 1 for x in data]  # No function call overhead

#### Example

from datetime import datetime

timestamps = []
for i in range(1_000_000):
    timestamps.append(datetime.now())  # Creating 1M datetime objects

#### Example

now = datetime.now()
timestamps = [now] * 1_000_000

#### Example

try:
    risky_operation()
except:  # Catches EVERYTHING, including system exits!
    pass  # Silent failure

#### Example

try:
    risky_operation()
except Exception as e:  # Catches only Exception subclasses
    logger.error(f"Operation failed: {e}")
    # KeyboardInterrupt, SystemExit still propagate

#### Example

try:
    result = 1 / 0
except ZeroDivisionError:
    raise ValueError("Invalid input")  # Original exception lost!

#### Example

try:
    result = 1 / 0
except ZeroDivisionError:
    raise ValueError("Invalid input")  # Automatically chains

#### Example

try:
    user_id = int(input("Enter ID: "))
    user = db.get_user(user_id)
except Exception:  # Too broad - catches everything
    print("Error occurred")

#### Example

try:
    user_id = int(input("Enter ID: "))
    user = db.get_user(user_id)
except ValueError:
    print("Invalid ID format")
except UserNotFound:
    print("User not found")
except DatabaseError as e:
    logger.error("Database error", exc_info=True)
    raise  # Re-raise unexpected database errors

#### Example

file = open("data.txt")
try:
    data = file.read()
    process(data)
except Exception:
    pass  # File never closed!

#### Example

# Use context manager
with open("data.txt") as file:
    try:
        data = file.read()
        process(data)
    except Exception as e:
        logger.error(f"Processing failed: {e}")
        raise
# File automatically closed

#### Example

try:
    risky_operation()
finally:
    cleanup()  # If this raises, original exception is lost!

#### Example

try:
    risky_operation()
except Exception:

#### Example

raise
finally:
    try:
        cleanup()
    except Exception as e:
        logger.error(f"Cleanup failed: {e}")

#### Example

try:
    process_payment()
except PaymentError:
    pass  # No logging - impossible to debug!

#### Example

import logging

logger = logging.getLogger(__name__)

try:
    process_payment()
except PaymentError as e:
    logger.error(f"Payment failed: {e}", exc_info=True)
    # Include traceback for debugging
    raise

#### Example

errors = []
try:
    process_item(item1)
except Exception as e:
    errors.append(e)

try:
    process_item(item2)
except Exception as e:
    errors.append(e)

if errors:
    raise ValueError(f"Multiple errors: {errors}")  # Loses individual tracebacks

#### Example

try:
    result = risky_operation()
    if result is None:
        return default_value
except Exception:
    return default_value
# Code after try runs even if exception occurred

#### Example

try:
    result = risky_operation()
except Exception:
    return default_value
else:
    # Only runs if no exception
    return process_result(result)

#### Example

[] is []  # False - different objects
() == ()  # True - equal values

a = [1, 2, 3]
b = [1, 2, 3]
print(a is b)  # False - different list objects
print(a == b)  # True - same contents

#### Example

a = 256
b = 256
print(a is b)  # True - cached (implementation detail!)

c = 257
d = 257
print(c is d)  # False - not cached (varies by implementation)

#### Example

if user.age == 18:  # Correct
    pass

#### Example

if user is None:  # Correct
    pass

if user is admin_user:  # Same object check
    pass

#### Example

items = [1, 2, 3, 4, 5]

for item in items:
    if item % 2 == 0:
        items.remove(item)  # Modifies list during iteration!

# Result: [1, 3, 5] - but behavior is unpredictable
# May skip elements or raise RuntimeError

#### Example

for item in items[:]:  # Slice creates copy
    if item % 2 == 0:
        items.remove(item)

#### Example

items = [item for item in items if item % 2 != 0]

#### Example

for i in range(len(items) - 1, -1, -1):
    if items[i] % 2 == 0:
        del items[i]

#### Example

d = {"a": 1, "b": 2, "c": 3}
keys = d.keys()  # dict_keys view object

d["d"] = 4  # Modify dict
print(list(keys))  # ['a', 'b', 'c', 'd'] - view reflects changes!

#### Example

d = {"a": 1, "b": 2, "c": 3}
keys = list(d.keys())  # Convert to list (snapshot)

d["d"] = 4
print(keys)  # ['a', 'b', 'c'] - unchanged

#### Example

for item in items:
    if item == target:
        break
else:
    print("Not found")  # Many think this is "if loop didn't break"

#### Example

found = False
for item in items:
    if item == target:
        found = True
        break

if not found:
    print("Not found")  # More explicit

#### Example

for item in items:
    if item == target:
        print("Found")
        break
else:
    print("Not found")  # Runs if loop completes without break

#### Example

s1 = "caf√©"
s2 = "cafe\u0301"  # Same character, different representation

print(s1 == s2)  # False - different byte sequences!
print(len(s1))  # 4
print(len(s2))  # 5

#### Example

import unicodedata

s1 = "caf√©"
s2 = "cafe\u0301"

# Normalize before comparison
s1_norm = unicodedata.normalize("NFC", s1)
s2_norm = unicodedata.normalize("NFC", s2)
print(s1_norm == s2_norm)  # True

#### Example

try:
    naive < aware  # TypeError: can't compare naive and aware
except TypeError:
    print("Cannot compare!")

#### Example

aware = datetime(2025, 1, 1, 12, 0, tzinfo=timezone.utc)

#### Example

naive = datetime(2025, 1, 1, 12, 0)
aware = naive.replace(tzinfo=timezone.utc)

#### Example

print(aware < aware.replace(hour=13))  # True

#### Example

typedef struct _object {
    Py_ssize_t ob_refcnt;  // Reference count
    PyTypeObject *ob_type; // Type pointer
} PyObject;

#### Example

python -W default::DeprecationWarning your_script.py

#### Example

pyupgrade --py310-plus your_file.py

#### Example

result = []
for item in items:
    if item.is_valid():
        result.append(item.value)

#### Example

if "key" in data:
    value = data["key"]
else:
    value = "default"

#### Example

value = data.get("key", "default")

#### Example

result = ""
for item in items:
    result += str(item) + ", "
result = result.rstrip(", ")

#### Example

result = ", ".join(str(item) for item in items)

#### Example

c = C()
print(c.method())  # Output: "A" (A comes first in C's MRO)

d = D()
print(d.method())  # Output: "B" (B comes first in D's MRO)

#### Example

graph TD
    Header[PyObject HEADER] --> RefCnt[Py_ssize_t ob_refcnt<br/>Reference count 4/8 bytes]
    Header --> TypePtr[PyTypeObject *ob_type<br/>Pointer to type object 8 bytes]
    
    TypePtr --> TypeSpecific[Type-specific data follows]
    
    TypeSpecific --> PyLong[PyLongObject<br/>ob_digit variable]
    TypeSpecific --> PyList[PyListObject<br/>PyObject** ob_item<br/>Py_ssize_t allocated<br/>Py_ssize_t size]
    TypeSpecific --> PyUnicode[PyUnicodeObject<br/>length<br/>kind<br/>data]
    TypeSpecific --> PyDict[PyDictObject<br/>ma_keys<br/>ma_values<br/>ma_used]
    
    style Header fill:#e1f5ff
    style RefCnt fill:#ffe1f5
    style TypePtr fill:#e1ffe1
    style TypeSpecific fill:#fff4e1

#### Example

> **Quick Answer:** > - Classes define **blueprint** for objects; instances are **actual objects** > - Use `@dataclass` for data containers (less boilerplate) > - Use `@property` for computed attributes with validation > - Prefer **composition over inheritance** > > ```python > from dataclasses import dataclass > > @dataclass > class User: > name: str > email: str > > @property > def domain(self) -> str: > return self.email.split("@")[1] > ```

#### Example

1. **Inheritance considerations:** ```python class Base: __slots__ = ("x",)

#### Example

# Derived instances have slots: ("x", "y") ```

#### Example

2. **Cannot use with weak references** (unless `__weakref__` is in slots): ```python class Point: __slots__ = ("x", "y", "__weakref__") # Enable weakrefs ```

#### Example

3. **Cannot add arbitrary attributes:** ```python p = Point(1, 2) p.z = 3 # AttributeError: 'Point' object has no attribute 'z' ```

#### Example

4. **Works with dataclasses (Python 3.10+):** ```python from dataclasses import dataclass

#### Example

@dataclass(slots=True) # Automatically creates __slots__ class Point: x: int y: int ```

#### Example

> **Quick Answer:** > - **I/O-bound (many connections):** Use `asyncio` > - **CPU-bound (heavy computation):** Use `multiprocessing` > - **Simple background tasks:** Use `threading` > > ```python > # asyncio for I/O-bound > async def fetch_all(urls): > async with httpx.AsyncClient() as client: > tasks = [client.get(url) for url in urls] > return await asyncio.gather(*tasks) > > # multiprocessing for CPU-bound > from multiprocessing import Pool > with Pool(4) as p: > results = p.map(cpu_heavy_function, data) > ```

#### Example

> **Quick Answer:** > - A docstring is a string literal placed as the first statement in a module, class, or function. > - It defines the public contract of your API and is consumed by IDEs, Sphinx, inspect(), doctest, and LLM/RAG systems. > > **Example ‚Äî Correct Pattern:** > ```python > # ‚úÖ Correct docstring pattern > def add(x: int, y: int) -> int: > """Add two integers and return their sum.""" > return x + y > ``` > > **Estimated time:** 2‚Äì3 hours > **When you need this:** Any time you define a public API, library, or maintain internal tooling.

#### Example

1. **Clone the repository:** ```bash git clone https://github.com/python/cpython cd cpython ```

#### Example

3. **Build CPython:** ```bash ./configure --with-pydebug make -j8 ```

#### Constraint

disable certificate verification in production

Solution: Always use `create_default_context()` for production
- ‚úÖ Never disable certificate verification in production
- ‚úÖ Use proper certificate valid

#### Constraint

Lower layers must NOT import upper layers

#### Constraint

Domain layer must NOT depend on frameworks

#### Constraint

must not be committed

Solution: should be encrypted

#### Constraint

Error messages must not leak internal data

#### Constraint

**CRITICAL SECURITY RISK:**

Solution: import pickle

# NEVER do this with user input!
user_data = input("Enter data: ")
obj = pickle.loads(user_data)  # CODE EXECUTION VULNERABILITY!

# Attacker can

#### Constraint

Forbidden or disallowed behavior.

#### Table

::: qa
id: QA-cb41ce799b608f33
chapter: GLOBAL
q: What is How to Use This Bible. in the context of Rego/OPA?
a: How to Use This Bible
reference: BLK-a5b4450b93f9db62
importance: low
digest: f1df1b831aa6666ae59bed705f76fd00d3bc4e418883cee523c5f077341e9748
symbol_refs: [Rego]
semantic_role: explanation
embedding_hint_importance: low
embedding_hint_chunk: ignore

#### Reasoning Chain

- Read the question carefully.
- Recall the relevant definition or rule.
- Match the question scenario to the rule.
- Consider edge cases (e.g., undefined vs false).
- Summarize the conclusion clearly.

#### Inference

If UNKNOWN reference CH-30, understanding UNKNOWN usually helps understand CH-30.

#### Inference

If UNKNOWN reference CH-17, understanding UNKNOWN usually helps understand CH-17.

#### Inference

If UNKNOWN reference CH-27, understanding UNKNOWN usually helps understand CH-27.

#### Inference

If UNKNOWN reference CH-03, understanding UNKNOWN usually helps understand CH-03.

#### Inference

If UNKNOWN reference CH-07, understanding UNKNOWN usually helps understand CH-07.

#### Inference

If UNKNOWN reference CH-12, understanding UNKNOWN usually helps understand CH-12.

#### Inference

If everything-is-an-object used_by type-hints, understanding everything-is-an-object usually helps understand type-hints.

#### Inference

If everything-is-an-object used_by typingprotocol, understanding everything-is-an-object usually helps understand typingprotocol.

#### Inference

If a-is-b used_by len, understanding a-is-b usually helps understand len.

#### Inference

If easy used_by hard, understanding easy usually helps understand hard.

#### Inference

If easy implements hard, understanding easy usually helps understand hard.

#### Inference

If easy implements validate_types, understanding easy usually helps understand validate_types.

#### Inference

If avoid-when requires __weakref__, understanding avoid-when usually helps understand __weakref__.

#### Inference

If everything-is-an-object used_by super-is-mro-aware, understanding everything-is-an-object usually helps understand super-is-mro-aware.

#### Inference

If super implements __enter__, understanding super usually helps understand __enter__.

#### Inference

If easy implements medium, understanding easy usually helps understand medium.

#### Inference

If datetime used_by time, understanding datetime usually helps understand time.

#### Inference

If defaultdict requires if-key-in-dict, understanding defaultdict usually helps understand if-key-in-dict.

#### Inference

If move_to_end requires ordereddicta-1-b-2-ordereddictb-2-a-1, understanding move_to_end usually helps understand ordereddicta-1-b-2-ordereddictb-2-a-1.

#### Inference

If quick-answer used_by use-secrets-module, understanding quick-answer usually helps understand use-secrets-module.

#### Inference

If processpoolexecutor related_to threadpoolexecutor, understanding processpoolexecutor usually helps understand threadpoolexecutor.

#### Inference

If jython-273 used_by experimental-work-exists-but, understanding jython-273 usually helps understand experimental-work-exists-but.

#### Inference

If use-graalpy requires avoid-jython, understanding use-graalpy usually helps understand avoid-jython.

#### Inference

If cpython-pythonnet used_by graalpy-net-interop, understanding cpython-pythonnet usually helps understand graalpy-net-interop.

#### Inference

If c-extension-support contradicts ecosystem, understanding c-extension-support usually helps understand ecosystem.

#### Inference

If pyston-v23 used_by originally, understanding pyston-v23 usually helps understand originally.

#### Inference

If python-311 used_by status, understanding python-311 usually helps understand status.

#### Inference

If python-specific-considerations used_by functoolspartial, understanding python-specific-considerations usually helps understand functoolspartial.

#### Inference

If legend requires skipped, understanding legend usually helps understand skipped.

#### Diagram

flowchart TD
    Start([Start Learning Python]) --> Beginner[Beginner Path<br/>Ch. 1 ‚Üí Ch. 2 ‚Üí Ch. 4 ‚Üí Ch. 5 ‚Üí Ch. 6 ‚Üí Ch. 7<br/>Intro, Syntax, Types, Control, Functions, OOP<br/>Focus: Core language, basic data structures, functions]
    
    Beginner --> Intermediate[Intermediate Path<br/>Ch. 8 ‚Üí Ch. 9 ‚Üí Ch. 10 ‚Üí Ch. 11 ‚Üí Ch. 14<br/>Modules, Stdlib, Errors, Arch, Testing<br/>Focus: Project structure, error handling, testing]
    
    Intermediate --> Advanced[Advanced Path<br/>Ch. 12 ‚Üí Ch. 13 ‚Üí Ch. 17 ‚Üí Ch. 18 ‚Üí Ch. 20<br/>Perf, Security, Concurrency, Meta, Web<br/>Focus: Performance, security, async, metaprogramming]
    
    Advanced --> Specialist{Choose Specialist Path}
    
    Specialist -->|Systems Programming| Systems[Ch. 27 Internals<br/>‚Üí Ch. 28 Implementations]
    Specialist -->|Backend Development| Backend[Ch. 20 Web<br/>‚Üí Ch. 21 Data<br/>‚Üí Ch. 22 Eng]
    Specialist -->|Performance Engineering| Perf[Ch. 12 Perf<br/>‚Üí Ch. 27 Internals<br/>‚Üí Ch. 28 PyPy]
    Specialist -->|Architecture & Design| Arch[Ch. 11 Arch<br/>‚Üí Ch. 18 Meta<br/>‚Üí Appendix A Patterns]

#### Diagram

flowchart TD
    Source[Source Code<br/>hello.py] --> Tokenization[1. TOKENIZATION<br/>Tokenizer converts characters ‚Üí tokens<br/>Example: def ‚Üí NAME, ( ‚Üí LPAR, x ‚Üí NAME]
    
    Tokenization --> Parsing[2. PARSING PEG Parser<br/>Tokens ‚Üí Abstract Syntax Tree AST<br/>Example: FunctionDef name='greet', args=[...]]
    
    Parsing --> ASTOpt[3. AST OPTIMIZATION<br/>Constant folding, dead code elimination<br/>Example: 2 + 3 ‚Üí 5 compile-time]
    
    ASTOpt --> Bytecode[4. BYTECODE COMPILATION<br/>AST ‚Üí Bytecode instructions<br/>Example: LOAD_FAST, CALL_FUNCTION, RETURN_VALUE]
    
    Bytecode --> CodeObj[5. CODE OBJECT CREATION<br/>Bytecode + metadata ‚Üí code object<br/>Stored in: __pycache__/hello.cpython-313.pyc]
    
    CodeObj --> Execution[6. EXECUTION CPython VM]
    
    Execution --> Tier0[Tier 0: Baseline Interpreter 3.11+<br/>Standard bytecode execution]
    
    Tier0 -->|hot code detected| Tier1[Tier 1: Adaptive Interpreter 3.11+<br/>Specialized opcodes<br/>Type-specific optimizations]
    
    Tier1 -->|very hot code, 3.13+| Tier2[Tier 2: JIT Compiler 3.13+ experimental<br/>Copy-and-patch JIT<br/>Native machine code]
    
    Tier0 --> Runtime[Runtime Execution<br/>Frame objects, stack, namespaces]
    Tier1 --> Runtime
    Tier2 --> Runtime
    
    style Source fill:#e1f5ff
    style Runtime fill:#fff4e1
    style Tier0 fill:#ffe1f5
    style Tier1 fill:#e1ffe1
    style Tier2 fill:#ffe1e1

#### Diagram

# hello.py
def greet(name: str) -> str:
    """Return a personalized greeting."""
    return f"Hello, {name}!"

if __name__ == "__main__":
    print(greet("Python"))
    # Output: Hello, Python!

#### Diagram

def greet(name: str, title: str = "") -> str:
    """Return a personalized greeting with optional title."""
    if title:
        return f"Hello, {title} {name}!"
    return f"Hello, {name}!"

print(greet("Smith", "Dr."))
# Output: Hello, Dr. Smith!

#### Diagram

name = "Alice"
age = 30
message = f"Hello, {name}! You are {age} years old."
print(message)
# Output: Hello, Alice! You are 30 years old.

# With expressions:
message = f"Hello, {name.upper()}! You are {age + 1} years old next year."
# Output: Hello, ALICE! You are 31 years old next year.

#### Diagram

from typing import Optional

def format_greeting(name: str, age: Optional[int] = None) -> str:
    """Format a personalized greeting with type safety."""
    if age is None:
        return f"Hello, {name}!"
    return f"Hello, {name}! You are {age} years old."

print(format_greeting("Alice", 30))
# Output: Hello, Alice! You are 30 years old.

print(format_greeting("Bob"))
# Output: Hello, Bob!

#### Diagram

flowchart TD
    Source[Source Code<br/>hello.py] --> Tokenization[1. TOKENIZATION<br/>Tokenizer converts characters ‚Üí tokens<br/>Example: def ‚Üí NAME, ( ‚Üí LPAR, x ‚Üí NAME]
    
    Tokenization --> Parsing[2. PARSING PEG Parser<br/>Tokens ‚Üí Abstract Syntax Tree AST<br/>Example: FunctionDef name='greet', args=[...]]
    
    Parsing --> ASTOpt[3. AST OPTIMIZATION<br/>Constant folding, dead code elimination<br/>Example: 2 + 3 ‚Üí 5 compile-time]
    
    ASTOpt --> Bytecode[4. BYTECODE COMPILATION<br/>AST ‚Üí Bytecode instructions<br/>Example: LOAD_FAST, CALL_FUNCTION, RETURN_VALUE]
    
    Bytecode --> ByteOpt[5. BYTECODE OPTIMIZATION Peephole<br/>Dead jump removal, constant tuple building<br/>Example: JUMP_IF_FALSE ‚Üí removed if always true]
    
    ByteOpt --> CodeObj[6. CODE OBJECT CREATION<br/>Bytecode + metadata ‚Üí code object<br/>Stored in: __pycache__/hello.cpython-313.pyc]
    
    CodeObj --> Execution[7. EXECUTION CPython VM]
    
    Execution --> Tier0[Tier 0: Baseline Interpreter<br/>Standard bytecode execution]
    
    Tier0 -->|hot code detected| Tier1[Tier 1: Adaptive Interpreter 3.11+<br/>Specialized opcodes<br/>Type-specific optimizations]
    
    Tier1 -->|very hot code, 3.13+| Tier2[Tier 2: JIT Compiler 3.13+ experimental<br/>Copy-and-patch JIT<br/>Native machine code]
    
    Tier0 --> Runtime[Runtime Execution<br/>Frame objects, stack, namespaces]
    Tier1 --> Runtime
    Tier2 --> Runtime
    
    style Source fill:#e1f5ff
    style Runtime fill:#fff4e1
    style Tier0 fill:#ffe1f5
    style Tier1 fill:#e1ffe1
    style Tier2 fill:#ffe1e1

#### Diagram

def add(a, b):
    return a + b

#### Diagram

import tokenize
from io import BytesIO

code = b"def add(a, b):\n    return a + b"
for token in tokenize.tokenize(BytesIO(code).readline):
    print(f"{token.type:15} {token.string:20} {token.start} ‚Üí {token.end}")

#### Diagram

NAME            def                  (1, 0) ‚Üí (1, 3)
NAME            add                  (1, 4) ‚Üí (1, 7)
OP              (                    (1, 7) ‚Üí (1, 8)
NAME            a                    (1, 8) ‚Üí (1, 9)
OP              ,                    (1, 9) ‚Üí (1, 10)
NAME            b                    (1, 10) ‚Üí (1, 11)
OP              )                    (1, 11) ‚Üí (1, 12)
OP              :                    (1, 12) ‚Üí (1, 13)
NEWLINE         \n                   (1, 13) ‚Üí (1, 14)
INDENT          \n    \n             (2, 0) ‚Üí (2, 4)
NAME            return               (2, 4) ‚Üí (2, 10)
NAME            a                    (2, 11) ‚Üí (2, 12)
OP              +                    (2, 13) ‚Üí (2, 14)
NAME            b                    (2, 15) ‚Üí (2, 16)
NEWLINE         \n                   (2, 16) ‚Üí (2, 17)
DEDENT          \n                   (3, 0) ‚Üí (3, 0)
ENDMARKER       \n                   (3, 0) ‚Üí (3, 0)

#### Diagram

import ast

tree = ast.parse("def add(a, b):\n    return a + b")
print(ast.dump(tree, indent=2))

#### Diagram

import dis

def add(a, b):
    return a + b

dis.dis(add)

#### Diagram

import dis

# Compare different operations
dis.dis(lambda x: x + 1)      # Simple addition
dis.dis(lambda x: x * 2)      # Multiplication
dis.dis(lambda x: x if x > 0 else 0)  # Conditional

#### Diagram

flowchart TD
    Start[import mymodule] --> Step1[STEP 1: Check sys.modules cache<br/>if 'mymodule' in sys.modules:<br/>    return sys.modules['mymodule']  # Already loaded]
    
    Step1 -->|found| Return[Return cached module]
    Step1 -->|not found| Step2[STEP 2: Iterate sys.meta_path finders]
    
    Step2 --> Finder1[1. BuiltinImporter<br/>Checks built-in modules<br/>Examples: sys, builtins]
    
    Finder1 -->|not found| Finder2[2. FrozenImporter<br/>Checks frozen modules<br/>Examples: _frozen_importlib]
    
    Finder2 -->|not found| Finder3[3. PathFinder<br/>Searches sys.path<br/>Uses SourceFileLoader, etc.]
    
    Finder3 -->|finder returns ModuleSpec| Step3[STEP 3: Create ModuleSpec<br/>spec = ModuleSpec(<br/>    name='mymodule',<br/>    loader=SourceFileLoader...,<br/>    origin='/path/to/mymodule.py',<br/>    submodule_search_locations=None<br/>)]
    
    Step3 --> Step4[STEP 4: Loader.exec_module spec]
    
    Step4 --> Loader1[SourceFileLoader:<br/>1. Read .py file<br/>2. Compile to bytecode<br/>3. Execute bytecode<br/>4. Create module object]
    
    Step4 --> Loader2[ExtensionFileLoader:<br/>1. Load .so/.pyd file<br/>2. Initialize module]
    
    Step4 --> Loader3[NamespaceLoader:<br/>1. Create namespace package<br/>2. Set __path__]
    
    Loader1 --> Step5[STEP 5: Store in sys.modules<br/>sys.modules['mymodule'] = module_object]
    Loader2 --> Step5
    Loader3 --> Step5
    
    Step5 --> Step6[STEP 6: Module code executed<br/>Top-level code runs<br/>Functions/classes defined<br/>Module-level variables assigned]
    
    Step6 --> Return
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style Step3 fill:#fff4e1
    style Step4 fill:#ffe1e1
    style Step5 fill:#e1f5ff
    style Step6 fill:#ffe1f5
    style Return fill:#e1ffe1

#### Diagram

graph TD
    Object[object base class] --> Type[type metaclass]
    Object --> Exception[Exception]
    Object --> BaseException[BaseException]
    
    Type --> Class[class instances]
    
    Exception --> ValueError[ValueError]
    Exception --> KeyError[KeyError]
    
    BaseException --> KeyboardInterrupt[KeyboardInterrupt]
    
    Class --> BuiltInTypes[Built-in Types]
    
    BuiltInTypes --> Numeric[Numeric Types:<br/>int, float, complex, bool]
    BuiltInTypes --> Sequence[Sequence Types:<br/>str, list, tuple, bytes,<br/>bytearray, range]
    BuiltInTypes --> Mapping[Mapping Types:<br/>dict]
    BuiltInTypes --> Set[Set Types:<br/>set, frozenset]
    BuiltInTypes --> Callable[Callable Types:<br/>function, method, builtin]
    BuiltInTypes --> Iterator[Iterator Types:<br/>iterator, generator]
    BuiltInTypes --> Other[Other Types:<br/>NoneType, type,<br/>generator, coroutine]
    
    style Object fill:#e1f5ff
    style Type fill:#ffe1f5
    style BuiltInTypes fill:#e1ffe1

#### Diagram

flowchart TD
    Start([Function Call: inner]) --> Local[1. LOCAL SCOPE L<br/>def inner:<br/>    x = local ‚Üê Check here first<br/>    print x<br/><br/>If found ‚Üí use it, STOP<br/>If not found ‚Üí continue to Enclosing]
    
    Local -->|not found| Enclosing[2. ENCLOSING SCOPE E<br/>def outer:<br/>    x = enclosing ‚Üê Check here<br/>    def inner:<br/>        print x  # uses enclosing<br/>    return inner<br/><br/>If found ‚Üí use it, STOP<br/>If not found ‚Üí continue to Global]
    
    Enclosing -->|not found| Global[3. GLOBAL SCOPE G<br/>x = global ‚Üê Module-level<br/><br/>def outer:<br/>    def inner:<br/>        print x  # uses global<br/><br/>If found ‚Üí use it, STOP<br/>If not found ‚Üí continue to Built-in]
    
    Global -->|not found| Builtin[4. BUILT-IN SCOPE B<br/>Built-in names len, str, int, etc.<br/><br/>import builtins<br/>print builtins.__dict__<br/><br/>If found ‚Üí use it<br/>If not found ‚Üí NameError]
    
    Local -->|found| Stop1[Use Local Value]
    Enclosing -->|found| Stop2[Use Enclosing Value]
    Global -->|found| Stop3[Use Global Value]
    Builtin -->|found| Stop4[Use Built-in Value]
    Builtin -->|not found| Error[NameError]
    
    style Local fill:#e1f5ff
    style Enclosing fill:#ffe1f5
    style Global fill:#e1ffe1
    style Builtin fill:#fff4e1
    style Error fill:#ffe1e1

#### Diagram

class Calculator:
    def add(self, a: int, b: int) -> int:
        return a + b

calc = Calculator()
print(calc.add(2, 3))
# Output: 5

# Method is bound to instance
bound_method = calc.add
print(bound_method(4, 5))
# Output: 9

# Unbound method (from class)
unbound_method = Calculator.add
print(unbound_method(calc, 6, 7))
# Output: 13

#### Diagram

graph TD
    Object[object] --> A[A]
    Object --> B[B]
    
    A --> C[C]
    B --> C
    
    C --> MRO[MRO Resolution for: C A, B<br/><br/>Step 1: Build inheritance graph<br/>Step 2: C3 Linearization<br/>MRO C = C + merge<br/>    MRO A,<br/>    MRO B,<br/>    A, B<br/><br/>Result: C, A, B, object]
    
    style Object fill:#e1f5ff
    style C fill:#ffe1f5
    style MRO fill:#e1ffe1

#### Diagram

flowchart TD
    Start[obj.method] --> Step1[1. Check type obj.__mro__<br/>C, A, B, object]
    
    Step1 --> Step2[2. Search in order:<br/>C.__dict__['method']?<br/>A.__dict__['method']?<br/>B.__dict__['method']?<br/>object.__dict__['method']?]
    
    Step2 --> Step3[3. First match wins<br/>stops at first found]
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style Step3 fill:#fff4e1

#### Diagram

graph TD
    Object[object] --> A[A]
    Object --> B[B]
    
    A --> C[C]
    B --> C
    
    C --> D[D]
    C --> E[E]
    
    D --> F[F]
    E --> F
    
    F --> MRO[MRO Calculation for F:<br/>F.__mro__ = F + merge<br/>MRO D: D, C, A, object<br/>MRO E: E, C, B, object<br/>Direct parents: D, E<br/><br/>Step-by-step merge:<br/>1. Take D ‚Üí keep D<br/>2. Remove D, take E ‚Üí keep E<br/>3. Take C ‚Üí keep C<br/>4. Continue: A, B, object<br/><br/>Final MRO: F, D, E, C, A, B, object]
    
    style Object fill:#e1f5ff
    style F fill:#ffe1f5
    style MRO fill:#e1ffe1

#### Diagram

flowchart TD
    Start[obj.method] --> Step1[1. Get type obj.__mro__<br/>Example: F, D, E, C, A, B, object]
    
    Step1 --> Step2[2. Search in MRO order left to right]
    
    Step2 --> CheckF[Check F.__dict__['method']?<br/>‚Üí Not found]
    
    CheckF --> CheckD[Check D.__dict__['method']?<br/>‚Üí Not found]
    
    CheckD --> CheckE[Check E.__dict__['method']?<br/>‚Üí Not found]
    
    CheckE --> CheckC[Check C.__dict__['method']?<br/>‚Üí FOUND!]
    
    CheckC --> Step3[3. Return method bound to obj<br/>STOP searching first match wins]
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style CheckC fill:#fff4e1
    style Step3 fill:#ffe1e1

#### Diagram

flowchart TD
    Start[import mymodule] --> Step1[1. Check sys.modules cache<br/>Already imported?]
    
    Step1 -->|found| Return[Return cached module]
    Step1 -->|not found| Step2[2. Iterate sys.meta_path finders<br/>BuiltinImporter<br/>FrozenImporter<br/>PathFinder]
    
    Step2 -->|finder returns spec| Step3[3. ModuleSpec created<br/>name, loader, origin<br/>submodule_search_locations]
    
    Step3 --> Step4[4. Loader.exec_module spec<br/>SourceFileLoader<br/>ExtensionFileLoader<br/>NamespaceLoader]
    
    Step4 --> Step5[5. Module added to sys.modules<br/>6. Module code executed]
    
    Step5 --> Return
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style Step3 fill:#fff4e1
    style Step4 fill:#ffe1e1
    style Step5 fill:#e1f5ff
    style Return fill:#e1ffe1

#### Diagram

import shutil

# Copy single file
shutil.copy("source.txt", "dest.txt")  # Copies file, preserves permissions
shutil.copy2("source.txt", "dest.txt")  # Also preserves metadata (timestamps)

# Copy directory tree
shutil.copytree("src_dir", "dest_dir", dirs_exist_ok=True)  # Python 3.8+

#### Diagram

import tempfile

# Temporary file (auto-deleted on close)
with tempfile.TemporaryFile(mode='w+') as f:
    f.write("temporary data")
    f.seek(0)
    print(f.read())
# File automatically deleted when context exits

# Named temporary file (visible in filesystem)
with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:
    f.write("data")
    temp_name = f.name  # Keep name for later use
# File persists after context (delete=False)
# Clean up manually: os.unlink(temp_name)

#### Diagram

import tempfile
import os
from pathlib import Path

def process_with_temp_file(data: str) -> str:
    """Process data in a secure temporary file."""
    fd, path = tempfile.mkstemp(suffix='.txt', text=True)
    try:
        with os.fdopen(fd, 'w') as f:
            f.write(data)
        # Process file (e.g., read, transform, etc.)
        with open(path) as f:
            result = f.read().upper()  # Example: uppercase transformation
        return result
    finally:
        os.unlink(path)  # Always clean up

result = process_with_temp_file("hello world")
print(result)  # HELLO WORLD

#### Diagram

from datetime import datetime, timedelta, date, time

# Current time
now = datetime.now()
print(now)  # 2025-11-30 14:30:45.123456

# Specific datetime
dt = datetime(2025, 1, 27, 14, 30, 45)
print(dt)  # 2025-11-30 14:30:45

# Date arithmetic
tomorrow = now + timedelta(days=1)
next_week = now + timedelta(weeks=1)
in_2_hours = now + timedelta(hours=2)

# Time differences
diff = tomorrow - now
print(diff.total_seconds())  # 86400.0 seconds

#### Diagram

# Create timedelta
delta = timedelta(days=5, hours=3, minutes=30, seconds=15)
print(delta)  # 5 days, 3:30:15

# Access components
print(delta.days)         # 5
print(delta.seconds)      # 12615 (hours*3600 + minutes*60 + seconds)
print(delta.total_seconds())  # 447615.0

# Arithmetic
dt1 = datetime(2025, 1, 1)
dt2 = datetime(2025, 1, 10)
diff = dt2 - dt1
print(diff.days)  # 9

#### Diagram

from datetime import datetime, timedelta

def date_range(start: str, end: str, step_days: int = 1):
    """Generate dates in range."""
    start_dt = datetime.strptime(start, "%Y-%m-%d")
    end_dt = datetime.strptime(end, "%Y-%m-%d")
    current = start_dt
    
    while current <= end_dt:
        yield current.date()
        current += timedelta(days=step_days)

# Generate all dates in January 2025
for date in date_range("2025-01-01", "2025-01-31"):
    print(date.strftime("%A, %B %d, %Y"))

#### Diagram

c = Counter("banana")

# Access counts
print(c['a'])      # 3
print(c['z'])      # 0 (doesn't raise KeyError)

# Most common elements
print(c.most_common(2))  # [('a', 3), ('n', 2)]

# Update counter
c.update("apple")  # Add more items
print(c)  # Counter({'a': 4, 'n': 2, 'b': 1, 'p': 2, 'l': 1, 'e': 1})

# Arithmetic operations
c1 = Counter("ab")
c2 = Counter("bc")
print(c1 + c2)  # Counter({'b': 2, 'a': 1, 'c': 1})
print(c1 - c2)  # Counter({'a': 1}) (negative counts removed)

#### Diagram

from collections import defaultdict

# Default to empty list
groups = defaultdict(list)
groups["a"].append(1)  # No KeyError, list created automatically
groups["a"].append(2)
print(groups)  # defaultdict(<class 'list'>, {'a': [1, 2]})

# Default to 0 (for counting)
counts = defaultdict(int)
counts["apple"] += 1  # No KeyError
counts["banana"] += 1
print(counts)  # defaultdict(<class 'int'>, {'apple': 1, 'banana': 1})

#### Diagram

# Default to empty list
dd_list = defaultdict(list)
dd_list["key"].append("value")

# Default to 0
dd_int = defaultdict(int)
dd_int["count"] += 1

# Default to empty set
dd_set = defaultdict(set)
dd_set["tags"].add("python")

# Default to empty dict
dd_dict = defaultdict(dict)
dd_dict["user"]["name"] = "Alice"

# Custom default factory
def default_factory():
    return {"count": 0, "items": []}

dd_custom = defaultdict(default_factory)
dd_custom["group"]["count"] += 1

#### Diagram

from collections import ChainMap

# Configuration with fallback
defaults = {"host": "localhost", "port": 8080}
file_config = {"port": 9000, "debug": True}
env_config = {"host": "prod.example.com"}

# ChainMap searches in order: env_config ‚Üí file_config ‚Üí defaults
config = ChainMap(env_config, file_config, defaults)

print(config["host"])   # "prod.example.com" (from env_config)
print(config["port"])   # 9000 (from file_config)
print(config["debug"])  # True (from file_config)

#### Diagram

from collections import namedtuple

# Create named tuple type
Point = namedtuple("Point", "x y")
p = Point(1, 2)
print(p.x, p.y)  # 1 2
print(p)  # Point(x=1, y=2)

# Named tuple with defaults (Python 3.7+)
Person = namedtuple("Person", "name age", defaults=["Unknown", 0])
p1 = Person("Alice")
p2 = Person("Bob", 30)

#### Diagram

from dataclasses import dataclass

@dataclass
class Point:
    x: int
    y: int
    
    def distance(self, other: "Point") -> float:
        """Calculate distance to another point."""
        return ((self.x - other.x) ** 2 + (self.y - other.y) ** 2) ** 0.5

p1 = Point(1, 2)
p2 = Point(4, 6)
print(p1.distance(p2))  # 5.0

#### Diagram

import re

# Search for pattern
text = "Age 42 years old"
m = re.search(r"\d+", text)
if m:
    print(m.group())  # "42"
    print(m.start())  # 4
    print(m.end())    # 6

# Match at start
m = re.match(r"Age", text)  # Matches only at start
if m:
    print(m.group())  # "Age"

# Find all matches
numbers = re.findall(r"\d+", "I have 3 cats and 2 dogs")
print(numbers)  # ['3', '2']

# Find all with positions
for m in re.finditer(r"\d+", "I have 3 cats and 2 dogs"):
    print(f"{m.group()} at {m.start()}-{m.end()}")
# 3 at 7-8
# 2 at 18-19

#### Diagram

# Capturing groups
text = "John Doe, age 42"
m = re.search(r"(\w+) (\w+), age (\d+)", text)
if m:
    print(m.group(0))  # Full match: "John Doe, age 42"
    print(m.group(1))  # First group: "John"
    print(m.group(2))  # Second group: "Doe"
    print(m.group(3))  # Third group: "42"
    print(m.groups())  # All groups: ('John', 'Doe', '42')

# Named groups (more readable)
m = re.search(r"(?P<first>\w+) (?P<last>\w+), age (?P<age>\d+)", text)
if m:
    print(m.group('first'))  # "John"
    print(m.group('last'))   # "Doe"
    print(m.group('age'))    # "42"
    print(m.groupdict())     # {'first': 'John', 'last': 'Doe', 'age': '42'}

#### Diagram

# Email pattern (simplified)
email_pattern = r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}"
emails = re.findall(email_pattern, "Contact: alice@example.com or bob@test.org")

# Phone number (US format)
phone_pattern = r"\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}"
phones = re.findall(phone_pattern, "Call 555-1234 or (555) 987-6543")

# URL pattern
url_pattern = r"https?://[^\s]+"
urls = re.findall(url_pattern, "Visit https://example.com for more info")

#### Diagram

# Replace pattern
text = "Hello World"
new_text = re.sub(r"World", "Python", text)
print(new_text)  # "Hello Python"

# Replace with function
def replacer(match):
    return match.group(0).upper()

text = "hello world"
new_text = re.sub(r"\w+", replacer, text)
print(new_text)  # "HELLO WORLD"

# Replace with backreferences
text = "2025-11-30"
new_text = re.sub(r"(\d{4})-(\d{2})-(\d{2})", r"\3/\2/\1", text)
print(new_text)  # "27/01/2025" (US format)

#### Diagram

import re

# Compile once, use many times
pattern = re.compile(r"\d+")

# Much faster than re.search(r"\d+", text) in loops
for text in large_text_list:
    m = pattern.search(text)
    if m:
        print(m.group())

# Compiled patterns support same methods
pattern = re.compile(r"(\w+)@(\w+\.\w+)", re.IGNORECASE)
m = pattern.search("Contact: alice@example.com")
if m:
    print(m.groups())  # ('alice', 'example.com')

#### Diagram

import re
import time

text = "The number is 42"
pattern_str = r"\d+"
pattern_compiled = re.compile(pattern_str)

# Uncompiled (slower in loops)
start = time.perf_counter()
for _ in range(1000000):
    re.search(pattern_str, text)
uncompiled_time = time.perf_counter() - start

# Compiled (faster)
start = time.perf_counter()
for _ in range(1000000):
    pattern_compiled.search(text)
compiled_time = time.perf_counter() - start

print(f"Uncompiled: {uncompiled_time:.4f}s")
print(f"Compiled:   {compiled_time:.4f}s")
print(f"Speedup:    {uncompiled_time/compiled_time:.1f}x")

#### Diagram

# Positive lookahead: match followed by pattern
text = "Python3 Python2"
matches = re.findall(r"Python(?=\d)", text)
print(matches)  # ['Python', 'Python'] (matches Python before digit)

# Negative lookahead: match NOT followed by pattern
matches = re.findall(r"Python(?!\d)", text)
print(matches)  # [] (no Python without digit)

# Positive lookbehind: match preceded by pattern
text = "$100 and ‚Ç¨50"
matches = re.findall(r"(?<=\$)\d+", text)
print(matches)  # ['100'] (number after $)

# Negative lookbehind: match NOT preceded by pattern
matches = re.findall(r"(?<!\$)\d+", text)
print(matches)  # ['50'] (number not after $)

#### Diagram

# Use (?:...) for grouping without capturing
text = "abc123 def456"
# Capture only numbers, not the letters
matches = re.findall(r"(?:\w+)(\d+)", text)
print(matches)  # ['123', '456']

#### Diagram

import re

log_line = "[2025-11-30 14:30:45] ERROR: Database connection failed (code: 5001)"

# Pattern with named groups
pattern = re.compile(r"""
    \[(?P<timestamp>.*?)\]     # Timestamp in brackets
    \s+
    (?P<level>\w+)            # Log level
    :\s+
    (?P<message>.*?)          # Message
    \s*
    \(code:\s*(?P<code>\d+)\) # Optional error code
""", re.VERBOSE)

m = pattern.search(log_line)
if m:
    print(f"Time: {m.group('timestamp')}")
    print(f"Level: {m.group('level')}")
    print(f"Message: {m.group('message')}")
    print(f"Code: {m.group('code')}")

#### Diagram

import string

# Character sets
print(string.ascii_letters)  # 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
print(string.ascii_lowercase)  # 'abcdefghijklmnopqrstuvwxyz'
print(string.ascii_uppercase)  # 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
print(string.digits)  # '0123456789'
print(string.hexdigits)  # '0123456789abcdefABCDEF'
print(string.octdigits)  # '01234567'
print(string.punctuation)  # '!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~'
print(string.whitespace)  # ' \t\n\r\x0b\x0c'
print(string.printable)  # All printable ASCII characters

#### Diagram

import string
import secrets

def generate_password(length: int = 16) -> str:
    """Generate secure random password."""
    alphabet = string.ascii_letters + string.digits + string.punctuation
    return ''.join(secrets.choice(alphabet) for _ in range(length))

password = generate_password(20)
print(password)

#### Diagram

import textwrap

def format_docstring(text: str, width: int = 72) -> str:
    """Format docstring with proper indentation."""
    # Remove common indentation
    text = textwrap.dedent(text).strip()
    # Wrap and indent
    return textwrap.fill(text, width=width, initial_indent="    ", subsequent_indent="    ")

doc = """
    This is a long docstring that explains
    what the function does in detail.
    It should be properly formatted.
"""
print(format_docstring(doc))

#### Diagram

import difflib

text1 = "Hello world\nPython is great"
text2 = "Hello Python\nPython is awesome"

# Unified diff
diff = difflib.unified_diff(
    text1.splitlines(keepends=True),
    text2.splitlines(keepends=True),
    fromfile='old.txt',
    tofile='new.txt',
    lineterm=''
)
print(''.join(diff))
# --- old.txt
# +++ new.txt
# @@ -1,2 +1,2 @@
# -Hello world
# +Hello Python
# -Python is great
# +Python is awesome

# Context diff
diff = difflib.context_diff(
    text1.splitlines(keepends=True),
    text2.splitlines(keepends=True),
    fromfile='old.txt',
    tofile='new.txt'
)
print(''.join(diff))

#### Diagram

# Find similar sequences
s1 = ['apple', 'banana', 'cherry']
s2 = ['apple', 'berry', 'cherry']

matcher = difflib.SequenceMatcher(None, s1, s2)
ratio = matcher.ratio()
print(f"Similarity: {ratio:.2%}")  # Similarity: 66.67%

# Get matching blocks
for tag, i1, i2, j1, j2 in matcher.get_opcodes():
    print(f"{tag:7} s1[{i1}:{i2}] -> s2[{j1}:{j2}]")
# equal   s1[0:1] -> s2[0:1]  (apple matches)
# replace s1[1:2] -> s2[1:2]  (banana -> berry)
# equal   s1[2:3] -> s2[2:3]  (cherry matches)

#### Diagram

import difflib

def show_diff(old_text: str, new_text: str):
    """Show unified diff between two texts."""
    diff = difflib.unified_diff(
        old_text.splitlines(keepends=True),
        new_text.splitlines(keepends=True),
        lineterm='',
        n=3  # Context lines
    )
    for line in diff:
        if line.startswith('+'):
            print(f"\033[92m{line}\033[0m", end='')  # Green for additions
        elif line.startswith('-'):
            print(f"\033[91m{line}\033[0m", end='')  # Red for deletions
        else:
            print(line, end='')

old = "Hello world\nPython"
new = "Hello Python\nPython 3.12"
show_diff(old, new)

#### Diagram

import json
from pathlib import Path

class ConfigManager:
    def __init__(self, config_path: Path):
        self.config_path = config_path
        self.config = self.load()
    
    def load(self) -> dict:
        """Load configuration from JSON file."""
        if self.config_path.exists():
            with open(self.config_path) as f:
                return json.load(f)
        return {}
    
    def save(self):
        """Save configuration to JSON file."""
        with open(self.config_path, "w") as f:
            json.dump(self.config, f, indent=2)
    
    def get(self, key: str, default=None):
        """Get configuration value."""
        return self.config.get(key, default)
    
    def set(self, key: str, value):
        """Set configuration value."""
        self.config[key] = value
        self.save()

config = ConfigManager(Path("config.json"))
config.set("theme", "dark")
print(config.get("theme"))  # "dark"

#### Diagram

import csv
from typing import List, Dict

def read_csv_safe(filename: str) -> List[Dict[str, str]]:
    """Read CSV with error handling and validation."""
    rows = []
    with open(filename, "r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        for i, row in enumerate(reader, start=2):  # Start at 2 (header is row 1)
            try:
                # Validate required fields
                if not row.get("name") or not row.get("age"):
                    print(f"Warning: Row {i} missing required fields, skipping")
                    continue
                rows.append(row)
            except Exception as e:
                print(f"Error processing row {i}: {e}")
                continue
    return rows

data = read_csv_safe("users.csv")
for row in data:
    print(f"{row['name']}: {row['age']}")

#### Diagram

# Use highest protocol for efficiency (Python 3.8+)
pickled = pickle.dumps(data, protocol=pickle.HIGHEST_PROTOCOL)

# Protocol 5 (Python 3.8+) supports out-of-band data for large objects

#### Diagram

import pickle
import hashlib
from pathlib import Path

class SafePickleCache:
    """Safe pickle-based cache with validation."""
    
    def __init__(self, cache_dir: Path):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(exist_ok=True)
    
    def _get_cache_path(self, key: str) -> Path:
        """Get cache file path for key."""
        key_hash = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{key_hash}.pkl"
    
    def get(self, key: str):
        """Get cached object."""
        cache_path = self._get_cache_path(key)
        if cache_path.exists():
            try:
                with open(cache_path, "rb") as f:
                    return pickle.load(f)
            except Exception as e:
                print(f"Cache read error: {e}")
                cache_path.unlink()  # Remove corrupted cache
        return None
    
    def set(self, key: str, value):
        """Cache object."""
        cache_path = self._get_cache_path(key)
        try:
            with open(cache_path, "wb") as f:
                pickle.dump(value, f, protocol=pickle.HIGHEST_PROTOCOL)
        except Exception as e:
            print(f"Cache write error: {e}")

# Usage (only for trusted data!)
cache = SafePickleCache(Path(".cache"))
cache.set("user_data", {"name": "Alice"})
data = cache.get("user_data")

#### Diagram

# Set working directory
result = subprocess.run(
    ["ls"],
    cwd="/tmp",
    capture_output=True,
    text=True
)

# Set environment variables
env = {"PATH": "/usr/bin", "LANG": "en_US.UTF-8"}
result = subprocess.run(
    ["command"],
    env=env,
    capture_output=True,
    text=True
)

# Timeout (Python 3.3+)
try:
    result = subprocess.run(
        ["slow_command"],
        timeout=5.0,  # Seconds
        capture_output=True,
        text=True
    )
except subprocess.TimeoutExpired:
    print("Command timed out")

# Redirect input
result = subprocess.run(
    ["grep", "pattern"],
    input="line1\nline2\npattern\nline4",
    capture_output=True,
    text=True
)

#### Diagram

import subprocess
from typing import List, Optional

def run_command_safe(
    command: List[str],
    timeout: Optional[float] = None,
    cwd: Optional[str] = None
) -> tuple[int, str, str]:
    """Safely run command and return (returncode, stdout, stderr)."""
    try:
        result = subprocess.run(
            command,
            capture_output=True,
            text=True,
            timeout=timeout,
            cwd=cwd,
            check=False  # Don't raise on error
        )
        return result.returncode, result.stdout, result.stderr
    except subprocess.TimeoutExpired as e:
        return -1, "", f"Command timed out after {timeout}s"
    except Exception as e:
        return -1, "", str(e)

# Usage
returncode, stdout, stderr = run_command_safe(["ls", "-l"], timeout=5.0)
if returncode == 0:
    print(stdout)
else:
    print(f"Error: {stderr}")

#### Diagram

import os
from pathlib import Path

def find_files(directory: str, extension: str) -> list[str]:
    """Find all files with given extension."""
    files = []
    for root, dirs, filenames in os.walk(directory):
        for filename in filenames:
            if filename.endswith(extension):
                full_path = os.path.join(root, filename)
                files.append(full_path)
    return files

# Usage
py_files = find_files(".", ".py")
for file in py_files:
    print(file)

#### Diagram

import signal
import sys

def signal_handler(signum, frame):
    """Handle interrupt signal."""
    print("\nInterrupted! Cleaning up...")
    # Perform cleanup
    sys.exit(0)

# Register handler for SIGINT (Ctrl+C)
signal.signal(signal.SIGINT, signal_handler)

# Register handler for SIGTERM (termination request)
signal.signal(signal.SIGTERM, signal_handler)

# Your main program
while True:
    # Do work
    pass

#### Diagram

# SIGINT: Interrupt (Ctrl+C)
signal.signal(signal.SIGINT, handler)

# SIGTERM: Termination request
signal.signal(signal.SIGTERM, handler)

# SIGHUP: Hang up (terminal closed)
signal.signal(signal.SIGHUP, handler)

# SIGALRM: Alarm clock (for timeouts)
signal.signal(signal.SIGALRM, handler)

#### Diagram

from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError
from urllib.parse import urlencode

def http_get(url: str, headers: dict = None) -> tuple[int, bytes]:
    """Simple GET request with error handling."""
    try:
        req = Request(url)
        if headers:
            for key, value in headers.items():
                req.add_header(key, value)
        
        with urlopen(req, timeout=10) as response:
            return response.status, response.read()
    except HTTPError as e:
        return e.code, e.read()
    except URLError as e:
        raise ConnectionError(f"Failed to connect: {e.reason}")

status, data = http_get("https://example.com")
print(f"Status: {status}")
print(f"Data: {data[:100]}...")

#### Diagram

import socket

# Create server socket
server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
server.bind(("localhost", 8080))
server.listen(5)

print("Server listening on port 8080")

while True:
    client, addr = server.accept()
    print(f"Connection from {addr}")
    
    with client:
        data = client.recv(1024)
        if data:
            client.sendall(b"Echo: " + data)
    
    # For production, use threading or asyncio

#### Diagram

import socket
import threading

def handle_client(client, addr):
    """Handle client connection."""
    with client:
        print(f"Client connected: {addr}")
        while True:
            data = client.recv(1024)
            if not data:
                break
            client.sendall(b"Echo: " + data)
    print(f"Client disconnected: {addr}")

def start_server(host="localhost", port=8080):
    """Start echo server."""
    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server.bind((host, port))
    server.listen(5)
    
    print(f"Server listening on {host}:{port}")
    
    while True:
        client, addr = server.accept()
        thread = threading.Thread(target=handle_client, args=(client, addr))
        thread.start()

# start_server()  # Uncomment to run

#### Diagram

import ssl
import socket
from urllib.request import urlopen

def secure_get(url: str) -> bytes:
    """Secure HTTPS GET with proper certificate validation."""
    ctx = ssl.create_default_context()
    
    # Parse URL
    from urllib.parse import urlparse
    parsed = urlparse(url)
    
    # Create secure connection
    sock = socket.create_connection((parsed.hostname, 443))
    secure_sock = ctx.wrap_socket(sock, server_hostname=parsed.hostname)
    
    try:
        # Send request
        request = f"GET {parsed.path or '/'} HTTP/1.1\r\nHost: {parsed.hostname}\r\n\r\n"
        secure_sock.sendall(request.encode())
        
        # Receive response
        response = secure_sock.recv(4096)
        return response
    finally:
        secure_sock.close()

# Usage
response = secure_get("https://example.com")
print(response.decode()[:200])

#### Diagram

import gzip
from pathlib import Path

def compress_logs(log_dir: Path, keep_original: bool = False):
    """Compress all .log files in directory."""
    for log_file in log_dir.glob("*.log"):
        gz_file = log_file.with_suffix(".log.gz")
        
        with open(log_file, "rb") as f_in:
            with gzip.open(gz_file, "wb") as f_out:
                f_out.writelines(f_in)
        
        if not keep_original:
            log_file.unlink()
        
        print(f"Compressed: {log_file.name} -> {gz_file.name}")

compress_logs(Path("logs"))

#### Diagram

import traceback
import sys

def format_exception(e: Exception) -> str:
    """Format exception with full context."""
    exc_type, exc_value, exc_tb = sys.exc_info()
    tb_lines = traceback.format_exception(exc_type, exc_value, exc_tb)
    return ''.join(tb_lines)

try:
    risky_operation()
except Exception as e:
    error_msg = format_exception(e)
    logger.error(f"Operation failed:\n{error_msg}")

#### Diagram

import inspect

def example(a: int, b: str = "default", *args, **kwargs) -> str:
    """Example function."""
    pass

# Get signature
sig = inspect.signature(example)
print(sig)  # (a: int, b: str = 'default', *args, **kwargs) -> str

# Get parameters
for name, param in sig.parameters.items():
    print(f"{name}: {param.annotation} = {param.default}")

# Get return annotation
print(sig.return_annotation)  # <class 'str'>

#### Diagram

import inspect

def inspect_function(func):
    """Inspect function and print details."""
    sig = inspect.signature(func)
    doc = inspect.getdoc(func)
    source = inspect.getsource(func)
    
    print(f"Function: {func.__name__}")
    print(f"Signature: {sig}")
    print(f"Docstring: {doc}")
    print(f"Source:\n{source}")

def example(a: int, b: str) -> str:
    """Example function."""
    return f"{a}: {b}"

inspect_function(example)

#### Diagram

# ‚ùå WRONG: Cache grows unbounded
class Service:
    @lru_cache(maxsize=256)
    def process(self, data: str) -> dict:
        # 'self' is part of cache key ‚Üí unique per instance
        return expensive_computation(data)

#### Diagram

# ‚úÖ CORRECT: Module-level function with hashable args
@lru_cache(maxsize=256)
def _process_impl(data: str) -> dict:
    return expensive_computation(data)

class Service:
    def process(self, data: str) -> dict:
        return _process_impl(data)

#### Diagram

import time
import numpy as np
from typing import Callable

def benchmark(func: Callable, *args, iterations: int = 5) -> float:
    """Run function multiple times and return average time."""
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        func(*args)
        times.append(time.perf_counter() - start)
    return sum(times) / len(times)

# Test functions
def python_loop(n: int):
    return [i * 2 for i in range(n)]

def numpy_vectorized(n: int):
    return (np.arange(n) * 2).tolist()

def numpy_inplace(n: int):
    arr = np.arange(n, dtype=np.float64)
    arr *= 2
    return arr

# Benchmark different sizes
sizes = [1_000, 10_000, 100_000, 1_000_000, 10_000_000]

print("Array Size | Python Loop | NumPy (tolist) | NumPy (inplace) | Speedup")
print("-" * 75)

for n in sizes:
    py_time = benchmark(python_loop, n)
    np_time = benchmark(numpy_vectorized, n)
    np_inplace_time = benchmark(numpy_inplace, n)
    
    speedup = py_time / np_inplace_time
    
    print(f"{n:>10,} | {py_time:>10.4f}s | {np_time:>13.4f}s | "
          f"{np_inplace_time:>15.4f}s | {speedup:>6.1f}√ó")

# Typical Results (Python 3.12, NumPy 1.26):
# Array Size | Python Loop | NumPy (tolist) | NumPy (inplace) | Speedup
# ---------------------------------------------------------------------------
#      1,000 |     0.0001s |         0.0002s |         0.0000s |    2.5√ó
#     10,000 |     0.0012s |         0.0003s |         0.0000s |   12.0√ó
#    100,000 |     0.0125s |         0.0021s |         0.0001s |  125.0√ó
#  1,000,000 |     0.1250s |         0.0180s |         0.0008s |  156.3√ó
# 10,000,000 |     1.2500s |         0.1800s |         0.0080s |  156.3√ó

#### Diagram

from numba import njit
import numpy as np

@njit
def fast_sum(arr):
    """JIT-compiled function."""
    total = 0.0
    for i in range(len(arr)):
        total += arr[i]
    return total

# First call compiles (slower)
arr = np.arange(1_000_000, dtype=np.float64)
result = fast_sum(arr)  # Compilation overhead on first call

# Subsequent calls are fast
result = fast_sum(arr)  # Fast!

#### Diagram

import numpy as np
import time
from numba import njit

def python_sum(arr):
    """Pure Python sum."""
    total = 0.0
    for i in range(len(arr)):
        total += arr[i]
    return total

@njit
def numba_sum(arr):
    """Numba JIT-compiled sum."""
    total = 0.0
    for i in range(len(arr)):
        total += arr[i]
    return total

def numpy_sum(arr):
    """NumPy vectorized sum."""
    return np.sum(arr)

# Benchmark
arr = np.arange(10_000_000, dtype=np.float64)

# Python
start = time.perf_counter()
python_sum(arr)
py_time = time.perf_counter() - start

# NumPy
start = time.perf_counter()
numpy_sum(arr)
np_time = time.perf_counter() - start

# Numba (after warmup)
numba_sum(arr)  # Warmup
start = time.perf_counter()
numba_sum(arr)
nb_time = time.perf_counter() - start

print(f"Python: {py_time:.4f}s")
print(f"NumPy:  {np_time:.4f}s ({py_time/np_time:.1f}√ó faster)")
print(f"Numba:  {nb_time:.4f}s ({py_time/nb_time:.1f}√ó faster)")

# Typical Results:
# Python: 0.8500s
# NumPy:  0.0020s (425√ó faster)
# Numba:  0.0015s (567√ó faster)

#### Diagram

# math_ops.pyx
cpdef int add(int x, int y):
    return x + y

cpdef double fast_sum(double[:] arr):
    cdef double total = 0.0
    cdef int i
    for i in range(len(arr)):
        total += arr[i]
    return total

#### Diagram

# Pure Python
def python_sum(arr):
    total = 0.0
    for x in arr:
        total += x
    return total

# Cython (compiled)
# After compilation: import math_ops
# result = math_ops.fast_sum(arr)

# Benchmark results (typical):
# Python:  0.8500s (1.0√ó baseline)
# NumPy:   0.0020s (425√ó faster)
# Cython:  0.0010s (850√ó faster)

#### Diagram

// src/lib.rs
use pyo3::prelude::*;

#[pyfunction]
fn fast_sum(py: Python, arr: &PyArray1<f64>) -> PyResult<f64> {
    let array = unsafe { arr.as_array() };
    Ok(array.sum())
}

#[pymodule]
fn my_ext(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(fast_sum, m)?)?;
    Ok(())
}

#### Diagram

from multiprocessing import Pool
from concurrent.futures import ProcessPoolExecutor
import time

def cpu_task(n: int) -> int:
    """CPU-intensive task."""
    return sum(i * i for i in range(n))

# Single process
start = time.perf_counter()
results = [cpu_task(1_000_000) for _ in range(8)]
single_time = time.perf_counter() - start

# Multiprocessing (4 cores)
start = time.perf_counter()
with ProcessPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(cpu_task, [1_000_000] * 8))
multi_time = time.perf_counter() - start

print(f"Single process: {single_time:.2f}s")
print(f"4 processes:    {multi_time:.2f}s")
print(f"Speedup:        {single_time/multi_time:.2f}√ó")

# Typical Results (4-core CPU):
# Single process: 8.00s
# 4 processes:    2.50s (3.2√ó speedup, not 4√ó due to overhead)

#### Diagram

# Install: pip install line_profiler

@profile  # Decorator for line_profiler
def slow_function():
    total = 0
    for i in range(1000000):
        total += i ** 2
    return total

#### Diagram

from concurrent.futures import ProcessPoolExecutor, as_completed
import time

def expensive_computation(n: int) -> int:
    """CPU-intensive computation."""
    result = sum(i * i for i in range(n))
    return result

if __name__ == "__main__":
    data = [1000000, 2000000, 3000000, 4000000, 5000000]
    
    # Process pool with automatic cleanup
    with ProcessPoolExecutor(max_workers=4) as executor:
        # Submit tasks
        futures = [executor.submit(expensive_computation, n) for n in data]
        
        # Get results as they complete
        for future in as_completed(futures):
            result = future.result()
            print(f"Result: {result}")

#### Diagram

def risky_computation(n: int) -> int:
    """May raise exception."""
    if n < 0:
        raise ValueError("Negative number")
    return n * n

with ProcessPoolExecutor() as executor:
    futures = [executor.submit(risky_computation, n) for n in [-1, 2, 3]]
    
    for future in as_completed(futures):
        try:
            result = future.result()
            print(f"Success: {result}")
        except ValueError as e:
            print(f"Error: {e}")

#### Diagram

import time
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor

def cpu_task(n: int) -> int:
    """CPU-bound task."""
    return sum(i * i for i in range(n))

data = list(range(1000, 5000, 100))

# ThreadPool (limited by GIL)
start = time.perf_counter()
with ThreadPoolExecutor(max_workers=4) as executor:
    list(executor.map(cpu_task, data))
thread_time = time.perf_counter() - start

# ProcessPool (true parallelism)
start = time.perf_counter()
with ProcessPoolExecutor(max_workers=4) as executor:
    list(executor.map(cpu_task, data))
process_time = time.perf_counter() - start

print(f"ThreadPool: {thread_time:.2f}s")
print(f"ProcessPool: {process_time:.2f}s")
print(f"Speedup: {thread_time/process_time:.2f}x")

#### Diagram

from concurrent.futures import ProcessPoolExecutor
from pathlib import Path
from PIL import Image

def process_image(image_path: Path) -> Path:
    """Process single image (CPU-intensive)."""
    img = Image.open(image_path)
    # Resize and apply filters
    img = img.resize((800, 600))
    img = img.filter(Image.Filter.SHARPEN)
    output_path = image_path.parent / f"processed_{image_path.name}"
    img.save(output_path)
    return output_path

if __name__ == "__main__":
    images = list(Path("photos").glob("*.jpg"))
    
    with ProcessPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(process_image, images))
    
    print(f"Processed {len(results)} images")

#### Diagram

from multiprocessing import Process, Value, Array
import time

def increment_counter(counter: Value, lock):
    """Increment shared counter."""
    for _ in range(100000):
        with lock:
            counter.value += 1

if __name__ == "__main__":
    # Shared integer (Value)
    counter = Value('i', 0)  # 'i' = integer type
    lock = multiprocessing.Lock()
    
    # Create processes
    processes = [
        Process(target=increment_counter, args=(counter, lock))
        for _ in range(4)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print(f"Final counter value: {counter.value}")  # Should be 400000

#### Diagram

# ‚ùå WRONG: Race condition
counter = Value('i', 0)
def bad_increment():
    counter.value += 1  # Not atomic!

# ‚úÖ CORRECT: Use lock
from multiprocessing import Lock

lock = Lock()
def good_increment():
    with lock:
        counter.value += 1

#### Diagram

from multiprocessing import Process, Array, Lock
import math

def compute_row(arr: Array, row: int, cols: int, lock: Lock):
    """Compute values for one row."""
    for col in range(cols):
        index = row * cols + col
        with lock:
            arr[index] = math.sin(row) * math.cos(col)

if __name__ == "__main__":
    rows, cols = 1000, 1000
    shared_matrix = Array('d', [0.0] * (rows * cols))
    lock = Lock()
    
    # Process each row in parallel
    processes = [
        Process(target=compute_row, args=(shared_matrix, r, cols, lock))
        for r in range(rows)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    # Access results
    result = [shared_matrix[i] for i in range(rows * cols)]
    print(f"Computed {len(result)} values")

#### Diagram

from multiprocessing import Manager, Process

def worker(shared_dict: dict, shared_list: list):
    """Worker that modifies shared objects."""
    shared_dict['count'] = shared_dict.get('count', 0) + 1
    shared_list.append(os.getpid())

if __name__ == "__main__":
    manager = Manager()
    shared_dict = manager.dict()
    shared_list = manager.list()
    
    # Start workers
    processes = [
        Process(target=worker, args=(shared_dict, shared_list))
        for _ in range(5)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print(f"Dict: {dict(shared_dict)}")
    print(f"List: {list(shared_list)}")

#### Diagram

from multiprocessing import Manager, Process

def update_stats(stats):
    """Update statistics."""
    stats.processed += 1
    stats.total_time += 0.5

if __name__ == "__main__":
    manager = Manager()
    stats = manager.Namespace()
    stats.processed = 0
    stats.total_time = 0.0
    
    processes = [
        Process(target=update_stats, args=(stats,))
        for _ in range(10)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print(f"Processed: {stats.processed}")
    print(f"Total time: {stats.total_time}")

#### Diagram

# ‚ùå BAD: Large objects passed to processes
large_data = [list(range(10000)) for _ in range(1000)]

def process(data):
    return sum(sum(row) for row in data)

# Each process receives full copy ‚Üí huge memory usage
with ProcessPoolExecutor() as executor:
    results = executor.map(process, [large_data] * 10)

# ‚úÖ BETTER: Pass indices or file paths
def process_by_index(start_idx, end_idx):
    # Load data in process
    data = load_data_slice(start_idx, end_idx)
    return process(data)

#### Diagram

# ‚ùå BAD: Many small tasks
def tiny_task(x):
    return x * 2

# Process startup overhead > task time
with ProcessPoolExecutor() as executor:
    results = list(executor.map(tiny_task, range(100)))  # Slow!

# ‚úÖ BETTER: Batch small tasks
def batch_task(batch):
    return [x * 2 for x in batch]

batches = [list(range(i, i+100)) for i in range(0, 1000, 100)]
with ProcessPoolExecutor() as executor:
    results = list(executor.map(batch_task, batches))

#### Diagram

from abc import ABC, abstractmethod
from typing import Optional, List

class UserRepository(ABC):
    @abstractmethod
    def get_by_id(self, user_id: int) -> Optional[dict]:
        """Get user by ID."""
        pass
    
    @abstractmethod
    def save(self, user: dict) -> dict:
        """Save user."""
        pass

class SQLUserRepository(UserRepository):
    def __init__(self, db_connection):
        self.db = db_connection
    
    def get_by_id(self, user_id: int) -> Optional[dict]:
        cursor = self.db.execute("SELECT * FROM users WHERE id=?", (user_id,))
        row = cursor.fetchone()
        return dict(row) if row else None
    
    def save(self, user: dict) -> dict:
        # Implementation
        pass

class InMemoryUserRepository(UserRepository):
    def __init__(self):
        self._users = {}
    
    def get_by_id(self, user_id: int) -> Optional[dict]:
        return self._users.get(user_id)
    
    def save(self, user: dict) -> dict:
        self._users[user["id"]] = user
        return user

# Usage
class UserService:
    def __init__(self, repository: UserRepository):
        self.repo = repository
    
    def get_user(self, user_id: int) -> Optional[dict]:
        return self.repo.get_by_id(user_id)

# In tests
service = UserService(InMemoryUserRepository())
# In production
service = UserService(SQLUserRepository(db))

#### Diagram

from typing import Protocol

class IDatabase(Protocol):
    def execute(self, query: str, params: tuple) -> dict: ...

class Database:
    def execute(self, query: str, params: tuple) -> dict:
        # Real implementation
        return {"result": "data"}

class Service:
    def __init__(self, db: IDatabase):
        self.db = db
    
    def process(self):
        return self.db.execute("SELECT * FROM data", ())

# Manual injection
service = Service(Database())

# Using dependency injection framework (e.g., dependency-injector)
from dependency_injector import containers, providers

class Container(containers.DeclarativeContainer):
    db = providers.Singleton(Database)
    service = providers.Factory(Service, db=db)

container = Container()
service = container.service()

#### Diagram

from typing import Callable

def federal_tax(amount: float) -> float:
    return amount * 0.25

def state_tax(amount: float) -> float:
    return amount * 0.05

def calculate_total(amount: float, tax_strategy: Callable[[float], float]) -> float:
    return amount + tax_strategy(amount)

# Usage
total1 = calculate_total(100, federal_tax)  # 125.0
total2 = calculate_total(100, state_tax)   # 105.0

#### Diagram

from fastapi import FastAPI, Depends
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from pydantic import BaseModel

app = FastAPI()
engine = create_async_engine("postgresql+asyncpg://...")
SessionLocal = async_sessionmaker(engine, expire_on_commit=False)

class UserResponse(BaseModel):
    id: int
    name: str

async def get_db():
    async with SessionLocal() as session:
        yield session

@app.get("/users/{user_id}", response_model=UserResponse)
async def get_user(user_id: int, db: AsyncSession = Depends(get_db)):
    # Database query here
    return UserResponse(id=user_id, name="Alice")
    # Output: {"id": 1, "name": "Alice"}

#### Diagram

flowchart TD
    APIService[API Service] -->|enqueue job| MessageBus[Message Bus<br/>Redis/Kafka]
    
    MessageBus -->|deliver message| WorkerCluster[Worker Cluster<br/>Celery / Dramatiq / RQ]
    
    WorkerCluster --> Worker1[Worker1]
    WorkerCluster --> Worker2[Worker2]
    
    style APIService fill:#e1f5ff
    style MessageBus fill:#ffe1f5
    style WorkerCluster fill:#e1ffe1
    style Worker1 fill:#fff4e1
    style Worker2 fill:#ffe1e1

#### Diagram

# ‚úÖ CORRECT: Basic docstring example
def greet(name: str) -> str:
    """Return a greeting message for the given name."""
    return f"Hello, {name}!"

# Access the docstring
print(greet.__doc__)  # Returns: "Return a greeting message for the given name."

#### Diagram

flowchart LR
    A[Docstring in Source File] --> B[Python Runtime __doc__]
    B --> C[inspect.getdoc]
    C --> D[LSP Server / Editor]
    D --> E[IDE Tooltip Docs]
    B --> F[Sphinx / MkDocs Generators]
    B --> G[Doctest Runner]
    B --> H[LLM / RAG Processing Layer]

#### Diagram

# ‚úÖ CORRECT: Google-style docstring
def scale(x: float, factor: float) -> float:
    """Scale a numeric value by a given factor.

    Args:
        x: Input value.
        factor: The number to multiply by.

    Returns:
        The scaled result.
    """
    return x * factor

#### Diagram

# ‚úÖ CORRECT: Function with comprehensive docstring
def login_user(username: str, password: str) -> bool:
    """Authenticate a user against the credentials database.

    Args:
        username: The user's login name.
        password: Raw password input.

    Returns:
        True if the user is authenticated; otherwise False.

    Raises:
        AuthenticationError: If credentials are invalid.
        DatabaseError: If the database is unavailable.
    """
    # Implementation here
    pass

#### Diagram

# ‚úÖ CORRECT: Async function docstring
async def fetch_user(uid: str) -> dict:
    """Fetch a user record asynchronously from the database.

    Args:
        uid: Unique user identifier.

    Returns:
        Dictionary containing user data with keys: id, name, email.

    Raises:
        UserNotFoundError: If the user does not exist.
    """
    # Implementation here
    pass

#### Diagram

# ‚úÖ CORRECT: Property docstring
class User:
    """User account representation."""

    def __init__(self, first: str, last: str):
        self._first = first
        self._last = last

    @property
    def full_name(self) -> str:
        """Return the user's full name.

        Returns:
            Concatenated first and last name separated by a space.
        """
        return f"{self._first} {self._last}"

#### Diagram

# ‚úÖ CORRECT: Public function with docstring
def process_payment(amount: float, currency: str) -> bool:
    """Process a payment transaction."""
    return _validate_and_charge(amount, currency)

# ‚úÖ CORRECT: Private function can skip docstring for simple cases
def _validate_and_charge(amount: float, currency: str) -> bool:
    # Implementation
    return True

#### Diagram

# ‚úÖ CORRECT: Detailed return type documentation
def parse_config(path: str) -> dict[str, Any]:
    """Parse a YAML configuration file.

    Args:
        path: Path to the YAML configuration file.

    Returns:
        Dictionary containing parsed configuration with structure:
        {
            "database": {
                "host": str,
                "port": int,
                "credentials": dict
            },
            "logging": {
                "level": str,
                "handlers": list[str]
            }
        }

    Raises:
        FileNotFoundError: If the configuration file does not exist.
        YAMLError: If the file contains invalid YAML syntax.
    """
    pass

#### Diagram

# ‚úÖ CORRECT: Generic function with type variable documentation
from typing import TypeVar, Callable

T = TypeVar('T')

def retry(func: Callable[[], T], max_attempts: int = 3) -> T:
    """Retry a function until it succeeds or max attempts is reached.

    Type Parameters:
        T: The return type of the function being retried.

    Args:
        func: Zero-argument callable to retry.
        max_attempts: Maximum number of retry attempts.

    Returns:
        The result of the successful function call.

    Raises:
        MaxRetriesExceeded: If all retry attempts fail.
    """
    pass

#### Diagram

# ‚úÖ CORRECT: Decorator documentation
from functools import wraps
from typing import Callable, TypeVar, ParamSpec

P = ParamSpec('P')
T = TypeVar('T')

def memoize(func: Callable[P, T]) -> Callable[P, T]:
    """Decorator that caches function results based on arguments.

    Args:
        func: Function to memoize. Must have hashable arguments.

    Returns:
        Wrapped function with caching behavior.

    Examples:
        >>> @memoize
        ... def fibonacci(n: int) -> int:
        ...     if n < 2:
        ...         return n
        ...     return fibonacci(n-1) + fibonacci(n-2)
    """
    cache = {}
    
    @wraps(func)
    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
        key = (args, tuple(sorted(kwargs.items())))
        if key not in cache:
            cache[key] = func(*args, **kwargs)
        return cache[key]
    
    return wrapper

#### Diagram

# ‚ùå INCORRECT: Just repeats what the name already says
def add(x, y):
    """Add function."""
    return x + y

#### Diagram

# ‚ùå INCORRECT: Missing Raises section
def parse_int(value: str) -> int:
    """Convert a string to an integer."""
    return int(value)  # Can raise ValueError!

#### Diagram

# ‚ùå INCORRECT: Describes how instead of what
def authenticate(user: str, pwd: str) -> bool:
    """Check password by computing SHA256 hash and comparing with database.
    
    Uses the hashlib library to compute the hash, then queries the users
    table in PostgreSQL using SQLAlchemy ORM.
    """
    pass

#### Diagram

# ‚úÖ CORRECT: Clear, complete, focused on contract
def parse_int(value: str) -> int:
    """Convert a string to an integer.

    Args:
        value: String representation of an integer.

    Returns:
        The integer value.

    Raises:
        ValueError: If the string cannot be converted to an integer.
    """
    return int(value)

#### Diagram

# ‚úÖ CORRECT: Describes behavior, not implementation
def authenticate(user: str, pwd: str) -> bool:
    """Verify user credentials against stored credentials.

    Args:
        user: Username to authenticate.
        pwd: Password to verify.

    Returns:
        True if credentials are valid; False otherwise.

    Raises:
        DatabaseError: If credential verification fails due to database issues.
    """
    pass

#### Diagram

# ‚ùå INCORRECT: Exposes internal implementation details
def fetch_user(uid: str) -> dict:
    """Fetch user from database.
    
    Raises:
        psycopg2.OperationalError: If PostgreSQL connection fails.
        redis.ConnectionError: If Redis cache is unavailable.
    """
    pass

# ‚úÖ CORRECT: Public API uses abstracted exceptions
def fetch_user(uid: str) -> dict:
    """Fetch user from database.
    
    Raises:
        DatabaseError: If user data cannot be retrieved.
        UserNotFoundError: If the user does not exist.
    """
    pass

#### Diagram

# ‚ùå INCORRECT: Docstring doesn't match signature
def process_order(order_id: str, priority: bool = False) -> dict:
    """Process an order.
    
    Args:
        order_id: Order identifier.
        expedite: Whether to expedite shipping.  # ‚ùå Wrong parameter name!
    """
    pass

#### Diagram

# ‚ùå INCORRECT: States the obvious
def get_name(self) -> str:
    """Get the name.
    
    Returns:
        str: The name.
    """
    return self._name

# ‚úÖ CORRECT: Adds value
def get_name(self) -> str:
    """Return the user's display name.
    
    Returns:
        Full name if available; otherwise username.
    """
    return self._full_name or self._username

#### Diagram

# ‚úÖ CORRECT: Sphinx-compatible docstring
def calculate_tax(amount: float, rate: float) -> float:
    """Calculate tax on a given amount.

    Args:
        amount: Pre-tax amount in dollars.
        rate: Tax rate as a decimal (e.g., 0.08 for 8%).

    Returns:
        Tax amount in dollars.

    Examples:
        >>> calculate_tax(100.0, 0.08)
        8.0
        >>> calculate_tax(50.0, 0.10)
        5.0
    """
    return amount * rate

#### Diagram

# ‚úÖ CORRECT: Doctest examples in docstring
def factorial(n: int) -> int:
    """Calculate factorial of n.

    Args:
        n: Non-negative integer.

    Returns:
        Factorial of n.

    Raises:
        ValueError: If n is negative.

    Examples:
        >>> factorial(0)
        1
        >>> factorial(5)
        120
        >>> factorial(-1)
        Traceback (most recent call last):
            ...
        ValueError: n must be non-negative
    """
    if n < 0:
        raise ValueError("n must be non-negative")
    if n == 0:
        return 1
    return n * factorial(n - 1)

#### Diagram

# ‚úÖ CORRECT: Docstring consistent with type hints
def divide(x: float, y: float) -> float:
    """Divide x by y.

    Args:
        x: Numerator.
        y: Denominator.

    Returns:
        Result of division.

    Raises:
        ZeroDivisionError: If y is zero.
    """
    if y == 0:
        raise ZeroDivisionError("Cannot divide by zero")
    return x / y

#### Diagram

‚ü®stmt, œÉ‚ü© ‚Üí œÉ'    (statement transforms state)

or

‚ü®expr, œÉ‚ü© ‚Üí ‚ü®v, œÉ'‚ü©    (expression evaluates to value, may modify state)

#### Diagram

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-Assign]
‚ü®expr, œÉ‚ü© ‚Üí ‚ü®v, œÉ'‚ü©    œÉ'[name ‚Ü¶ v] = œÉ''
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name = expr, œÉ‚ü© ‚Üí œÉ''

#### Diagram

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-App]
‚ü®g(), œÉ‚ü© ‚Üí v‚ÇÅ    ‚ü®h(), œÉ'‚ü© ‚Üí v‚ÇÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®f(g(), h()), œÉ‚ü© ‚Üí ‚ü®f(v‚ÇÅ, v‚ÇÇ), œÉ''‚ü©

#### Diagram

Step 1: ‚ü®g(), œÉ‚ü© ‚Üí v‚ÇÅ
Step 2: ‚ü®h(), œÉ‚ü© ‚Üí v‚ÇÇ  
Step 3: ‚ü®f(v‚ÇÅ, v‚ÇÇ), œÉ‚ü© ‚Üí result

Final: ‚ü®f(g(), h()), œÉ‚ü© ‚Üí result

#### Diagram

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Local]
name ‚àà dom(Env_local)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí Env_local[name]

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Enclosing]
name ‚àâ dom(Env_local)    name ‚àà dom(Env_enclosing)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí Env_enclosing[name]

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Global]
name ‚àâ dom(Env_local ‚à™ Env_enclosing)    name ‚àà dom(Env_global)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí Env_global[name]

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Builtin]
name ‚àâ dom(Env_local ‚à™ Env_enclosing ‚à™ Env_global)    name ‚àà dom(Builtins)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí Builtins[name]

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Resolve-Error]
name ‚àâ dom(Env_local ‚à™ Env_enclosing ‚à™ Env_global ‚à™ Builtins)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®name, Env‚ü© ‚Üí NameError("name 'name' is not defined")

#### Diagram

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-FunDef]
Env' = {x ‚Ü¶ v | x ‚àà free_vars(fun_body) ‚àß x ‚àà dom(Env)}
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®def outer(x): ... def inner(y): return x + y, Env‚ü© 
  ‚Üí ‚ü®closure(inner_code, Env' = {x ‚Ü¶ Env[x]}), Env‚ü©

#### Diagram

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-ClosureApp]
‚ü®closure(code, Env_captured), Env‚ü© ‚Üí fun_obj
‚ü®arg, Env‚ü© ‚Üí v
Env_new = Env_captured ‚à™ {param ‚Ü¶ v}  (extend with argument)
‚ü®code, Env_new‚ü© ‚Üí result
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®closure(code, Env_captured)(arg), Env‚ü© ‚Üí result

#### Diagram

def outer(x):
    def inner(y):
        return x + y
    return inner

# Formal representation:
# outer_code = Œªx. (Œªy. x + y)
# When outer(5) is called:
#   Env_captured = {x ‚Ü¶ 5}
#   Returns: closure(inner_code, {x ‚Ü¶ 5})
# When closure(3) is called:
#   Env_new = {x ‚Ü¶ 5, y ‚Ü¶ 3}
#   Evaluates: x + y ‚Üí 5 + 3 ‚Üí 8

#### Diagram

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Var]
x : œÑ ‚àà Œì
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ x : œÑ

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Int]
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ n : int    (for integer literal n)

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Str]
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ s : str    (for string literal s)

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Fun]
Œì, x : œÑ‚ÇÅ ‚ä¢ body : œÑ‚ÇÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ (Œªx: œÑ‚ÇÅ. body) : œÑ‚ÇÅ ‚Üí œÑ‚ÇÇ

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-App]
Œì ‚ä¢ f : œÑ‚ÇÅ ‚Üí œÑ‚ÇÇ    Œì ‚ä¢ arg : œÑ‚ÇÅ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ f(arg) : œÑ‚ÇÇ

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [T-Union]
Œì ‚ä¢ e : œÑ‚ÇÅ    or    Œì ‚ä¢ e : œÑ‚ÇÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Œì ‚ä¢ e : œÑ‚ÇÅ | œÑ‚ÇÇ

#### Diagram

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-Eq]
‚ü®obj.__eq__(other), œÉ‚ü© ‚Üí ‚ü®True, œÉ'‚ü©    or    ‚ü®False, œÉ'‚ü©
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®obj == other, œÉ‚ü© ‚Üí ‚ü®obj.__eq__(other), œÉ‚ü©

Properties:
  - Reflexive: ‚àÄx. x == x
  - Symmetric: x == y ‚ü∫ y == x
  - Transitive: (x == y) ‚àß (y == z) ‚üπ (x == z)
  - Not guaranteed: objects may violate these (bad practice)

#### Diagram

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-Lt]
‚ü®obj.__lt__(other), œÉ‚ü© ‚Üí ‚ü®True, œÉ'‚ü©    or    ‚ü®False, œÉ'‚ü©
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®obj < other, œÉ‚ü© ‚Üí ‚ü®obj.__lt__(other), œÉ‚ü©

Properties:
  - Partial: Not all objects are comparable
  - If comparable: must satisfy transitivity, antisymmetry
  - TypeError raised if objects are not comparable

#### Diagram

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  [Eval-Hash]
‚ü®obj.__hash__(), œÉ‚ü© ‚Üí ‚ü®h, œÉ'‚ü©    h ‚àà ‚Ñ§
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ü®hash(obj), œÉ‚ü© ‚Üí ‚ü®h, œÉ'‚ü©

Invariant (for hashable objects):
  obj‚ÇÅ == obj‚ÇÇ ‚üπ hash(obj‚ÇÅ) == hash(obj‚ÇÇ)
  
Violation raises TypeError at runtime.

#### Diagram

graph TD
    Arena[Arena 256 KiB or 1 MiB] --> Pool0[Pool 0 4 KiB<br/>Block, Block, Block, ...]
    Arena --> Pool1[Pool 1 4 KiB<br/>...]
    Arena --> PoolN[Pool N 4 KiB<br/>...]
    
    Pool0 --> Blocks0[Blocks organized by size class<br/>8, 16, 24, 32, ... up to 512 bytes]
    Pool1 --> Blocks1[Blocks organized by size class]
    PoolN --> BlocksN[Blocks organized by size class]
    
    style Arena fill:#e1f5ff
    style Pool0 fill:#ffe1f5
    style Pool1 fill:#e1ffe1
    style PoolN fill:#fff4e1

#### Diagram

flowchart TD
    Orchestrator[Orchestrator] --> Architect[Architect]
    Orchestrator --> Reviewer[Reviewer]
    Orchestrator --> Tester[Tester]
    
    Architect --> Refactorer[Refactorer]
    Reviewer --> Security[Security]
    Tester --> Docs[Docs]
    
    Refactorer --> SharedMemory[Shared Memory<br/>Vector Store, Context]
    Security --> SharedMemory
    Docs --> SharedMemory
    
    style Orchestrator fill:#e1f5ff
    style SharedMemory fill:#fff4e1

#### Diagram

from typing import List, Dict, Any, Callable
from dataclasses import dataclass
from enum import Enum
import json

class AgentRole(Enum):
    ARCHITECT = "architect"
    REVIEWER = "reviewer"
    TESTER = "tester"
    REFACTORER = "refactorer"
    SECURITY = "security"
    DOCS = "documentation"

@dataclass
class AgentMessage:
    role: AgentRole
    content: str
    metadata: Dict[str, Any]

class BaseAgent:
    """Base class for all agents."""
    
    def __init__(self, role: AgentRole, llm_client, tools: List[Callable]):
        self.role = role
        self.llm_client = llm_client
        self.tools = {tool.__name__: tool for tool in tools}
        self.memory: List[AgentMessage] = []
    
    def execute(self, task: str, context: Dict[str, Any]) -> AgentMessage:
        """Execute agent task and return message."""
        # Agent-specific logic here
        result = self._process(task, context)
        message = AgentMessage(
            role=self.role,
            content=result,
            metadata=context
        )
        self.memory.append(message)
        return message
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        """Override in subclasses."""
        raise NotImplementedError

class ArchitectAgent(BaseAgent):
    """Proposes system design and architecture."""
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        prompt = f"""
        As an architect agent, analyze the following task and propose a design:
        
        Task: {task}
        Context: {json.dumps(context, indent=2)}
        
        Provide:
        1. Architecture proposal
        2. Component breakdown
        3. Dependencies
        4. File structure
        """
        # In real implementation, call LLM
        return f"Architecture proposal for: {task}"

class ReviewerAgent(BaseAgent):
    """Reviews code for patterns and compliance."""
    
    def __init__(self, *args, rules: List[str], **kwargs):
        super().__init__(*args, **kwargs)
        self.rules = rules
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        code = context.get("code", "")
        violations = []
        
        # Check against rules
        for rule in self.rules:
            if self._violates_rule(code, rule):
                violations.append(rule)
        
        if violations:
            return f"Review failed. Violations: {violations}"
        return "Review passed. Code complies with patterns."

    def _violates_rule(self, code: str, rule: str) -> bool:
        """Check if code violates rule."""
        # Simplified - real implementation would use AST analysis
        return False

class TesterAgent(BaseAgent):
    """Generates tests for code."""
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        code = context.get("code", "")
        test_code = f"""
# Generated tests for: {task}
import pytest

def test_basic_functionality():
    # Test implementation
    pass

def test_edge_cases():
    # Edge case tests
    pass
"""
        return test_code

class SecurityAgent(BaseAgent):
    """Checks for security anti-patterns."""
    
    SECURITY_PATTERNS = [
        "subprocess.run",
        "eval(",
        "exec(",
        "pickle.loads",
        "yaml.load(",
    ]
    
    def _process(self, task: str, context: Dict[str, Any]) -> str:
        code = context.get("code", "")
        issues = []
        
        for pattern in self.SECURITY_PATTERNS:
            if pattern in code:
                issues.append(f"Security risk: {pattern}")
        
        if issues:
            return f"Security issues found: {issues}"
        return "Security check passed."

class MultiAgentOrchestrator:
    """Coordinates multiple agents."""
    
    def __init__(self, agents: List[BaseAgent]):
        self.agents = {agent.role: agent for agent in agents}
        self.shared_memory: List[AgentMessage] = []
    
    def execute_workflow(self, task: str) -> Dict[AgentRole, str]:
        """Execute multi-agent workflow."""
        results = {}
        
        # Step 1: Architect proposes design
        arch_result = self.agents[AgentRole.ARCHITECT].execute(
            task, {"phase": "design"}
        )
        results[AgentRole.ARCHITECT] = arch_result.content
        self.shared_memory.append(arch_result)
        
        # Step 2: Generate code (simplified)
        code = self._generate_code(task, arch_result.content)
        
        # Step 3: Reviewer checks patterns
        review_result = self.agents[AgentRole.REVIEWER].execute(
            "Review code", {"code": code, "task": task}
        )
        results[AgentRole.REVIEWER] = review_result.content
        
        # Step 4: Security check
        security_result = self.agents[AgentRole.SECURITY].execute(
            "Security audit", {"code": code}
        )
        results[AgentRole.SECURITY] = security_result.content
        
        # Step 5: Tester generates tests
        test_result = self.agents[AgentRole.TESTER].execute(
            "Generate tests", {"code": code, "task": task}
        )
        results[AgentRole.TESTER] = test_result.content
        
        # Step 6: Refactor if needed
        if "failed" in review_result.content.lower():
            refactor_result = self.agents[AgentRole.REFACTORER].execute(
                "Refactor code", {"code": code, "issues": review_result.content}
            )
            results[AgentRole.REFACTORER] = refactor_result.content
        
        return results
    
    def _generate_code(self, task: str, design: str) -> str:
        """Generate code based on design (simplified)."""
        return f"# Generated code for: {task}\n# Design: {design}"

# Usage
orchestrator = MultiAgentOrchestrator([
    ArchitectAgent(AgentRole.ARCHITECT, llm_client=None, tools=[]),
    ReviewerAgent(AgentRole.REVIEWER, llm_client=None, tools=[], 
                  rules=["no_global_state", "type_hints_required"]),
    TesterAgent(AgentRole.TESTER, llm_client=None, tools=[]),
    SecurityAgent(AgentRole.SECURITY, llm_client=None, tools=[]),
])

results = orchestrator.execute_workflow("Create user authentication system")
for role, result in results.items():
    print(f"{role.value}: {result}")

#### Diagram

from typing import List, Dict, Any
from dataclasses import dataclass

@dataclass
class ReActStep:
    thought: str
    action: str
    action_input: Dict[str, Any]
    observation: str

class ReActAgent:
    """ReAct pattern agent: reasons before acting."""
    
    def __init__(self, llm_client, tools: Dict[str, Callable], max_steps: int = 10):
        self.llm_client = llm_client
        self.tools = tools
        self.max_steps = max_steps
        self.steps: List[ReActStep] = []
    
    def execute(self, task: str) -> str:
        """Execute task using ReAct pattern."""
        observation = f"Task: {task}"
        
        for step_num in range(self.max_steps):
            # Think
            thought = self._think(observation, self.steps)
            
            # Decide action
            action, action_input = self._decide_action(thought)
            
            if action == "FINISH":
                return self._extract_answer(thought)
            
            # Execute action
            if action in self.tools:
                observation = str(self.tools[action](**action_input))
            else:
                observation = f"Unknown action: {action}"
            
            # Record step
            self.steps.append(ReActStep(
                thought=thought,
                action=action,
                action_input=action_input,
                observation=observation
            ))
        
        return "Max steps reached. Task incomplete."
    
    def _think(self, observation: str, history: List[ReActStep]) -> str:
        """Generate reasoning thought."""
        # In real implementation, use LLM
        return f"Analyzing: {observation}"
    
    def _decide_action(self, thought: str) -> tuple[str, Dict[str, Any]]:
        """Decide next action based on thought."""
        # In real implementation, use LLM to choose tool
        return "FINISH", {}
    
    def _extract_answer(self, thought: str) -> str:
        """Extract final answer from thought."""
        return thought

# Example: File system agent
def read_file(path: str) -> str:
    """Read file content."""
    with open(path, 'r') as f:
        return f.read()

def write_file(path: str, content: str) -> None:
    """Write file content."""
    with open(path, 'w') as f:
        f.write(content)

agent = ReActAgent(
    llm_client=None,
    tools={"read_file": read_file, "write_file": write_file}
)

result = agent.execute("Read config.json and update the version field")

#### Diagram

from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import Tool
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

# Define tools
def search_codebase(query: str) -> str:
    """Search codebase for patterns."""
    # Implementation
    return f"Found: {query}"

def run_tests() -> str:
    """Run test suite."""
    # Implementation
    return "Tests passed"

tools = [
    Tool(name="search_codebase", func=search_codebase, 
         description="Search codebase for code patterns"),
    Tool(name="run_tests", func=run_tests,
         description="Run the test suite"),
]

# Create agent
llm = ChatOpenAI(model="gpt-4o", temperature=0)
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code review agent. Use tools to analyze code."),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

agent = create_openai_tools_agent(llm, tools, prompt)
executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# Execute
result = executor.invoke({"input": "Review the authentication module"})

#### Diagram

class CodeCleanupAgent:
    """Multi-agent system for code cleanup."""
    
    def __init__(self):
        self.agents = {
            "analyzer": self._analyze_code,
            "refactorer": self._refactor_code,
            "validator": self._validate_code,
        }
    
    def cleanup(self, code: str) -> str:
        """Clean up code using agent pipeline."""
        # Analyze
        issues = self.agents["analyzer"](code)
        
        # Refactor
        cleaned = self.agents["refactorer"](code, issues)
        
        # Validate
        if self.agents["validator"](cleaned):
            return cleaned
        else:
            return code  # Return original if validation fails
    
    def _analyze_code(self, code: str) -> List[str]:
        """Analyze code for issues."""
        issues = []
        if "import *" in code:
            issues.append("wildcard_import")
        if "eval(" in code:
            issues.append("eval_usage")
        return issues
    
    def _refactor_code(self, code: str, issues: List[str]) -> str:
        """Refactor code to fix issues."""
        # Refactoring logic
        return code
    
    def _validate_code(self, code: str) -> bool:
        """Validate refactored code."""
        # Run linter, type checker, tests
        return True

#### Diagram

from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import json
import sqlite3
from pathlib import Path

@dataclass
class ToolResult:
    success: bool
    result: Any
    error: Optional[str] = None

class PythonToolAgent:
    """Agent with real Python tools for file I/O, DB access, etc."""
    
    def __init__(self, llm_client, db_path: str = "agent.db"):
        self.llm_client = llm_client
        self.db_path = db_path
        self.tools = {
            "read_file": self._read_file,
            "write_file": self._write_file,
            "list_directory": self._list_directory,
            "query_database": self._query_database,
            "execute_sql": self._execute_sql,
            "search_files": self._search_files,
            "run_command": self._run_command_safe,
        }
    
    def _read_file(self, path: str) -> ToolResult:
        """Read file content safely."""
        try:
            file_path = Path(path)
            if not file_path.exists():
                return ToolResult(False, None, f"File not found: {path}")
            if not file_path.is_file():
                return ToolResult(False, None, f"Not a file: {path}")
            # Security: prevent reading outside allowed directories
            if not str(file_path.resolve()).startswith(str(Path.cwd().resolve())):
                return ToolResult(False, None, "Path traversal not allowed")
            
            content = file_path.read_text(encoding='utf-8')
            return ToolResult(True, content)
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _write_file(self, path: str, content: str, mode: str = "w") -> ToolResult:
        """Write file content safely."""
        try:
            file_path = Path(path)
            # Security: prevent writing outside allowed directories
            if not str(file_path.resolve()).startswith(str(Path.cwd().resolve())):
                return ToolResult(False, None, "Path traversal not allowed")
            
            file_path.parent.mkdir(parents=True, exist_ok=True)
            file_path.write_text(content, encoding='utf-8')
            return ToolResult(True, f"Written {len(content)} bytes to {path}")
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _list_directory(self, path: str = ".") -> ToolResult:
        """List directory contents."""
        try:
            dir_path = Path(path)
            if not dir_path.exists():
                return ToolResult(False, None, f"Directory not found: {path}")
            if not dir_path.is_dir():
                return ToolResult(False, None, f"Not a directory: {path}")
            
            items = {
                "files": [str(p) for p in dir_path.iterdir() if p.is_file()],
                "directories": [str(p) for p in dir_path.iterdir() if p.is_dir()],
            }
            return ToolResult(True, items)
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _query_database(self, query: str, params: Dict[str, Any] = None) -> ToolResult:
        """Execute SELECT query safely."""
        try:
            if not query.strip().upper().startswith("SELECT"):
                return ToolResult(False, None, "Only SELECT queries allowed")
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            results = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description] if cursor.description else []
            
            conn.close()
            
            return ToolResult(True, {
                "columns": columns,
                "rows": results,
                "count": len(results)
            })
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _execute_sql(self, query: str, params: Dict[str, Any] = None) -> ToolResult:
        """Execute write SQL (with approval)."""
        # In production, require approval for write operations
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            conn.commit()
            affected = cursor.rowcount
            conn.close()
            
            return ToolResult(True, f"Query executed. Rows affected: {affected}")
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _search_files(self, pattern: str, directory: str = ".") -> ToolResult:
        """Search for files matching pattern."""
        try:
            dir_path = Path(directory)
            matches = list(dir_path.rglob(pattern))
            return ToolResult(True, [str(m) for m in matches])
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def _run_command_safe(self, command: str) -> ToolResult:
        """Run command with restrictions."""
        # Whitelist of allowed commands
        ALLOWED_COMMANDS = ["ls", "pwd", "cat", "grep"]
        
        parts = command.split()
        if not parts or parts[0] not in ALLOWED_COMMANDS:
            return ToolResult(False, None, f"Command not allowed: {parts[0] if parts else 'empty'}")
        
        import subprocess
        try:
            result = subprocess.run(
                command.split(),
                capture_output=True,
                text=True,
                timeout=5,
                cwd=Path.cwd()
            )
            return ToolResult(
                True,
                {
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode
                }
            )
        except Exception as e:
            return ToolResult(False, None, str(e))
    
    def execute_with_tools(self, task: str) -> str:
        """Execute task using available tools."""
        # In real implementation, use LLM to decide which tools to call
        # This is a simplified version
        
        # Example: "Read config.json and update the database"
        if "read" in task.lower() and "file" in task.lower():
            # Extract file path (simplified)
            file_path = "config.json"  # In real implementation, extract from task
            result = self._read_file(file_path)
            if result.success:
                return f"File content: {result.result[:100]}..."
            else:
                return f"Error: {result.error}"
        
        return "Task completed"

# Usage
agent = PythonToolAgent(llm_client=None, db_path="app.db")
result = agent.execute_with_tools("Read config.json and show database schema")

#### Diagram

from typing import Callable, Optional
from enum import Enum
import time
import logging

class ErrorType(Enum):
    RATE_LIMIT = "rate_limit"
    TIMEOUT = "timeout"
    INVALID_RESPONSE = "invalid_response"
    TOOL_ERROR = "tool_error"
    NETWORK_ERROR = "network_error"

class RetryStrategy:
    """Configurable retry strategies."""
    
    @staticmethod
    def exponential_backoff(max_retries: int = 3, base_delay: float = 1.0):
        """Exponential backoff retry."""
        def retry(func: Callable, *args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise
                    delay = base_delay * (2 ** attempt)
                    time.sleep(delay)
                    logging.warning(f"Retry {attempt + 1}/{max_retries} after {delay}s")
        return retry
    
    @staticmethod
    def circuit_breaker(threshold: int = 5, timeout: float = 60.0):
        """Circuit breaker pattern."""
        failures = 0
        last_failure_time = 0
        
        def wrapper(func: Callable, *args, **kwargs):
            nonlocal failures, last_failure_time
            
            # Check if circuit is open
            if failures >= threshold:
                if time.time() - last_failure_time < timeout:
                    raise Exception("Circuit breaker is OPEN")
                else:
                    # Reset after timeout
                    failures = 0
            
            try:
                result = func(*args, **kwargs)
                failures = 0  # Reset on success
                return result
            except Exception as e:
                failures += 1
                last_failure_time = time.time()
                raise
        return wrapper

class ResilientAgent:
    """Agent with error recovery mechanisms."""
    
    def __init__(self, llm_client, tools: Dict[str, Callable]):
        self.llm_client = llm_client
        self.tools = tools
        self.retry_strategy = RetryStrategy.exponential_backoff(max_retries=3)
        self.circuit_breaker = RetryStrategy.circuit_breaker(threshold=5)
    
    def execute_with_recovery(self, task: str) -> str:
        """Execute with automatic error recovery."""
        # Try primary execution
        try:
            return self._execute_primary(task)
        except Exception as e:
            error_type = self._classify_error(e)
            
            # Recover based on error type
            if error_type == ErrorType.RATE_LIMIT:
                return self._handle_rate_limit(task)
            elif error_type == ErrorType.TIMEOUT:
                return self._handle_timeout(task)
            elif error_type == ErrorType.INVALID_RESPONSE:
                return self._handle_invalid_response(task)
            elif error_type == ErrorType.TOOL_ERROR:
                return self._handle_tool_error(task, e)
            else:
                return self._handle_generic_error(task, e)
    
    def _execute_primary(self, task: str) -> str:
        """Primary execution path."""
        # Wrapped with retry strategy
        return self.retry_strategy(self._call_llm, task)
    
    def _call_llm(self, task: str) -> str:
        """Call LLM (simplified)."""
        # In real implementation, call actual LLM
        if "fail" in task.lower():
            raise Exception("Simulated LLM failure")
        return f"Result for: {task}"
    
    def _classify_error(self, error: Exception) -> ErrorType:
        """Classify error type."""
        error_str = str(error).lower()
        if "rate limit" in error_str or "429" in error_str:
            return ErrorType.RATE_LIMIT
        elif "timeout" in error_str:
            return ErrorType.TIMEOUT
        elif "invalid" in error_str or "parse" in error_str:
            return ErrorType.INVALID_RESPONSE
        else:
            return ErrorType.NETWORK_ERROR
    
    def _handle_rate_limit(self, task: str) -> str:
        """Handle rate limit errors."""
        logging.info("Rate limit hit, waiting and retrying...")
        time.sleep(60)  # Wait 1 minute
        return self._execute_primary(task)
    
    def _handle_timeout(self, task: str) -> str:
        """Handle timeout errors."""
        logging.info("Timeout occurred, retrying with shorter context...")
        # Retry with simplified task
        simplified_task = task[:100]  # Truncate
        return self._execute_primary(simplified_task)
    
    def _handle_invalid_response(self, task: str) -> str:
        """Handle invalid LLM responses."""
        logging.info("Invalid response, requesting structured output...")
        # Retry with stricter prompt
        structured_task = f"{task}\n\nRespond in JSON format only."
        return self._execute_primary(structured_task)
    
    def _handle_tool_error(self, task: str, error: Exception) -> str:
        """Handle tool execution errors."""
        logging.warning(f"Tool error: {error}")
        # Try alternative approach without the failing tool
        return f"Task partially completed. Tool error: {error}"
    
    def _handle_generic_error(self, task: str, error: Exception) -> str:
        """Handle generic errors."""
        logging.error(f"Unrecoverable error: {error}")
        return f"Task failed: {error}"

# Usage
agent = ResilientAgent(llm_client=None, tools={})
result = agent.execute_with_recovery("Process user data")

#### Diagram

from functools import lru_cache
from typing import List, Dict, Any
import hashlib
import json
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class CacheEntry:
    result: str
    timestamp: datetime
    cost: float
    tokens_used: int

class CostOptimizedAgent:
    """Agent optimized for cost and latency."""
    
    def __init__(self, llm_client, cache_ttl: timedelta = timedelta(hours=24)):
        self.llm_client = llm_client
        self.cache: Dict[str, CacheEntry] = {}
        self.cache_ttl = cache_ttl
        self.total_cost = 0.0
        self.total_tokens = 0
    
    def _cache_key(self, task: str, context: Dict[str, Any] = None) -> str:
        """Generate cache key from task and context."""
        key_data = {"task": task, "context": context or {}}
        key_str = json.dumps(key_data, sort_keys=True)
        return hashlib.sha256(key_str.encode()).hexdigest()
    
    def execute_cached(self, task: str, context: Dict[str, Any] = None) -> str:
        """Execute with caching."""
        cache_key = self._cache_key(task, context)
        
        # Check cache
        if cache_key in self.cache:
            entry = self.cache[cache_key]
            if datetime.now() - entry.timestamp < self.cache_ttl:
                logging.info(f"Cache hit for: {task[:50]}")
                return entry.result
        
        # Cache miss - call LLM
        result, cost, tokens = self._call_llm_with_metrics(task)
        
        # Store in cache
        self.cache[cache_key] = CacheEntry(
            result=result,
            timestamp=datetime.now(),
            cost=cost,
            tokens_used=tokens
        )
        
        self.total_cost += cost
        self.total_tokens += tokens
        
        return result
    
    def batch_execute(self, tasks: List[str]) -> List[str]:
        """Execute multiple tasks in a single LLM call."""
        # Combine tasks into single prompt
        combined_prompt = "\n\n".join([
            f"Task {i+1}: {task}" for i, task in enumerate(tasks)
        ])
        
        # Single LLM call
        result, cost, tokens = self._call_llm_with_metrics(combined_prompt)
        
        # Parse results (simplified - real implementation needs structured parsing)
        results = result.split("\n\n")
        
        # Cost per task
        cost_per_task = cost / len(tasks)
        tokens_per_task = tokens / len(tasks)
        
        logging.info(f"Batch execution: {len(tasks)} tasks, "
                    f"{cost:.4f} total cost ({cost_per_task:.4f} per task)")
        
        return results
    
    def _call_llm_with_metrics(self, prompt: str) -> tuple[str, float, int]:
        """Call LLM and track metrics."""
        # In real implementation:
        # - Call actual LLM
        # - Extract token usage from response
        # - Calculate cost based on model pricing
        
        # Simplified metrics
        tokens = len(prompt.split()) * 1.3  # Rough estimate
        cost = tokens * 0.000002  # Example: $0.002 per 1K tokens
        
        result = f"Response to: {prompt[:50]}"
        return result, cost, int(tokens)
    
    def get_cost_summary(self) -> Dict[str, Any]:
        """Get cost and usage summary."""
        return {
            "total_cost": self.total_cost,
            "total_tokens": self.total_tokens,
            "cache_size": len(self.cache),
            "cache_hit_rate": self._calculate_cache_hit_rate(),
        }
    
    def _calculate_cache_hit_rate(self) -> float:
        """Calculate cache hit rate (simplified)."""
        # In real implementation, track hits/misses
        return 0.0

# Usage
agent = CostOptimizedAgent(llm_client=None)

# Single execution (cached)
result1 = agent.execute_cached("Analyze code quality")

# Batch execution (cost-efficient)
tasks = [
    "Review function A",
    "Review function B",
    "Review function C",
]
results = agent.batch_execute(tasks)

# Cost summary
summary = agent.get_cost_summary()
print(f"Total cost: ${summary['total_cost']:.4f}")
print(f"Total tokens: {summary['total_tokens']:,}")

#### Diagram

class CodeReviewAgent(CostOptimizedAgent):
    """Code review agent with cost optimization."""
    
    def review_file(self, file_path: str) -> Dict[str, Any]:
        """Review a file with caching."""
        with open(file_path, 'r') as f:
            code = f.read()
        
        # Use cached execution
        review = self.execute_cached(
            f"Review this Python code for issues:\n\n{code}",
            context={"file": file_path}
        )
        
        return {
            "file": file_path,
            "review": review,
            "cached": self._was_cached(file_path, code)
        }
    
    def _was_cached(self, file_path: str, code: str) -> bool:
        """Check if review was cached."""
        cache_key = self._cache_key(
            f"Review code: {code}",
            context={"file": file_path}
        )
        return cache_key in self.cache

#### Diagram

from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import Tool, StructuredTool
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
from langchain.callbacks import StreamingStdOutCallbackHandler
from pydantic import BaseModel, Field

# Define structured tool with Pydantic schema
class CodeReviewInput(BaseModel):
    file_path: str = Field(description="Path to the file to review")
    rules: list[str] = Field(default=[], description="Specific rules to check")

def review_code(file_path: str, rules: list[str] = None) -> str:
    """Review Python code for quality issues."""
    with open(file_path, 'r') as f:
        code = f.read()
    
    issues = []
    if "import *" in code:
        issues.append("Wildcard import detected")
    if "eval(" in code:
        issues.append("eval() usage detected")
    
    return f"Review complete. Issues: {issues}" if issues else "No issues found"

# Create structured tool
review_tool = StructuredTool.from_function(
    func=review_code,
    name="review_code",
    description="Review Python code for quality and security issues",
    args_schema=CodeReviewInput
)

# Create agent with memory
llm = ChatOpenAI(model="gpt-4o", temperature=0, streaming=True)
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a code review agent. Use tools to analyze code.
    Always explain your reasoning before using tools.
    Provide actionable feedback."""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

agent = create_openai_tools_agent(llm, [review_tool], prompt)
executor = AgentExecutor(
    agent=agent,
    tools=[review_tool],
    memory=memory,
    verbose=True,
    max_iterations=5,
    handle_parsing_errors=True
)

# Execute with streaming
result = executor.invoke(
    {"input": "Review the authentication module in src/auth.py"},
    config={"callbacks": [StreamingStdOutCallbackHandler()]}
)

#### Diagram

from llama_index import VectorStoreIndex, ServiceContext
from llama_index.llms import OpenAI
from llama_index.tools import FunctionTool
from llama_index.agent import ReActAgent
from llama_index.query_engine import RetrieverQueryEngine

# Initialize LlamaIndex
llm = OpenAI(model="gpt-4", temperature=0)
service_context = ServiceContext.from_defaults(llm=llm)

# Load codebase documents
from llama_index import SimpleDirectoryReader
documents = SimpleDirectoryReader("src").load_data()

# Create index
index = VectorStoreIndex.from_documents(documents, service_context=service_context)

# Define tools
def search_codebase(query: str) -> str:
    """Search codebase for patterns."""
    query_engine = index.as_query_engine()
    response = query_engine.query(query)
    return str(response)

def analyze_dependencies(file_path: str) -> str:
    """Analyze dependencies for a file."""
    # Implementation
    return f"Dependencies for {file_path}"

# Create tools
tools = [
    FunctionTool.from_defaults(fn=search_codebase),
    FunctionTool.from_defaults(fn=analyze_dependencies),
]

# Create ReAct agent
agent = ReActAgent.from_tools(
    tools=tools,
    llm=llm,
    verbose=True
)

# Execute
response = agent.chat("Find all authentication-related code")

#### Diagram

from llama_index.tools import ToolMetadata
from llama_index.agent import OpenAIAgent

class CodebaseTool:
    """Custom tool for codebase operations."""
    
    def __init__(self, codebase_path: str):
        self.codebase_path = codebase_path
    
    def read_file(self, file_path: str) -> str:
        """Read file from codebase."""
        full_path = f"{self.codebase_path}/{file_path}"
        with open(full_path, 'r') as f:
            return f.read()
    
    def list_files(self, directory: str = ".") -> list[str]:
        """List files in directory."""
        import os
        full_path = f"{self.codebase_path}/{directory}"
        return os.listdir(full_path)

# Create tool instance
codebase_tool = CodebaseTool("src")

# Wrap as LlamaIndex tool
from llama_index.tools import FunctionTool

read_file_tool = FunctionTool.from_defaults(
    fn=codebase_tool.read_file,
    name="read_file",
    description="Read a file from the codebase"
)

list_files_tool = FunctionTool.from_defaults(
    fn=codebase_tool.list_files,
    name="list_files",
    description="List files in a directory"
)

# Create agent
agent = OpenAIAgent.from_tools(
    [read_file_tool, list_files_tool],
    verbose=True
)

# Execute
response = agent.chat("Read the main.py file and list all Python files in src/")

#### Diagram

import hashlib
from pathlib import Path

class SnapshotTester:
    """Test AI-generated code against snapshots."""
    
    def __init__(self, snapshot_dir: Path = Path("snapshots")):
        self.snapshot_dir = snapshot_dir
        self.snapshot_dir.mkdir(exist_ok=True)
    
    def test_generated_code(self, task: str, generated_code: str) -> bool:
        """Test generated code against snapshot."""
        snapshot_path = self.snapshot_dir / f"{self._hash_task(task)}.py"
        
        if snapshot_path.exists():
            # Compare with snapshot
            expected = snapshot_path.read_text()
            if generated_code.strip() == expected.strip():
                return True
            else:
                print(f"Snapshot mismatch for: {task}")
                return False
        else:
            # Create new snapshot
            snapshot_path.write_text(generated_code)
            print(f"Created snapshot: {snapshot_path}")
            return True
    
    def _hash_task(self, task: str) -> str:
        """Generate hash for task."""
        return hashlib.sha256(task.encode()).hexdigest()[:16]

# Usage
tester = SnapshotTester()
tester.test_generated_code(
    "Create user authentication",
    "def authenticate(): pass"
)

#### Diagram

import ast
import inspect

class BehavioralTester:
    """Test that generated functions obey invariants."""
    
    def test_function(self, code: str, invariants: list[callable]) -> bool:
        """Test function against invariants."""
        try:
            # Parse and execute code
            tree = ast.parse(code)
            exec(compile(tree, "<string>", "exec"))
            
            # Extract function
            func_name = self._extract_function_name(tree)
            func = locals()[func_name]
            
            # Test invariants
            for invariant in invariants:
                if not invariant(func):
                    return False
            
            return True
        except Exception as e:
            print(f"Behavioral test failed: {e}")
            return False
    
    def _extract_function_name(self, tree: ast.AST) -> str:
        """Extract function name from AST."""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                return node.name
        raise ValueError("No function found")

# Usage
def invariant_no_side_effects(func):
    """Check that function has no side effects."""
    # Simplified - real implementation would check for global mutations
    return True

tester = BehavioralTester()
tester.test_function(
    "def add(a, b): return a + b",
    [invariant_no_side_effects]
)

#### Diagram

import subprocess
from pathlib import Path

class CodeQualityChecker:
    """Run linting and type checking on generated code."""
    
    def check(self, code: str, output_file: Path = Path("temp_code.py")) -> dict:
        """Check code quality."""
        # Write code to temp file
        output_file.write_text(code)
        
        results = {
            "ruff": self._run_ruff(output_file),
            "mypy": self._run_mypy(output_file),
            "pytest": self._run_pytest(output_file),
        }
        
        # Cleanup
        output_file.unlink()
        
        return results
    
    def _run_ruff(self, file_path: Path) -> dict:
        """Run ruff linter."""
        try:
            result = subprocess.run(
                ["ruff", "check", str(file_path)],
                capture_output=True,
                text=True
            )
            return {
                "success": result.returncode == 0,
                "output": result.stdout
            }
        except FileNotFoundError:
            return {"success": False, "output": "ruff not installed"}
    
    def _run_mypy(self, file_path: Path) -> dict:
        """Run mypy type checker."""
        try:
            result = subprocess.run(
                ["mypy", "--strict", str(file_path)],
                capture_output=True,
                text=True
            )
            return {
                "success": result.returncode == 0,
                "output": result.stdout
            }
        except FileNotFoundError:
            return {"success": False, "output": "mypy not installed"}
    
    def _run_pytest(self, file_path: Path) -> dict:
        """Run pytest."""
        try:
            result = subprocess.run(
                ["pytest", str(file_path), "-q"],
                capture_output=True,
                text=True
            )
            return {
                "success": result.returncode == 0,
                "output": result.stdout
            }
        except FileNotFoundError:
            return {"success": False, "output": "pytest not installed"}

# Usage
checker = CodeQualityChecker()
results = checker.check("def add(a: int, b: int) -> int: return a + b")
print(results)

#### Diagram

import random
import json

class AdversarialTester:
    """Test code robustness against adversarial inputs."""
    
    def test_robustness(self, func: callable, test_cases: list) -> dict:
        """Test function with adversarial inputs."""
        results = {
            "passed": 0,
            "failed": 0,
            "errors": []
        }
        
        for test_case in test_cases:
            try:
                result = func(*test_case["args"], **test_case["kwargs"])
                results["passed"] += 1
            except Exception as e:
                results["failed"] += 1
                results["errors"].append({
                    "test_case": test_case,
                    "error": str(e)
                })
        
        return results
    
    def generate_adversarial_inputs(self) -> list:
        """Generate adversarial test inputs."""
        return [
            {"args": [], "kwargs": {}},  # Empty input
            {"args": [None], "kwargs": {}},  # None input
            {"args": [""], "kwargs": {}},  # Empty string
            {"args": [{}], "kwargs": {}},  # Empty dict
            {"args": [1e10], "kwargs": {}},  # Large number
            {"args": ["<script>alert('xss')</script>"], "kwargs": {}},  # XSS attempt
            {"args": [json.dumps({"malformed": True})], "kwargs": {}},  # Malformed JSON
        ]

# Usage
def example_func(data: str) -> str:
    """Example function to test."""
    return data.upper()

tester = AdversarialTester()
test_cases = tester.generate_adversarial_inputs()
results = tester.test_robustness(example_func, test_cases)
print(f"Passed: {results['passed']}, Failed: {results['failed']}")

#### Diagram

PARSERS: dict[str, type[Parser]] = {
    "json": JSONParser,
    "yaml": YAMLParser,
    "xml": XMLParser,
}

def create_parser(kind: str) -> Parser:
    parser_class = PARSERS.get(kind)
    if parser_class is None:
        raise ValueError(f"Unknown parser: {kind}")
    return parser_class()

# Usage
parser = create_parser("json")

#### Diagram

from typing import Protocol

class Parser(Protocol):
    def parse(self, text: str) -> dict: ...

class ParserFactory(Protocol):
    def create(self) -> Parser: ...

class JSONParserFactory:
    def create(self) -> Parser:
        return JSONParser()

class YAMLParserFactory:
    def create(self) -> Parser:
        return YAMLParser()

# Usage
factory: ParserFactory = JSONParserFactory()
parser = factory.create()

#### Diagram

from typing import Protocol
from dataclasses import dataclass

@dataclass
class DatabaseConfig:
    host: str
    port: int
    database: str

class Database(Protocol):
    def connect(self) -> None: ...
    def query(self, sql: str) -> list[dict]: ...

class PostgreSQLDatabase:
    def __init__(self, config: DatabaseConfig):
        self.config = config
    
    def connect(self) -> None:
        # Connection logic
        pass
    
    def query(self, sql: str) -> list[dict]:
        # Query logic
        return []

class MySQLDatabase:
    def __init__(self, config: DatabaseConfig):
        self.config = config
    
    def connect(self) -> None:
        pass
    
    def query(self, sql: str) -> list[dict]:
        return []

def create_database(db_type: str, config: DatabaseConfig) -> Database:
    factories = {
        "postgresql": PostgreSQLDatabase,
        "mysql": MySQLDatabase,
    }
    
    factory = factories.get(db_type)
    if factory is None:
        raise ValueError(f"Unknown database type: {db_type}")
    
    return factory(config)

# Usage
config = DatabaseConfig(host="localhost", port=5432, database="mydb")
db = create_database("postgresql", config)
db.connect()

#### Diagram

from typing import Callable, Any, TypeVar
from enum import Enum

T = TypeVar("T")

class Lifecycle(Enum):
    SINGLETON = "singleton"
    TRANSIENT = "transient"
    SCOPED = "scoped"

class Container:
    def __init__(self):
        self._providers: dict[str, Callable[[], Any]] = {}
        self._lifecycles: dict[str, Lifecycle] = {}
        self._singletons: dict[str, Any] = {}
        self._scoped: dict[str, dict[str, Any]] = {}
    
    def register(
        self,
        name: str,
        provider: Callable[[], T],
        lifecycle: Lifecycle = Lifecycle.TRANSIENT
    ) -> None:
        self._providers[name] = provider
        self._lifecycles[name] = lifecycle
    
    def resolve(self, name: str, scope_id: str | None = None) -> Any:
        if name not in self._providers:
            raise ValueError(f"Service '{name}' not registered")
        
        lifecycle = self._lifecycles[name]
        
        if lifecycle == Lifecycle.SINGLETON:
            if name not in self._singletons:
                self._singletons[name] = self._providers[name]()
            return self._singletons[name]
        
        elif lifecycle == Lifecycle.SCOPED:
            if scope_id is None:
                raise ValueError("Scope ID required for scoped services")
            if scope_id not in self._scoped:
                self._scoped[scope_id] = {}
            if name not in self._scoped[scope_id]:
                self._scoped[scope_id][name] = self._providers[name]()
            return self._scoped[scope_id][name]
        
        else:  # TRANSIENT
            return self._providers[name]()
    
    def clear_scope(self, scope_id: str) -> None:
        """Clear all scoped instances for a scope."""
        if scope_id in self._scoped:
            del self._scoped[scope_id]

# Usage
container = Container()

# Register services
container.register("database", lambda: create_db_connection(), Lifecycle.SINGLETON)
container.register("logger", lambda: Logger(), Lifecycle.SINGLETON)
container.register("user_service", lambda: UserService(
    container.resolve("database"),
    container.resolve("logger")
), Lifecycle.TRANSIENT)

# Resolve
db = container.resolve("database")
user_service = container.resolve("user_service")

#### Diagram

from typing import Protocol
from dataclasses import dataclass

class Database(Protocol):
    def query(self, sql: str) -> list[dict]: ...

class Logger(Protocol):
    def log(self, message: str) -> None: ...

@dataclass
class UserService:
    db: Database
    logger: Logger
    
    def get_user(self, user_id: int) -> dict | None:
        self.logger.log(f"Fetching user {user_id}")
        results = self.db.query(f"SELECT * FROM users WHERE id = {user_id}")
        return results[0] if results else None

# Factory function (simple DI)
def create_user_service(db: Database, logger: Logger) -> UserService:
    return UserService(db=db, logger=logger)

# Usage
db = create_database()
logger = create_logger()
user_service = create_user_service(db, logger)  # Explicit dependencies

#### Diagram

import inspect
from typing import get_type_hints

class AutoContainer:
    def __init__(self):
        self._services: dict[type, Any] = {}
        self._factories: dict[type, Callable] = {}
    
    def register_singleton(self, service_type: type, instance: Any) -> None:
        self._services[service_type] = instance
    
    def register_factory(self, service_type: type, factory: Callable) -> None:
        self._factories[service_type] = factory
    
    def resolve(self, service_type: type) -> Any:
        if service_type in self._services:
            return self._services[service_type]
        
        if service_type in self._factories:
            factory = self._factories[service_type]
            # Auto-wire dependencies
            sig = inspect.signature(factory)
            kwargs = {}
            for param_name, param in sig.parameters.items():
                if param.annotation != inspect.Parameter.empty:
                    kwargs[param_name] = self.resolve(param.annotation)
            return factory(**kwargs)
        
        raise ValueError(f"Service {service_type} not registered")

# Usage
container = AutoContainer()
container.register_singleton(Database, create_database())
container.register_factory(Logger, create_logger)
container.register_factory(UserService, UserService)

user_service = container.resolve(UserService)  # Auto-wired!

#### Diagram

# Variables
x = 10
name: str = "Python"  # Type annotation

# Functions
def greet(name: str) -> str:
    return f"Hello, {name}!"

# Classes
class User:
    def __init__(self, name: str):
        self.name = name

# Conditionals
if condition:
    do_something()
elif other_condition:
    do_other()
else:
    do_default()

# Loops
for item in items:
    process(item)

while condition:
    do_work()

# Comprehensions
[x**2 for x in range(10)]  # List
{x: x**2 for x in range(10)}  # Dict
{x**2 for x in range(10)}  # Set
(x**2 for x in range(10))  # Generator

# Exception Handling
try:
    risky_operation()
except SpecificError as e:
    handle_error(e)
except Exception as e:
    handle_generic(e)
else:
    no_exception()
finally:
    always_run()

#### Diagram

from typing import Optional, Union

value: Optional[int] = None
value: int | None = None  # 3.10+

result: Union[int, str] = 42
result: int | str = 42  # 3.10+

#### Diagram

def process(data: list[int]) -> dict[str, int]:
    return {"count": len(data)}

# Variable arguments
def func(*args: int, **kwargs: str) -> None:
    pass

# Callable
from typing import Callable
handler: Callable[[int, str], bool] = my_func

#### Diagram

from typing import Protocol

class Drawable(Protocol):
    def draw(self) -> None: ...

def render(obj: Drawable) -> None:
    obj.draw()

#### Diagram

I/O-bound, many connections ‚Üí asyncio
CPU-bound, single machine ‚Üí multiprocessing
CPU-bound, distributed ‚Üí Celery / Dask
Mixed I/O + CPU ‚Üí ThreadPoolExecutor + ProcessPoolExecutor
Free-threading available (3.13+) ‚Üí threading for CPU-bound

#### Diagram

Small dataset (<1GB) ‚Üí pandas
Large dataset (>1GB) ‚Üí Polars or Dask
Streaming data ‚Üí Polars lazy or Dask
ML/AI workloads ‚Üí NumPy, PyTorch, TensorFlow
Time series ‚Üí pandas, Polars

#### Diagram

New project ‚Üí uv
Legacy project ‚Üí pip + pip-tools
Poetry ecosystem ‚Üí Poetry
Enterprise ‚Üí pip + requirements.txt

#### Diagram

import threading

def cpu_bound_task(n):
    total = 0
    for i in range(n):
        total += i * i
    return total

# This does NOT run in parallel!
thread1 = threading.Thread(target=cpu_bound_task, args=(10_000_000,))
thread2 = threading.Thread(target=cpu_bound_task, args=(10_000_000,))

thread1.start()
thread2.start()
thread1.join()
thread2.join()

# Takes ~2√ó the time of single thread (due to GIL switching overhead)

#### Diagram

import multiprocessing

def cpu_bound_task(n):
    total = 0
    for i in range(n):
        total += i * i
    return total

if __name__ == "__main__":
    with multiprocessing.Pool() as pool:
        results = pool.map(cpu_bound_task, [10_000_000, 10_000_000])
    # Actually runs in parallel across CPU cores

#### Diagram

counter = 0

def increment():
    global counter
    for _ in range(100_000):
        counter += 1  # NOT atomic! Race condition possible

threads = [threading.Thread(target=increment) for _ in range(10)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print(counter)  # May be < 1_000_000 due to race conditions

#### Diagram

import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100_000):
        with lock:
            counter += 1  # Atomic operation

#### Diagram

# Python 3.14+ with --disable-gil flag
# Threads can actually run CPU-bound code in parallel!

#### Diagram

CPU-bound work?
‚îú‚îÄ Yes ‚Üí Use multiprocessing or C extensions
‚îî‚îÄ No (I/O-bound) ‚Üí Use threading or asyncio

#### Diagram

def add(a: int, b: int) -> int:
    return a + b

result = add("hello", "world")  # No error at runtime!
print(result)  # "helloworld" (works, but wrong type)

#### Diagram

from typing import assert_type

def add(a: int, b: int) -> int:
    assert_type(a, int)  # Runtime check (Python 3.13+)
    assert_type(b, int)
    return a + b

# Or use Pydantic for validation
from pydantic import validate_call

@validate_call
def add(a: int, b: int) -> int:
    return a + b

#### Diagram

from typing import Any

def process(data: Any) -> Any:
    return data.anything()  # Type checker can't help

result: Any = process(123)
result.foo.bar.baz  # No type errors, but runtime error!

#### Diagram

from typing import Protocol

class Processable(Protocol):
    def process(self) -> str: ...

def process(data: Processable) -> str:
    return data.process()  # Type-safe

#### Diagram

from typing import TypedDict

class Config(TypedDict):
    items: list[str]

def create_config(items: list[str] = []) -> Config:  # Mutable default!
    return {"items": items}

config1 = create_config()
config2 = create_config()
config1["items"].append("x")
print(config2["items"])  # ['x'] - shared list!

#### Diagram

def create_config(items: list[str] | None = None) -> Config:
    if items is None:
        items = []
    return {"items": items}

#### Diagram

from typing import TypeVar

T = TypeVar("T", bound=int)  # Too restrictive

def identity(x: T) -> T:
    return x

identity("hello")  # Type error, but maybe you wanted str support

#### Diagram

T = TypeVar("T")  # Unconstrained

def identity(x: T) -> T:
    return x

identity("hello")  # Works
identity(42)  # Works

#### Diagram

from typing import Protocol

class Drawable(Protocol):
    def draw(self) -> None: ...

class Circle:
    def draw(self, color: str) -> None:  # Extra parameter!
        print(f"Drawing circle in {color}")

def render(obj: Drawable):
    obj.draw()  # Type error: draw() signature doesn't match

circle = Circle()
render(circle)  # Runtime error: missing argument

#### Diagram

class Circle:
    def draw(self, color: str = "black") -> None:  # Default parameter
        print(f"Drawing circle in {color}")

def render(obj: Drawable):
    obj.draw()  # Works: default parameter satisfies protocol

#### Diagram

from typing import TypeVar, Generic

T = TypeVar("T")

class Container(Generic[T]):
    def __init__(self, value: T):
        self.value = value

def get_value(container: Container) -> int:  # Missing type parameter!
    return container.value  # Type checker can't infer T

#### Diagram

def get_value(container: Container[int]) -> int:
    return container.value  # Type-safe

#### Diagram

from typing import Optional

def process(data: Optional[str]) -> str:
    return data.upper()  # Type error: data might be None

#### Diagram

def process(data: Optional[str]) -> str:
    if data is None:
        return ""
    return data.upper()  # Type checker knows data is str here

#### Diagram

from typing import TypeVar, Generic

T = TypeVar("T")

class Box(Generic[T]):
    def put(self, item: T) -> None: ...
    def get(self) -> T: ...

def put_string(box: Box[str]) -> None:
    box.put("hello")

string_box: Box[str] = Box()
any_box: Box[object] = string_box  # Type error: Box is invariant
put_string(any_box)  # Would allow putting non-string!

#### Diagram

# Use covariant TypeVar for read-only containers
from typing import TypeVar, Generic

T_co = TypeVar("T_co", covariant=True)

class ReadOnlyBox(Generic[T_co]):
    def get(self) -> T_co: ...

# Now this works:
str_box: ReadOnlyBox[str] = ReadOnlyBox()
obj_box: ReadOnlyBox[object] = str_box  # Covariant: safe

#### Diagram

result = ""
for i in range(100_000):
    result += str(i)  # Creates new string each time!

# Each += creates a new string object, copying all previous characters
# Time complexity: O(n¬≤)

#### Diagram

# Use list + join
parts = []
for i in range(100_000):
    parts.append(str(i))
result = "".join(parts)  # Single allocation

# Or use list comprehension
result = "".join(str(i) for i in range(100_000))

#### Diagram

import pandas as pd

df = pd.DataFrame({"x": range(1_000_000), "y": range(1_000_000)})

# .apply() uses Python loops internally
df["sum"] = df.apply(lambda row: row["x"] + row["y"], axis=1)  # SLOW!

#### Diagram

# Vectorized operations use NumPy/C code
df["sum"] = df["x"] + df["y"]  # 100√ó faster!

# Or for complex operations
df["sum"] = df["x"].add(df["y"])  # Still vectorized

#### Diagram

def factorial(n):
    result = 1
    for i in range(2, n + 1):  # Iterative
        result *= i
    return result

# Or use tail recursion optimization (if available)
from functools import lru_cache

@lru_cache(maxsize=None)
def factorial_cached(n):
    if n <= 1:
        return 1
    return n * factorial_cached(n - 1)

#### Diagram

def add_one(x):
    return x + 1

def process(data):
    result = []
    for item in data:  # 1M iterations
        result.append(add_one(item))  # 1M function calls
    return result

#### Diagram

def process(data):
    # Inline operation or use list comprehension (faster)
    return [x + 1 for x in data]  # No function call overhead

# Or use NumPy for large arrays
import numpy as np
result = np.array(data) + 1  # Vectorized

#### Diagram

try:
    result = 1 / 0
except ZeroDivisionError as e:
    raise ValueError("Invalid input") from e  # Preserves chain

# Or use implicit chaining (Python 3.11+)
try:
    result = 1 / 0
except ZeroDivisionError:
    raise ValueError("Invalid input")  # Automatically chains

#### Diagram

class Counter:
    count = 0  # Class attribute
    
    def increment(self):
        self.count += 1  # Creates instance attribute!

c1 = Counter()
c2 = Counter()

c1.increment()
print(c1.count)  # 1 (instance attribute)
print(c2.count)  # 0 (class attribute)
print(Counter.count)  # 0 (class attribute unchanged)

#### Diagram

class Counter:
    count = 0
    
    def increment(self):
        Counter.count += 1  # Explicitly modify class attribute

# Or use instance attributes
class Counter:
    def __init__(self):
        self.count = 0  # Instance attribute
    
    def increment(self):
        self.count += 1

#### Diagram

result = ""
for item in items:
    result += str(item) + ", "
result = result.rstrip(", ")

#### Diagram

flowchart TD
    Start[import mymodule] --> Step1[STEP 1: Check sys.modules cache<br/>if 'mymodule' in sys.modules:<br/>    return sys.modules['mymodule']  # Already loaded]
    
    Step1 -->|not found| Step2[STEP 2: Iterate sys.meta_path finders]
    
    Step2 --> Finder1[1. BuiltinImporter<br/>Checks built-in modules<br/>Examples: sys, builtins]
    
    Finder1 -->|not found| Finder2[2. FrozenImporter<br/>Checks frozen modules<br/>Examples: _frozen_importlib]
    
    Finder2 -->|not found| Finder3[3. PathFinder<br/>Searches sys.path<br/>Uses SourceFileLoader, etc.]
    
    Finder3 -->|finder returns ModuleSpec| Step3[STEP 3: Create ModuleSpec<br/>spec = ModuleSpec(<br/>    name='mymodule',<br/>    loader=SourceFileLoader...,<br/>    origin='/path/to/mymodule.py',<br/>    submodule_search_locations=None<br/>)]
    
    Step3 --> Step4[STEP 4: Loader.exec_module spec]
    
    Step4 --> Loader1[SourceFileLoader:<br/>1. Read .py file<br/>2. Compile to bytecode<br/>3. Execute bytecode<br/>4. Create module object]
    
    Step4 --> Loader2[ExtensionFileLoader:<br/>1. Load .so/.pyd file<br/>2. Initialize module]
    
    Step4 --> Loader3[NamespaceLoader:<br/>1. Create namespace package<br/>2. Set __path__]
    
    Loader1 --> Step5[STEP 5: Store in sys.modules<br/>sys.modules['mymodule'] = module_object]
    Loader2 --> Step5
    Loader3 --> Step5
    
    Step5 --> Step6[STEP 6: Module code executed<br/>Top-level code runs<br/>Functions/classes defined<br/>Module-level variables assigned]
    
    Step6 --> Return[Return module object]
    
    Step1 -->|found| Return
    
    style Start fill:#e1f5ff
    style Step1 fill:#ffe1f5
    style Step2 fill:#e1ffe1
    style Step3 fill:#fff4e1
    style Step4 fill:#ffe1e1
    style Step5 fill:#e1f5ff
    style Step6 fill:#ffe1f5
    style Return fill:#e1ffe1

#### Diagram

graph TD
    Header[PyObject HEADER] --> RefCnt[Py_ssize_t ob_refcnt<br/>Reference count 4/8 bytes]
    Header --> TypePtr[PyTypeObject *ob_type<br/>Pointer to type object 8 bytes]
    
    TypePtr --> TypeSpecific[Type-specific data follows]
    
    TypeSpecific --> PyLong[PyLongObject<br/>ob_digit variable]
    TypeSpecific --> PyList[PyListObject<br/>PyObject** ob_item<br/>Py_ssize_t allocated<br/>Py_ssize_t size]
    TypeSpecific --> PyUnicode[PyUnicodeObject<br/>length<br/>kind<br/>data]
    TypeSpecific --> PyDict[PyDictObject<br/>ma_keys<br/>ma_values<br/>ma_used]
    
    style Header fill:#e1f5ff
    style RefCnt fill:#ffe1f5
    style TypePtr fill:#e1ffe1
    style TypeSpecific fill:#fff4e1

#### Test Hint

Convert this snippet into a unit test by constructing input and asserting allow/deny.

#### Uncertainty

This content may have ambiguous or context-dependent interpretation.

#### Relation

optional docstring (see Chapter 30 for comprehensive docstring conventions)

#### Relation

Event loop + tasks integration covered in Chapter 17 (Concurrency).

#### Relation

garbage collection (see Chapter 27 for internals)

#### Relation

**See Chapter 3.5 (Bytecode Compilation) for details on LOAD_FAST v

#### Relation

**See Chapter 7.5.3 for complete __slots__ coverage including memor

#### Relation

y-critical classes
- ‚úÖ Profile before optimizing (see Chapter 12.3)

#### Relation

allows

#### Relation

enable

#### Relation

supports

#### Relation

Implement

#### Relation

Need

#### Relation

enables

#### Relation

support

#### Relation

similar to

#### Relation

but **not

#### Section Meta

::: pattern
id: PATTERN-1804cc6bc147172f
name: ** never use `@lru_cache` on methods with mutable `self`. extract to module-level function or use `functools.cached_property` for instance attributes.
description: **Prevention Pattern:** Never use `@lru_cache` on methods with mutable `self`. Extract to module-level function or use `functools.cached_property` for instance attributes.
12.3 Profiling Tools (CPU, Wall Time, Memory)
category: generic
chapter: GLOBAL
pattern_type: conceptual
digest: 519e692355da984a683024f78082b75ba621d6cee059e55f63d35ec21bede83e
symbol_refs: [self]
semantic_role: pattern
embedding_hint_importance: low
embedding_hint_scope: local
embedding_hint_chunk: auto

#### Rationale

Python is a high-level, general-purpose programming language emphasizing:

#### Rationale

Python Matters (2025+)

#### Rationale

Python continues to dominate because:

#### Rationale

Python works this way

#### Rationale

`my_list = [1, 2, 3]; another_list = my_list; another_list

#### Rationale

chaining?

#### Rationale

generators matter

#### Rationale

mutable default arguments are dangerous?
4

#### Rationale

it matters for `super()`?
3

#### Rationale

those have their own dedicated chapters

#### Rationale

Python 3

#### Rationale

not to

#### Rationale

Why?

#### Rationale

Architecture Matters in Python

#### Rationale

the heavy lifting happens in optimized C code and uses contiguous, typed memory

#### Rationale

‚úÖ Need maximum performance
‚úÖ Complex algorithms that benefit from static typing
‚úÖ Existing C libraries to wrap
‚ùå Simple operations (NumPy is easier)
‚ùå Rapid prototyping (compilation overhead)

#### Rationale

‚úÖ CPU-bound tasks that benefit from parallelization
‚úÖ Tasks that can be split into independent chunks
‚úÖ Long-running computations (amortizes process startup cost)
‚ùå Small, quick tasks (overhead > benefit)
‚ùå Tasks requiring frequent communication (IPC overhead)

#### Rationale

Concurrency Is Hard in Python

#### Rationale

Purpose of the GIL:

#### Rationale

‚úÖ CPU-bound tasks (image processing, data analysis, ML preprocessing)
‚úÖ Tasks that benefit from multiple CPU cores
‚úÖ Isolated computations that don't need frequent communication
‚ùå IO-bound tasks (use threading or asyncio instead)
‚ùå Tasks requiring frequent data sharing (high IPC overhead)

#### Rationale

Use Metaclasses?

#### Rationale

each layer exists

#### Rationale

is the service slow?

#### Rationale

**clean docstrings directly improve maintainability, correctness, API usability, and LLM comprehension

#### Rationale

**Rationale:**

#### Rationale

Python behaves the way it does

#### Rationale

about dynamic code

#### Rationale

understanding formal semantics enables reliable reasoning about code behavior

#### Rationale

CPython's memory model is not thread-safe

#### Rationale

reasoning about concurrency

#### Rationale

Alternative Implementations Exist

#### Rationale

to choose something else

#### Rationale

- **Python 3.11+** support (partial, improving)
- **Status**: Experimental, not production-ready
- **Purpose**: Educational, research, embedded Python

#### Rationale

It's Deprecated:**

#### Rationale

General-purpose apps / web backends / CLIs

#### Rationale

about past actions (‚Äúreflection loop‚Äù)

#### Rationale

29.3.2 ‚Äî DO: Ask for Step-by-Step Reasoning (but not in code)

#### Rationale

ReAct (Reasoning + Acting) is a powerful pattern for tool-using agents:

#### Rationale

Python design patterns differ from classical OOP patterns because:

#### Rationale

Purpose:
Provides structural expectations without requiring concrete implementation.

#### Rationale

Python has an unusually high number of core concepts beginning with C, including:

#### Rationale

Jan 1, 1970 (Unix epoch)

#### Rationale

ML is a major Python ecosystem domain

#### Rationale

GC is fast, but beneficial in high-performance systems

#### Rationale

not stored in memory

#### Rationale

epoch)

#### Rationale

they appear across the "Python Bible"

#### Rationale

it matters

#### Rationale

does my lambda use the last value?!‚Äù
‚ùå Incorrect
funcs = [lambda: i for i in range(3)]
[f() for f in funcs]  # ‚Üí [2, 2, 2]

#### Rationale

üß† Why?

#### Rationale

this breaks real code:

#### Rationale

does it work sometimes?‚Äù)

#### Rationale

Python is permissive with truthiness

#### Rationale

floats use binary IEEE-754 representation

#### Rationale

`time.sleep()` is a blocking call that freezes the entire event loop. All other async tasks wait, defeating the purpose of async.

#### Rationale

üîç **Why?**

#### Rationale

"GIL prevents races" (wrong!)
- Using threads for CPU-bound work instead of multiprocessing
- Not understanding when GIL is released

#### Rationale

- Assuming type hints catch bugs at runtime
- Using `Any` everywhere defeats the purpose
- Protocol mismatches in large codebases
- Generic type inference failures

#### Contrast

identity vs equality

identity vs equality

#### Contrast

shallow copies vs deep copies

shallow copies vs deep copies

#### Contrast

Mutable default arguments
‚ö†Ô∏è is vs ==
‚ö†Ô∏è Modifying sequences during iteration
‚ö†Ô∏è Late binding in closures
‚ö†Ô∏è Raw string edge cases
‚ö†Ô∏è Line-continuation bugs
‚ö†Ô∏è Copying vs aliasing

‚ö†Ô∏è Mutable default arguments
‚ö†Ô∏è is vs ==
‚ö†Ô∏è Modifying sequences during iteration
‚ö†Ô∏è Late binding in closures
‚ö†Ô∏è Raw string edge cases
‚ö†Ô∏è Line-continuation bugs
‚ö†Ô∏è Copying vs aliasing

#### Contrast

Circular imports
‚ö†Ô∏è Mutable module-level state
‚ö†Ô∏è Overusing import *
‚ö†Ô∏è Confusing script vs module execution
‚ö†Ô∏è Using assert for runtime checks
‚ö†Ô∏è Modifying sys

‚ö†Ô∏è Circular imports
‚ö†Ô∏è Mutable module-level state
‚ö†Ô∏è Overusing import *
‚ö†Ô∏è Confusing script vs module execution
‚ö†Ô∏è Using assert for runtime checks
‚ö†Ô∏è Modifying sys.path directly
‚ö†Ô∏è Relying on bytecode-only releases

#### Contrast

Iterable vs Iterator
Concept	Has	Example
Iterable	__iter__	list

6.7.1 Iterable vs Iterator
Concept	Has	Example
Iterable	__iter__	list, dict, set, str
Iterator	__iter__, __next__	generators, iterators
6.7.2 Creating custom iterators
class Count:
    def __init__(self, start):
        self.value = start

#### Contrast

misunderstanding self
‚ö† confusing class vs instance attributes
‚ö† overriding __getattribute__ without care
‚ö† multiple inheritance diamonds
‚ö† descriptor mistakes
‚ö† misuse of metaclasses (overkill)
‚ö† dataclass mutable default fields
‚ö† mismatched type annotations

‚ö† misunderstanding self
‚ö† confusing class vs instance attributes
‚ö† overriding __getattribute__ without care
‚ö† multiple inheritance diamonds
‚ö† descriptor mistakes
‚ö† misuse of metaclasses (overkill)
‚ö† dataclass mutable default fields
‚ö† mismatched type annotations

#### Contrast

When should you use `@dataclass` vs a regular class?

[ ] When would you use `@classmethod` vs `@staticmethod`

#### Contrast

absolute vs relative imports

absolute vs relative imports

#### Contrast

top-level vs local imports

top-level vs local imports

#### Contrast

Absolute vs Relative Imports
8

8.3 Absolute vs Relative Imports
8.3.1 Absolute Import
from project.module import func

#### Contrast

Try This:** Compare namedtuple vs dataclass:

**Try This:** Compare namedtuple vs dataclass:

#### Contrast

Greedy vs Non-greedy:**

**Greedy vs Non-greedy:**

#### Contrast

Error Codes vs Exceptions
‚úî Prefer exceptions inside Python code
‚úî Convert to error codes only at boundaries:

10.7 Error Codes vs Exceptions
‚úî Prefer exceptions inside Python code
‚úî Convert to error codes only at boundaries:

#### Contrast

Monorepo vs Multirepo for Python
11

11.8 Monorepo vs Multirepo for Python
11.8.1 Monorepo Pros

#### Contrast

Monorepo vs multirepo should be deliberate

Monorepo vs multirepo should be deliberate

#### Contrast

Global/name resolution is slower (LOAD_GLOBAL vs LOAD_FAST)

Global/name resolution is slower (LOAD_GLOBAL vs LOAD_FAST).

#### Contrast

Bytecode Compilation) for details on LOAD_FAST vs LOAD_GLOBAL opcodes

**See Chapter 3.5 (Bytecode Compilation) for details on LOAD_FAST vs LOAD_GLOBAL opcodes.**

#### Contrast

Function calls are slow vs inlined operations

Function calls are slow vs inlined operations.

#### Contrast

Try This:** Benchmark NumPy vs Python for your array sizes:

**Try This:** Benchmark NumPy vs Python for your array sizes:

#### Contrast

python -m venv vs virtualenv

16.1.3 python -m venv vs virtualenv

#### Contrast

Fork vs Spawn:**

Fork vs Spawn:**

#### Contrast

ASGI vs WSGI

ASGI vs WSGI

#### Contrast

WSGI vs ASGI
20

20.1 WSGI vs ASGI
20.1.1 WSGI (Web Server Gateway Interface)

#### Contrast

Wheels vs Source Distributions
Wheel (

22.1 Python Packaging Fundamentals
22.1.1 Wheels vs Source Distributions
Wheel (.whl)

#### Contrast

Monorepo vs Multi-Repo Packaging
22

22.12 Monorepo vs Multi-Repo Packaging
22.12.1 Monorepo Benefits

#### Contrast

Required vs Optional Variables
DATABASE_URL = os

23.2.1 Required vs Optional Variables
DATABASE_URL = os.environ["DATABASE_URL"]  # required
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")  # optional

#### Contrast

Build-time vs runtime config:

Build-time vs runtime config:

#### Contrast

monolith vs microservices

monolith vs microservices

#### Contrast

serverless vs containerized

serverless vs containerized

#### Contrast

Lexical vs Dynamic Scoping:**

**Lexical vs Dynamic Scoping:**

#### Contrast

concurrency semantics vary by model (threading vs async vs processes)

concurrency semantics vary by model (threading vs async vs processes)

#### Contrast

moving vs non-moving)

GC strategy (tracing, generational, moving vs non-moving)

#### Contrast

threading model (GIL vs no GIL vs VM-native threads)

threading model (GIL vs no GIL vs VM-native threads)

#### Contrast

By-Value vs By-Reference

By-Value vs By-Reference

#### Contrast

Copy vs Deep Copy

Copy vs Deep Copy

#### Contrast

Class Variable vs Instance Variable

Class Variable vs Instance Variable

#### Contrast

Lambdas vs Def

Lambdas vs Def

#### Contrast

Python is lexically scoped; vs dynamic scoping

Python is lexically scoped; differs from dynamic scoping.

#### Contrast

Sync vs Async

Sync vs Async

#### Contrast

Threading vs asyncio versions exist

Threading vs asyncio versions exist.

#### Contrast

When to use threading vs asyncio vs multiprocessing vs distributed:

When to use threading vs asyncio vs multiprocessing vs distributed:

#### Contrast

I/O Models vs Typical Libraries

D.2 ‚Äî I/O Models vs Typical Libraries

#### Contrast

Web Frameworks vs Use Cases

D.3 ‚Äî Web Frameworks vs Use Cases

#### Contrast

Test Types vs Tools

D.4 ‚Äî Test Types vs Tools

#### Contrast

When to Choose X vs Y" Cheat Sheets

D.5 ‚Äî "When to Choose X vs Y" Cheat Sheets

#### Contrast

NumPy vs Polars vs pandas:

NumPy vs Polars vs pandas:

#### Contrast

SQLAlchemy vs raw SQL:

SQLAlchemy vs raw SQL:

#### Contrast

is` vs `==` - Identity vs Equality**

`is` vs `==` - Identity vs Equality**

#### Contrast

Time Zone Naive vs Aware Datetime Mixing**

Time Zone Naive vs Aware Datetime Mixing**

#### Ssm Meta

::: symbol-table
id: SYMTAB-b817e6c5b6e051ef
chapter: META
total_symbols: 3070
symbols: [--disable-gil, --enable-experimental-jit, 2GB, ABC, APIRouter, Abelson, Ability, Absolute, Abstract, Accepts, Access, Accessible, Accidental, Accidentally, Acting, Actions, Active, Actual, Ad, Adafruit, Adapter, Adapters, Adaptive, Add, Added, Adding, Additional, Adds, Adopt, Advanced, Advantages, Affects, Agent, Agentic, Agents, Ahe, Ahead, Airflow, Alembic, Algebraic, Algorithm, Algorithmic, Algorithms, Alice, All, Allocate, Allocated, Allocation, Allowed, Allows, Also, Alt, Alternate, Alternative, Always, Amortized, Analyze, Animal, Annotation, Annotations, Anonymous, Anti, Any, AnyUrl, Anything, Api, App, Appe, Appen, Append, Appendices, Appendix, Application, Applications, Applicative, Applied, Apply, Applying, Approx, Arbitrary, Architectural, Architecture, Archive, Archives, Arenas, Args, Argument, Arguments, Array, Arrow, Ask, Assert, Assertion, Assign, Assignment, Assistants, Associated, Associating, Associative, Assuming, Async, AsyncIOScheduler, AsyncMock, AsyncSession, Asynchronous, Asyncio, Asyncpg, Atomic, Attach, Attribute, Attributes, Attrs, Audit, Authentication, Authorization, Authorizing, Auto, Autogenerate, Automate, Automated, Automatic, Automatically, Automation, Autonomous, Autoscaling, Avoid, Avoiding, Avoids, Await, BINARY_ADD, Backed, Backend, Backends, Background, BackgroundTasks, Backing, Backoff, Bandit, Bare, Base, BaseClass, BaseHTTPMiddleware, BaseModel, BaseSettings, Based, Baseline, Basic, Batch, BatchSpanProcessor, Batching, Batteries, BeautifulSoup, Because, Before, Beginner, Behavior, Behavioral, Below, Benchmark, Benefits, Best, Between, Beware, Bible, Bidirectional, Big, Binary, Binding, Bisect, Bitwise, Black, Block, Blocked, Blocking, Blocks, Blue, Bob, Boolean, Bound, Boundary, Breadth, Breakpoints, Broad, Broadcasting, Broker, Buffering, Buffers, Bug, Buggy, Build, Buildable, Builder, Building, Built, Builtins, Bundling, Business, Bypass, Bypassing, Bytecode, BytesIO, CERT_NONE, CORSMiddleware, Ca, Cache, Caching, Call, Callable, Callables, Callback, Called, Callers, Calling, Calls, Can, Cancel, Cancellations, Cannot, Capture, Captured, Captures, Capturing, Catastrophic, Catch, Catches, Catching, Categories, Ce, Celery, Central, Centralized, Certain, Cfg, Ch, Cha, Chain, ChainMap, Chaining, Changelog, Channel, Chapt, Chapter, Chapters, Character, ChatOpenAI, Check, Checked, Checking, Choose, Choosing, Chris, Chroma, Circuit, Circuiting, Circular, Class, Classes, Classic, Classmethod, Clause, Clean, Cleaned, Click, Client, Closed, Closer, Closing, Closure, Closures, Cloud, Clustering, Cmd, Code, Codebase, Collaborate, Collapse, Collections, Collecto, Collector, Collects, Collision, Colum, Column, Combinatorics, Combined, Combining, Comma, Command, Commands, Comments, Common, Compact, Compare, Comparing, Comparison, Compatibility, Compilation, Compile, Compiled, Compiler, Compiles, Complete, Completing, Complex, Complexity, Component, Composed, Composition, Compr, Comprehension, Comprehensions, Comprehensive, Compress, Compression, Computational, Concepts, Concurrency, Conda, Condition, Conditional, Conditionals, Config, Configuration, Configured, Conflict, Confusing, Confusion, Conn, Connected, Connection, Cons, Consensus, Consider, Consistent, ConsoleLogger, Consta, Constant, Constants, Constructing, Consumer, Consumers, Consumption, Container, Containers, Contains, Context, Contravariant, Control, Controlling, Controls, Convention, Conventions, ConversationBufferMemory, ConversationSummaryBufferMemory, ConversationalRetrievalChain, Convert, Converter, Converting, Converts, Cooperative, Copy, Copying, Core, Coro, Coroutine, Coroutines, Correlation, Cost, Costs, Count, Countdown, Counter, Counters, Covariant, Coverage, Crashes, Creat, Create, Created, Creates, Creating, Credentials, Critical, Cron, Cross, Ctrl, Ctx, Ctypes, Cur, Curly, Custom, Cython, DAG, Dangerous, Dashboards, Dask, Data, Database, Databases, Dataclass, Dataclasses, Datadog, Dataframe, Date, DateTime, Datetime, Deadlocks, Debug, Debugger, Debuggers, Debugging, Decimal, Decision, DeclarativeBase, Declared, Declares, Declaring, Decorator, Decorators, Dedent, Dedicated, Deduplicating, Deduplication, Deep, Deeply, Def, Default, Defaultdict, Defined, Defines, Definitions, Dehydration, Delay, Delaying, Delegates, Delimiters, Demonstrates, Dependencies, Dependency, Depends, Deploy, Deployment, Deployments, Deprecated, Deque, Descriptor, Descriptors, Deserializing, Design, Designed, Designing, Destruction, Detail, Determined, Determines, Deterministic, Developer, Development, Df, Diagrams, Dict, Dictionaries, Dictionary, Dicts, Different, Differentiate, Dir, Direct, Directory, Dirty, Disable, Disassembly, Discovered, Disguise, Disk, Dispatcher, Distributed, Distributing, Distribution, Dive, Dj, Django, Docker, Dockerfi, Dockerfile, Dockerfiles, Docstrings, Doctest, Doctrine, Document, Documentation, Dog, Domain, Don, Double, Dramatiq, Drastically, Driven, Drivers, Drop, Dropbox, Duck, Dummy, Dumping, Dunder, During, Dynaconf, Dynamic, Dynamically, Each, Easier, Easy, Echo, Ecosystem, Edition, Educational, Effective, Efficient, Elasticsearch, Element, Elif, Eliminates, EllipsisType, Embed, Embedded, Empt, Empty, Enable, Enclosed, Enclosing, Encoded, Encoder, Encoding, Encrypted, End, Endianness, Endpoint, Enforce, Enforcement, Enforcing, Engine, Engineering, Ensure, Ensures, Ensuring, Enterprise, Entities, Entry, Enum, Enumeration, Env, Environment, Envoy, Eps, Equality, Equivalent, Error, Essential, Essentials, Estimated, Eval, Evaluate, Evaluates, Evaluation, Even, Event, Every, Everything, Exact, Exactly, Example, Examples, Excellent, Except, Exception, Exceptions, Exec, Execute, Executed, Executes, Executing, Execution, Executor, Existing, Exits, Expanding, Experiment, Experimental, Expert, Explain, Explained, Explicit, Explicitly, Explore, Exponential, Export, Expose, Exposing, Expression, Expressions, Extension, Extensions, Extern, External, Extract, Extremely, Eyeballing, Factory, Failure, Failures, Fake, Fallback, False, Falsey, Falsy, Fast, FastAPI, FastAPIInstrumentor, Faster, Fastest, Favor, Feather, Feature, Features, Felleisen, Fernet, Fetchone, Fewer, Field, Fields, File, FileLogger, Filename, Files, Filesystem, Filter, Filtering, Final, Financial, Find, Finder, Finished, First, Fisher, Fixed, Fixing, Fixtures, Flask, Float, Floating, Flow, Flowchart, Fluent, Folder, Follow, Followed, Forgetting, Fork, Form, Formal, Format, Formatter, Formatting, Found, Foundation, Foundations, Four, Fra, Fraction, Fragmentation, Frame, Frames, Framework, Frameworks, Free, Frontend, Frozen, Full, Fully, Fun, Funcs, Functio, Function, FunctionTool, Functional, Functions, Functools, Fut, Future, Futures, Gang, Garbage, Gateway, Gauges, Gene, General, Generally, Generate, Generated, Generates, Generation, Generational, Generator, GeneratorExit, Generators, Generic, Generics, Get, Getattr, Getattribute, Getitem, Given, Global, Globally, Goal, God, Google, Google-style, Graceful, Gradle, Gradually, Grafana, Graph, Great, Greedy, Group, Grouping, Groups, Grows, Guards, Guice, Guidance, Gunicorn, Hackaday, Hadoop, Handled, Handler, Handles, Handling, Happens, Hard, Hash, Hatch, Hatchling, Having, Heapq, Heavy, Hello, Helpful, Helps, Hexagonal, Hi, Hiding, Hierarchical, High, Higher, Highly, Histogram, Histograms, Historical, Hook, Hooks, Hot, HttpClient, Httpx, Huge, Human, Hybrid, Hydration, Hypothesis, Id, Ideally, Identifiers, Identify, Identity, Idiomatic, If, Ignoring, Illustrat, Illustrated, Immortal, Immutability, Immutable, Implement, Implementation, Implemented, Implementing, Implements, Implicit, Import, Importing, Imports, Impossible, Improved, Improves, Improving, Inaccurate, Include, Included, Includes, Including, Incomplete, Indentation, Independent, Index, Indexing, Individual, Infinite, Influence, Influenced, Influential, Informal, Infra, Infrastructure, Ingress, Inheritance, Initialization, Initialize, Initializer, Injection, Injector, Inline, Inlines, Input, Insecure, Inserting, Inside, Inspect, Inspecting, Inspired, Install, Installable, Installed, Instance, Instead, Instruction, Int, Integer, Integrate, Integrated, Integration, Integrations, Intenti, Inter, Interaction, Interactive, Interceptors, Intercepts, Interface, Interfaces, Interfacing, Intermediate, Internal, Internals, Internationalization, Interop, Interoperability, Interpreted, Interpreter, Interrupt, Intersection, Intra, Introduced, Introducing, Introduction, Introspective, Ints, Invali, Invalid, Invoice, Ipdb, Isolate, Isolated, It, Item, Iterable, Iterables, Iteration, Iterator, Iterators, Itertools, JSON, JSONResponse, Jaeger, Jan, Java, Jobs, John, Json, Jump, Jupyter, Just, Jython, Kafka, Keep, Kernel, Kernprof, Key, KeyboardInterrupt, Keyword, Keywords, Kibana, Kontinuation, Kubernetes, Kwargs, LOAD_FAST, Lambda, Lambdas, Language, Large, Last, Late, Latency, Later, Latin, Lattice, Layer, Layout, Lazy, Le, Left, Legacy, Legend, Less, Let, Lets, Level, Lexer, Lexical, Libraries, Library, Lifecycle, Lightweight, Limited, Limiting, Line, Linearization, Lines, Linker, Lint, Linter, Linters, Linting, Linux, Lisp, List, Lists, Literal, Literals, Liveness, Load, Loaded, Loader, Loaders, Loads, Local, Locals, Lock, Lockfiles, Locks, Log, Logger, Logging, Logic, Logs, Logstash, Loki, Long, Lookaheads, Lookbehinds, Lookup, Loop, Losing, Lost, Low, Lower, Mac, Machine, Machinery, Macro, Macros, Main, Maintenance, Make, Malicious, Managed, Manager, Managers, Managing, Mangum, Manipulating, Manual, Many, Map, Mapped, Mapping, Mappings, Mark, Marked, Markup, Marshmallow, Match, Matching, Mathematical, Matrix, Mature, Maven, Means, Measure, Measuring, Mechanics, Mechanism, Medium, Mega, Membership, Memoization, Memory, Merging, Message, Meta, Metaclass, Metaclasses, Metadata, Method, Methods, Metrics, Microcontrollers, Microservice, Microservices, Microsoft, Microtask, Middleware, Migrating, Migrations, Minimal, Minimum, Misconception, Missing, Mistakes, Misusing, Mixing, Mkvirtualenv, Mock, Mocking, Mocks, Mod, Mode, Model, Models, Modern, Modified, Modifies, Modify, Modifying, Module, ModuleSpec, Modules, Monitoring, Monkeypatch, Monolith, Monoliths, Monorepo, Most, Mount, Move, Much, Multi, Multiple, Multiprocessing, Multirepo, Mutability, Mutable, Mutating, Mutex, Mutual, Myapp, Mypy, Naive, Name, Named, Namedtuple, Names, Namespace, Namespaces, Naming, Narrowing, Nati, Native, Need, Negative, Network, Neural, Never, New, NewType, Nginx, Node, Non, None, NoneType, Nonexistent, Normalization, Normalize, Not, NotImplementedType, Note, Notifier, Now, NumPy, NumPy-style, Numba, Number, Numbers, Numeric, Numerical, Nums, OAuth2PasswordBearer, OTLPSpanExporter, Obj, Object, Objects, Obmalloc, Observability, Observer, Offloading, Offset, Offside, Often, Old, Omitted, One, Only, Open, OpenAI, OpenAIEmbeddings, Operate, Operating, Operation, Operational, Operations, Operator, Operators, Opposite, Ops, Optimization, Optimizations, Optimize, Optimized, Optimizer, Optimizes, Optimizing, Optional, Oracle, Order, OrderedDict, Ordering, Ordinary, Organize, Originally, Other, Out, Outperform, Output, Over, Overengineering, Overhead, Overly, Overuse, Overusing, Overview, Package, Packages, Packaging, Pandas, Pandera, Parallel, ParamSpec, Parameter, Parameterized, Parent, Parenthesized, Parquet, Parse, Parser, Parsing, Part, Partially, Pass, Passable, Passive, Password, PasswordHasher, Patch, Path, Pathlib, Pattern, Patterns, Pauses, Pdb, Peephole, Per, Percent, Perfect, Performance, Performed, Permission, Permissions, Perturb, Pickle, Pierce, Pillars, Pin, Pip, Pipeline, Pipes, Pipx, Pitfalls, Pkgutil, Placeholder, Planner, Playwright, Plotkin, Plugin, Poetry, Point, Polars, Policy, Polyglot, Pool, Pools, Poor, Popen, Popular, Porting, Ports, Positional, Possible, Post, Powerful, Pr, Practical, Pre, Precompiled, Predictable, Prefect, Prefer, Preferred, Prefers, Prerequisites, Presentation, Preserve, Preserves, Pretty, Prevent, Prevention, Prevents, Preview, Primary, Prime, Principle, Print, Prioritize, Private, Pro, Procedural, Proceed, Process, ProcessPoolExecutor, Processes, Processing, Producer, Producers, Produces, Productio, Production, Production-ready, Professional, Profile, Profiler, Profiling, Program, Programming, Project, Prometheus, Propagating, Proper, Properties, Property, Propose, Protected, Protects, Protobuf, Protocol, Protocols, Prototyping, Provide, Provider, Provides, Pub, Public, Publish, Publisher, Publishing, Purpose, Push, Py, PyAPI_FUNC, PyObject, PyObject_HEAD, PyObject_VAR_HEAD, Py_DECREF, Py_INCREF, Pydantic, Pyenv, Pyjion, Pylance, Pyodide, Pyproject, Pyramid, Pyright, Pyston, Pyt, Pytest, Python, PythonOperator, Pythonic, Qt, Quality, Queries, Queue, Queues, Quick, RETURN_VALUE, Race, Raise, Raised, Raises, Raising, Randomized, Rapid, Raw, Ray, Re, ReActAgent, Read, Readable, Readiness, Reading, Reads, Ready, Real, Realistic, Reasoning, Rebinding, Recommendation, Recommended, Recursive, Redefining, Redis, Reduced, Reducing, Redundant, Ref, Refactor, Refactoring, Refcount, Refer, Reference, References, Reflection, Regex, Registries, Registry, Rego, Regular, Reinforcement, Related, Relational, Relative, Releasing, Relevance, Relevant, Reload, Relying, Remote, Remove, Removes, Removing, Render, Replace, Replaceable, Replaced, Replacing, Replicas, Repo, Repos, Repositories, Repository, Represent, Representation, Represents, Reproduce, Request, Requests, Required, Requirements, Requires, Resolution, Resolves, Resource, Response, Responsibility, Result, Retries, RetrieverQueryEngine, Retry, Return, Returnable, Returned, Returns, Reusable, Reusing, Reverse, Review, Reviewer, Revived, Richly, Ro, Robust, Role, Rollbar, Rolling, Roughly, Route, Router, Ruff, Rule, Rules, Run, Runner, Running, Runs, Runtime, Runtimes, Rust, SIGINT, SIGTERM, Safe, Same, Sample, SandboxedEnvironment, Sandboxing, Sc, Scalable, Scaling, Scanning, Scenario, Scheduled, Scheduler, Scheduling, Schema, Scientific, Scikit, Scope, Scoped, Scrip, Scripting, Scripts, Search, Searching, Seconds, Secret, Secrets, Section, Sections, Secure, Security, See, Selecting, Selection, Self, Semantics, Semgrep, Sent, Sentinel, Sentry, Separate, Separates, Sequences, Serialization, Serialized, Server, Serverless, Servers, Servi, Service, Services, Serving, Session, SessionLocal, Sessions, Set, Sets, Setting, Settings, Setup, Setuptools, Shadowing, Shallow, Shared, Ship, Sho, Short, Shorter, Shouldn, Show, Shows, Signa, Signal, Signals, Signature, Signatures, Significance, Significant, Silent, Simple, SimpleDirectoryReader, Simpler, Simplifies, Single, Singleton, Situation, Skipped, Skips, Slicing, Slots, Slow, Slower, Small, Smaller, Smallest, So, Soft, Software, Solution, Some, Sometimes, Sort, Sorted, Sorting, Sound, Source, Sources, Spark, SparkSession, Spatial, Spawn, Special, Specialized, Specific, Speed, Sphinx, Split, Spy, Stack, Stacks, Stage, Stages, Stale, Standard, Starlette, Start, Startup, State, Stateful, Static, Staticmethod, Statistic, Statistical, Stats, Status, Step, Still, Stop, Stopped, Storable, Storage, Store, Stored, Storing, Str, Strategy, Streaming, StreamingResponse, StreamingStdOutCallbackHandler, Strengths, Stricter, String, Strings, Strip, Strong, Strongly, Structlog, Structural, Structure, Structured, Structuring, Stub, Style, Sub, Subclass, Subprocess, Summaries, Summary, Super, Supply, Support, Supported, Supporting, Supports, Suppressing, Surprises, Sussman, Swallowing, Synchronization, Synonym, Syntax, Sys, System, SystemExit, Tab, Table, Tabs, Tail, Takeaway, Takeaways, Task, Tasks, Teaser, Technique, Temp, Template, Templating, Tempo, Temporary, Tenacity, Term, Terms, Test, TestClient, Testable, Testcontainers, Testing, Tests, Text, Then, Theoretical, There, They, Thorough, Thread, ThreadPoolExecutor, Threading, Threads, Three, Throughout, Tier, Tiered, Time, Timeout, Timeouts, Timer, Times, Timestamp, Timestamps, Timezone, Timsort, Tiny, Tips, Todo, Token, Tokenization, Tokenize, Tokenizer, Tokens, Tolerances, Too, Tool, Tooling, Tools, Top, Topic, Tornado, Tortoise, Total, Tour, Trace, Tracemalloc, Tracer, TracerProvider, Traces, Tracing, Tracking, Trade, Traditional, Traefik, Traffic, Transactional, Transactions, Transducer, Transform, Transformation, Transforming, Transforms, Traversal, Traversing, Tree, Tricks, Trigger, Triggered, Triggers, True, Truffle, Trust, Trusting, Try, Ts, Twine, Two, Type, TypeAlias, TypeError, TypeGuard, TypeVar, TypedDict, Typedef, Types, Typical, Typing, Ultra, Unbounded, Underlying, Understand, Understanding, Underused, Unexpected, Unicode, Unified, Unify, Union, Unique, Unit, Unittest, Unix, Unless, Unordered, Unpacking, Unpickle, Unpinned, Unsafe, Untyped, Unvalidated, Unwinding, Update, Upload, Urllib, Us, Usage, Use, Used, User, UserCreate, UserRepository, UserService, Users, Uses, Using, Usually, Utilities, Uv, Uvicorn, Validate, Validation, Validators, Value, Values, Variable, Variables, Variadic, Vault, Vec, Vector, Vectorization, Vectorize, Vectorized, Verbose, Verify, Version, Versioning, Versus, Very, Via, Virtual, Virtualenv, Visualization, Volatile, Waiting, Waldo, Want, Warehouse, Warning, Warnings, Watch, We, Weak, Web, WebSocket, Wh, Wheels, While, Whitespace, Wikipedia, Windows, Wiring, Without, Wor, Words, Work, Worker, Workers, Workflow, Working, Workloads, Wraps, Wright, Write, Writes, Writing, Written, YAML, Yates, You, Zero, ZoneInfo, Zoneinfo, _PyEval_EvalFrame, _PyEval_EvalFrameDefault, __add__, __aenter__, __aexit__, __call__, __del__, __delete__, __dict__, __doc__, __enter__, __exit__, __future__, __get__, __getitem__, __init__, __init_subclass__, __iter__, __len__, __lt__, __mro__, __mul__, __name__, __new__, __next__, __post_init__, __repr__, __set__, __slots__, __weakref__, _analyze_code, _calculate_cache_hit_rate, _call_llm, _call_llm_with_metrics, _celsius, _chunks, _classify_error, _connect, _create, _decide_action, _execute_primary, _extract_answer, _extract_function_name, _first, _generate_code, _handle_generic_error, _handle_invalid_response, _handle_rate_limit, _handle_timeout, _handle_tool_error, _handler, _hash_task, _initialized, _instance, _last, _load_db, _lock, _parent, _process, _process_impl, _py, _refactor_code, _save_db, _scrape_one, _think, _users, _validate_and_charge, _validate_code, _violates_rule, _was_cached, _write_file, abc, abs_path, abstract_method, access, action, action_input, add, add_one, adder, addopts, addr, admin_user, against, age, age1, agent, agents, aiohttp, airflow, allocation, allocations, allowed_hosts, alphabet, amount, analyze_dependencies, analyze_errors, analyze_log, animal_type, animals, annotations, any_box, api_url, app, append, append_to_list, application, apply, arch_result, architect, arcname, arg, argon2, args, args_schema, arguments, arr, array, assert_type, ast, async_sessionmaker, asyncio, asyncpg, attr, attributes, authenticate, autoescape, autouse, avoidance, aware, axis, background_task, backoff, backstory, bad_increment, base, basename, batch_execute, batch_task, batches, beijing, belonging, berlin, binding, bisect, blocks, bodies, body, bool, both, boto3, bound, bound_method, box, bs4, build, burst, bytes, bz2, bz2_size, c1, c2, cProfile, cache, cache_key, cache_ttl, cached_util, caching, calc, calculate_tax, call, called, calling, calls, can, capture_output, case, celery, celery_app, celsius, central, cfg, chain, charge, check, check_hostname, child, child_conn, children, circle, classical, cleaned, cleanup, cleanup_node, cli, click, client, close, cls, code, codebase_tool, collections, color, combined_prompt, combining, command, comparable, compiled_time, complex_function, complexity, compresslevel, compute, concurrent, condition, config, config1, config2, configparser, confluent_kafka, conn, connect, connection, considerations, console_format, console_handler, container, content, context, contextlib, contextmanager, convention, copy, correctly, correlation_id, cost, cost_per_task, count, countdown, counter, counts, cov, covariant, cpu_bound_task, cpu_task, create, create_animal, create_app, create_async_engine, create_config, create_engine, create_item, create_objects, create_parser, create_product, create_task, create_user, create_user_service, crew, crewai, crewai_tools, csv, csv_to_json, ctx, currency, custom_filter, cutoff, cwd, data, database, database_transaction, dataclass, dataclasses, datefmt, datetime, dateutil, days, db, db1, db2, db_host, db_path, db_port, db_session, dct, dd_custom, dd_dict, dd_int, dd_list, dd_set, debug, debug_function, debug_print, debugging, debugpy, declares, deco, decoded, decorators, decouple, dedented, default, default_factory, defaultdict, defaults, defined, definition, definitions, delete, delimiter, delta, denied, dependency_injector, dept_users, depth, deque, deque_time, describes, description, design, design_task, detail, df, dict, diff, differences, difflib, dir, dirname, dirs_exist_ok, dis, disk, dispatch, distance, distance_from_origin, distutils, divide, doc, docstring, documents, domain, done, dotenv, double, dramatiq, draw, dt, dt1, dt2, dt_local, dt_ny, dt_tokyo, dt_tz, dt_utc, dtype, duckdb, dynaconf, dynamic, each, eastern, else, email, email_pattern, emails, embedding, embeddings, emit, empty, enclosing, encoded, encoding, end, endswith, engine, entry, enum, env, env_config, environment, equality, error, error_counts, error_msg, error_str, error_type, errors, estimated_py_time, event, event_name, example, example_func, exc, exc_info, exc_tb, except, exclude_lines, exec_module, execute, executing, execution, executor, exist_ok, expected, expected_output, expedite, expensive, expensive_computation, expression, ext, extension, extensions, extra, extract, extract_all, f_in, f_out, factor, factorial, factorial_cached, factory, failed, failing_task, failure, fallback, fast_sum, fastapi, fetch, fetch_all, fetch_data, fetch_html, fetch_page, fetch_url, fetch_user, fib, fieldnames, file, file_config, file_format, file_handler, file_path, filename, files, fill, filled, filter, filter_errors, filtered, finally, find_item, find_spec, find_user, finders, first, first_arg, flatten, float, flow, fn, foo, format, format_docstring, format_exception, format_greeting, formatted, found, frame, frames, free, fromdesc, fromfile, full_name, full_url, func, func_name, functools, futures, gc, gdb, gen, generate_latest, generate_password, generating, get, get_all, get_by_id, get_cost_summary, get_db, get_name, get_session, get_status_message, get_stream, get_user, get_user_service, get_value, get_version, gid, given, glob, goal, good_increment, greedy, greet, group, grouped, groups, guaranteed, gz_size, gzip, handle, handler, hashlib, health, heapq, heavy, hello, helper, history, home, homepage, hooks, host, hour, hours, html_diff, http, https, httpx, hypothesis, id, identity, idx, ignore, ignore_errors, importlib, imports, in_2_hours, inc, increment, increment_counter, indent, indented, index, industry-standard, init_db, initial_indent, inner, input, input_file, insert, inspect, inspect_function, inspector, int, integration, invariant_no_side_effects, invariants, io, ipdb, is_active, is_int_list, is_str, iso_str, issues, item, item_dict, itemgetter, items, iterable, itertools, job, json, json_str, keepends, key, keys, kind, kwargs, label, langchain_openai, large_data, large_text_list, last, left, length, level, limit, line, lines, lineterm, list, list_files_tool, list_items, list_time, list_users, llama_index, llm, llm_client, load, load_config, load_data, load_dotenv, load_file, load_module, load_plugins, load_secrets, load_tasks, loaded, loader, local_time, localhost, lock, locks, log, log_exception, log_file, log_level, log_line, logged, logger, logging, logging_setup, login_user, london, long_text, lru_cache, lst, lzma, machinery, main, make_adder, manager, mapped_column, markers, marshmallow, match, matcher, matches, max_attempts, max_token_limit, max_value, max_workers, maxlen, maxsize, maybe, members, memoize, memory, memory_intensive, memory_repo, merge, message, meta_path, metadata, method, metrics, middleware, min_size, min_value, minutes, mock, mock_api, mock_client, mock_func, mock_obj, mode, model, modules, move, msg, msgpack, mul, multi_time, multiple, multiprocessing, mutability, my_decorator, my_ext, my_function, my_list, my_method, naive, name, name1, namedtuple, names, napoleon_google_docstring, napoleon_numpy_docstring, nb_time, new_item, new_root, new_text, new_tree, newline, next_week, nightly, njit, non_greedy, now, np_inplace_time, np_time, nullcontext, num_workers, numba, numba_sum, numbers, numpy, numpy_inplace, numpy_sum, numpy_vectorized, obj, obj_box, object, object_hook, objects, objtype, observation, od, omit, on_startup, openai, opentelemetry, operational, operator, options, orchestrator, order, order_id, origin, os, other, other_condition, outer, outer_code, output, output_file, override, overriding, overwhelming, p1, p2, pacific, packed, pair, pandas, pandera, parallelization, params, parent, parents, paris, parse, parse_args, parse_config, parse_int, parse_log, parse_title, parsed, parser, parser_class, partial, parts, passed, password, patch, path, pathlib, pattern, pattern_compiled, pattern_str, pdb, peak, perf, person, person_decoder, person_encoder, phone_pattern, phones, pickle, pickled, pid, pipeline, placeholder, plugin, points, polars, pool, port, ppid, pprint, pragma, precedence, prefect, prefix, prelude, preserved, prime, print_info, priority, process, process_by_index, process_chunk, process_data, process_file, process_items, process_log, process_order, process_payment, process_time, processes, product_type, profile, profile_function, profiler, prometheus_client, prompt, protocol, pstats, public, publish, publishing, put, put_string, pwd, py, py-spy, py_time, pydantic, pydantic_settings, pyo3, pytest, python, python_loop, python_path, python_sum, q_deque, q_list, qa_chain, qualifies, query, query_engine, queue, quoting, random, rate, rate_limit, ratio, re, read_all, read_all_lines, read_file, read_file_tool, read_large, read_lines, reader, receiving, recursive, redirect_stdout, redis, refactor_result, references, register, register_user, registry, regular, regular_points, regular_size, relative, render, repeat, replace_whitespace, replacer, repo, report, repository, representation, req, request, request_id, request_with_backoff, requests, reset_state, response, respx, result, result1, result_dict, results, retaining, retriever, retry, retry_with_backoff, return_messages, return_value, returning, returns, review, review_code, review_file, review_result, review_task, review_tool, reviewer, risky_computation, risky_function, role, root, route, router, row, rq, rtype, rule, rules, run, run_pipeline, run_tests, running, s1, s1_norm, s2, s2_norm, safe_get, safe_join, safe_json_loads, same, sample_user, sanitized, save, save_tasks, scale, schedule_event, scope, scrape, scratch, search, search_codebase, search_list, seconds, secrets, secure_get, secure_sock, security_result, select, self, send, send_email, serializer, server, server_hostname, service, service_context, session, set, set_x, settings, setup_logging, setup_tracing, setuptools, shared, shared_arr, shared_barrier, shared_dict, shared_event, shared_list, shared_lock, shared_namespace, shared_obj, shared_queue, shared_semaphore, shell, shlex, short, should_continue, shutdown, shutdown_requested, shutil, sig, signal, signal_handler, signatures, simplified_task, single_time, singledispatch, sizes, skipinitialspace, sleep, sliding_window, slots, slotted, slotted_points, slotted_size, slow, slow_function, slower, slugify, snapshot, snapshot1, snapshot2, sock, socket, source, speak, spec, speedup, split, sql, sqlalchemy, sqlite, sqlite3, square_array, ssl, stack, start, startswith, startup, stat, statements, static, stats, status, status_code, stderr, stdin, stdout, stmt, str, str_box, strategy, stream, string, string_box, structlog, structure, structured_task, submodule_search_locations, subprocess, subscribe, subsequent_indent, success, suffix, suite, sum, summarize, summary, supporting, supports, sys, system, tag, tagged, taking, tarfile, target, task, task1, task_queue, tasks, tb_lines, tb_str, temp, temp_file, temp_name, temperature, tempfile, template, test_add, test_add_commutative, test_api, test_api_call, test_async, test_async_function, test_basic_functionality, test_cases, test_code, test_create, test_db, test_division_by_zero, test_edge_cases, test_email_validation, test_expensive_operation, test_function, test_get_users, test_http, test_multiply, test_process, test_query, test_result, test_reverse_twice_is_identity, test_service, test_service_calls_repo, test_sum, test_sum_positive, test_task, test_uppercase, test_user_creation, test_with_context, test_with_mock, test_with_patch, test_with_pytest_mock, test_zero_division, tester, text, text1, text2, texts, textwrap, thought, thread1, thread2, thread_time, threading, threads, threshold, tied, time, timeit, timeout, timestamp, timestamps, timezone, tiny_task, title, tmpdir, todesc, tofile, token, tokenize, tokens, tokens_per_task, tokens_used, tokyo, tomorrow, tools, top_2, top_errors, top_stat, top_stats, tortoise, total, total_ordering, trace, traceback, tracemalloc, trans, transaction, transform, transform_xml, tree, trigger_email, try, tuple, type, typing, tzinfo, uid, unbound_method, uncompiled_time, under, unicodedata, unit, unpickled, until, upper, url, url_pattern, urllib, urlopen, urlparse, urls, use_b, use_db, user, user1, user_code, user_data, user_id, user_input, user_service, user_tmp, username, users, using, utc, utc_time, util, uuid, val, valgrind, valid, validate, validate_call, value, variable_name, vectorstore, verbose, verify_mode, versions, violations, vs, warnings, weakref, weeks, width, window, window_size, without, word_count, word_freq, words, worker, worker_id, workers, wrap, wrapped, wrapper, wraps, write_file, writer, ws, xml_declaration, xml_str, xz_size, yaml, yield, zipfile, zoneinfo]
chapters_by_symbol: {'Hiding': ['GLOBAL'], 'float': ['GLOBAL'], 'Validate': ['GLOBAL'], 'Python': ['GLOBAL'], 'Java': ['GLOBAL'], '_parent': ['GLOBAL'], 'process_by_index': ['GLOBAL'], 'tagged': ['GLOBAL'], 'Large': ['GLOBAL'], 'scale': ['GLOBAL'], 'Feature': ['GLOBAL'], 'Modules': ['GLOBAL'], 'design_task': ['GLOBAL'], 'Deeply': ['GLOBAL'], 'Left': ['GLOBAL'], 'increment': ['GLOBAL'], 'indent': ['GLOBAL'], 'tree': ['GLOBAL'], 'JSON': ['GLOBAL'], 'review_result': ['GLOBAL'], 'Alternative': ['GLOBAL'], 'Immutable': ['GLOBAL'], 'Existing': ['GLOBAL'], 'recursive': ['GLOBAL'], 'Compile': ['GLOBAL'], 'UserCreate': ['GLOBAL'], 'test_task': ['GLOBAL'], '_handle_rate_limit': ['GLOBAL'], '_was_cached': ['GLOBAL'], 'get_db': ['GLOBAL'], 'Limiting': ['GLOBAL'], 'Refactoring': ['GLOBAL'], 'ratio': ['GLOBAL'], 'Smaller': ['GLOBAL'], 'Tenacity': ['GLOBAL'], 'Adding': ['GLOBAL'], 'Chroma': ['GLOBAL'], 'Parallel': ['GLOBAL'], 'extension': ['GLOBAL'], 'pstats': ['GLOBAL'], 'PyObject_VAR_HEAD': ['GLOBAL'], 'Underlying': ['GLOBAL'], 'ParamSpec': ['GLOBAL'], 'Returnable': ['GLOBAL'], 'Re': ['GLOBAL'], 'summary': ['GLOBAL'], 'Classes': ['GLOBAL'], 'Check': ['GLOBAL'], 'Logging': ['GLOBAL'], 'paris': ['GLOBAL'], 'Pyramid': ['GLOBAL'], 'Tail': ['GLOBAL'], 'format_docstring': ['GLOBAL'], 'keys': ['GLOBAL'], 'variable_name': ['GLOBAL'], 'Architecture': ['GLOBAL'], 'Highly': ['GLOBAL'], 'temp_file': ['GLOBAL'], 'Relevance': ['GLOBAL'], 'scrape': ['GLOBAL'], 'Out': ['GLOBAL'], 'beijing': ['GLOBAL'], 'Minimum': ['GLOBAL'], 'Primary': ['GLOBAL'], 'Idiomatic': ['GLOBAL'], 'Abelson': ['GLOBAL'], 'Meta': ['GLOBAL'], 'autoescape': ['GLOBAL'], 'Apply': ['GLOBAL'], 'dir': ['GLOBAL'], 'Table': ['GLOBAL'], 'Creating': ['GLOBAL'], 'Floating': ['GLOBAL'], 'Collects': ['GLOBAL'], 'dedented': ['GLOBAL'], 'Output': ['GLOBAL'], 'Web': ['GLOBAL'], 'Trade': ['GLOBAL'], '__future__': ['GLOBAL'], 'Update': ['GLOBAL'], 'detail': ['GLOBAL'], 'csv': ['GLOBAL'], 'utc_time': ['GLOBAL'], 'analyze_dependencies': ['GLOBAL'], 'Unix': ['GLOBAL'], '__len__': ['GLOBAL'], 'Try': ['GLOBAL'], 'cutoff': ['GLOBAL'], 'Formatter': ['GLOBAL'], 'sleep': ['GLOBAL'], '__delete__': ['GLOBAL'], 'speedup': ['GLOBAL'], 'Local': ['GLOBAL'], 'Between': ['GLOBAL'], 'Influence': ['GLOBAL'], 'parse': ['GLOBAL'], 'Observability': ['GLOBAL'], 'test_code': ['GLOBAL'], 'Ctx': ['GLOBAL'], 'Endianness': ['GLOBAL'], 'process_data': ['GLOBAL'], 'Sentinel': ['GLOBAL'], 'docstring': ['GLOBAL'], 'Execute': ['GLOBAL'], 'df': ['GLOBAL'], 'Pierce': ['GLOBAL'], 'running': ['GLOBAL'], 'Count': ['GLOBAL'], 'frame': ['GLOBAL'], 'Lists': ['GLOBAL'], 'Inspired': ['GLOBAL'], 'service_context': ['GLOBAL'], 'Protocol': ['GLOBAL'], 'Declaring': ['GLOBAL'], 'engine': ['GLOBAL'], 'profiler': ['GLOBAL'], 'Most': ['GLOBAL'], 'relative': ['GLOBAL'], 'Distributing': ['GLOBAL'], 'replace_whitespace': ['GLOBAL'], 'ctx': ['GLOBAL'], 'Pyt': ['GLOBAL'], 'Input': ['GLOBAL'], '__weakref__': ['GLOBAL'], 'threads': ['GLOBAL'], 'environment': ['GLOBAL'], 'Rollbar': ['GLOBAL'], 'Provides': ['GLOBAL'], 'skipinitialspace': ['GLOBAL'], 'Surprises': ['GLOBAL'], 'bz2': ['GLOBAL'], 'arguments': ['GLOBAL'], 'Consider': ['GLOBAL'], 'Grows': ['GLOBAL'], 'Sussman': ['GLOBAL'], 'Cur': ['GLOBAL'], 'Revived': ['GLOBAL'], 'Illustrat': ['GLOBAL'], 'Sequences': ['GLOBAL'], 'Operators': ['GLOBAL'], 'Still': ['GLOBAL'], 'Same': ['GLOBAL'], 'Convert': ['GLOBAL'], 'Amortized': ['GLOBAL'], 'user_tmp': ['GLOBAL'], 'Allows': ['GLOBAL'], 'good_increment': ['GLOBAL'], 'registry': ['GLOBAL'], 'Pathlib': ['GLOBAL'], 'Implementation': ['GLOBAL'], 'Workers': ['GLOBAL'], 'Section': ['GLOBAL'], 'expedite': ['GLOBAL'], 'Comparison': ['GLOBAL'], 'Timestamps': ['GLOBAL'], 'User': ['GLOBAL'], 'greedy': ['GLOBAL'], 'wraps': ['GLOBAL'], 'Inspect': ['GLOBAL'], 'Complexity': ['GLOBAL'], 'DateTime': ['GLOBAL'], 'logging': ['GLOBAL'], 'Hooks': ['GLOBAL'], 'Confusion': ['GLOBAL'], 'security_result': ['GLOBAL'], 'Scenario': ['GLOBAL'], 'Engineering': ['GLOBAL'], 'fetch_all': ['GLOBAL'], 'process_order': ['GLOBAL'], 'parse_title': ['GLOBAL'], 'Frames': ['GLOBAL'], 'parse_log': ['GLOBAL'], 'Documentation': ['GLOBAL'], 'source': ['GLOBAL'], 'Offside': ['GLOBAL'], 'user_id': ['GLOBAL'], 'Falsey': ['GLOBAL'], 'Seconds': ['GLOBAL'], '_hash_task': ['GLOBAL'], 'Oracle': ['GLOBAL'], 'llama_index': ['GLOBAL'], 'celery': ['GLOBAL'], 'Poetry': ['GLOBAL'], 'Buildable': ['GLOBAL'], 'Storing': ['GLOBAL'], 'Total': ['GLOBAL'], 'Intercepts': ['GLOBAL'], 'circle': ['GLOBAL'], 'Elasticsearch': ['GLOBAL'], 'get_name': ['GLOBAL'], '__slots__': ['GLOBAL'], 'tb_lines': ['GLOBAL'], 'Analyze': ['GLOBAL'], 'Dict': ['GLOBAL'], 'Ro': ['GLOBAL'], 'Complex': ['GLOBAL'], 'val': ['GLOBAL'], 'Reinforcement': ['GLOBAL'], 'Interpreter': ['GLOBAL'], 'group': ['GLOBAL'], 'template': ['GLOBAL'], '_extract_answer': ['GLOBAL'], 'Interaction': ['GLOBAL'], 'host': ['GLOBAL'], 'fallback': ['GLOBAL'], 'Trace': ['GLOBAL'], 'Only': ['GLOBAL'], 'Setup': ['GLOBAL'], 'Replace': ['GLOBAL'], 'Essential': ['GLOBAL'], 'use_b': ['GLOBAL'], 'Experimental': ['GLOBAL'], 'init_db': ['GLOBAL'], 'insert': ['GLOBAL'], 'Cfg': ['GLOBAL'], 'mock_client': ['GLOBAL'], 'Creates': ['GLOBAL'], 'max_token_limit': ['GLOBAL'], 'public': ['GLOBAL'], 'counter': ['GLOBAL'], 'Intenti': ['GLOBAL'], 'c1': ['GLOBAL'], 'Serverless': ['GLOBAL'], 'BaseSettings': ['GLOBAL'], 'Introducing': ['GLOBAL'], 'Enumeration': ['GLOBAL'], 'peak': ['GLOBAL'], 'filename': ['GLOBAL'], 'Generation': ['GLOBAL'], 'Late': ['GLOBAL'], 'Authorization': ['GLOBAL'], 'bz2_size': ['GLOBAL'], 'key': ['GLOBAL'], 'cpu_bound_task': ['GLOBAL'], 'priority': ['GLOBAL'], 'valid': ['GLOBAL'], 'Reviewer': ['GLOBAL'], 'marshmallow': ['GLOBAL'], 'Compare': ['GLOBAL'], 'Returned': ['GLOBAL'], '_process_impl': ['GLOBAL'], 'gz_size': ['GLOBAL'], 'Suppressing': ['GLOBAL'], 'Benchmark': ['GLOBAL'], 'collections': ['GLOBAL'], 'Linting': ['GLOBAL'], 'Peephole': ['GLOBAL'], 'Kernel': ['GLOBAL'], 'encoding': ['GLOBAL'], 'eastern': ['GLOBAL'], 'Mocks': ['GLOBAL'], 'Without': ['GLOBAL'], 'Avoid': ['GLOBAL'], 'Accidental': ['GLOBAL'], 'Checked': ['GLOBAL'], 'parallelization': ['GLOBAL'], 'Finished': ['GLOBAL'], 'Initializer': ['GLOBAL'], 'Each': ['GLOBAL'], 'Publisher': ['GLOBAL'], 'Starlette': ['GLOBAL'], 'Expert': ['GLOBAL'], 'Incomplete': ['GLOBAL'], 'central': ['GLOBAL'], 'Caching': ['GLOBAL'], 'loader': ['GLOBAL'], 'Asyncio': ['GLOBAL'], 'distance': ['GLOBAL'], 'Much': ['GLOBAL'], 'Secrets': ['GLOBAL'], 'Reflection': ['GLOBAL'], 'langchain_openai': ['GLOBAL'], 'container': ['GLOBAL'], 'Controlling': ['GLOBAL'], 'embeddings': ['GLOBAL'], 'tokyo': ['GLOBAL'], 'Methods': ['GLOBAL'], 'Calls': ['GLOBAL'], 'Sample': ['GLOBAL'], 'last': ['GLOBAL'], 'Explained': ['GLOBAL'], 'test_sum': ['GLOBAL'], 'Float': ['GLOBAL'], 'Method': ['GLOBAL'], 'Search': ['GLOBAL'], 'Exponential': ['GLOBAL'], 'Shorter': ['GLOBAL'], 'Temp': ['GLOBAL'], 'rate': ['GLOBAL'], 'memory_intensive': ['GLOBAL'], 'Kafka': ['GLOBAL'], 'Warning': ['GLOBAL'], 'Rolling': ['GLOBAL'], 'dispatch': ['GLOBAL'], 'blocks': ['GLOBAL'], 'contextmanager': ['GLOBAL'], 'gid': ['GLOBAL'], 'Structured': ['GLOBAL'], 'Algebraic': ['GLOBAL'], 'Click': ['GLOBAL'], 'get': ['GLOBAL'], 'sig': ['GLOBAL'], 'machinery': ['GLOBAL'], 'read_all_lines': ['GLOBAL'], 'Agent': ['GLOBAL'], 'background_task': ['GLOBAL'], 'Practical': ['GLOBAL'], 'Warnings': ['GLOBAL'], 'Countdown': ['GLOBAL'], 'ABC': ['GLOBAL'], 'Redefining': ['GLOBAL'], 'test_async': ['GLOBAL'], 'Store': ['GLOBAL'], 'Wiring': ['GLOBAL'], '__del__': ['GLOBAL'], 'Machinery': ['GLOBAL'], 'Recommendation': ['GLOBAL'], 'Matching': ['GLOBAL'], 'Dedent': ['GLOBAL'], 'Manager': ['GLOBAL'], 'Waldo': ['GLOBAL'], 'Special': ['GLOBAL'], 'Archive': ['GLOBAL'], 'CORSMiddleware': ['GLOBAL'], 'Converts': ['GLOBAL'], 'Getattribute': ['GLOBAL'], 'exc': ['GLOBAL'], 'comparable': ['GLOBAL'], 'Serving': ['GLOBAL'], 'greet': ['GLOBAL'], 'precedence': ['GLOBAL'], 'Objects': ['GLOBAL'], 'Lock': ['GLOBAL'], 'Parsing': ['GLOBAL'], 'Allocation': ['GLOBAL'], 'args': ['GLOBAL'], 'TypeVar': ['GLOBAL'], 'Pr': ['GLOBAL'], 'Significant': ['GLOBAL'], 'Allowed': ['GLOBAL'], 'Verify': ['GLOBAL'], 'Thread': ['GLOBAL'], 'Todo': ['GLOBAL'], 'log_line': ['GLOBAL'], 'Production-ready': ['GLOBAL'], 'Delaying': ['GLOBAL'], 'analyze_errors': ['GLOBAL'], 'Used': ['GLOBAL'], 'Linter': ['GLOBAL'], 'Itertools': ['GLOBAL'], 'Ce': ['GLOBAL'], 'boto3': ['GLOBAL'], 'Very': ['GLOBAL'], 'window': ['GLOBAL'], 'Precompiled': ['GLOBAL'], 'error_msg': ['GLOBAL'], 'Interpreted': ['GLOBAL'], 'Flask': ['GLOBAL'], 'Writing': ['GLOBAL'], 'Boolean': ['GLOBAL'], 'transform_xml': ['GLOBAL'], 'Pyodide': ['GLOBAL'], 'test_get_users': ['GLOBAL'], 'localhost': ['GLOBAL'], 'Dynaconf': ['GLOBAL'], 'Chris': ['GLOBAL'], 'Consensus': ['GLOBAL'], 'Requires': ['GLOBAL'], 'Deserializing': ['GLOBAL'], 'Strong': ['GLOBAL'], 'Identifiers': ['GLOBAL'], 'my_method': ['GLOBAL'], 'Prioritize': ['GLOBAL'], 'cached_util': ['GLOBAL'], 'Ready': ['GLOBAL'], 'Managers': ['GLOBAL'], 'Randomized': ['GLOBAL'], 'Garbage': ['GLOBAL'], 'test_zero_division': ['GLOBAL'], 'Heapq': ['GLOBAL'], 'task': ['GLOBAL'], 'word_freq': ['GLOBAL'], 'strategy': ['GLOBAL'], 'Version': ['GLOBAL'], 'Infrastructure': ['GLOBAL'], 'Common': ['GLOBAL'], 'serializer': ['GLOBAL'], 'Collision': ['GLOBAL'], 'close': ['GLOBAL'], 'Scripts': ['GLOBAL'], 'Pkgutil': ['GLOBAL'], 'Performance': ['GLOBAL'], 'Vault': ['GLOBAL'], 'Summaries': ['GLOBAL'], 'logging_setup': ['GLOBAL'], 'console_handler': ['GLOBAL'], 'Ask': ['GLOBAL'], 'Traversal': ['GLOBAL'], 'rules': ['GLOBAL'], 'Underused': ['GLOBAL'], 'cost_per_task': ['GLOBAL'], 'Repositories': ['GLOBAL'], 'Pub': ['GLOBAL'], 'Closer': ['GLOBAL'], 'Higher': ['GLOBAL'], 'Memoization': ['GLOBAL'], 'multiprocessing': ['GLOBAL'], 'OAuth2PasswordBearer': ['GLOBAL'], 'error_str': ['GLOBAL'], 'Processes': ['GLOBAL'], 'Covariant': ['GLOBAL'], 'receiving': ['GLOBAL'], 'Operate': ['GLOBAL'], 'fast_sum': ['GLOBAL'], 'Less': ['GLOBAL'], 'Just': ['GLOBAL'], 'Dispatcher': ['GLOBAL'], 'Blocks': ['GLOBAL'], 'batches': ['GLOBAL'], 'user_service': ['GLOBAL'], 'put_string': ['GLOBAL'], 'pprint': ['GLOBAL'], 'Active': ['GLOBAL'], 'Context': ['GLOBAL'], 'Obj': ['GLOBAL'], 'exc_info': ['GLOBAL'], 'Closure': ['GLOBAL'], 'Complete': ['GLOBAL'], 'width': ['GLOBAL'], 'Guidance': ['GLOBAL'], 'Jython': ['GLOBAL'], '__aenter__': ['GLOBAL'], 'lineterm': ['GLOBAL'], 'Fake': ['GLOBAL'], 'Planner': ['GLOBAL'], 'See': ['GLOBAL'], 'Control': ['GLOBAL'], 'py': ['GLOBAL'], 'correctly': ['GLOBAL'], 'Hot': ['GLOBAL'], 'Fun': ['GLOBAL'], 'test_expensive_operation': ['GLOBAL'], 'max_attempts': ['GLOBAL'], '--disable-gil': ['GLOBAL'], 'Namespaces': ['GLOBAL'], 'Means': ['GLOBAL'], 'factor': ['GLOBAL'], 'Overly': ['GLOBAL'], 'Sent': ['GLOBAL'], 'Executing': ['GLOBAL'], 'hashlib': ['GLOBAL'], 'indented': ['GLOBAL'], 'Eval': ['GLOBAL'], 'Get': ['GLOBAL'], 'console_format': ['GLOBAL'], 'p1': ['GLOBAL'], 'add': ['GLOBAL'], 'Pyright': ['GLOBAL'], 'transform': ['GLOBAL'], 'Powerful': ['GLOBAL'], 'Propagating': ['GLOBAL'], 'typing': ['GLOBAL'], 'Repo': ['GLOBAL'], 'trigger_email': ['GLOBAL'], 'Decimal': ['GLOBAL'], 'orchestrator': ['GLOBAL'], 'imports': ['GLOBAL'], 'Closures': ['GLOBAL'], 'confluent_kafka': ['GLOBAL'], 'slugify': ['GLOBAL'], 'violations': ['GLOBAL'], 'large_text_list': ['GLOBAL'], 'children': ['GLOBAL'], 'Zero': ['GLOBAL'], '_last': ['GLOBAL'], 'Comprehension': ['GLOBAL'], 'format_greeting': ['GLOBAL'], 'Interrupt': ['GLOBAL'], 'Codebase': ['GLOBAL'], 'Recursive': ['GLOBAL'], 'Historical': ['GLOBAL'], 'pid': ['GLOBAL'], 'emit': ['GLOBAL'], 'Definitions': ['GLOBAL'], 'Encrypted': ['GLOBAL'], 'Attrs': ['GLOBAL'], 'Small': ['GLOBAL'], 'State': ['GLOBAL'], 'review_task': ['GLOBAL'], 'Warehouse': ['GLOBAL'], 'newline': ['GLOBAL'], 'test_http': ['GLOBAL'], 'Managed': ['GLOBAL'], 're': ['GLOBAL'], '_validate_and_charge': ['GLOBAL'], 'options': ['GLOBAL'], 'redis': ['GLOBAL'], '_call_llm_with_metrics': ['GLOBAL'], 'Runs': ['GLOBAL'], 'reviewer': ['GLOBAL'], 'nightly': ['GLOBAL'], 'dataclass': ['GLOBAL'], 'Mature': ['GLOBAL'], '_call_llm': ['GLOBAL'], 'Id': ['GLOBAL'], 'Dockerfi': ['GLOBAL'], 'Semgrep': ['GLOBAL'], 'requests': ['GLOBAL'], 'min_value': ['GLOBAL'], 'action_input': ['GLOBAL'], 'Double': ['GLOBAL'], 'Binary': ['GLOBAL'], 'db2': ['GLOBAL'], 'Upload': ['GLOBAL'], 'load_dotenv': ['GLOBAL'], 'Archives': ['GLOBAL'], 'Logic': ['GLOBAL'], 'calling': ['GLOBAL'], 'expression': ['GLOBAL'], 'scratch': ['GLOBAL'], 'stats': ['GLOBAL'], 'create_engine': ['GLOBAL'], 'supporting': ['GLOBAL'], 'Scheduler': ['GLOBAL'], 'passed': ['GLOBAL'], 'Limited': ['GLOBAL'], 'Wraps': ['GLOBAL'], 'Poor': ['GLOBAL'], 'python_path': ['GLOBAL'], 'Three': ['GLOBAL'], 'Supply': ['GLOBAL'], 'qa_chain': ['GLOBAL'], 'dct': ['GLOBAL'], 'Lambda': ['GLOBAL'], 'square_array': ['GLOBAL'], 'Instance': ['GLOBAL'], 'flatten': ['GLOBAL'], 'PyAPI_FUNC': ['GLOBAL'], 'Ecosystem': ['GLOBAL'], 'Databases': ['GLOBAL'], 'cwd': ['GLOBAL'], 'Fixed': ['GLOBAL'], 'Folder': ['GLOBAL'], 'body': ['GLOBAL'], 'plugin': ['GLOBAL'], 'High': ['GLOBAL'], 'Ts': ['GLOBAL'], 'Finder': ['GLOBAL'], 'Ports': ['GLOBAL'], 'email_pattern': ['GLOBAL'], 'Json': ['GLOBAL'], 'Mappings': ['GLOBAL'], 'Installable': ['GLOBAL'], 'Super': ['GLOBAL'], 'shared_event': ['GLOBAL'], 'dd_dict': ['GLOBAL'], 'Actions': ['GLOBAL'], 'Procedural': ['GLOBAL'], 'Bypass': ['GLOBAL'], 'list': ['GLOBAL'], 'Component': ['GLOBAL'], 'encoded': ['GLOBAL'], 'Compatibility': ['GLOBAL'], 'workers': ['GLOBAL'], 'zipfile': ['GLOBAL'], 'load_data': ['GLOBAL'], 'risky_computation': ['GLOBAL'], 'Extremely': ['GLOBAL'], 'Internationalization': ['GLOBAL'], 'Misconception': ['GLOBAL'], 'condition': ['GLOBAL'], 'Sys': ['GLOBAL'], 'names': ['GLOBAL'], 'Organize': ['GLOBAL'], 'tokens_per_task': ['GLOBAL'], 'Point': ['GLOBAL'], 'helper': ['GLOBAL'], 'Animal': ['GLOBAL'], 'Example': ['GLOBAL'], 'text1': ['GLOBAL'], 'Model': ['GLOBAL'], 'currency': ['GLOBAL'], 'crewai': ['GLOBAL'], 'row': ['GLOBAL'], 'product_type': ['GLOBAL'], 'Foundations': ['GLOBAL'], 'Set': ['GLOBAL'], 'Multirepo': ['GLOBAL'], 'Anything': ['GLOBAL'], 'Sorting': ['GLOBAL'], 'Mutating': ['GLOBAL'], 'Qt': ['GLOBAL'], 'shared_list': ['GLOBAL'], 'Broker': ['GLOBAL'], 'modules': ['GLOBAL'], 'Pre': ['GLOBAL'], 'Optimizer': ['GLOBAL'], 'parse_args': ['GLOBAL'], 'Keywords': ['GLOBAL'], 'tokenize': ['GLOBAL'], 'Start': ['GLOBAL'], 'Graceful': ['GLOBAL'], 'Combining': ['GLOBAL'], 'bool': ['GLOBAL'], 'Declared': ['GLOBAL'], 'Monorepo': ['GLOBAL'], 'Normalization': ['GLOBAL'], 'Cons': ['GLOBAL'], 'Reading': ['GLOBAL'], 'subprocess': ['GLOBAL'], 'Watch': ['GLOBAL'], 'database': ['GLOBAL'], 'statements': ['GLOBAL'], 'text': ['GLOBAL'], 'Comprehensive': ['GLOBAL'], 'Load': ['GLOBAL'], 'Operator': ['GLOBAL'], 'done': ['GLOBAL'], 'aiohttp': ['GLOBAL'], 'Measure': ['GLOBAL'], 'Use': ['GLOBAL'], 'app': ['GLOBAL'], 'exclude_lines': ['GLOBAL'], 'Asynchronous': ['GLOBAL'], 'Truffle': ['GLOBAL'], 'Adaptive': ['GLOBAL'], 'Circular': ['GLOBAL'], 'Retries': ['GLOBAL'], 'Equality': ['GLOBAL'], 'Notifier': ['GLOBAL'], 'Found': ['GLOBAL'], 'Disk': ['GLOBAL'], 'AnyUrl': ['GLOBAL'], 'Rego': ['GLOBAL'], 'name': ['GLOBAL'], 'password': ['GLOBAL'], 'int': ['GLOBAL'], 'test_service_calls_repo': ['GLOBAL'], 'formatted': ['GLOBAL'], 'Autogenerate': ['GLOBAL'], 'p2': ['GLOBAL'], 'embedding': ['GLOBAL'], 'Features': ['GLOBAL'], 'create_product': ['GLOBAL'], 'Structlog': ['GLOBAL'], 'scope': ['GLOBAL'], 'Formal': ['GLOBAL'], 'Manipulating': ['GLOBAL'], 'taking': ['GLOBAL'], 'Cancel': ['GLOBAL'], 'Deterministic': ['GLOBAL'], 'read_lines': ['GLOBAL'], 'Smallest': ['GLOBAL'], 'Internal': ['GLOBAL'], 'Lines': ['GLOBAL'], 'users': ['GLOBAL'], 'polars': ['GLOBAL'], 'Raised': ['GLOBAL'], 'ConversationSummaryBufferMemory': ['GLOBAL'], 'str': ['GLOBAL'], 'generate_password': ['GLOBAL'], 'processes': ['GLOBAL'], 'uuid': ['GLOBAL'], 'FileLogger': ['GLOBAL'], 'Spark': ['GLOBAL'], 'Containers': ['GLOBAL'], 'application': ['GLOBAL'], 'Cleaned': ['GLOBAL'], 'Production': ['GLOBAL'], 'Lattice': ['GLOBAL'], 'Catch': ['GLOBAL'], 'Constant': ['GLOBAL'], 'dd_set': ['GLOBAL'], 'server_hostname': ['GLOBAL'], 'complexity': ['GLOBAL'], 'Stub': ['GLOBAL'], 'foo': ['GLOBAL'], 'Pyenv': ['GLOBAL'], 'dd_list': ['GLOBAL'], 'calc': ['GLOBAL'], 'length': ['GLOBAL'], 'snapshot': ['GLOBAL'], 'Ref': ['GLOBAL'], 'BytesIO': ['GLOBAL'], 'test_uppercase': ['GLOBAL'], 'cache_ttl': ['GLOBAL'], 'Entry': ['GLOBAL'], 'Scrip': ['GLOBAL'], 'Adopt': ['GLOBAL'], 'tomorrow': ['GLOBAL'], 'Process': ['GLOBAL'], 'task1': ['GLOBAL'], '__enter__': ['GLOBAL'], 'basename': ['GLOBAL'], 'YAML': ['GLOBAL'], 'handler': ['GLOBAL'], 'Mount': ['GLOBAL'], 'process_log': ['GLOBAL'], 'Rule': ['GLOBAL'], 'hooks': ['GLOBAL'], 'ChatOpenAI': ['GLOBAL'], 'Deep': ['GLOBAL'], 'Print': ['GLOBAL'], 'data': ['GLOBAL'], 'failure': ['GLOBAL'], 'list_items': ['GLOBAL'], 'Ca': ['GLOBAL'], 'Mathematical': ['GLOBAL'], 'Catastrophic': ['GLOBAL'], 'Assuming': ['GLOBAL'], 'Slower': ['GLOBAL'], 'Accessible': ['GLOBAL'], 'Echo': ['GLOBAL'], 'Transformation': ['GLOBAL'], 'Returns': ['GLOBAL'], 'Format': ['GLOBAL'], 'Pyproject': ['GLOBAL'], 'Fixtures': ['GLOBAL'], 'SimpleDirectoryReader': ['GLOBAL'], 'definition': ['GLOBAL'], 'matches': ['GLOBAL'], 'cleaned': ['GLOBAL'], 'Alt': ['GLOBAL'], 'Helpful': ['GLOBAL'], 'Capturing': ['GLOBAL'], 'Tortoise': ['GLOBAL'], 'Triggers': ['GLOBAL'], 'Traversing': ['GLOBAL'], 'Takeaway': ['GLOBAL'], 'Separate': ['GLOBAL'], 'differences': ['GLOBAL'], 'hours': ['GLOBAL'], 'tasks': ['GLOBAL'], 'user': ['GLOBAL'], 'Celery': ['GLOBAL'], 'Queries': ['GLOBAL'], 'Playwright': ['GLOBAL'], 'Blocked': ['GLOBAL'], 'Stored': ['GLOBAL'], 'Agentic': ['GLOBAL'], 'Algorithms': ['GLOBAL'], 'Auto': ['GLOBAL'], 'Functools': ['GLOBAL'], 'Metrics': ['GLOBAL'], 'Rules': ['GLOBAL'], 'file_path': ['GLOBAL'], 'Trust': ['GLOBAL'], 'Agents': ['GLOBAL'], 'Parse': ['GLOBAL'], 'Parenthesized': ['GLOBAL'], 'traceback': ['GLOBAL'], 'Fields': ['GLOBAL'], 'Handles': ['GLOBAL'], 'Multi': ['GLOBAL'], 'Export': ['GLOBAL'], 'Examples': ['GLOBAL'], 'Handling': ['GLOBAL'], 'Summary': ['GLOBAL'], 'Readable': ['GLOBAL'], 'get_user': ['GLOBAL'], 'Boundary': ['GLOBAL'], 'hypothesis': ['GLOBAL'], 'Initialize': ['GLOBAL'], 'Statistical': ['GLOBAL'], 'numpy_vectorized': ['GLOBAL'], 'Distribution': ['GLOBAL'], 'Resource': ['GLOBAL'], 'Hackaday': ['GLOBAL'], 'pydantic': ['GLOBAL'], 'Logs': ['GLOBAL'], 'Topic': ['GLOBAL'], 'debug_print': ['GLOBAL'], 'Tiny': ['GLOBAL'], 'Realistic': ['GLOBAL'], 'apply': ['GLOBAL'], 'httpx': ['GLOBAL'], 'quoting': ['GLOBAL'], 'Isolate': ['GLOBAL'], 'configparser': ['GLOBAL'], 'Ideally': ['GLOBAL'], 'total_ordering': ['GLOBAL'], 'Settings': ['GLOBAL'], 'objects': ['GLOBAL'], 'item_dict': ['GLOBAL'], 'File': ['GLOBAL'], 'Strategy': ['GLOBAL'], 'Enterprise': ['GLOBAL'], 'get_version': ['GLOBAL'], 'Heavy': ['GLOBAL'], 'Determines': ['GLOBAL'], 'Loki': ['GLOBAL'], 'Dashboards': ['GLOBAL'], 'Gunicorn': ['GLOBAL'], 'else': ['GLOBAL'], 'Container': ['GLOBAL'], 'Make': ['GLOBAL'], 'dtype': ['GLOBAL'], 'vectorstore': ['GLOBAL'], 'delta': ['GLOBAL'], 'Pitfalls': ['GLOBAL'], 'file': ['GLOBAL'], 'create_parser': ['GLOBAL'], 'Dependencies': ['GLOBAL'], 'equality': ['GLOBAL'], 'convention': ['GLOBAL'], 'iso_str': ['GLOBAL'], 'decouple': ['GLOBAL'], 'parent': ['GLOBAL'], '_scrape_one': ['GLOBAL'], 'find_spec': ['GLOBAL'], 'Faster': ['GLOBAL'], 'level': ['GLOBAL'], 'tracemalloc': ['GLOBAL'], 'sql': ['GLOBAL'], 'code': ['GLOBAL'], 'metadata': ['GLOBAL'], 'json_str': ['GLOBAL'], 'Hook': ['GLOBAL'], '_py': ['GLOBAL'], 'profile': ['GLOBAL'], 'Safe': ['GLOBAL'], 'Executes': ['GLOBAL'], 'overwhelming': ['GLOBAL'], 'stmt': ['GLOBAL'], 'documents': ['GLOBAL'], 'Gradually': ['GLOBAL'], 'openai': ['GLOBAL'], 'Statistic': ['GLOBAL'], 'dt1': ['GLOBAL'], 'text2': ['GLOBAL'], 'Pythonic': ['GLOBAL'], 'Foundation': ['GLOBAL'], 'Lightweight': ['GLOBAL'], 'locks': ['GLOBAL'], 'Mark': ['GLOBAL'], 'Computational': ['GLOBAL'], 'calculate_tax': ['GLOBAL'], 'Purpose': ['GLOBAL'], 'Assignment': ['GLOBAL'], 'fetch_page': ['GLOBAL'], 'Part': ['GLOBAL'], 'Deduplicating': ['GLOBAL'], 'Porting': ['GLOBAL'], 'pair': ['GLOBAL'], 'Pylance': ['GLOBAL'], 'Router': ['GLOBAL'], 'Introspective': ['GLOBAL'], 'Attributes': ['GLOBAL'], 'compiled_time': ['GLOBAL'], 'Classmethod': ['GLOBAL'], 'parse_int': ['GLOBAL'], 'Number': ['GLOBAL'], 'amount': ['GLOBAL'], 'Bitwise': ['GLOBAL'], 'Authentication': ['GLOBAL'], 'test_result': ['GLOBAL'], 'Adapters': ['GLOBAL'], 'Jobs': ['GLOBAL'], 'Hadoop': ['GLOBAL'], 'SparkSession': ['GLOBAL'], 'schedule_event': ['GLOBAL'], 'use_db': ['GLOBAL'], 'assert_type': ['GLOBAL'], 'Dj': ['GLOBAL'], 'limit': ['GLOBAL'], 'Generics': ['GLOBAL'], 'Best': ['GLOBAL'], 'Need': ['GLOBAL'], 'pattern_compiled': ['GLOBAL'], 'maybe': ['GLOBAL'], 'belonging': ['GLOBAL'], 'operator': ['GLOBAL'], 'Tracemalloc': ['GLOBAL'], 'Searching': ['GLOBAL'], 'agent': ['GLOBAL'], 'setuptools': ['GLOBAL'], 'service': ['GLOBAL'], 'Gauges': ['GLOBAL'], 'Vectorized': ['GLOBAL'], 'email': ['GLOBAL'], 'Argument': ['GLOBAL'], 'Propose': ['GLOBAL'], 'Regex': ['GLOBAL'], 'Replaceable': ['GLOBAL'], 'until': ['GLOBAL'], 'BaseModel': ['GLOBAL'], 'Result': ['GLOBAL'], 'Object': ['GLOBAL'], 'identity': ['GLOBAL'], 'results': ['GLOBAL'], 'Richly': ['GLOBAL'], 'Prerequisites': ['GLOBAL'], 'Configured': ['GLOBAL'], 'Manual': ['GLOBAL'], 'Lost': ['GLOBAL'], 'Extract': ['GLOBAL'], 'prefix': ['GLOBAL'], 'Module': ['GLOBAL'], 'Functional': ['GLOBAL'], 'Cross': ['GLOBAL'], 'Wikipedia': ['GLOBAL'], 'Breakpoints': ['GLOBAL'], 'Arenas': ['GLOBAL'], 'Latin': ['GLOBAL'], 'Legacy': ['GLOBAL'], 'Long': ['GLOBAL'], 'Union': ['GLOBAL'], 'Us': ['GLOBAL'], 'Typing': ['GLOBAL'], 'simplified_task': ['GLOBAL'], 'Modified': ['GLOBAL'], 'omit': ['GLOBAL'], 'test_email_validation': ['GLOBAL'], 'Observer': ['GLOBAL'], 'fromdesc': ['GLOBAL'], 'Debuggers': ['GLOBAL'], '_instance': ['GLOBAL'], 'inc': ['GLOBAL'], 'Writes': ['GLOBAL'], 'fill': ['GLOBAL'], 'Outperform': ['GLOBAL'], 'middleware': ['GLOBAL'], 'Scientific': ['GLOBAL'], 'sys': ['GLOBAL'], '_connect': ['GLOBAL'], 'Tasks': ['GLOBAL'], 'Consta': ['GLOBAL'], 'ChainMap': ['GLOBAL'], 'Intra': ['GLOBAL'], 'title': ['GLOBAL'], 'max_workers': ['GLOBAL'], 'Spawn': ['GLOBAL'], 'Twine': ['GLOBAL'], 'Depends': ['GLOBAL'], 'Semantics': ['GLOBAL'], 'Bob': ['GLOBAL'], 'cache': ['GLOBAL'], 'Exact': ['GLOBAL'], 'Appen': ['GLOBAL'], 'db_host': ['GLOBAL'], 'Retry': ['GLOBAL'], 'system': ['GLOBAL'], 'Specific': ['GLOBAL'], 'arch_result': ['GLOBAL'], 'Missing': ['GLOBAL'], 'Replaced': ['GLOBAL'], 'Injection': ['GLOBAL'], 'load_file': ['GLOBAL'], 'Values': ['GLOBAL'], 'Optimized': ['GLOBAL'], 'Filter': ['GLOBAL'], 'urllib': ['GLOBAL'], 'thread1': ['GLOBAL'], 'False': ['GLOBAL'], 'Bundling': ['GLOBAL'], 'Compression': ['GLOBAL'], 'fib': ['GLOBAL'], 'od': ['GLOBAL'], 'Internals': ['GLOBAL'], 'Pattern': ['GLOBAL'], 'issues': ['GLOBAL'], 'PyObject_HEAD': ['GLOBAL'], 'snapshot1': ['GLOBAL'], 'crewai_tools': ['GLOBAL'], 'Domain': ['GLOBAL'], 'Embedded': ['GLOBAL'], 'Free': ['GLOBAL'], 'Dangerous': ['GLOBAL'], 'Mechanism': ['GLOBAL'], 'check_hostname': ['GLOBAL'], 'token': ['GLOBAL'], 'Consumers': ['GLOBAL'], 'Descriptor': ['GLOBAL'], 'Graph': ['GLOBAL'], 'calls': ['GLOBAL'], 'Bound': ['GLOBAL'], 'New': ['GLOBAL'], 'send': ['GLOBAL'], 'itemgetter': ['GLOBAL'], 'Some': ['GLOBAL'], 'batch_execute': ['GLOBAL'], 'Jupyter': ['GLOBAL'], 'in_2_hours': ['GLOBAL'], 'datefmt': ['GLOBAL'], 'default_factory': ['GLOBAL'], 'Specialized': ['GLOBAL'], 'Medium': ['GLOBAL'], 'Structure': ['GLOBAL'], 'Hash': ['GLOBAL'], 'Logger': ['GLOBAL'], 'Hatch': ['GLOBAL'], 'Pillars': ['GLOBAL'], 'Naive': ['GLOBAL'], 'role': ['GLOBAL'], 'suffix': ['GLOBAL'], 'There': ['GLOBAL'], 'Improves': ['GLOBAL'], 'Encoding': ['GLOBAL'], 'pickled': ['GLOBAL'], 'ProcessPoolExecutor': ['GLOBAL'], 'exist_ok': ['GLOBAL'], 'allocation': ['GLOBAL'], 'config1': ['GLOBAL'], 'zoneinfo': ['GLOBAL'], 'Kibana': ['GLOBAL'], 'Sections': ['GLOBAL'], 'Form': ['GLOBAL'], 'Not': ['GLOBAL'], 'Api': ['GLOBAL'], 'ReActAgent': ['GLOBAL'], 'Pool': ['GLOBAL'], 'weeks': ['GLOBAL'], 'test_with_pytest_mock': ['GLOBAL'], 'gzip': ['GLOBAL'], 'Microservice': ['GLOBAL'], 'Setuptools': ['GLOBAL'], 'unpickled': ['GLOBAL'], 'Imports': ['GLOBAL'], 'doc': ['GLOBAL'], 'Operation': ['GLOBAL'], 'Exception': ['GLOBAL'], 'Baseline': ['GLOBAL'], 'Gang': ['GLOBAL'], 'Pass': ['GLOBAL'], 'SandboxedEnvironment': ['GLOBAL'], 'Reload': ['GLOBAL'], 'Proceed': ['GLOBAL'], 'Operating': ['GLOBAL'], 'failed': ['GLOBAL'], 'list_users': ['GLOBAL'], 'Name': ['GLOBAL'], 'func': ['GLOBAL'], 'Pauses': ['GLOBAL'], 'So': ['GLOBAL'], 'mock_obj': ['GLOBAL'], 'returns': ['GLOBAL'], '_calculate_cache_hit_rate': ['GLOBAL'], 'Dynamic': ['GLOBAL'], 'Optimize': ['GLOBAL'], 'Merging': ['GLOBAL'], 'py_time': ['GLOBAL'], 'Setting': ['GLOBAL'], 'Replacing': ['GLOBAL'], 'Misusing': ['GLOBAL'], 'free': ['GLOBAL'], 'parser_class': ['GLOBAL'], 'Shadowing': ['GLOBAL'], 'Behavioral': ['GLOBAL'], 'Files': ['GLOBAL'], 'context': ['GLOBAL'], 'Appendix': ['GLOBAL'], 'Dependency': ['GLOBAL'], 'numpy': ['GLOBAL'], 'Reproduce': ['GLOBAL'], 'Endpoint': ['GLOBAL'], 'home': ['GLOBAL'], 'Pip': ['GLOBAL'], 'slower': ['GLOBAL'], 'Decorators': ['GLOBAL'], 'Negative': ['GLOBAL'], 'time': ['GLOBAL'], 'process_file': ['GLOBAL'], 'Let': ['GLOBAL'], 'request': ['GLOBAL'], 'Literal': ['GLOBAL'], 'Isolated': ['GLOBAL'], 'get_cost_summary': ['GLOBAL'], 'Via': ['GLOBAL'], 'Source': ['GLOBAL'], 'weakref': ['GLOBAL'], 'Driven': ['GLOBAL'], 'Mega': ['GLOBAL'], 'Explicit': ['GLOBAL'], 'create_user_service': ['GLOBAL'], 'extract': ['GLOBAL'], 'long_text': ['GLOBAL'], 'root': ['GLOBAL'], 'executor': ['GLOBAL'], 'Inter': ['GLOBAL'], 'Tips': ['GLOBAL'], '__dict__': ['GLOBAL'], 'url': ['GLOBAL'], 'parser': ['GLOBAL'], 'Block': ['GLOBAL'], 'router': ['GLOBAL'], 'Item': ['GLOBAL'], 'risky_function': ['GLOBAL'], 'Literals': ['GLOBAL'], 'Except': ['GLOBAL'], 'abstract_method': ['GLOBAL'], 'Secret': ['GLOBAL'], 'Different': ['GLOBAL'], 'Acting': ['GLOBAL'], 'Service': ['GLOBAL'], 'Match': ['GLOBAL'], 'Hypothesis': ['GLOBAL'], 'Nums': ['GLOBAL'], 'Interface': ['GLOBAL'], 'Deadlocks': ['GLOBAL'], 'request_with_backoff': ['GLOBAL'], 'Guice': ['GLOBAL'], 's1': ['GLOBAL'], 'Prevents': ['GLOBAL'], 'Chain': ['GLOBAL'], 'redirect_stdout': ['GLOBAL'], 'dotenv': ['GLOBAL'], 'Hello': ['GLOBAL'], 'Reduced': ['GLOBAL'], 'Disguise': ['GLOBAL'], 'authenticate': ['GLOBAL'], 'declares': ['GLOBAL'], 'result': ['GLOBAL'], 'Completing': ['GLOBAL'], 'response': ['GLOBAL'], 'now': ['GLOBAL'], 'representation': ['GLOBAL'], 'Related': ['GLOBAL'], 'move': ['GLOBAL'], 'Combined': ['GLOBAL'], 'Chapter': ['GLOBAL'], 'qualifies': ['GLOBAL'], 'Migrations': ['GLOBAL'], 'deque': ['GLOBAL'], 'Flow': ['GLOBAL'], 'Singleton': ['GLOBAL'], 'merge': ['GLOBAL'], 'Contains': ['GLOBAL'], 'Direct': ['GLOBAL'], 'pandas': ['GLOBAL'], 'create_async_engine': ['GLOBAL'], 'read_file_tool': ['GLOBAL'], 'Counters': ['GLOBAL'], 'Discovered': ['GLOBAL'], 'generating': ['GLOBAL'], 'search_list': ['GLOBAL'], 'Consistent': ['GLOBAL'], 'Colum': ['GLOBAL'], 'Scheduling': ['GLOBAL'], 'Raw': ['GLOBAL'], '_load_db': ['GLOBAL'], 'list_time': ['GLOBAL'], 'Storable': ['GLOBAL'], 'Envoy': ['GLOBAL'], 'BatchSpanProcessor': ['GLOBAL'], 'Requirements': ['GLOBAL'], 'todesc': ['GLOBAL'], 'Always': ['GLOBAL'], 'Microcontrollers': ['GLOBAL'], 'Post': ['GLOBAL'], 'Absolute': ['GLOBAL'], 'Linker': ['GLOBAL'], 'Also': ['GLOBAL'], 'Encoder': ['GLOBAL'], 'click': ['GLOBAL'], 'cache_key': ['GLOBAL'], 'pwd': ['GLOBAL'], 'prelude': ['GLOBAL'], 'Reducing': ['GLOBAL'], 'Shouldn': ['GLOBAL'], 'Scaling': ['GLOBAL'], 'debug_function': ['GLOBAL'], 'Over': ['GLOBAL'], 'Convention': ['GLOBAL'], 'Working': ['GLOBAL'], 'FastAPI': ['GLOBAL'], 'Str': ['GLOBAL'], '__aexit__': ['GLOBAL'], 'Represents': ['GLOBAL'], 'Async': ['GLOBAL'], 'example_func': ['GLOBAL'], 'Catches': ['GLOBAL'], 'Modern': ['GLOBAL'], 'mock': ['GLOBAL'], 'Google': ['GLOBAL'], 'debugpy': ['GLOBAL'], 'Opposite': ['GLOBAL'], 'pdb': ['GLOBAL'], 'Removing': ['GLOBAL'], 'Traefik': ['GLOBAL'], 'rate_limit': ['GLOBAL'], 'Namespace': ['GLOBAL'], 'age1': ['GLOBAL'], 'file_config': ['GLOBAL'], 'Unbounded': ['GLOBAL'], 'stat': ['GLOBAL'], 'PasswordHasher': ['GLOBAL'], 'Reference': ['GLOBAL'], 'meta_path': ['GLOBAL'], 'fetch_data': ['GLOBAL'], 'arr': ['GLOBAL'], 'Times': ['GLOBAL'], 'given': ['GLOBAL'], 'os': ['GLOBAL'], 'Timeout': ['GLOBAL'], 'futures': ['GLOBAL'], 'Credentials': ['GLOBAL'], 'should_continue': ['GLOBAL'], 'inspect': ['GLOBAL'], 'llm_client': ['GLOBAL'], 'cleanup_node': ['GLOBAL'], 'dirname': ['GLOBAL'], 'ignore': ['GLOBAL'], 'Blue': ['GLOBAL'], 'Quality': ['GLOBAL'], 'Reverse': ['GLOBAL'], 'Marked': ['GLOBAL'], 'tester': ['GLOBAL'], '_handle_tool_error': ['GLOBAL'], 'Dunder': ['GLOBAL'], 'avoidance': ['GLOBAL'], 'Unit': ['GLOBAL'], 'Sc': ['GLOBAL'], 'diff': ['GLOBAL'], 'Because': ['GLOBAL'], 'shlex': ['GLOBAL'], 'other_condition': ['GLOBAL'], 'Maintenance': ['GLOBAL'], 'Signatures': ['GLOBAL'], 'Recommended': ['GLOBAL'], 'Readiness': ['GLOBAL'], 'Quick': ['GLOBAL'], 'string': ['GLOBAL'], 'Logstash': ['GLOBAL'], 'filter_errors': ['GLOBAL'], 'Dictionaries': ['GLOBAL'], 'Understand': ['GLOBAL'], 'xml_str': ['GLOBAL'], 'shutdown_requested': ['GLOBAL'], 'shared_queue': ['GLOBAL'], 'verbose': ['GLOBAL'], 'tiny_task': ['GLOBAL'], 'Principle': ['GLOBAL'], 'top_2': ['GLOBAL'], 'autouse': ['GLOBAL'], 'Factory': ['GLOBAL'], 'Visualization': ['GLOBAL'], 'Includes': ['GLOBAL'], '--enable-experimental-jit': ['GLOBAL'], 'Alice': ['GLOBAL'], 'Productio': ['GLOBAL'], 'review': ['GLOBAL'], 'dt_local': ['GLOBAL'], 'Subprocess': ['GLOBAL'], 'Loader': ['GLOBAL'], 'Polars': ['GLOBAL'], 'dynaconf': ['GLOBAL'], 'compute': ['GLOBAL'], '__lt__': ['GLOBAL'], 'Hierarchical': ['GLOBAL'], 'allocations': ['GLOBAL'], 'Easier': ['GLOBAL'], 'Tokenizer': ['GLOBAL'], 'design': ['GLOBAL'], 'Classic': ['GLOBAL'], 'Preserves': ['GLOBAL'], 'Frontend': ['GLOBAL'], 'analyze_log': ['GLOBAL'], 'params': ['GLOBAL'], 'shared_dict': ['GLOBAL'], 'invariant_no_side_effects': ['GLOBAL'], 'Pandera': ['GLOBAL'], 'Testable': ['GLOBAL'], 'Level': ['GLOBAL'], 'startswith': ['GLOBAL'], 'textwrap': ['GLOBAL'], 'Int': ['GLOBAL'], 'Influenced': ['GLOBAL'], 'Structuring': ['GLOBAL'], 'search_codebase': ['GLOBAL'], 'gdb': ['GLOBAL'], 'Dataclasses': ['GLOBAL'], 'fetch_url': ['GLOBAL'], 'Supporting': ['GLOBAL'], 'ipdb': ['GLOBAL'], 'api_url': ['GLOBAL'], 'Monoliths': ['GLOBAL'], 'Dog': ['GLOBAL'], 'Mutability': ['GLOBAL'], 'run_pipeline': ['GLOBAL'], 'Immutability': ['GLOBAL'], 'SIGINT': ['GLOBAL'], 'metrics': ['GLOBAL'], 'Proper': ['GLOBAL'], 'async_sessionmaker': ['GLOBAL'], 'check': ['GLOBAL'], 'build': ['GLOBAL'], 'Integrate': ['GLOBAL'], 'Handled': ['GLOBAL'], 'fn': ['GLOBAL'], 'Ignoring': ['GLOBAL'], 'Associative': ['GLOBAL'], 'TypeError': ['GLOBAL'], 'Encoded': ['GLOBAL'], 'Cannot': ['GLOBAL'], 'Document': ['GLOBAL'], 'alphabet': ['GLOBAL'], 'stderr': ['GLOBAL'], 'Rebinding': ['GLOBAL'], 'extensions': ['GLOBAL'], 'Test': ['GLOBAL'], 'One': ['GLOBAL'], 'Percent': ['GLOBAL'], 'finders': ['GLOBAL'], 'case': ['GLOBAL'], 'Included': ['GLOBAL'], 'Disassembly': ['GLOBAL'], 'Comparing': ['GLOBAL'], 'Stages': ['GLOBAL'], 'is_int_list': ['GLOBAL'], 'Never': ['GLOBAL'], 'abc': ['GLOBAL'], 'person_encoder': ['GLOBAL'], 'my_ext': ['GLOBAL'], 'Circuit': ['GLOBAL'], 'Package': ['GLOBAL'], 'cpu_task': ['GLOBAL'], 'Clustering': ['GLOBAL'], 'Conditional': ['GLOBAL'], 'overriding': ['GLOBAL'], 'file_format': ['GLOBAL'], 'Property': ['GLOBAL'], 'create_item': ['GLOBAL'], 'server': ['GLOBAL'], 'Teaser': ['GLOBAL'], 'short': ['GLOBAL'], 'Extensions': ['GLOBAL'], 'Prometheus': ['GLOBAL'], 'Install': ['GLOBAL'], 'Tolerances': ['GLOBAL'], 'Decorator': ['GLOBAL'], 'Synonym': ['GLOBAL'], 'Associated': ['GLOBAL'], 'Inspecting': ['GLOBAL'], 'Actual': ['GLOBAL'], 'shared_lock': ['GLOBAL'], 'Helps': ['GLOBAL'], 'Obmalloc': ['GLOBAL'], 'Distributed': ['GLOBAL'], 'Identity': ['GLOBAL'], 'Provider': ['GLOBAL'], 'object_hook': ['GLOBAL'], 'observation': ['GLOBAL'], 'Iterable': ['GLOBAL'], 'save_tasks': ['GLOBAL'], 'Response': ['GLOBAL'], 'Fra': ['GLOBAL'], 'Nonexistent': ['GLOBAL'], 'Slow': ['GLOBAL'], 'sizes': ['GLOBAL'], 'prometheus_client': ['GLOBAL'], 'Hydration': ['GLOBAL'], 's1_norm': ['GLOBAL'], 'pipeline': ['GLOBAL'], 'Built': ['GLOBAL'], 'Requests': ['GLOBAL'], 'Design': ['GLOBAL'], 'Interfacing': ['GLOBAL'], 'chain': ['GLOBAL'], 'Linearization': ['GLOBAL'], 'berlin': ['GLOBAL'], 'target': ['GLOBAL'], 'url_pattern': ['GLOBAL'], 'test_edge_cases': ['GLOBAL'], 'Rust': ['GLOBAL'], 'finally': ['GLOBAL'], 'Users': ['GLOBAL'], 'capture_output': ['GLOBAL'], 'arg': ['GLOBAL'], 'SystemExit': ['GLOBAL'], '_initialized': ['GLOBAL'], 'Pipes': ['GLOBAL'], 'Duck': ['GLOBAL'], 'expected': ['GLOBAL'], 'Servers': ['GLOBAL'], 'Exceptions': ['GLOBAL'], 'Split': ['GLOBAL'], 'spec': ['GLOBAL'], 'repository': ['GLOBAL'], 'Compact': ['GLOBAL'], 'rtype': ['GLOBAL'], 'EllipsisType': ['GLOBAL'], 'Silent': ['GLOBAL'], 'Buggy': ['GLOBAL'], 'matcher': ['GLOBAL'], 'defined': ['GLOBAL'], 'dt_tokyo': ['GLOBAL'], 'Processing': ['GLOBAL'], 'factory': ['GLOBAL'], 'any_box': ['GLOBAL'], 'Indexing': ['GLOBAL'], 'Loop': ['GLOBAL'], 'perf': ['GLOBAL'], 'Overuse': ['GLOBAL'], 'concurrent': ['GLOBAL'], 'get_session': ['GLOBAL'], 'Infra': ['GLOBAL'], 'Core': ['GLOBAL'], 'send_email': ['GLOBAL'], 'review_file': ['GLOBAL'], 'Consumer': ['GLOBAL'], 'Models': ['GLOBAL'], 'age': ['GLOBAL'], 'Appendices': ['GLOBAL'], 'Defines': ['GLOBAL'], 'string_box': ['GLOBAL'], 'urlparse': ['GLOBAL'], 'Preserve': ['GLOBAL'], 'can': ['GLOBAL'], 'Fork': ['GLOBAL'], 'Ray': ['GLOBAL'], 'Invalid': ['GLOBAL'], 'Main': ['GLOBAL'], 'Lookaheads': ['GLOBAL'], 'Shows': ['GLOBAL'], '_think': ['GLOBAL'], 'register_user': ['GLOBAL'], 'Dynamically': ['GLOBAL'], 'Integer': ['GLOBAL'], '_handle_invalid_response': ['GLOBAL'], 'top_stat': ['GLOBAL'], '__doc__': ['GLOBAL'], 'BeautifulSoup': ['GLOBAL'], 'Building': ['GLOBAL'], 'tempfile': ['GLOBAL'], 'urlopen': ['GLOBAL'], 'endswith': ['GLOBAL'], '__new__': ['GLOBAL'], 'Airflow': ['GLOBAL'], 'Certain': ['GLOBAL'], 'Comma': ['GLOBAL'], 'snapshot2': ['GLOBAL'], 'Speed': ['GLOBAL'], 'Fastest': ['GLOBAL'], 'Dicts': ['GLOBAL'], 'Language': ['GLOBAL'], 'Ruff': ['GLOBAL'], 'Typedef': ['GLOBAL'], 'Virtual': ['GLOBAL'], 'Explain': ['GLOBAL'], 'Comprehensions': ['GLOBAL'], 'Financial': ['GLOBAL'], 'tarfile': ['GLOBAL'], 'Coverage': ['GLOBAL'], 'Engine': ['GLOBAL'], 'Perturb': ['GLOBAL'], 'addr': ['GLOBAL'], 'inspector': ['GLOBAL'], 'Happens': ['GLOBAL'], 'thread2': ['GLOBAL'], 'retaining': ['GLOBAL'], 'Malicious': ['GLOBAL'], 'Static': ['GLOBAL'], 'Mocking': ['GLOBAL'], 'Builder': ['GLOBAL'], 'login_user': ['GLOBAL'], 'temperature': ['GLOBAL'], 'np_time': ['GLOBAL'], 'Forgetting': ['GLOBAL'], 'Low': ['GLOBAL'], 'Passable': ['GLOBAL'], 'UserRepository': ['GLOBAL'], 'Simple': ['GLOBAL'], 'Last': ['GLOBAL'], 'write_file': ['GLOBAL'], 'Terms': ['GLOBAL'], 'Weak': ['GLOBAL'], 'Backed': ['GLOBAL'], 'Native': ['GLOBAL'], 'allowed_hosts': ['GLOBAL'], 'Coroutines': ['GLOBAL'], 'Detail': ['GLOBAL'], 'Tokens': ['GLOBAL'], 'cls': ['GLOBAL'], 'Enclosing': ['GLOBAL'], 'retriever': ['GLOBAL'], 'Return': ['GLOBAL'], 'Inheritance': ['GLOBAL'], 'is_active': ['GLOBAL'], 'Serialization': ['GLOBAL'], 'Anti': ['GLOBAL'], 'Two': ['GLOBAL'], 'duckdb': ['GLOBAL'], 'custom_filter': ['GLOBAL'], '_process': ['GLOBAL'], 'Workloads': ['GLOBAL'], 'Redundant': ['GLOBAL'], 'Adapter': ['GLOBAL'], 'double': ['GLOBAL'], 'Scanning': ['GLOBAL'], 'dd_custom': ['GLOBAL'], 'Protobuf': ['GLOBAL'], 'Developer': ['GLOBAL'], 'Iterables': ['GLOBAL'], 'Raise': ['GLOBAL'], 'Possible': ['GLOBAL'], 'Macro': ['GLOBAL'], 'ast': ['GLOBAL'], 'Chapters': ['GLOBAL'], 'numpy_inplace': ['GLOBAL'], 'called': ['GLOBAL'], 'Breadth': ['GLOBAL'], 'invariants': ['GLOBAL'], 'Fewer': ['GLOBAL'], 'Old': ['GLOBAL'], 'defaultdict': ['GLOBAL'], 'Illustrated': ['GLOBAL'], 'f_out': ['GLOBAL'], 'Fixing': ['GLOBAL'], 'Solution': ['GLOBAL'], 'Group': ['GLOBAL'], 'SIGTERM': ['GLOBAL'], 'wrapper': ['GLOBAL'], 'q_list': ['GLOBAL'], 'enum': ['GLOBAL'], 'StreamingStdOutCallbackHandler': ['GLOBAL'], 'Plotkin': ['GLOBAL'], 'disk': ['GLOBAL'], 'Value': ['GLOBAL'], 'dept_users': ['GLOBAL'], 'Prevent': ['GLOBAL'], 'client': ['GLOBAL'], '__next__': ['GLOBAL'], '__call__': ['GLOBAL'], 'Everything': ['GLOBAL'], 'dynamic': ['GLOBAL'], 'settings': ['GLOBAL'], 'rule': ['GLOBAL'], 'Operational': ['GLOBAL'], 'Fetchone': ['GLOBAL'], 'multi_time': ['GLOBAL'], 'Stale': ['GLOBAL'], 'Bandit': ['GLOBAL'], 'keepends': ['GLOBAL'], 'Rapid': ['GLOBAL'], 'test_cases': ['GLOBAL'], 'get_status_message': ['GLOBAL'], 'mapped_column': ['GLOBAL'], 'failing_task': ['GLOBAL'], 'self': ['GLOBAL'], 'lru_cache': ['GLOBAL'], 'result1': ['GLOBAL'], 'trans': ['GLOBAL'], 'Any': ['GLOBAL'], 'regular_points': ['GLOBAL'], 'Protected': ['GLOBAL'], 'Unsafe': ['GLOBAL'], 'Queues': ['GLOBAL'], 'Project': ['GLOBAL'], 'Constructing': ['GLOBAL'], 'process': ['GLOBAL'], 'Identify': ['GLOBAL'], 'Selecting': ['GLOBAL'], '_classify_error': ['GLOBAL'], 'Overusing': ['GLOBAL'], 'Broad': ['GLOBAL'], 'dirs_exist_ok': ['GLOBAL'], 'Prototyping': ['GLOBAL'], 'Ensuring': ['GLOBAL'], 'top_errors': ['GLOBAL'], 'filtered': ['GLOBAL'], 'my_list': ['GLOBAL'], 'Usually': ['GLOBAL'], 'bisect': ['GLOBAL'], 'JSONResponse': ['GLOBAL'], 'signatures': ['GLOBAL'], 'Pipx': ['GLOBAL'], 'Raising': ['GLOBAL'], 'Simpler': ['GLOBAL'], 'error_counts': ['GLOBAL'], 'Beware': ['GLOBAL'], 'Sometimes': ['GLOBAL'], 'heapq': ['GLOBAL'], 'Volatile': ['GLOBAL'], 'Transforming': ['GLOBAL'], '_write_file': ['GLOBAL'], 'days': ['GLOBAL'], 'backoff': ['GLOBAL'], 'Follow': ['GLOBAL'], 'Latency': ['GLOBAL'], 'next_week': ['GLOBAL'], 'split': ['GLOBAL'], 'bound': ['GLOBAL'], 'describes': ['GLOBAL'], 'Security': ['GLOBAL'], 'Including': ['GLOBAL'], 'Tempo': ['GLOBAL'], 'Professional': ['GLOBAL'], 'Docker': ['GLOBAL'], 'Access': ['GLOBAL'], 'total': ['GLOBAL'], 'words': ['GLOBAL'], 'handle': ['GLOBAL'], 'compresslevel': ['GLOBAL'], 'Import': ['GLOBAL'], 'tag': ['GLOBAL'], 'warnings': ['GLOBAL'], 'Tokenization': ['GLOBAL'], 'Generators': ['GLOBAL'], '2GB': ['GLOBAL'], 'Dataframe': ['GLOBAL'], 'Tier': ['GLOBAL'], 'dt_utc': ['GLOBAL'], '__iter__': ['GLOBAL'], 'Spy': ['GLOBAL'], 'Audit': ['GLOBAL'], 'port': ['GLOBAL'], 'Hard': ['GLOBAL'], 'Google-style': ['GLOBAL'], 'Real': ['GLOBAL'], 'Callers': ['GLOBAL'], 'It': ['GLOBAL'], 'print_info': ['GLOBAL'], 'DAG': ['GLOBAL'], 'Typical': ['GLOBAL'], 'Tree': ['GLOBAL'], 'Full': ['GLOBAL'], 'Expressions': ['GLOBAL'], 'Explore': ['GLOBAL'], 'Mutex': ['GLOBAL'], 'HttpClient': ['GLOBAL'], 'Interceptors': ['GLOBAL'], 'find_item': ['GLOBAL'], 'Optimizes': ['GLOBAL'], 'Destruction': ['GLOBAL'], 'Iteration': ['GLOBAL'], 'Backoff': ['GLOBAL'], 'Associating': ['GLOBAL'], 'Mypy': ['GLOBAL'], 'Enforcement': ['GLOBAL'], 'Node': ['GLOBAL'], 'Text': ['GLOBAL'], 'Commands': ['GLOBAL'], 'set_x': ['GLOBAL'], 'AsyncIOScheduler': ['GLOBAL'], 'Kernprof': ['GLOBAL'], 'error_type': ['GLOBAL'], 'Vector': ['GLOBAL'], 'Partially': ['GLOBAL'], '__repr__': ['GLOBAL'], 'Flowchart': ['GLOBAL'], 'Adafruit': ['GLOBAL'], 'Call': ['GLOBAL'], 'Tab': ['GLOBAL'], 'TestClient': ['GLOBAL'], 'Kubernetes': ['GLOBAL'], 'Tool': ['GLOBAL'], 'review_tool': ['GLOBAL'], 'read_large': ['GLOBAL'], 'binding': ['GLOBAL'], 'Locks': ['GLOBAL'], 'Then': ['GLOBAL'], 'distutils': ['GLOBAL'], 'mode': ['GLOBAL'], 'ConversationalRetrievalChain': ['GLOBAL'], 'signal': ['GLOBAL'], 'timezone': ['GLOBAL'], 'Dramatiq': ['GLOBAL'], 'Fully': ['GLOBAL'], 'Reusing': ['GLOBAL'], 'get_value': ['GLOBAL'], 'Scoped': ['GLOBAL'], 'input_file': ['GLOBAL'], 'Pyston': ['GLOBAL'], 'TypeAlias': ['GLOBAL'], 'pragma': ['GLOBAL'], 'end': ['GLOBAL'], 'copy': ['GLOBAL'], 'test_basic_functionality': ['GLOBAL'], 'Vec': ['GLOBAL'], 'Combinatorics': ['GLOBAL'], 'KeyboardInterrupt': ['GLOBAL'], 'Signal': ['GLOBAL'], 'Mod': ['GLOBAL'], 'Introduced': ['GLOBAL'], 'event': ['GLOBAL'], 'first_arg': ['GLOBAL'], 'Applied': ['GLOBAL'], 'Slots': ['GLOBAL'], 'supports': ['GLOBAL'], 'sock': ['GLOBAL'], 'python_loop': ['GLOBAL'], 'Lockfiles': ['GLOBAL'], 'Threading': ['GLOBAL'], 'Assign': ['GLOBAL'], 'Open': ['GLOBAL'], 'decoded': ['GLOBAL'], 'bodies': ['GLOBAL'], 'Log': ['GLOBAL'], 'Technique': ['GLOBAL'], 'Evaluate': ['GLOBAL'], 'lock': ['GLOBAL'], 'Sub': ['GLOBAL'], 'match': ['GLOBAL'], 'Include': ['GLOBAL'], 'env': ['GLOBAL'], 'create_config': ['GLOBAL'], 'Alembic': ['GLOBAL'], 'deco': ['GLOBAL'], 'namedtuple': ['GLOBAL'], 'Generational': ['GLOBAL'], 'Originally': ['GLOBAL'], 'label': ['GLOBAL'], 'Enum': ['GLOBAL'], 'Avoiding': ['GLOBAL'], 'Memory': ['GLOBAL'], 'user_code': ['GLOBAL'], 'stack': ['GLOBAL'], 'Patch': ['GLOBAL'], 'f_in': ['GLOBAL'], 'Four': ['GLOBAL'], 'Bug': ['GLOBAL'], 'Character': ['GLOBAL'], 'Constants': ['GLOBAL'], 'Verbose': ['GLOBAL'], 'asyncpg': ['GLOBAL'], 'Sho': ['GLOBAL'], 'test_add_commutative': ['GLOBAL'], 'get_stream': ['GLOBAL'], 'Connected': ['GLOBAL'], 'opentelemetry': ['GLOBAL'], 'Framework': ['GLOBAL'], 'Efficient': ['GLOBAL'], 'Integrations': ['GLOBAL'], 'left': ['GLOBAL'], 'Autoscaling': ['GLOBAL'], 'Adds': ['GLOBAL'], 'Relevant': ['GLOBAL'], 'startup': ['GLOBAL'], 'Worker': ['GLOBAL'], 'db1': ['GLOBAL'], 'Multiple': ['GLOBAL'], 'backstory': ['GLOBAL'], 'Cron': ['GLOBAL'], 'Linters': ['GLOBAL'], 'bad_increment': ['GLOBAL'], 'Usage': ['GLOBAL'], 'Categories': ['GLOBAL'], 'set': ['GLOBAL'], 'Drivers': ['GLOBAL'], 'Startup': ['GLOBAL'], 'cost': ['GLOBAL'], 'Microservices': ['GLOBAL'], 'Greedy': ['GLOBAL'], 'test_with_context': ['GLOBAL'], 'event_name': ['GLOBAL'], 'load_module': ['GLOBAL'], 'Reasoning': ['GLOBAL'], 'subscribe': ['GLOBAL'], 'tb_str': ['GLOBAL'], 'asyncio': ['GLOBAL'], 'Evaluates': ['GLOBAL'], 'obj_box': ['GLOBAL'], 'Integration': ['GLOBAL'], 'Created': ['GLOBAL'], 'Integrated': ['GLOBAL'], 'Mapped': ['GLOBAL'], 'Sphinx': ['GLOBAL'], 'Application': ['GLOBAL'], 'Neural': ['GLOBAL'], 'aware': ['GLOBAL'], 'test_division_by_zero': ['GLOBAL'], 'inspect_function': ['GLOBAL'], 'Prefers': ['GLOBAL'], 'Predictable': ['GLOBAL'], 'Theoretical': ['GLOBAL'], 'Unless': ['GLOBAL'], 'entry': ['GLOBAL'], 'Alternate': ['GLOBAL'], 'Installed': ['GLOBAL'], 'Role': ['GLOBAL'], 'difflib': ['GLOBAL'], 'distance_from_origin': ['GLOBAL'], 'uncompiled_time': ['GLOBAL'], 'put': ['GLOBAL'], 'csv_to_json': ['GLOBAL'], 'my_decorator': ['GLOBAL'], 'Frozen': ['GLOBAL'], 'preserved': ['GLOBAL'], 'Followed': ['GLOBAL'], 'TypedDict': ['GLOBAL'], 'Passive': ['GLOBAL'], 'Cancellations': ['GLOBAL'], 'Running': ['GLOBAL'], 'shared_semaphore': ['GLOBAL'], 'extra': ['GLOBAL'], 'Ints': ['GLOBAL'], 'Lambdas': ['GLOBAL'], 'Signa': ['GLOBAL'], 'py-spy': ['GLOBAL'], 'numba': ['GLOBAL'], 'Arbitrary': ['GLOBAL'], 'Consumption': ['GLOBAL'], 'Route': ['GLOBAL'], 'Synchronization': ['GLOBAL'], 'Build': ['GLOBAL'], 'Repository': ['GLOBAL'], 'Interactive': ['GLOBAL'], 'Invoice': ['GLOBAL'], 'Provide': ['GLOBAL'], 'functools': ['GLOBAL'], 'delete': ['GLOBAL'], 'shutil': ['GLOBAL'], 'Resolution': ['GLOBAL'], 'Changelog': ['GLOBAL'], 'BINARY_ADD': ['GLOBAL'], 'signal_handler': ['GLOBAL'], 'shell': ['GLOBAL'], 'Black': ['GLOBAL'], 'sqlite': ['GLOBAL'], 'Failure': ['GLOBAL'], 'Parent': ['GLOBAL'], 'Transducer': ['GLOBAL'], 'Docstrings': ['GLOBAL'], 'io': ['GLOBAL'], 'Copy': ['GLOBAL'], 'Timestamp': ['GLOBAL'], 'ConsoleLogger': ['GLOBAL'], 'test_user_creation': ['GLOBAL'], 'Transactions': ['GLOBAL'], 'Counter': ['GLOBAL'], 'Pyjion': ['GLOBAL'], 'Interop': ['GLOBAL'], 'regular_size': ['GLOBAL'], 'Wright': ['GLOBAL'], 'System': ['GLOBAL'], 'tools': ['GLOBAL'], 'Mkvirtualenv': ['GLOBAL'], 'Unpinned': ['GLOBAL'], 'Reusable': ['GLOBAL'], 'lzma': ['GLOBAL'], 'Conflict': ['GLOBAL'], 'UserService': ['GLOBAL'], 'Ad': ['GLOBAL'], 'Buffers': ['GLOBAL'], 'Runner': ['GLOBAL'], 'under': ['GLOBAL'], 'Task': ['GLOBAL'], 'Allocated': ['GLOBAL'], 'window_size': ['GLOBAL'], 'query': ['GLOBAL'], 'Delimiters': ['GLOBAL'], 'Attribute': ['GLOBAL'], 'upper': ['GLOBAL'], 'Schema': ['GLOBAL'], 'Registry': ['GLOBAL'], 'Shallow': ['GLOBAL'], 'Collaborate': ['GLOBAL'], 'Keep': ['GLOBAL'], 'process_payment': ['GLOBAL'], 'Dir': ['GLOBAL'], 'manager': ['GLOBAL'], 'Swallowing': ['GLOBAL'], 'Centralized': ['GLOBAL'], 'Intermediate': ['GLOBAL'], 'Expanding': ['GLOBAL'], 'retry_with_backoff': ['GLOBAL'], 'Curly': ['GLOBAL'], '__getitem__': ['GLOBAL'], 'Monolith': ['GLOBAL'], 'Channel': ['GLOBAL'], 'Avoids': ['GLOBAL'], 'log': ['GLOBAL'], 'Improved': ['GLOBAL'], 'BaseClass': ['GLOBAL'], 'Modify': ['GLOBAL'], 'full_name': ['GLOBAL'], 'bound_method': ['GLOBAL'], 'worker': ['GLOBAL'], '__mro__': ['GLOBAL'], 'NoneType': ['GLOBAL'], 'Catching': ['GLOBAL'], 'Simplifies': ['GLOBAL'], 'cProfile': ['GLOBAL'], 'prompt': ['GLOBAL'], 'list_files_tool': ['GLOBAL'], 'Overengineering': ['GLOBAL'], 'load_config': ['GLOBAL'], 'get_all': ['GLOBAL'], 'Essentials': ['GLOBAL'], 'Selection': ['GLOBAL'], 'Uv': ['GLOBAL'], 'NumPy-style': ['GLOBAL'], 'complex_function': ['GLOBAL'], 'Positional': ['GLOBAL'], 'Kontinuation': ['GLOBAL'], 'Abstract': ['GLOBAL'], 'Work': ['GLOBAL'], 'App': ['GLOBAL'], 'Final': ['GLOBAL'], 'members': ['GLOBAL'], 'Bytecode': ['GLOBAL'], 'writer': ['GLOBAL'], 'glob': ['GLOBAL'], 'file_handler': ['GLOBAL'], 'session': ['GLOBAL'], 'min_size': ['GLOBAL'], 'Scikit': ['GLOBAL'], 'extract_all': ['GLOBAL'], 'Standard': ['GLOBAL'], 'Eps': ['GLOBAL'], 'Unified': ['GLOBAL'], 'versions': ['GLOBAL'], 'temp_name': ['GLOBAL'], 'Automation': ['GLOBAL'], 'Cmd': ['GLOBAL'], 'child_conn': ['GLOBAL'], 'prime': ['GLOBAL'], 'domain': ['GLOBAL'], 'Machine': ['GLOBAL'], 'filled': ['GLOBAL'], 'nullcontext': ['GLOBAL'], 'John': ['GLOBAL'], 'batch_task': ['GLOBAL'], 'random': ['GLOBAL'], 'Tornado': ['GLOBAL'], 'TypeGuard': ['GLOBAL'], 'Ordering': ['GLOBAL'], 'Popen': ['GLOBAL'], 'Fernet': ['GLOBAL'], 'Arrow': ['GLOBAL'], 'pydantic_settings': ['GLOBAL'], 'Validation': ['GLOBAL'], 'Exposing': ['GLOBAL'], 'Expression': ['GLOBAL'], 'Structural': ['GLOBAL'], 'abs_path': ['GLOBAL'], 'dict': ['GLOBAL'], '_execute_primary': ['GLOBAL'], 'Formatting': ['GLOBAL'], 'Backend': ['GLOBAL'], 'np_inplace_time': ['GLOBAL'], 'Map': ['GLOBAL'], 'test_multiply': ['GLOBAL'], 'patch': ['GLOBAL'], '__mul__': ['GLOBAL'], 'numbers': ['GLOBAL'], 'Create': ['GLOBAL'], 'WebSocket': ['GLOBAL'], 'TracerProvider': ['GLOBAL'], 'Pretty': ['GLOBAL'], 'Cha': ['GLOBAL'], 'Template': ['GLOBAL'], 'codebase_tool': ['GLOBAL'], 'non_greedy': ['GLOBAL'], 'test_process': ['GLOBAL'], 'Filtering': ['GLOBAL'], 'Tokenize': ['GLOBAL'], '_handle_generic_error': ['GLOBAL'], '__init__': ['GLOBAL'], 'Lookup': ['GLOBAL'], 'Future': ['GLOBAL'], 'shared_namespace': ['GLOBAL'], 'setup_logging': ['GLOBAL'], 'top_stats': ['GLOBAL'], 'new_root': ['GLOBAL'], '_users': ['GLOBAL'], 's2_norm': ['GLOBAL'], 'Enable': ['GLOBAL'], 'Responsibility': ['GLOBAL'], 'Element': ['GLOBAL'], 'Traces': ['GLOBAL'], 'ZoneInfo': ['GLOBAL'], 'mock_api': ['GLOBAL'], 'Tricks': ['GLOBAL'], 'sum': ['GLOBAL'], 'Sorted': ['GLOBAL'], 'load_secrets': ['GLOBAL'], 'Le': ['GLOBAL'], 'safe_get': ['GLOBAL'], 'wrapped': ['GLOBAL'], 'airflow': ['GLOBAL'], 'Backing': ['GLOBAL'], 'Implemented': ['GLOBAL'], 'Bidirectional': ['GLOBAL'], 'expensive_computation': ['GLOBAL'], 'Tools': ['GLOBAL'], 'Cython': ['GLOBAL'], 'Sound': ['GLOBAL'], 'Show': ['GLOBAL'], 'Copying': ['GLOBAL'], 'Support': ['GLOBAL'], 'Prime': ['GLOBAL'], 'Find': ['GLOBAL'], 'Client': ['GLOBAL'], 'route': ['GLOBAL'], 'Now': ['GLOBAL'], 'Frameworks': ['GLOBAL'], 'Blocking': ['GLOBAL'], 'Slicing': ['GLOBAL'], 'Non': ['GLOBAL'], 'prefect': ['GLOBAL'], 'defaults': ['GLOBAL'], 'xml_declaration': ['GLOBAL'], 'attributes': ['GLOBAL'], 'Numbers': ['GLOBAL'], 'Protects': ['GLOBAL'], 'arcname': ['GLOBAL'], 'draw': ['GLOBAL'], 'Evaluation': ['GLOBAL'], 'Coroutine': ['GLOBAL'], 'Generate': ['GLOBAL'], 'Relational': ['GLOBAL'], 'max_value': ['GLOBAL'], 'Naming': ['GLOBAL'], 'Indentation': ['GLOBAL'], 'Estimated': ['GLOBAL'], 'iterable': ['GLOBAL'], 'Nati': ['GLOBAL'], 'sqlalchemy': ['GLOBAL'], 'Composed': ['GLOBAL'], 'Contravariant': ['GLOBAL'], 'Captured': ['GLOBAL'], 'config': ['GLOBAL'], 'pyo3': ['GLOBAL'], 'Software': ['GLOBAL'], 'celery_app': ['GLOBAL'], 'return_value': ['GLOBAL'], '_save_db': ['GLOBAL'], 'contextlib': ['GLOBAL'], '__get__': ['GLOBAL'], 'Servi': ['GLOBAL'], 'Introduction': ['GLOBAL'], 'setup_tracing': ['GLOBAL'], 'Tabs': ['GLOBAL'], 'ppid': ['GLOBAL'], 'Handler': ['GLOBAL'], 'General': ['GLOBAL'], 'Optimization': ['GLOBAL'], 'Called': ['GLOBAL'], 'Executed': ['GLOBAL'], 'items': ['GLOBAL'], 'Decision': ['GLOBAL'], 'annotations': ['GLOBAL'], 'Improving': ['GLOBAL'], 'Thorough': ['GLOBAL'], 'Measuring': ['GLOBAL'], 'protocol': ['GLOBAL'], 'Stack': ['GLOBAL'], 'read_file': ['GLOBAL'], 'q_deque': ['GLOBAL'], 'user_input': ['GLOBAL'], 'BackgroundTasks': ['GLOBAL'], 'test_reverse_twice_is_identity': ['GLOBAL'], 'Pytest': ['GLOBAL'], 'Buffering': ['GLOBAL'], 'Disable': ['GLOBAL'], 'Polyglot': ['GLOBAL'], 'Unittest': ['GLOBAL'], 'test_api_call': ['GLOBAL'], 'Multiprocessing': ['GLOBAL'], 'Timsort': ['GLOBAL'], 'Public': ['GLOBAL'], 'If': ['GLOBAL'], 'Designed': ['GLOBAL'], 'Vectorization': ['GLOBAL'], 'Accidentally': ['GLOBAL'], 'Unpacking': ['GLOBAL'], '__post_init__': ['GLOBAL'], 'Experiment': ['GLOBAL'], 'Utilities': ['GLOBAL'], 'Trusting': ['GLOBAL'], 'Strings': ['GLOBAL'], 'pattern': ['GLOBAL'], 'Compiled': ['GLOBAL'], 'You': ['GLOBAL'], 'kind': ['GLOBAL'], 'dataclasses': ['GLOBAL'], 'Creat': ['GLOBAL'], '_first': ['GLOBAL'], 'Iterators': ['GLOBAL'], 'Enforcing': ['GLOBAL'], 'Sets': ['GLOBAL'], 'Additional': ['GLOBAL'], 'Policy': ['GLOBAL'], 'NewType': ['GLOBAL'], 'errors': ['GLOBAL'], 'denied': ['GLOBAL'], 'Even': ['GLOBAL'], 'Markup': ['GLOBAL'], 'Asyncpg': ['GLOBAL'], 'Inaccurate': ['GLOBAL'], 'God': ['GLOBAL'], 'Mangum': ['GLOBAL'], 'tmpdir': ['GLOBAL'], '_lock': ['GLOBAL'], 'Instruction': ['GLOBAL'], 'Subclass': ['GLOBAL'], 'connect': ['GLOBAL'], 'RETURN_VALUE': ['GLOBAL'], 'Ingress': ['GLOBAL'], 'Stop': ['GLOBAL'], 'Generates': ['GLOBAL'], 'line': ['GLOBAL'], 'Bare': ['GLOBAL'], 'Producers': ['GLOBAL'], 'count': ['GLOBAL'], 'Costs': ['GLOBAL'], 'Strip': ['GLOBAL'], 'End': ['GLOBAL'], 'Compiler': ['GLOBAL'], 'parts': ['GLOBAL'], 'Circuiting': ['GLOBAL'], 'Skips': ['GLOBAL'], 'Py_DECREF': ['GLOBAL'], 'nb_time': ['GLOBAL'], 'Hi': ['GLOBAL'], 'Per': ['GLOBAL'], '_handle_timeout': ['GLOBAL'], 'create_objects': ['GLOBAL'], 'https': ['GLOBAL'], 'save': ['GLOBAL'], 'Delegates': ['GLOBAL'], 'Collecto': ['GLOBAL'], 'Versioning': ['GLOBAL'], 'Empt': ['GLOBAL'], 'shared_obj': ['GLOBAL'], 'ThreadPoolExecutor': ['GLOBAL'], 'memoize': ['GLOBAL'], 'LOAD_FAST': ['GLOBAL'], 'thread_time': ['GLOBAL'], 'mul': ['GLOBAL'], 'Performed': ['GLOBAL'], 'publishing': ['GLOBAL'], 'Staticmethod': ['GLOBAL'], 'hour': ['GLOBAL'], 'Concurrency': ['GLOBAL'], 'Bypassing': ['GLOBAL'], 'Histogram': ['GLOBAL'], 'Doctrine': ['GLOBAL'], 'color': ['GLOBAL'], 'Ch': ['GLOBAL'], 'Zoneinfo': ['GLOBAL'], 'Spatial': ['GLOBAL'], 'msg': ['GLOBAL'], 'Descriptors': ['GLOBAL'], 'Designing': ['GLOBAL'], '__add__': ['GLOBAL'], 'unbound_method': ['GLOBAL'], 'Compiles': ['GLOBAL'], 'fieldnames': ['GLOBAL'], 'Eliminates': ['GLOBAL'], 'Legend': ['GLOBAL'], 'Basic': ['GLOBAL'], 'tortoise': ['GLOBAL'], 'Custom': ['GLOBAL'], 'test_service': ['GLOBAL'], 'reader': ['GLOBAL'], 'Ops': ['GLOBAL'], 'String': ['GLOBAL'], 'Untyped': ['GLOBAL'], 'Automated': ['GLOBAL'], 'debugging': ['GLOBAL'], 'Type': ['GLOBAL'], 'Modifies': ['GLOBAL'], 'database_transaction': ['GLOBAL'], 'Mapping': ['GLOBAL'], 'create': ['GLOBAL'], 'generate_latest': ['GLOBAL'], 'Resolves': ['GLOBAL'], 'static': ['GLOBAL'], 'memory_repo': ['GLOBAL'], 'Cooperative': ['GLOBAL'], 'Normalize': ['GLOBAL'], 'order': ['GLOBAL'], 'Run': ['GLOBAL'], 'Interoperability': ['GLOBAL'], 'Directory': ['GLOBAL'], 'Term': ['GLOBAL'], 'Initialization': ['GLOBAL'], 'Temporary': ['GLOBAL'], 'Permissions': ['GLOBAL'], 'Invali': ['GLOBAL'], 'secrets': ['GLOBAL'], 'During': ['GLOBAL'], 'secure_sock': ['GLOBAL'], '__set__': ['GLOBAL'], 'Filename': ['GLOBAL'], 'points': ['GLOBAL'], 'default': ['GLOBAL'], 'Parquet': ['GLOBAL'], 'Closing': ['GLOBAL'], 'shared_barrier': ['GLOBAL'], 'Locals': ['GLOBAL'], 'dt2': ['GLOBAL'], 'Beginner': ['GLOBAL'], 'Status': ['GLOBAL'], 'Short': ['GLOBAL'], 'Date': ['GLOBAL'], 'gc': ['GLOBAL'], 'Too': ['GLOBAL'], 'Dask': ['GLOBAL'], 'Prefect': ['GLOBAL'], 'stream': ['GLOBAL'], 'factorial': ['GLOBAL'], 'Numerical': ['GLOBAL'], 'Stacks': ['GLOBAL'], 'pandera': ['GLOBAL'], 'slow_function': ['GLOBAL'], 'Library': ['GLOBAL'], 'Embed': ['GLOBAL'], 'Unpickle': ['GLOBAL'], 'Properties': ['GLOBAL'], 'Microsoft': ['GLOBAL'], 'Remove': ['GLOBAL'], 'Redis': ['GLOBAL'], 'Edition': ['GLOBAL'], 'importlib': ['GLOBAL'], 'Triggered': ['GLOBAL'], '_celsius': ['GLOBAL'], 'load_tasks': ['GLOBAL'], 'Omitted': ['GLOBAL'], 'ConversationBufferMemory': ['GLOBAL'], 'Development': ['GLOBAL'], 'Chaining': ['GLOBAL'], 'logger': ['GLOBAL'], 'get_by_id': ['GLOBAL'], 'user_data': ['GLOBAL'], 'process_items': ['GLOBAL'], 'gen': ['GLOBAL'], 'both': ['GLOBAL'], 'create_user': ['GLOBAL'], 'packed': ['GLOBAL'], 'Inline': ['GLOBAL'], 'Queue': ['GLOBAL'], 'integration': ['GLOBAL'], 'Inside': ['GLOBAL'], 'True': ['GLOBAL'], 'connection': ['GLOBAL'], 'Executor': ['GLOBAL'], 'Falsy': ['GLOBAL'], 'Env': ['GLOBAL'], 'status': ['GLOBAL'], 'Written': ['GLOBAL'], 'llm': ['GLOBAL'], 'fetch_user': ['GLOBAL'], 'Using': ['GLOBAL'], 'Implement': ['GLOBAL'], 'log_level': ['GLOBAL'], 'objtype': ['GLOBAL'], 'Network': ['GLOBAL'], 'Raises': ['GLOBAL'], 'append_to_list': ['GLOBAL'], 'tokens_used': ['GLOBAL'], 'return_messages': ['GLOBAL'], 'main': ['GLOBAL'], 'structlog': ['GLOBAL'], 'Mode': ['GLOBAL'], 'Throughout': ['GLOBAL'], 'Doctest': ['GLOBAL'], 'Generator': ['GLOBAL'], 'yield': ['GLOBAL'], 'Preferred': ['GLOBAL'], 'animal_type': ['GLOBAL'], '_PyEval_EvalFrame': ['GLOBAL'], 'index': ['GLOBAL'], 'Execution': ['GLOBAL'], 'Ahe': ['GLOBAL'], 'Packaging': ['GLOBAL'], 'Reads': ['GLOBAL'], 'counts': ['GLOBAL'], '_create': ['GLOBAL'], 'heavy': ['GLOBAL'], 'dd_int': ['GLOBAL'], 'tokens': ['GLOBAL'], 'person': ['GLOBAL'], 'Captures': ['GLOBAL'], 'cfg': ['GLOBAL'], 'Checking': ['GLOBAL'], 'idx': ['GLOBAL'], 'method': ['GLOBAL'], 'Expose': ['GLOBAL'], 'format': ['GLOBAL'], 'timeit': ['GLOBAL'], 'Sessions': ['GLOBAL'], 'APIRouter': ['GLOBAL'], 'config2': ['GLOBAL'], '__exit__': ['GLOBAL'], 'Inlines': ['GLOBAL'], 'fastapi': ['GLOBAL'], 'same': ['GLOBAL'], 'placeholder': ['GLOBAL'], 'Parameterized': ['GLOBAL'], 'array': ['GLOBAL'], 'slow': ['GLOBAL'], 'memory': ['GLOBAL'], 'Extern': ['GLOBAL'], 'Pickle': ['GLOBAL'], 'suite': ['GLOBAL'], 'CERT_NONE': ['GLOBAL'], 'utc': ['GLOBAL'], 'factorial_cached': ['GLOBAL'], 'Tests': ['GLOBAL'], 'json': ['GLOBAL'], 'Coro': ['GLOBAL'], 'ModuleSpec': ['GLOBAL'], 'Gateway': ['GLOBAL'], 'Message': ['GLOBAL'], 'Refcount': ['GLOBAL'], 'Central': ['GLOBAL'], 'verify_mode': ['GLOBAL'], 'Field': ['GLOBAL'], 'expensive': ['GLOBAL'], 'SessionLocal': ['GLOBAL'], 'Numba': ['GLOBAL'], 'Dockerfiles': ['GLOBAL'], 'Accepts': ['GLOBAL'], 'slots': ['GLOBAL'], 'Exec': ['GLOBAL'], 'Feather': ['GLOBAL'], 'tofile': ['GLOBAL'], 'Metaclass': ['GLOBAL'], 'Composition': ['GLOBAL'], 'Loads': ['GLOBAL'], 'Skipped': ['GLOBAL'], 'combining': ['GLOBAL'], 'Unwinding': ['GLOBAL'], 'multiple': ['GLOBAL'], 'decorators': ['GLOBAL'], 'Narrowing': ['GLOBAL'], 'Add': ['GLOBAL'], 'Takeaways': ['GLOBAL'], 'Transactional': ['GLOBAL'], 'Soft': ['GLOBAL'], 'Password': ['GLOBAL'], 'Robust': ['GLOBAL'], 'Goal': ['GLOBAL'], 'While': ['GLOBAL'], 'run': ['GLOBAL'], 'replacer': ['GLOBAL'], 'charge': ['GLOBAL'], 'error': ['GLOBAL'], 'kwargs': ['GLOBAL'], 'Ability': ['GLOBAL'], 'req': ['GLOBAL'], 'Demonstrates': ['GLOBAL'], 'html_diff': ['GLOBAL'], 'lines': ['GLOBAL'], 'Membership': ['GLOBAL'], '_decide_action': ['GLOBAL'], 'Services': ['GLOBAL'], 'user1': ['GLOBAL'], 'db_session': ['GLOBAL'], 'admin_user': ['GLOBAL'], 'my_function': ['GLOBAL'], 'Strongly': ['GLOBAL'], 'valgrind': ['GLOBAL'], 'First': ['GLOBAL'], 'Request': ['GLOBAL'], 'Elif': ['GLOBAL'], 'Frame': ['GLOBAL'], 'Templating': ['GLOBAL'], 'Note': ['GLOBAL'], 'Before': ['GLOBAL'], 'first': ['GLOBAL'], 'List': ['GLOBAL'], 'Connection': ['GLOBAL'], 'job': ['GLOBAL'], 'Automatic': ['GLOBAL'], 'Unordered': ['GLOBAL'], 'Django': ['GLOBAL'], 'expected_output': ['GLOBAL'], 'Exactly': ['GLOBAL'], 'Mutable': ['GLOBAL'], 'Prevention': ['GLOBAL'], 'append': ['GLOBAL'], 'shutdown': ['GLOBAL'], 'Optimizations': ['GLOBAL'], 'word_count': ['GLOBAL'], 'Datadog': ['GLOBAL'], 'Base': ['GLOBAL'], 'Atomic': ['GLOBAL'], 'Time': ['GLOBAL'], 'Timeouts': ['GLOBAL'], 'Immortal': ['GLOBAL'], 'Variables': ['GLOBAL'], 'Ultra': ['GLOBAL'], 'Placeholder': ['GLOBAL'], 'xz_size': ['GLOBAL'], 'Def': ['GLOBAL'], 'Versus': ['GLOBAL'], 'transaction': ['GLOBAL'], 'success': ['GLOBAL'], 'parse_config': ['GLOBAL'], 'tied': ['GLOBAL'], 'pool': ['GLOBAL'], 'Capture': ['GLOBAL'], 'select': ['GLOBAL'], 'Choosing': ['GLOBAL'], 'http': ['GLOBAL'], 'hello': ['GLOBAL'], 'person_decoder': ['GLOBAL'], 'Based': ['GLOBAL'], 'Huge': ['GLOBAL'], 'sample_user': ['GLOBAL'], 'Critical': ['GLOBAL'], 'Ahead': ['GLOBAL'], 'conn': ['GLOBAL'], 'Append': ['GLOBAL'], 'Packages': ['GLOBAL'], 'correlation_id': ['GLOBAL'], 'Often': ['GLOBAL'], 'safe_json_loads': ['GLOBAL'], 'Debugger': ['GLOBAL'], 'Hexagonal': ['GLOBAL'], 'StreamingResponse': ['GLOBAL'], 'Profiler': ['GLOBAL'], 'minutes': ['GLOBAL'], 'timestamp': ['GLOBAL'], 'Releasing': ['GLOBAL'], 'msgpack': ['GLOBAL'], 'input': ['GLOBAL'], 'Controls': ['GLOBAL'], 'found': ['GLOBAL'], 'dramatiq': ['GLOBAL'], 'Tracer': ['GLOBAL'], 'Globally': ['GLOBAL'], 'NotImplementedType': ['GLOBAL'], 'large_data': ['GLOBAL'], 'Fisher': ['GLOBAL'], 'BaseHTTPMiddleware': ['GLOBAL'], 'Educational': ['GLOBAL'], 'Runtimes': ['GLOBAL'], 'DeclarativeBase': ['GLOBAL'], 'Ordinary': ['GLOBAL'], 'find_user': ['GLOBAL'], 'Tracing': ['GLOBAL'], 'Deploy': ['GLOBAL'], 'run_tests': ['GLOBAL'], 'Relative': ['GLOBAL'], 'Produces': ['GLOBAL'], 'pickle': ['GLOBAL'], 'example': ['GLOBAL'], 'test_with_patch': ['GLOBAL'], 'Layout': ['GLOBAL'], 'Advantages': ['GLOBAL'], 'Dataclass': ['GLOBAL'], 'Dehydration': ['GLOBAL'], 'depth': ['GLOBAL'], 'Felleisen': ['GLOBAL'], '_validate_code': ['GLOBAL'], 'Ctrl': ['GLOBAL'], 'Words': ['GLOBAL'], 'register': ['GLOBAL'], 'ws': ['GLOBAL'], 'Jaeger': ['GLOBAL'], 'PythonOperator': ['GLOBAL'], 'create_animal': ['GLOBAL'], 'Lisp': ['GLOBAL'], 'Py': ['GLOBAL'], 'threshold': ['GLOBAL'], 'test_db': ['GLOBAL'], 'Publishing': ['GLOBAL'], 'override': ['GLOBAL'], 'partial': ['GLOBAL'], 'Tiered': ['GLOBAL'], 'Conda': ['GLOBAL'], 'ssl': ['GLOBAL'], 'Defined': ['GLOBAL'], 'pacific': ['GLOBAL'], 'func_name': ['GLOBAL'], 'single_time': ['GLOBAL'], 'is_str': ['GLOBAL'], 'Ship': ['GLOBAL'], 'Global': ['GLOBAL'], 'Drop': ['GLOBAL'], 'submodule_search_locations': ['GLOBAL'], 'Implicit': ['GLOBAL'], 'Later': ['GLOBAL'], 'Relying': ['GLOBAL'], 'guaranteed': ['GLOBAL'], 'Myapp': ['GLOBAL'], 'They': ['GLOBAL'], 'validate': ['GLOBAL'], 'Libraries': ['GLOBAL'], 'unicodedata': ['GLOBAL'], 'london': ['GLOBAL'], 'Command': ['GLOBAL'], 'napoleon_google_docstring': ['GLOBAL'], 'Debug': ['GLOBAL'], 'Supported': ['GLOBAL'], 'load': ['GLOBAL'], 'Scope': ['GLOBAL'], 'seconds': ['GLOBAL'], 'Program': ['GLOBAL'], 'Fluent': ['GLOBAL'], 'Declares': ['GLOBAL'], 'Understanding': ['GLOBAL'], 'Publish': ['GLOBAL'], 'Clause': ['GLOBAL'], 'add_one': ['GLOBAL'], 'call': ['GLOBAL'], 'item': ['GLOBAL'], 'action': ['GLOBAL'], 'rq': ['GLOBAL'], 'architect': ['GLOBAL'], 'Vectorize': ['GLOBAL'], 'Builtins': ['GLOBAL'], 'Assistants': ['GLOBAL'], 'Top': ['GLOBAL'], 'Injector': ['GLOBAL'], 'Assertion': ['GLOBAL'], 'Inserting': ['GLOBAL'], 'Workflow': ['GLOBAL'], 'Mistakes': ['GLOBAL'], 'Operations': ['GLOBAL'], 'Anonymous': ['GLOBAL'], 'Pro': ['GLOBAL'], 'cli': ['GLOBAL'], 'Sentry': ['GLOBAL'], 'Benefits': ['GLOBAL'], 'shared_arr': ['GLOBAL'], 'Regular': ['GLOBAL'], 'Serialized': ['GLOBAL'], 'threading': ['GLOBAL'], 'Iterator': ['GLOBAL'], 'itertools': ['GLOBAL'], 'create_task': ['GLOBAL'], 'Fraction': ['GLOBAL'], 'Crashes': ['GLOBAL'], '_refactor_code': ['GLOBAL'], 'args_schema': ['GLOBAL'], 'Overview': ['GLOBAL'], 'Hybrid': ['GLOBAL'], 'Column': ['GLOBAL'], 'Token': ['GLOBAL'], 'Urllib': ['GLOBAL'], 'Pools': ['GLOBAL'], 'Futures': ['GLOBAL'], 'each': ['GLOBAL'], 'Secure': ['GLOBAL'], 'Attach': ['GLOBAL'], 'Py_INCREF': ['GLOBAL'], 'Importing': ['GLOBAL'], 'Parameter': ['GLOBAL'], 'subsequent_indent': ['GLOBAL'], 'Deque': ['GLOBAL'], 'Conn': ['GLOBAL'], 'regular': ['GLOBAL'], 'description': ['GLOBAL'], 'Monitoring': ['GLOBAL'], 'start': ['GLOBAL'], 'executing': ['GLOBAL'], 'Server': ['GLOBAL'], 'napoleon_numpy_docstring': ['GLOBAL'], 'make_adder': ['GLOBAL'], 'Correlation': ['GLOBAL'], 'Defaultdict': ['GLOBAL'], 'Offset': ['GLOBAL'], 'Pandas': ['GLOBAL'], 'dependency_injector': ['GLOBAL'], 'using': ['GLOBAL'], 'Other': ['GLOBAL'], 'mutability': ['GLOBAL'], 'Transforms': ['GLOBAL'], 'Optional': ['GLOBAL'], 'Autonomous': ['GLOBAL'], 'Callable': ['GLOBAL'], 'shared': ['GLOBAL'], 'queue': ['GLOBAL'], 'Representation': ['GLOBAL'], 'Database': ['GLOBAL'], 'Collapse': ['GLOBAL'], 'Fallback': ['GLOBAL'], 'c2': ['GLOBAL'], 'Wor': ['GLOBAL'], 'PyObject': ['GLOBAL'], 'Automate': ['GLOBAL'], 'Supports': ['GLOBAL'], 'Comments': ['GLOBAL'], 'Functio': ['GLOBAL'], 'Removes': ['GLOBAL'], 'Read': ['GLOBAL'], 'Yates': ['GLOBAL'], 'Trigger': ['GLOBAL'], 'Self': ['GLOBAL'], '__name__': ['GLOBAL'], 'Loaded': ['GLOBAL'], 'model': ['GLOBAL'], 'Plugin': ['GLOBAL'], 'Given': ['GLOBAL'], '_chunks': ['GLOBAL'], 'markers': ['GLOBAL'], 'divide': ['GLOBAL'], 'industry-standard': ['GLOBAL'], 'username': ['GLOBAL'], 'Deployment': ['GLOBAL'], 'Uses': ['GLOBAL'], 'Cloud': ['GLOBAL'], 'timestamps': ['GLOBAL'], 'animals': ['GLOBAL'], 'history': ['GLOBAL'], 'Want': ['GLOBAL'], 'Parser': ['GLOBAL'], 'Confusing': ['GLOBAL'], 'outer_code': ['GLOBAL'], 'Stateful': ['GLOBAL'], 'id': ['GLOBAL'], 'unit': ['GLOBAL'], 'Independent': ['GLOBAL'], 'Gene': ['GLOBAL'], 'str_box': ['GLOBAL'], 'filter': ['GLOBAL'], 'Dictionary': ['GLOBAL'], 'test_with_mock': ['GLOBAL'], 'Business': ['GLOBAL'], 'burst': ['GLOBAL'], 'Programming': ['GLOBAL'], 'Generated': ['GLOBAL'], 'Great': ['GLOBAL'], 'Syntax': ['GLOBAL'], 'slotted': ['GLOBAL'], 'structure': ['GLOBAL'], 'Optimizing': ['GLOBAL'], 'classical': ['GLOBAL'], 'summarize': ['GLOBAL'], 'Layer': ['GLOBAL'], 'Ensures': ['GLOBAL'], 'Failures': ['GLOBAL'], 'numpy_sum': ['GLOBAL'], 'Intersection': ['GLOBAL'], 'caching': ['GLOBAL'], 'Offloading': ['GLOBAL'], 'test_function': ['GLOBAL'], 'Timezone': ['GLOBAL'], 'load_plugins': ['GLOBAL'], 'inner': ['GLOBAL'], 'Event': ['GLOBAL'], 'Advanced': ['GLOBAL'], 'Converter': ['GLOBAL'], 'Presentation': ['GLOBAL'], 'emails': ['GLOBAL'], 'object': ['GLOBAL'], 'Debugging': ['GLOBAL'], 'output': ['GLOBAL'], 'Extension': ['GLOBAL'], 'Mixing': ['GLOBAL'], 'content': ['GLOBAL'], 'Converting': ['GLOBAL'], 'order_id': ['GLOBAL'], 'Testing': ['GLOBAL'], 'countdown': ['GLOBAL'], 'Minimal': ['GLOBAL'], 'format_exception': ['GLOBAL'], 'Generic': ['GLOBAL'], 'Explicitly': ['GLOBAL'], 'Args': ['GLOBAL'], 'grouped': ['GLOBAL'], 'Don': ['GLOBAL'], 'value': ['GLOBAL'], 'Getitem': ['GLOBAL'], 'access': ['GLOBAL'], 'Unicode': ['GLOBAL'], 'Monkeypatch': ['GLOBAL'], 'Applying': ['GLOBAL'], 'Funcs': ['GLOBAL'], 'refactor_result': ['GLOBAL'], 'log_exception': ['GLOBAL'], 'Managing': ['GLOBAL'], 'lst': ['GLOBAL'], 'env_config': ['GLOBAL'], 'read_all': ['GLOBAL'], 'Stage': ['GLOBAL'], 'Stats': ['GLOBAL'], 'Informal': ['GLOBAL'], 'flow': ['GLOBAL'], 'local_time': ['GLOBAL'], 'returning': ['GLOBAL'], 'Lower': ['GLOBAL'], 'create_app': ['GLOBAL'], 'Drastically': ['GLOBAL'], 'Step': ['GLOBAL'], 'trace': ['GLOBAL'], 'Mutual': ['GLOBAL'], 'maxlen': ['GLOBAL'], 'homepage': ['GLOBAL'], 'AsyncSession': ['GLOBAL'], 'util': ['GLOBAL'], 'Namedtuple': ['GLOBAL'], 'crew': ['GLOBAL'], 'Unify': ['GLOBAL'], 'phones': ['GLOBAL'], 'Lint': ['GLOBAL'], 'Virtualenv': ['GLOBAL'], 'debug': ['GLOBAL'], 'OrderedDict': ['GLOBAL'], 'Await': ['GLOBAL'], 'Callables': ['GLOBAL'], 'Producer': ['GLOBAL'], 'except': ['GLOBAL'], 'Many': ['GLOBAL'], 'External': ['GLOBAL'], 'Profiling': ['GLOBAL'], 'Backends': ['GLOBAL'], 'Session': ['GLOBAL'], 'Fast': ['GLOBAL'], '_generate_code': ['GLOBAL'], 'Below': ['GLOBAL'], 'Scheduled': ['GLOBAL'], 'Individual': ['GLOBAL'], 'pathlib': ['GLOBAL'], 'GeneratorExit': ['GLOBAL'], 'dt': ['GLOBAL'], 'covariant': ['GLOBAL'], 'Profile': ['GLOBAL'], 'Binding': ['GLOBAL'], 'respx': ['GLOBAL'], 'All': ['GLOBAL'], 'Effective': ['GLOBAL'], 'get_user_service': ['GLOBAL'], 'Dirty': ['GLOBAL'], 'Transform': ['GLOBAL'], 'Interfaces': ['GLOBAL'], 'Modifying': ['GLOBAL'], 'References': ['GLOBAL'], 'mock_func': ['GLOBAL'], 'Line': ['GLOBAL'], 'Nginx': ['GLOBAL'], 'Refactor': ['GLOBAL'], 'pytest': ['GLOBAL'], 'We': ['GLOBAL'], 'groups': ['GLOBAL'], 'Closed': ['GLOBAL'], 'Tour': ['GLOBAL'], 'Dropbox': ['GLOBAL'], 'Prefer': ['GLOBAL'], 'on_startup': ['GLOBAL'], 'Matrix': ['GLOBAL'], 'Automatically': ['GLOBAL'], 'render': ['GLOBAL'], 'slotted_points': ['GLOBAL'], 'Unvalidated': ['GLOBAL'], 'Config': ['GLOBAL'], 'dis': ['GLOBAL'], 'initial_indent': ['GLOBAL'], 'Migrating': ['GLOBAL'], 'RetrieverQueryEngine': ['GLOBAL'], 'delimiter': ['GLOBAL'], 'Windows': ['GLOBAL'], 'Empty': ['GLOBAL'], 'Arguments': ['GLOBAL'], 'Lazy': ['GLOBAL'], 'Enforce': ['GLOBAL'], 'retry': ['GLOBAL'], 'Popular': ['GLOBAL'], 'Significance': ['GLOBAL'], 'Generally': ['GLOBAL'], 'obj': ['GLOBAL'], 'Strengths': ['GLOBAL'], 'Bible': ['GLOBAL'], 'bytes': ['GLOBAL'], 'Added': ['GLOBAL'], 'Metaclasses': ['GLOBAL'], 'Required': ['GLOBAL'], 'Scalable': ['GLOBAL'], 'stdin': ['GLOBAL'], 'Differentiate': ['GLOBAL'], 'texts': ['GLOBAL'], 'Batch': ['GLOBAL'], 'Style': ['GLOBAL'], 'Sources': ['GLOBAL'], 'Implementing': ['GLOBAL'], 'Collections': ['GLOBAL'], 'Traditional': ['GLOBAL'], 'request_id': ['GLOBAL'], 'path': ['GLOBAL'], 'Lexer': ['GLOBAL'], 'Filesystem': ['GLOBAL'], 'temp': ['GLOBAL'], 'Dockerfile': ['GLOBAL'], 'fromfile': ['GLOBAL'], 'stdout': ['GLOBAL'], 'Push': ['GLOBAL'], 'try': ['GLOBAL'], 'socket': ['GLOBAL'], 'Background': ['GLOBAL'], 'profile_function': ['GLOBAL'], 'Ctypes': ['GLOBAL'], 'Getattr': ['GLOBAL'], 'Liveness': ['GLOBAL'], 'Batteries': ['GLOBAL'], 'considerations': ['GLOBAL'], 'child': ['GLOBAL'], 'files': ['GLOBAL'], 'worker_id': ['GLOBAL'], 'Render': ['GLOBAL'], 'Signals': ['GLOBAL'], 'Determined': ['GLOBAL'], 'Waiting': ['GLOBAL'], 'numba_sum': ['GLOBAL'], 'uid': ['GLOBAL'], 'test_sum_positive': ['GLOBAL'], 'Batching': ['GLOBAL'], 'Compilation': ['GLOBAL'], 'fetch_html': ['GLOBAL'], 'Index': ['GLOBAL'], 'Histograms': ['GLOBAL'], 'sanitized': ['GLOBAL'], 'test_add': ['GLOBAL'], 'agents': ['GLOBAL'], 'Ipdb': ['GLOBAL'], 'Ensure': ['GLOBAL'], 'Types': ['GLOBAL'], 'Array': ['GLOBAL'], 'Loaders': ['GLOBAL'], 'origin': ['GLOBAL'], 'Testcontainers': ['GLOBAL'], 'outer': ['GLOBAL'], 'Lifecycle': ['GLOBAL'], 'Validators': ['GLOBAL'], 'repo': ['GLOBAL'], 'Functions': ['GLOBAL'], 'Every': ['GLOBAL'], 'operational': ['GLOBAL'], 'Variadic': ['GLOBAL'], 'bs4': ['GLOBAL'], 'Losing': ['GLOBAL'], 'Tracking': ['GLOBAL'], 'Uvicorn': ['GLOBAL'], 'Cache': ['GLOBAL'], 'Shared': ['GLOBAL'], 'Appe': ['GLOBAL'], 'command': ['GLOBAL'], 'Eyeballing': ['GLOBAL'], 'Conventions': ['GLOBAL'], 'Repos': ['GLOBAL'], 'Wheels': ['GLOBAL'], 'search': ['GLOBAL'], 'FastAPIInstrumentor': ['GLOBAL'], 'Class': ['GLOBAL'], 'Linux': ['GLOBAL'], 'result_dict': ['GLOBAL'], 'ignore_errors': ['GLOBAL'], 'Conditionals': ['GLOBAL'], 'Dummy': ['GLOBAL'], 'Algorithm': ['GLOBAL'], 'Pdb': ['GLOBAL'], 'exec_module': ['GLOBAL'], 'Metadata': ['GLOBAL'], 'increment_counter': ['GLOBAL'], 'dateutil': ['GLOBAL'], 'Algorithmic': ['GLOBAL'], 'new_item': ['GLOBAL'], 'repeat': ['GLOBAL'], 'Datetime': ['GLOBAL'], 'Excellent': ['GLOBAL'], 'Httpx': ['GLOBAL'], 'Registries': ['GLOBAL'], 'new_tree': ['GLOBAL'], 'Situation': ['GLOBAL'], 'empty': ['GLOBAL'], 'Perfect': ['GLOBAL'], 'dt_ny': ['GLOBAL'], 'Applications': ['GLOBAL'], 'enclosing': ['GLOBAL'], 'Guards': ['GLOBAL'], 'Entities': ['GLOBAL'], 'Macros': ['GLOBAL'], 'Dedicated': ['GLOBAL'], 'Annotation': ['GLOBAL'], 'parsed': ['GLOBAL'], 'Permission': ['GLOBAL'], 'db_port': ['GLOBAL'], 'Kwargs': ['GLOBAL'], 'new_text': ['GLOBAL'], 'Clean': ['GLOBAL'], 'maxsize': ['GLOBAL'], 'type': ['GLOBAL'], 'attr': ['GLOBAL'], 'Collector': ['GLOBAL'], 'Lexical': ['GLOBAL'], 'Named': ['GLOBAL'], 'argon2': ['GLOBAL'], 'Sort': ['GLOBAL'], 'secure_get': ['GLOBAL'], 'Allocate': ['GLOBAL'], 'Pipeline': ['GLOBAL'], 'Enclosed': ['GLOBAL'], 'Wh': ['GLOBAL'], 'task_queue': ['GLOBAL'], 'Lookbehinds': ['GLOBAL'], 'Lets': ['GLOBAL'], 'Pydantic': ['GLOBAL'], 'Impossible': ['GLOBAL'], 'vs': ['GLOBAL'], 'FunctionTool': ['GLOBAL'], 'deque_time': ['GLOBAL'], 'health': ['GLOBAL'], 'singledispatch': ['GLOBAL'], 'Keyword': ['GLOBAL'], 'process_chunk': ['GLOBAL'], 'Deployments': ['GLOBAL'], 'against': ['GLOBAL'], 'output_file': ['GLOBAL'], 'Configuration': ['GLOBAL'], 'Gradle': ['GLOBAL'], 'cleanup': ['GLOBAL'], 'Unique': ['GLOBAL'], 'box': ['GLOBAL'], 'pattern_str': ['GLOBAL'], 'Threads': ['GLOBAL'], 'slotted_size': ['GLOBAL'], 'Timer': ['GLOBAL'], 's2': ['GLOBAL'], 'Diagrams': ['GLOBAL'], 'Hatchling': ['GLOBAL'], 'Storage': ['GLOBAL'], 'naive': ['GLOBAL'], 'test_api': ['GLOBAL'], 'Easy': ['GLOBAL'], 'full_url': ['GLOBAL'], 'Affects': ['GLOBAL'], 'Annotations': ['GLOBAL'], 'axis': ['GLOBAL'], 'Equivalent': ['GLOBAL'], 'timeout': ['GLOBAL'], 'wrap': ['GLOBAL'], 'Tooling': ['GLOBAL'], 'Callback': ['GLOBAL'], 'Dive': ['GLOBAL'], 'njit': ['GLOBAL'], '_analyze_code': ['GLOBAL'], 'log_file': ['GLOBAL'], 'dt_tz': ['GLOBAL'], 'Authorizing': ['GLOBAL'], 'ext': ['GLOBAL'], '_handler': ['GLOBAL'], 'Error': ['GLOBAL'], 'Mock': ['GLOBAL'], 'Choose': ['GLOBAL'], 'review_code': ['GLOBAL'], 'Dumping': ['GLOBAL'], 'reset_state': ['GLOBAL'], 'Key': ['GLOBAL'], 'addopts': ['GLOBAL'], 'Marshmallow': ['GLOBAL'], 'Variable': ['GLOBAL'], 'Code': ['GLOBAL'], 'definitions': ['GLOBAL'], 'Favor': ['GLOBAL'], 'Df': ['GLOBAL'], 'Signature': ['GLOBAL'], 'base': ['GLOBAL'], 'Fragmentation': ['GLOBAL'], 'Condition': ['GLOBAL'], 'Maven': ['GLOBAL'], 'Replicas': ['GLOBAL'], 'db_path': ['GLOBAL'], 'Scripting': ['GLOBAL'], 'Insecure': ['GLOBAL'], 'safe_join': ['GLOBAL'], 'Cost': ['GLOBAL'], 'Deduplication': ['GLOBAL'], 'Implements': ['GLOBAL'], 'fetch': ['GLOBAL'], 'Influential': ['GLOBAL'], 'NumPy': ['GLOBAL'], 'Move': ['GLOBAL'], 'Bisect': ['GLOBAL'], 'Fut': ['GLOBAL'], 'Mechanics': ['GLOBAL'], 'Jan': ['GLOBAL'], 'other': ['GLOBAL'], 'sqlite3': ['GLOBAL'], 'test_async_function': ['GLOBAL'], 'yaml': ['GLOBAL'], 'speak': ['GLOBAL'], 'adder': ['GLOBAL'], 'Roughly': ['GLOBAL'], 'Concepts': ['GLOBAL'], 'Infinite': ['GLOBAL'], 'OpenAI': ['GLOBAL'], '_PyEval_EvalFrameDefault': ['GLOBAL'], 'Jump': ['GLOBAL'], 'test_query': ['GLOBAL'], 'Function': ['GLOBAL'], 'process_time': ['GLOBAL'], 'query_engine': ['GLOBAL'], 'Groups': ['GLOBAL'], 'Instead': ['GLOBAL'], 'OpenAIEmbeddings': ['GLOBAL'], 'Assert': ['GLOBAL'], 'Write': ['GLOBAL'], 'num_workers': ['GLOBAL'], 'Sandboxing': ['GLOBAL'], 'Big': ['GLOBAL'], '_violates_rule': ['GLOBAL'], 'Unexpected': ['GLOBAL'], 'structured_task': ['GLOBAL'], 'Patterns': ['GLOBAL'], 'Approx': ['GLOBAL'], 'combined_prompt': ['GLOBAL'], 'Names': ['GLOBAL'], 'Mac': ['GLOBAL'], 'Overhead': ['GLOBAL'], 'Microtask': ['GLOBAL'], 'Having': ['GLOBAL'], 'phone_pattern': ['GLOBAL'], 'message': ['GLOBAL'], 'Path': ['GLOBAL'], 'Deprecated': ['GLOBAL'], 'db': ['GLOBAL'], 'execution': ['GLOBAL'], 'Environment': ['GLOBAL'], 'report': ['GLOBAL'], 'Human': ['GLOBAL'], 'without': ['GLOBAL'], 'Architectural': ['GLOBAL'], 'validate_call': ['GLOBAL'], 'Whitespace': ['GLOBAL'], 'Exits': ['GLOBAL'], 'test_create': ['GLOBAL'], 'Protocols': ['GLOBAL'], 'Default': ['GLOBAL'], 'Pin': ['GLOBAL'], 'exc_tb': ['GLOBAL'], 'Middleware': ['GLOBAL'], 'sliding_window': ['GLOBAL'], 'Separates': ['GLOBAL'], 'Single': ['GLOBAL'], 'frames': ['GLOBAL'], 'Private': ['GLOBAL'], 'Delay': ['GLOBAL'], 'publish': ['GLOBAL'], 'Compr': ['GLOBAL'], 'Stopped': ['GLOBAL'], 'python': ['GLOBAL'], 'execute': ['GLOBAL'], 'Data': ['GLOBAL'], 'Broadcasting': ['GLOBAL'], 'cov': ['GLOBAL'], 'AsyncMock': ['GLOBAL'], 'tzinfo': ['GLOBAL'], 'Represent': ['GLOBAL'], 'loaded': ['GLOBAL'], 'urls': ['GLOBAL'], 'OTLPSpanExporter': ['GLOBAL'], 'logged': ['GLOBAL'], 'Preview': ['GLOBAL'], '_extract_function_name': ['GLOBAL'], '__init_subclass__': ['GLOBAL'], 'None': ['GLOBAL'], 'Can': ['GLOBAL'], 'Applicative': ['GLOBAL'], 'Stricter': ['GLOBAL'], 'Chapt': ['GLOBAL'], 'Behavior': ['GLOBAL'], 'estimated_py_time': ['GLOBAL'], 'tuple': ['GLOBAL'], 'Traffic': ['GLOBAL'], 'Race': ['GLOBAL'], 'datetime': ['GLOBAL'], 'Numeric': ['GLOBAL'], 'references': ['GLOBAL'], 'Grafana': ['GLOBAL'], 'Review': ['GLOBAL'], 'Calling': ['GLOBAL'], 'Refer': ['GLOBAL'], 'thought': ['GLOBAL'], 'Remote': ['GLOBAL'], 'status_code': ['GLOBAL'], 'celsius': ['GLOBAL'], 'goal': ['GLOBAL'], 'name1': ['GLOBAL'], 'Runtime': ['GLOBAL'], 'Compress': ['GLOBAL'], 'parents': ['GLOBAL'], 'Grouping': ['GLOBAL'], 'Order': ['GLOBAL'], 'python_sum': ['GLOBAL'], 'Streaming': ['GLOBAL']}

#### Compile Summary

Compilation summary: 16022 blocks, 4076 QA pairs, 122 antipatterns.


---

## Chapter 30 ‚Äî DOCSTRINGS: FORMAL SEMANTICS, STYLES & ENTERPRISE GOVERNANCE üü† Advanced.

### Concepts

#### <!-- SSM:CHUNK_BOUNDARY id="ch30-start" --> üìò CHAPTER 30 ‚Äî DOCSTRINGS: FORMAL SEMANTICS, STYLES & ENTERPRISE GOVERNANCE üü† Advanced.

<!-- SSM:CHUNK_BOUNDARY id="ch30-start" --> üìò CHAPTER 30 ‚Äî DOCSTRINGS: FORMAL SEMANTICS, STYLES & ENTERPRISE GOVERNANCE üü† Advanced

#### Depth Level: 4 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì5, 12, 18.

Depth Level: 4 Python Versions: 3.8‚Äì3.14+ Prerequisites: Chapters 1‚Äì5, 12, 18

#### Docstrings are the foundation of Python documentation and the primary mechanism for describing program behavior, API contracts, and module intent.

Docstrings are the foundation of Python documentation and the primary mechanism for describing program behavior, API contracts, and module intent. They are parsed by the Python runtime, type tools, documentation generators, IDEs, and LLM-based assistants.

#### In this chapter you will learn:.

In this chapter you will learn:

#### # 30.1 Docstrings in Python's Language Model.

# **30.1 Docstrings in Python's Language Model**

#### ## 30.1.1 What Docstrings Are (Formal Definition).

## **30.1.1 What Docstrings Are (Formal Definition)**

#### A docstring is a string literal in the first statement of a module, class, or function.

A docstring is a **string literal** in the first statement of a module, class, or function. Python stores it on the object's `__doc__` attribute.

#### Python exposes docstrings via:.

Python exposes docstrings via:

#### Obj.__doc__ - inspect.getdoc() - help().

- `obj.__doc__` - `inspect.getdoc()` - `help()`

#### ## 30.1.2 Docstring Lifecycle Diagram.

## **30.1.2 Docstring Lifecycle Diagram**

#### When you write a docstring, it becomes immediately available to multiple consumers without any additional processing.

This diagram illustrates how docstrings flow from source code through Python's runtime into various documentation and tooling systems. When you write a docstring, it becomes immediately available to multiple consumers without any additional processing.

#### ## 30.1.3 Docstring Styles (Observed Across Industry).

## **30.1.3 Docstring Styles (Observed Across Industry)**

#### Readable, modern, compatible with Sphinx (via napoleon):.

Readable, modern, compatible with Sphinx (via napoleon):

#### Common in scientific fields:.

Common in scientific fields:

#### Traditional reStructuredText format:.

Traditional reStructuredText format:

#### Style Selection Guidelines:.

**Style Selection Guidelines:**

#### Google-style ‚Äî Default choice for modern Python projects - NumPy-style ‚Äî Scientific computing, data analysis, numerical libraries - Sphinx/RST ‚Äî Le...

- **Google-style** ‚Äî Default choice for modern Python projects - **NumPy-style** ‚Äî Scientific computing, data analysis, numerical libraries - **Sphinx/RST** ‚Äî Legacy codebases, existing projects with established conventions

#### ## 30.1.4 Documenting All Python Constructs.

## **30.1.4 Documenting All Python Constructs**

#### ## 30.1.5 Try This.

## **30.1.5 Try This**

#### A 1-line summary 2.

1. A 1-line summary 2. Attributes section 3. Args/Returns/Raises sections for methods 4. Realistic usage example in the class docstring

#### Verify your docstrings by running:.

Verify your docstrings by running:

#### # 30.2 Enterprise Documentation Governance.

# **30.2 Enterprise Documentation Governance**

#### ## 30.2.1 Style Requirements.

## **30.2.1 Style Requirements**

#### Your Python Bible mandates Google-style docstrings for standard development.

Your Python Bible mandates **Google-style docstrings** for standard development. NumPy style is permitted only for numerical modules where the scientific community expects it.

#### Google-style has excellent IDE support - Sphinx/napoleon provides seamless integration - Most readable for junior developers - Consistent with mode...

- Google-style has excellent IDE support - Sphinx/napoleon provides seamless integration - Most readable for junior developers - Consistent with modern Python ecosystem standards

#### Public modules - Public classes - Public functions/methods - Public module-level constants (when semantically complex).

- Public modules - Public classes - Public functions/methods - Public module-level constants (when semantically complex)

#### Minimum acceptable coverage in CI: 95%.

**Minimum acceptable coverage in CI: 95%**

#### ## 30.2.3 CI Enforcement.

## **30.2.3 CI Enforcement**

#### # 30.3 Advanced Docstring Patterns.

# **30.3 Advanced Docstring Patterns**

#### ## 30.3.1 Documenting Complex Return Types.

## **30.3.1 Documenting Complex Return Types**

#### ## 30.3.2 Documenting Type Variables and Generics.

## **30.3.2 Documenting Type Variables and Generics**

#### ## 30.3.3 Documenting Context Managers.

## **30.3.3 Documenting Context Managers**

#### ## 30.3.4 Documenting Decorators.

## **30.3.4 Documenting Decorators**

#### ## 30.4.3 Security Warnings.

## **30.4.3 Security Warnings**

#### Do not expose internal exceptions in public API docstrings:.

**Do not expose internal exceptions in public API docstrings:**

#### Outdated Docstrings:.

**Outdated Docstrings:**

#### When you refactor code, update docstrings immediately.

When you refactor code, update docstrings immediately. Stale documentation is worse than no documentation.

#### Over-Documentation:

**Over-Documentation:**

#### Don't document the obvious:.

Don't document the obvious:

#### # 30.5 Integration with Development Tools.

# **30.5 Integration with Development Tools**

#### ## 30.5.1 IDE Integration.

## **30.5.1 IDE Integration**

#### Modern IDEs parse docstrings to provide:.

Modern IDEs parse docstrings to provide:

#### Inline documentation tooltips - Parameter hints during function calls - Quick documentation popups - Signature help.

- Inline documentation tooltips - Parameter hints during function calls - Quick documentation popups - Signature help

#### Example: VSCode with Pylance.

**Example: VSCode with Pylance**

#### When you hover over a function call, VSCode displays the docstring in a tooltip, parsed and formatted for readability.

When you hover over a function call, VSCode displays the docstring in a tooltip, parsed and formatted for readability.

#### ## 30.5.2 Sphinx Documentation Generation.

## **30.5.2 Sphinx Documentation Generation**

#### Sphinx Configuration:.

**Sphinx Configuration:**

#### ## 30.5.3 Doctest Integration.

## **30.5.3 Doctest Integration**

#### Running Doctests:.

**Running Doctests:**

#### ## 30.5.4 Type Checker Integration.

## **30.5.4 Type Checker Integration**

#### Type checkers like mypy can validate that docstrings match type hints:.

Type checkers like mypy can validate that docstrings match type hints:

#### # 30.6 Summary & Key Takeaways.

# **30.6 Summary & Key Takeaways**

#### <!-- SSM:CHUNK_BOUNDARY id="ch30-end" -->.

<!-- SSM:CHUNK_BOUNDARY id="ch30-end" -->


---

## Global Content

### Concept

--- title: "Python Bible V3" version: "3.0.0" status: "STABLE" authors: ["VeroField"] target_audience: ["beginner", "intermediate", "advanced", "expert"] python_versions: ["3.10", "3.11", "3.12", "3.13", "3.14"] last_updated: "2025-11-30" ---

### Concept

<!-- SSM:PART id="part1" title="Part I: Foundations" -->

### Concept

# Part I: Foundations

---
