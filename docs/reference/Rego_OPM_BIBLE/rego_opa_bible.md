# The REGO & OPA Bible â€” Ultimate Expanded Edition

**Definitive Guide to the Rego Language and the Open Policy Agent (OPA) Ecosystem**

Version: 2025-11-25 (Expanded)  
Author: Prof. [Your Name], Ph.D.  
Discipline: Computer Engineering, Logic Programming, Declarative Policy Systems

---

## ğŸ“˜ Preface â€” Why This Book Exists

Rego and Open Policy Agent (OPA) are not "just another policy framework." They represent the culmination of 40+ years of declarative programming research, drawing from:

- **Datalog** (1980s) - Logic programming for databases
- **Prolog** (1972) - Logic programming paradigm
- **Relational Calculus** (1970s) - Theoretical foundations
- **Modern Distributed Systems** (2010s+) - Cloud-native architectures

This Bible serves multiple audiences with unprecedented depth:

1. **Beginners** â€” Practical, example-driven explanations with progressive learning
2. **Practitioners** â€” Design patterns, testing strategies, and deployment architectures
3. **Researchers & Architects** â€” Formal semantics, fixpoint models, and enterprise policy theory
4. **Enterprise Engineers** â€” Governance frameworks, multi-tenant patterns, and observability

---

# PART I â€” FOUNDATIONS AND INTRODUCTION

## Chapter 1 â€” Introduction to OPA and Rego

### 1.1 Why Policy as Code?

Modern distributed systems face unprecedented complexity:

- **Microservices Architecture**: 10-1000+ services requiring consistent authorization
- **Zero-Trust Networks**: Every request must be authenticated and authorized
- **Multi-Cloud Deployments**: Policies must work across AWS, Azure, GCP, on-prem
- **Regulatory Compliance**: GDPR, HIPAA, SOC2, PCI-DSS requirements
- **Dynamic Infrastructure**: Kubernetes, service meshes, serverless functions

Traditional approaches fail because:

1. **Hardcoded Logic**: Authorization embedded in application code creates:
   - Inconsistency across services
   - Difficult auditing and compliance
   - Slow policy updates requiring redeployments
   - No centralized visibility

2. **RBAC Limitations**: Role-based access control cannot express:
   - Context-dependent decisions
   - Attribute-based logic
   - Relationship-based access
   - Time-based constraints

3. **Lack of Portability**: Policies tied to specific languages/frameworks

**OPA's Solution**: Externalize policy logic into a declarative language that:
- Runs anywhere (Kubernetes, API gateways, applications, CI/CD)
- Evaluates consistently
- Supports auditing and testing
- Enables policy-as-code workflows

### 1.2 What is OPA?

OPA (Open Policy Agent) is a **general-purpose policy decision engine** that:

**Core Capabilities**:
- Accepts JSON input and data
- Evaluates Rego policies
- Returns structured decision documents
- Supports partial evaluation for optimization
- Provides comprehensive built-in functions
- Enables policy bundling and distribution

**Architecture Model**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Query
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     OPA     â”‚â”€â”€â”€â”€â–¶â”‚ Policies â”‚
â”‚   Engine    â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Decision
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Result    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Integration Points**:

1. **Kubernetes Admission Control**
   - Gatekeeper validates/mutates resources
   - Prevents non-compliant deployments
   - Enforces security policies

2. **API Gateways & Service Meshes**
   - Envoy External Authorization
   - Istio/Linkerd integration
   - Kong/Traefik plugins

3. **CI/CD Pipelines**
   - Infrastructure-as-Code validation
   - Terraform plan analysis
   - Docker image policy enforcement

4. **Application Authorization**
   - Microservices decisions
   - GraphQL field authorization
   - Database query filtering

5. **Cloud Security**
   - AWS IAM policy validation
   - Azure ARM template scanning
   - GCP resource compliance

### 1.3 What is Rego?

Rego is a **declarative logic language** with unique characteristics:

**Theoretical Foundations**:
- **Datalog**: Recursive query language for databases
- **Horn Clauses**: Logical rules with no disjunction in head
- **Closed World Assumption**: What cannot be proven true is false
- **Stratified Negation**: Safe negation without paradoxes

**Design Philosophy**:
```
SQL:  Queries over relational tables
Rego: Queries over hierarchical JSON documents
```

**Key Differences from Procedural Languages**:

| Aspect | Procedural (Python/Java) | Declarative (Rego) |
|--------|-------------------------|-------------------|
| Focus | How to compute | What should be true |
| Execution | Sequential steps | Search-based evaluation |
| Variables | Mutable state | Immutable bindings |
| Control Flow | if/for/while | Logical conjunction/disjunction |
| Side Effects | Common | Prohibited |

**Example Comparison**:

```python
# Python (Procedural)
def is_admin(user):
    if user is None:
        return False
    if 'roles' not in user:
        return False
    for role in user['roles']:
        if role == 'admin':
            return True
    return False
```

```rego
# Rego (Declarative)
is_admin if "admin" in input.user.roles
```

### 1.4 The OPA Ecosystem

**Core Projects**:
- **OPA**: Policy engine (Go, ~50MB binary)
- **Gatekeeper**: Kubernetes-native OPA
- **Conftest**: CLI for testing configs
- **opa-docker-authz**: Docker authorization
- **opa-envoy-plugin**: Envoy integration

**Community Tools**:
- **Regal**: Official Rego linter
- **opa-idea-plugin**: IntelliJ IDEA support
- **vscode-opa**: VS Code extension
- **rego-playground**: Web-based testing

**Cloud Offerings**:
- **Styra DAS**: Enterprise OPA platform
- **Styra Run**: Free tier for developers

---

## Chapter 2 â€” Language Specification

### 2.1 Syntax Overview

A Rego module consists of three components:

```rego
# 1. Package Declaration (required)
package http.authz

# 2. Imports (optional)
import rego.v1
import data.users
import input.request as req

# 3. Rules (policy logic)
default allow := false

allow if {
    input.user.role == "admin"
}

allow if {
    input.method == "GET"
    input.path == "/public"
}
```

**Modern Syntax (OPA 1.0+)**:
- `import rego.v1` enables modern keywords by default
- Keywords: `if`, `in`, `contains`, `every`
- Legacy syntax still supported with `--v0-compatible`

### 2.2 Grammar (Complete EBNF)

```ebnf
module     ::= package { import } policy
package    ::= "package" ref
import     ::= "import" ref [ "as" var ]
policy     ::= { rule }

rule       ::= [ "default" ] rule-name [ rule-key ] [ rule-value ] [ "if" ] rule-body
rule-name  ::= var | ref
rule-key   ::= "[" term "]" | "contains" term
rule-value ::= "=" term | ":=" term
rule-body  ::= "{" query "}" | literal

query      ::= literal { ( ";" | LF ) literal }
literal    ::= ( some-decl | expr | "not" expr ) { with-modifier }
with-modifier ::= "with" term "as" term
some-decl  ::= "some" var { "," var } [ "in" expr ]

expr       ::= term
             | expr infix-operator expr
             | unary-operator expr
             | call-expr
             | "(" expr ")"
             | "every" var [ "," var ] "in" expr "{" query "}"

call-expr  ::= ref "(" [ term { "," term } ] ")"

term       ::= ref | var | scalar | array | object | set
             | array-compr | object-compr | set-compr

array-compr  ::= "[" term "|" query "]"
set-compr    ::= "{" term "|" query "}"
object-compr ::= "{" object-item "|" query "}"

infix-operator ::= ":=" | "=" | "==" | "!=" | "<" | ">" | ">=" | "<="
                 | "+" | "-" | "*" | "/" | "%" | "&" | "|" | "in"

unary-operator ::= "-"

ref      ::= ref-base { ref-arg }
ref-base ::= var | call-expr
ref-arg  ::= "." var | "[" ( scalar | var | array | object | set | "_" ) "]"

var      ::= ( ALPHA | "_" ) { ALPHA | DIGIT | "_" }
scalar   ::= string | NUMBER | TRUE | FALSE | NULL
string   ::= STRING | raw-string
raw-string ::= "`" { CHAR-"`" } "`"

array    ::= "[" [ term { "," term } ] "]"
object   ::= "{" [ object-item { "," object-item } ] "}"
object-item ::= ( scalar | var | ref ) ":" term
set      ::= "{" term { "," term } "}" | "set(" ")"
```

**Reserved Keywords**:
```
as       default   else      every     false
if       import    in        input     not
null     package   some      true      with
data
```

### 2.3 Comments and Formatting

**Comment Styles**:
```rego
# Single-line comment

# Multi-line documentation
# can span several lines
# with consistent indentation

allow if {
    input.user == "admin"  # Inline comment
}
```

**Formatting Tool**:
```bash
# Format all files in directory
opa fmt --write .

# Check formatting (CI)
opa fmt --fail .

# Use Rego v1 syntax
opa fmt --rego-v1 --write .
```
When you should use opa fmt
1. Every time you write or modify Rego
Just like go fmt or black for Python:
â€¢	run opa fmt -w before committing
â€¢	ensures consistent indentation, spacing, rule structure
Use it when:
â€¢	adding new policies
â€¢	editing existing rules
â€¢	refactoring code
â€¢	reviewing a pull request
________________________________________
2. Automatically in CI
Use it in CI to prevent unformatted code from merging.
Why?
â€¢	Prevents style drift
â€¢	Prevents person-to-person formatting debates
â€¢	Keeps code reviews focused on logic, not style
CI check:
opa fmt --diff .
Use it when you want CI to enforce a formatting contract.
________________________________________
3. Before generating OPA bundles or deploying
Formatting helps avoid:
â€¢	unnecessary diff churn
â€¢	unreadable bundle changes
â€¢	merge conflicts caused by spacing differences
Use it when preparing a release or bundle.
________________________________________
4. When onboarding new developers
New devs often write inconsistent Rego.
opa fmt makes their code instantly match the organizationâ€™s style without a learning curve.
Use it during:
â€¢	onboarding
â€¢	training
â€¢	AI code generation reviews
________________________________________
5. After using AI tools (Cursor, ChatGPT, GitHub Copilot, etc.)
AI-generated Rego is usually:
â€¢	valid
â€¢	but not formatted to OPA conventions
You should run opa fmt immediately after AI/model generation.
This is especially true if:
â€¢	you use Prompt Engineering to generate complex Rego
â€¢	Cursor writes policy libraries
â€¢	models generate example data
________________________________________
6. When converting JSON/YAML schemas into Rego
If you auto-generate code (e.g., from OPA schemas), format it afterward so it becomes readable.
________________________________________
7. Anytime code readability matters
Examples:
â€¢	cross-team policy review
â€¢	audits
â€¢	security reviews
â€¢	discussions with legal/compliance teams
â€¢	contract policy negotiations
Formatted policies reduce friction with stakeholders.
________________________________________
ğŸš« When NOT to use it (rare cases)
1. When investigating a bug caused by whitespace or formatting
Almost never happens in Rego, but if you're comparing raw text output or diffing a policy artifact to reproduce an issue, you might avoid opa fmt temporarily.
2. If formatting breaks a handcrafted test snapshot
If you have an exact string match test involving policy source code, formatting will change the file.
But this is extremely rare in real OPA projects.



**Canonical Style**:
- Use tabs for indentation (OPA default)
- 120 character line limit
- Blank line between rules
- Space after `if` keyword
- Consistent spacing around operators

### 2.4 Metadata Annotations

```rego
# METADATA
# title: API Authorization Policy
# description: Controls access to API resources based on user roles
# authors:
# - Security Team <security@example.com>
# organizations:
# - Example Corp
# scope: document
package authz.api

# METADATA
# title: Admin Access Rule
# description: Grants full access to users with admin role
# scope: rule
allow if {
    _is_admin
}
```

**Queryable Metadata**:
```rego
rule_metadata := rego.metadata.rule()
chain_metadata := rego.metadata.chain()
```

---

# PART II â€” CORE LANGUAGE CONCEPTS

## Chapter 3 â€” Core Concepts and Evaluation Model

### 3.1 World Model

OPA operates on a **two-document model**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         OPA Universe            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     input       â”‚     data      â”‚
â”‚  (transient)    â”‚  (persistent) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Request      â”‚  â€¢ Policies   â”‚
â”‚  â€¢ Context      â”‚  â€¢ Config     â”‚
â”‚  â€¢ User info    â”‚  â€¢ Reference  â”‚
â”‚  â€¢ Resource     â”‚  â€¢ Lookup     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Input Document** (`input`):
- Provided per query
- Represents current request/context
- Typically contains:
  - User identity and attributes
  - Resource being accessed
  - Action/operation requested
  - Environmental context (time, location)

**Data Document** (`data`):
- Loaded into OPA at startup or via bundles
- Contains:
  - Policy rules (your Rego code)
  - Static reference data
  - Configuration
  - External data from APIs

**Example Request**:
```json
{
  "input": {
    "user": {
      "id": "alice",
      "role": "developer",
      "department": "engineering"
    },
    "resource": {
      "type": "repository",
      "id": "backend-api",
      "owner": "engineering"
    },
    "action": "push"
  }
}
```

### 3.2 Rules â€” The Building Blocks

Rules are **logical assertions** about your world model.

**Rule Categories**:

1. **Complete Rules**: Define a single value
   ```rego
   max_memory := 32
   user_role := "admin"
   ```

2. **Partial Rules**: Define sets or objects incrementally
   ```rego
   # Partial Set
   valid_users contains user.id if {
       some user in data.users
       user.active == true
   }
   
   # Partial Object
   user_roles[user.id] := user.role if {
       some user in data.users
   }
   ```

3. **Boolean Rules**: Produce true/undefined
   ```rego
   allow if {
       input.user.role == "admin"
   }
   ```

4. **Functions**: Take parameters, return values
   ```rego
   full_name(user) := concat(" ", [user.first, user.last])
   ```

### 3.3 Evaluation Semantics

**Key Principle**: Rego is **declarative, not procedural**

```
Procedural: Execute step-by-step
Declarative: Find all valid solutions
```

**Evaluation Process**:

1. **Parse**: Convert Rego text to AST
2. **Compile**: Build evaluation plan
3. **Ground**: Bind variables systematically
4. **Unify**: Match patterns and values
5. **Search**: Explore all possibilities
6. **Collect**: Gather valid solutions

**Example Evaluation**:
```rego
allow if {
    some role in input.user.roles
    role == "admin"
}
```

**Evaluation Steps**:
1. Access `input.user.roles` (e.g., `["developer", "admin"]`)
2. Iterate: bind `role` to `"developer"`, then `"admin"`
3. Check `role == "admin"` for each binding
4. Return `true` when binding succeeds

**Critical Insight**: Order of expressions is **semantically irrelevant**:
```rego
# These are equivalent
allow if {
    role == "admin"
    some role in input.user.roles
}

allow if {
    some role in input.user.roles
    role == "admin"
}
```

However, performance may differ (covered in Chapter 11).

### 3.4 Undefined vs False

**Critical Distinction**:

```rego
# Returns false explicitly
deny := false if input.user.role != "admin"

# Returns undefined (no rule matches)
deny if input.user.role == "admin"
# When user.role is "developer", deny is undefined, not false
```

**Truth Table**:

| Rule Output | Meaning | Example |
|------------|---------|---------|
| `true` | Explicitly true | `allow := true` |
| `false` | Explicitly false | `allow := false` |
| `undefined` | No rule produced value | No matching rule body |

**Why It Matters**:
```rego
# âŒ Common mistake
allow if not deny  # Broken if deny is undefined

# âœ… Correct
default deny := false
allow if not deny
```

### 3.5 Logical Conjunction and Disjunction

**Conjunction (AND)**: Multiple expressions in one rule body
```rego
allow if {
    expr1  # AND
    expr2  # AND
    expr3  # All must be true
}
```

**Disjunction (OR)**: Multiple rule bodies with same name
```rego
allow if { expr1 }  # OR
allow if { expr2 }  # OR
allow if { expr3 }  # Any can be true
```

**Complex Example**:
```rego
# (admin OR owner) AND active
allow if {
    input.user.role == "admin"
    input.user.active == true
}

allow if {
    input.resource.owner == input.user.id
    input.user.active == true
}
```

### 3.6 Rule Conflicts and Resolution

**Complete Rule Conflicts**:
```rego
# âŒ ERROR: Conflict
max_value := 10 if condition1
max_value := 20 if condition2
# If both conditions true â†’ conflict error
```

**Resolution Strategy**:
```rego
# âœ… Use default + conditional override
default max_value := 10
max_value := 20 if high_priority_user
```

**Partial Rules**: No conflicts, values merge
```rego
# âœ… OK: Set accumulates values (union)
admins contains "alice" if alice_is_admin
admins contains "bob" if bob_is_admin
# Result: {"alice", "bob"} if both true
```

**Critical: Set Union Behavior in Partial Rules**

Multiple rule bodies with the same partial rule name create a **union** for sets and objects, but this only works when each rule body adds distinct elements. For complete rules (single value), multiple bodies create conflicts.

**For Sets (Union Works):**
```rego
# âœ… CORRECT: Each body adds to the set
admins contains "alice" if alice_is_admin
admins contains "bob" if bob_is_admin
# Result: {"alice", "bob"} if both true (union)
```

**For Complete Rules with Sets (Use Comprehensions):**
```rego
# âœ… CORRECT: Single rule with comprehension creates union
_missing_patterns_set(content) := missing_set if {
    missing_set := {
        name |
        some name in ["error_handling", "audit_logging", "structured_logging"]
        not pattern_present(name, content)
    }
}
# This creates a set containing ALL missing patterns

# âŒ WRONG: Multiple complete rules with different set values
_missing_patterns_set(content) := {"error_handling"} if { not error_handling }
_missing_patterns_set(content) := {"audit_logging"} if { not audit_logging }
# Problem: These are complete rules (:=), not partial (contains)
# If both conditions true, you get a conflict or non-deterministic selection
# Only ONE value will be chosen, not a union
```

**Key Insight:** 
- **Partial rules** (`contains`, `[key] := value`): Multiple bodies union automatically
- **Complete rules** (`:= value`): Multiple bodies with different values create conflicts or non-deterministic selection
- **Best Practice:** For building sets from multiple conditions, use a single rule with a comprehension that unions all possibilities

---

## Chapter 4 â€” Variables, References, and Operators

### 4.1 Variables and Unification

**Variable Declaration**:
```rego
# Assignment with :=
x := 42
name := input.user.name

# Variables are immutable within scope
x := 42
x := 43  # âŒ ERROR: Variable x referenced above
```

**Unification with =**:
```rego
# Pattern matching
[first, second] = [1, 2]
# first â†’ 1, second â†’ 2

# Symmetric unification
x = y  # Makes x and y equal

# Complex patterns
{"user": user, "role": role} = input.request
```

**Safety Requirement**:

Variables must be "grounded" (defined) before use in:
- Negated expressions
- Certain built-in function arguments
- Comparisons (when using `==`)

```rego
# âŒ Unsafe
bad_rule if {
    not blacklisted[user]  # user never defined
}

# âœ… Safe
good_rule if {
    user := input.user.id
    not blacklisted[user]
}
```

### 4.2 References â€” Traversing Documents

**Reference Syntax**:
```rego
# Dot notation (for simple keys)
input.user.name
data.roles.admin

# Bracket notation (for complex keys)
input["user"]["name"]
data["user-roles"]["admin-user"]

# Variable keys
users[user_id]
data.permissions[input.user.role]

# Array indices
items[0]
items[i]  # Iteration
items[_]  # All values (underscore = wildcard)
```

**Reference Rules**:

1. Must start with:
   - Variable
   - `input` or `data` (implicitly imported)
   - Function call

2. Cannot start with:
   - Literal arrays: `[1,2,3][0]` âŒ
   - Literal objects: `{"a":1}.a` âŒ
   - Literal sets: `{1,2,3}[0]` âŒ

```rego
# âŒ Invalid reference starts
x := [1, 2, 3][0]
y := {"name": "Alice"}.name

# âœ… Valid: Assign first
arr := [1, 2, 3]
x := arr[0]

obj := {"name": "Alice"}
y := obj.name
```
References & the Data Model

Rego references let you navigate input, data, and local bindings.

4.1 Reference Roots

Valid reference roots:

input â€“ request-scoped data

data â€“ bundle-scoped data (policies + static data)

local variables (from rule heads or := in bodies)

function calls (results assigned to a variable first)

input.user.id
data.config.defaults.timeout
user := input.user
user.profile.email

4.2 What Cannot Start a Reference (Literals vs References)

Regoâ€™s reference grammar requires that a reference start from a reference root, not a literal value.

You cannot start a reference with:

# âŒ Invalid: literals are values, not reference roots
x := [1, 2, 3][0]
y := {"name": "Alice"}.name
z := {1, 2, 3}[0]


The problem is not that indexing literals is conceptually impossible; itâ€™s that in Rego, literals are not references.

You can assign literals to variables and then reference them:

# âœ… Valid: assign literal to variable then index/select
arr := [1, 2, 3]
x := arr[0]

obj := {"name": "Alice"}
y := obj.name

s := {1, 2, 3}
contains_one if 1 in s


Takeaways:

Think of literals as values.

Refs start from input, data, locals, or function results.

Use a local binding when you want to operate on a literal in â€œreference formâ€.

**Deep Traversal**:
```rego
# Multi-level access
sites[i].servers[j].hostname

# With wildcards
all_hostnames := sites[_].servers[_].hostname

# Safe access with default
hostname := input.server.hostname if input.server.hostname
default hostname := "unknown"
```

### 4.3 The `some` Keyword

**Explicit Variable Declaration**:

```rego
# Without 'some' (implicit)
result if {
    sites[i].region == "west"
}

# With 'some' (explicit - recommended)
result if {
    some i
    sites[i].region == "west"
}

# Modern style with 'in'
result if {
    some site in sites
    site.region == "west"
}
```

**Benefits**:
- Makes intent explicit
- Prevents variable capture from outer scope
- Improves readability
- Required for safety in some contexts

**Multiple Variables**:
```rego
result if {
    some i, j
    sites[i].servers[j].name == "web-0"
    hostname := sites[i].servers[j].hostname
}

# Or with 'in'
result if {
    some site in sites
    some server in site.servers
    server.name == "web-0"
}
```

### 4.4 Operators

#### Assignment and Equality

| Operator | Name | Usage | Rebind Allowed? |
|----------|------|-------|-----------------|
| `:=` | Assignment | `x := 10` | No |
| `=` | Unification | `x = y` | Yes (pattern match) |
| `==` | Equality | `x == y` | Yes (comparison) |

**When to Use**:
```rego
# := for clear assignment (preferred)
count := array.length(items)

# = for pattern matching
[first, second] = [1, 2]

# == for comparison
result if count == 5
```

#### Comparison Operators

```rego
x == y   # Equal
x != y   # Not equal
x < y    # Less than
x <= y   # Less than or equal
x > y    # Greater than
x >= y   # Greater than or equal
```

**Type Compatibility**:
```rego
# Same types
1 < 2                    # âœ… true
"a" < "b"                # âœ… true

# Different types
1 < "2"                  # âŒ undefined (not an error)
```

#### Arithmetic Operators

```rego
x + y    # Addition
x - y    # Subtraction
x * y    # Multiplication
x / y    # Division (float result)
x % y    # Modulo (remainder)
```

**Examples**:
```rego
sum := 10 + 5        # 15
diff := 10 - 5       # 5
product := 10 * 5    # 50
quotient := 10 / 5   # 2 (float)
remainder := 10 % 3  # 1
```

#### Bitwise Operators

```rego
x & y    # Bitwise AND
x | y    # Bitwise OR
```

**Use Cases**:
```rego
# Permission bits
read_bit := 1
write_bit := 2
execute_bit := 4

has_write := (permissions & write_bit) != 0
```

#### Membership: The `in` Operator

**Dual Purpose**: Membership testing AND iteration

```rego
# Membership testing (returns boolean)
"admin" in user.roles                 # true/false
3 in [1, 2, 3]                        # true
"key" in {"key": "value"}             # true (checks keys in objects)

# Iteration (with 'some')
some role in user.roles
some i, item in items                 # index and value
some key, value in object             # key and value

# Negation
not "admin" in user.roles
```

**Array Iteration**:
```rego
# Values only
some item in [1, 2, 3]

# Index and value
some i, item in [1, 2, 3]
# Binds: i=0, item=1; then i=1, item=2; etc.
```

**Object Iteration**:
```rego
# Values only
some val in {"a": 1, "b": 2}

# Key and value
some key, val in {"a": 1, "b": 2}
```

**Set Iteration**:
```rego
# Members
some member in {1, 2, 3}
```

---

## Chapter 5 â€” Control Flow and Iteration

### 5.1 Logical Conjunction (AND)

**Multiple expressions in a rule body**:
```rego
allow if {
    input.user.role == "admin"       # Must be true AND
    input.user.active == true         # Must be true AND
    input.resource.sensitive == false # Must be true
}
```

**Evaluation**: All expressions must evaluate to `true`.

### 5.2 Logical Disjunction (OR)

**Multiple rule bodies**:
```rego
allow if {
    input.user.role == "admin"
}

allow if {
    input.action == "read"
    input.resource.public == true
}
```

**Evaluation**: Any rule body can make `allow` true.

### 5.3 Comprehensions

**Array Comprehensions**:
```rego
# Format: [ <term> | <query> ]

# Simple transformation
squares := [x * x | some x in numbers]

# With filtering
evens := [x | some x in numbers; x % 2 == 0]

# Complex example
admin_emails := [user.email |
    some user in data.users
    "admin" in user.roles
    user.active == true
]

# Nested iteration
pairs := [[x, y] |
    some x in [1, 2, 3]
    some y in ["a", "b", "c"]
]
# Result: [[1, "a"], [1, "b"], [1, "c"], [2, "a"], ...]
```

**Set Comprehensions**:
```rego
# Format: { <term> | <query> }

# Remove duplicates
unique := {x | some x in items}

# Extract unique properties
departments := {user.dept | some user in users}

# Complex filtering
valid_ips := {addr |
    some addr in input.addresses
    net.cidr_contains("10.0.0.0/8", addr)
}
```

**Object Comprehensions**:
```rego
# Format: { <key>: <value> | <query> }

# Create mapping
name_to_age := {person.name: person.age |
    some person in people
}

# With transformation
doubled := {k: v * 2 |
    some k, v in original
}

# Aggregation
user_counts := {dept: count |
    some dept in departments
    users_in_dept := [u | some u in users; u.dept == dept]
    count := array.length(users_in_dept)
}
```

### 5.4 Universal Quantification (FOR ALL)

**Three Approaches**:

#### 1. Using `every` (Modern, Recommended)

```rego
# All items must satisfy condition
all_approved if {
    every item in items {
        item.status == "approved"
    }
}

# With index
all_valid if {
    every i, item in items {
        item.id == i
        item.valid == true
    }
}

# Multiple conditions
all_healthy if {
    every server in servers {
        server.status == "up"
        server.cpu < 80
        server.memory < 90
    }
}
```

#### 2. Using Negation (Helper Pattern)

```rego
all_valid if not any_invalid

any_invalid if {
    some item in items
    item.status != "approved"
}
```

#### 3. Using Comprehensions

```rego
all_approved if {
    approved := {i | some i in items; i.status == "approved"}
    count(approved) == count(items)
}

# Or check for violations
all_valid if {
    violations := {i | some i in items; i.status != "valid"}
    count(violations) == 0
}
```

### 5.5 Negation

**Negation-as-Failure Semantics**:

```rego
# Simple negation
unauthorized if not authorized

# Negation with expressions
invalid if not startswith(input.name, "valid_")

# Check non-membership
not_admin if not "admin" in input.user.roles
```

**Safety Requirements**:

```rego
# âŒ Unsafe: user not grounded
unsafe if {
    not blacklisted[user]
}

# âœ… Safe: user grounded first
safe if {
    user := input.user.id
    not blacklisted[user]
}
```

**Common Pitfall â€” Existential vs Universal**:

```rego
# âŒ WRONG: "Is there any element != 'foo'?"
# This is true if ANY element is not "foo"
has_non_foo if {
    items[_] != "foo"  # Existential quantification
}

# âœ… CORRECT: "Is 'foo' not in array?"
foo_not_present if {
    not "foo" in items
}

# âœ… CORRECT: "Are all elements not foo?"
all_non_foo if not any_foo

any_foo if {
    some item in items
    item == "foo"
}
```

---

6.2 Built-in Function Categories (Overview)

For orientation, here is the taxonomy weâ€™ll use in this chapter:

Aggregates: count, sum, product, min, max, sort, all, any

Arrays: array.concat, array.slice, array.reverse, array.sort, array.filter

Sets & Set-like operations: union, intersection, set_diff, minus, distinct, to_set

Objects & JSON paths: object.get, object.remove, object.union, object.filter, json.filter

Strings: concat, contains, startswith, endswith, indexof, lower, upper, replace, split, sprintf, substring, trim* family

Regular Expressions: regex.is_valid, regex.match, regex.find_n, regex.split

Numbers & Numeric Utilities: abs, ceil, floor, round, numbers.range, comparisons

Type Conversion & Validation: to_number, to_string, to_set, to_array, to_object, cast_*, json.is_valid, yaml.is_valid

Encoding/Decoding & Serialization: base64.*, base64url.*, hex.*, json.marshal/unmarshal, yaml.marshal/unmarshal, urlquery.*

Type Introspection: is_array, is_boolean, is_null, is_number, is_object, is_set, is_string, type_name

Cryptography & Security: crypto.* hashes, HMAC, PBKDF, bcrypt, JWT (io.jwt.*), crypto.x509.*

Time & Temporal Logic: time.now_ns, time.parse_*, time.date, time.clock, time.weekday, diffs

HTTP & I/O: http.send for outbound HTTP calls

Network & CIDR: net.cidr_contains, net.cidr_expand, net.cidr_intersects, net.cidr_merge

UUID/ULID: uuid.*, ulid.generate

Graph & Structural Walks: graph.reachable, walk

Units: units.parse, units.parse_bytes

Metadata & Introspection: rego.metadata.rule, rego.metadata.chain

Debugging: print, trace

Error Semantics: Strict vs non-strict behavior

Weâ€™ll now go category by category, with semantics, examples, and pitfalls.

6.3 Aggregates

Purpose: Reduce collections to scalars (counts, sums, min/max, logical AND/OR).

Key built-ins:

count(x)            # length of array, set, or string
sum(array)          # numeric sum of array elements
product(array)      # numeric product
max(array)          # maximum element
min(array)          # minimum element
sort(array)         # sorted copy (ascending)
all(array_bool)     # AND over boolean array
any(array_bool)     # OR over boolean array


Examples:

# Count API keys
api_key_count := count(input.api_keys)

# Any admin users?
has_admin if {
    any([role == "admin" | some role in input.user.roles])
}

# All servers must be healthy
all_healthy if {
    all([s.healthy | some s in input.servers])
}


Typing & Errors:

sum, product, max, min require arrays of numbers; mixing types â†’ expression undefined.

count accepts arrays, sets, strings:

count("abc")  # 3
count({"a", "b"})  # 2


Pattern: Use count for guardrails:

deny[msg] if {
    count(input.changed_files) > 100
    msg := "PR changes too many files"
}

6.4 Arrays

Arrays are ordered; built-ins treat them as such.

Key built-ins:

array.concat(a, b)         # [a..., b...]
array.slice(a, start, end) # a[start:end], end-exclusive
array.reverse(a)           # reversed copy


Examples:

# Pagination utilities
page(slice_start, slice_len) := array.slice(input.results, slice_start, slice_start+slice_len)

# Compose routes
full_path := concat("/", ["api", input.version, "users", input.user_id])
reversed := array.reverse([1, 2, 3])  # [3, 2, 1]


Indexing vs slicing:

OPA has no direct a[1:3] slicing syntax; use array.slice.

Out-of-range indices â†’ expression undefined.

6.5 Sets and Set-like Operations

Rego sets are unordered, unique collections.

Key built-ins:

intersection(s1, s2)      # {x | x in s1 âˆ§ x in s2}
union(s1, s2)             # {x | x in s1 âˆ¨ x in s2}
set_diff(s1, s2)          # {x | x in s1 âˆ§ x âˆ‰ s2}
to_set(array)             # convert array to set


Example:

allowed_regions := {"us-east-1", "us-west-2"}
requested_regions := to_set(input.regions)

invalid_regions := set_diff(requested_regions, allowed_regions)

deny[msg] if {
    invalid_regions != set()
    msg := sprintf("Invalid regions: %v", [invalid_regions])
}


Performance pattern: Prefer sets for membership:

# Fast: O(1)
admin_users := {"alice", "bob"}
allow if input.user in admin_users

# Slower: O(n)
admin_list := ["alice", "bob"]
allow if input.user in admin_list

6.6 Objects & JSON Path Helpers

Objects represent mappings from scalar keys to arbitrary values.

Key built-ins:

object.get(obj, key, default)       # obj[key] or default
object.remove(obj, keys_array)      # remove listed keys
object.union(o1, o2)                # merge, o2 wins on conflict
object.filter(obj, keys_array)      # keep only listed keys
json.filter(obj, paths_array)       # filter by JSON paths (e.g., "a/b/c")


Examples:

# Defensive access with default
timeout_ms := object.get(input.config, "timeout_ms", 1000)

# Drop sensitive keys before logging
sanitized := object.remove(input.request, ["password", "token", "secret"])

# Only retain whitelisted fields
log_payload := object.filter(input.request, ["method", "path", "user.id"])

# Filter by paths
log_payload2 := json.filter(input.request, ["user/id", "request/path"])


Patterns:

Use object.get instead of chaining if input.config.timeout_ms checks everywhere.

Use object.remove before logging to avoid PII leaks.

6.6 JSON Filter (json.filter)

json.filter allows you to keep only selected fields from a JSON object.

Signature (conceptual):

json.filter(obj, paths_array)  # paths_array: array of slash-delimited strings


Example:

# Keep only user ID and requested path
filtered := json.filter(input.request, ["user/id", "request/path"])


Path strings are JSON Pointerâ€“style:

"user/id" corresponds to conceptual path segments ["user", "id"].

"request/path" corresponds to ["request", "path"].

Think of each string as a slash-delimited path from the root of obj. The function returns a new object containing only the specified paths.


6.7 Strings

Rego strings are Unicode text; built-ins operate on code points (not bytes).

Key built-ins:

concat(sep, array)             # join strings with separator
contains(s, substr)            # substring test
startswith(s, prefix)
endswith(s, suffix)
format_int(int, base)          # "2a" in base 16, etc.
indexof(s, substr)             # index or -1
lower(s) / upper(s)
replace(s, old, new)           # replace all occurrences
split(s, sep)                  # split into array
sprintf(format, args_array)    # printf-style format
substring(s, start, length)    # slice of string
trim(s, chars)                 # trim characters from both ends
trim_space(s)                  # trim whitespace
trim_prefix(s, prefix)
trim_suffix(s, suffix)


Examples:

# Normalize emails
norm_email := lower(trim_space(input.user.email))

# Path manipulation
endpoint := trim_prefix(input.path, "/api/v1/")
segments := split(endpoint, "/")

# Slugify a title (rough example)
slug := lower(replace(input.title, " ", "-"))

# Format numeric IDs
hex_id := format_int(input.id, 16)  # hex

# Human-readable messages
msg := sprintf("User %s attempted %s on %s", [input.user.id, input.action, input.resource.id])


Pitfall: contains is substring, not set membership (for that use in).

6.8 Regular Expressions

Regex built-ins are powerful but expensive; use carefully.

Key built-ins:

regex.is_valid(pattern)                  # sanity check
regex.match(pattern, string)             # boolean
regex.find_n(pattern, string, n)         # up to n matches
regex.split(pattern, string)             # array of splits


**Raw Strings (Backticks) - Implementation Note:**

The grammar defines raw strings with backticks (`raw-string ::= "`" { CHAR-"`" } "`"`), and examples in documentation may show them. However, **raw strings may not be supported in all OPA versions or implementations**. For maximum compatibility, prefer double-quoted strings with proper escaping:

# Compatible (recommended)
is_hex if regex.match("^[0-9a-fA-F]+$", input.value)

# May not work in all OPA versions
is_hex if regex.match(`^[0-9a-fA-F]+$`, input.value)

**Best Practice:** Always use double-quoted strings with escaped backslashes for regex patterns. Test with `opa check` to verify compatibility with your OPA version.

**Exception: Multi-Line Test Data**

For test files containing multi-line content (diffs, code blocks, structured text), raw strings are the preferred approach because they preserve actual newline characters. Unlike double-quoted strings where `\n` is a literal two-character sequence, raw strings interpret newlines as actual line breaks:

```rego
# âœ… CORRECT: Raw string for multi-line test data
test_diff_parsing if {
    diff_content := `+ // TODO: Fix issue
+ function implementation() {`
    # Contains actual newline between lines
    
    mock_input := {"diff": diff_content}
    # Policy regex patterns can now match newlines correctly
}

# âŒ PROBLEMATIC: Double-quoted string with \n literal
test_diff_parsing if {
    diff_content := "+ // TODO: Fix issue\n+ function implementation() {"
    # \n is literal backslash + 'n', NOT a newline
    # Regex patterns expecting newlines will fail
}
```

**When to Use Raw Strings:**
- Test inputs containing multi-line content (file diffs, code blocks)
- Regex patterns that need to match actual newline characters
- Content that must preserve line breaks exactly as written

**When to Use Double-Quoted Strings:**
- Single-line strings
- Regex patterns (for maximum compatibility)
- Strings where escape sequences are acceptable


Performance tips:

Avoid regex in tight loops over large collections if possible.

Pre-validate patterns with regex.is_valid when patterns are dynamic (e.g., user-supplied).

6.9 Numbers & Numeric Utilities

Basic numeric helpers:

abs(x)                      # absolute value
ceil(x)                     # smallest integer â‰¥ x
floor(x)                    # greatest integer â‰¤ x
round(x)                    # round half-up
numbers.range(start, end)   # [start, ..., end-1]


Examples:

# Generate ports 8000 to 8099
ports := numbers.range(8000, 8100)

# Check resource usage thresholds
over_limit if {
    usage := input.usage
    limit := input.limit
    usage > limit * 1.10  # 10% over limit
}


Combine with aggregates:

# Ensure all latencies below 100ms
all_fast if {
    not any_slow
}
any_slow if {
    some lat in input.latencies
    lat > 100
}

6.10 Type Conversion & Validation

Sometimes you ingest loosely typed JSON (forms, CSV turned JSON). Use conversion and validation built-ins:

to_number(x)       # best-effort numeric conversion
to_string(x)
to_set(x)
to_array(x)
to_object(x)       # shape-dependent
cast_number(x)
cast_string(x)
cast_bool(x)
json.is_valid(str) # syntactic JSON validation
yaml.is_valid(str)


Patterns:

# Robust score parsing
score_is_valid if {
    json.is_valid(input.body)
    body := json.unmarshal(input.body)
    s := to_number(body.score)
    s >= 0
    s <= 100
}

# Convert dynamic lists
tags_set := to_set(input.tags)


Difference: to_* is generally more permissive; cast_* may be stricter (implementation details can vary by versionâ€”always verify against your target OPA).

6.11 Encoding, Decoding & Serialization

Used to transform payloads between formats or safely embed them.

Key built-ins:

# Base64
base64.encode("hello")            # "aGVsbG8="
base64.decode("aGVsbG8=")         # "hello"
base64url.encode("hello")         # URL-safe
base64url.decode("...")

# Hex
hex.encode("hello")               # "68656c6c6f"
hex.decode("68656c6c6f")          # "hello"

# JSON
json.marshal(x)                   # value â†’ JSON string
json.unmarshal(json_str)         # JSON string â†’ value

# YAML
yaml.marshal(x)
yaml.unmarshal(yaml_str)

# URL query
urlquery.encode("a=1&b=2")       # "a%3D1%26b%3D2"
urlquery.decode("a%3D1")         # "a=1"


Examples:

# Parse JWT payload manually (not recommended vs io.jwt.* but illustrative)
parts := split(input.token, ".")
payload_b64 := parts[1]
payload_json := base64url.decode(payload_b64)
claims := json.unmarshal(payload_json)

# Marshal deny messages for logs
deny_json := json.marshal(deny_msgs)

6.12 Type Introspection

Type predicates and type_name are invaluable for robust policies:

is_array(x)
is_boolean(x)
is_null(x)
is_number(x)
is_object(x)
is_set(x)
is_string(x)
type_name(x)        # "array", "object", "set", "string", "number", "null", "boolean"


Pattern: Defensive guards before deeper logic:

valid_request if {
    is_object(input)
    is_object(input.user)
    is_string(input.user.id)
    is_string(input.action)
}

**Input Safety Best Practices:**

Always guard access to optional or potentially missing input fields:

```rego
# âŒ UNSAFE: May error if input.pr_body is missing or not a string
has_override(marker) if {
    contains(input.pr_body, marker)  # Type error if pr_body missing
}

# âœ… SAFE: Type guard before access
has_override(marker) if {
    is_string(input.pr_body)
    contains(input.pr_body, marker)
}

# âœ… SAFE: Guard array access
input_valid if {
    is_array(input.changed_files)
}

# Then use guard in all rules
deny[msg] if {
    input_valid
    some file in input.changed_files
    # ... rest of logic
}
```

**Common Patterns:**
- Check `is_string()` before `contains()`, `startswith()`, `endswith()`
- Check `is_array()` before iteration with `some ... in`
- Check `is_object()` before property access
- Check `is_number()` before arithmetic operations
- Create a top-level `input_valid` guard and use it in all rules that access input

6.13 Cryptography & Security Built-ins

Security-sensitive policies rely heavily on crypto built-ins.

Hash functions & HMAC:

crypto.md5(data)
crypto.sha1(data)
crypto.sha256(data)
crypto.sha3_256(data)
crypto.hmac.sha256(key, data)


Key-derivation & password hashing:

crypto.pbkdf2(hash_alg, password, salt, rounds)
crypto.bcrypt.hash(password)
crypto.bcrypt.compare(hash, password)


X.509 and certificates:

crypto.x509.parse_certificates(pem)  # parse PEM bundle â†’ array of certs


JWT helpers (in io.jwt namespace):

io.jwt.decode(token)                  # [header, payload, signature] or undefined
io.jwt.verify_hs256(token, key)       # boolean
io.jwt.verify_rs256(token, cert)
io.jwt.verify_es256(token, cert)
io.jwt.verify_ps256(token, cert)
io.jwt.encode_sign_raw(headers, payload, key)


Patterns:

valid_token if {
    io.jwt.verify_hs256(input.token, data.jwt_secret)
}

deny[msg] if {
    not valid_token
    msg := "Invalid JWT"
}


Security guidance:

Never bake secrets into Rego source; pass via data or environment.

Use strong algorithms (avoid MD5/SHA1 except for legacy fingerprints).

6.14 This chapter catalogs core built-ins and corrects a few subtle points (arrays, JSON filtering, time, UUIDs/ULIDs).

6.4 Arrays & array.concat

Arrays are ubiquitous: paths, lists of scopes, resource IDs, etc.

Common built-ins:

count(arr)              # length
arr[i]                  # index
arr[_]                  # iterate
concat(".", arr)        # join into string
array.concat(a, b)      # concatenate arrays


Concatenation:

array.concat([1, 2], [3])  # => [1, 2, 3]


Nuances:

Both arguments must be arrays.

If either argument is null (or not an array), OPA raises a type error.

For defensive code, wrap it:

safe_concat(a, b) := array.concat(a, b) if {
    is_array(a)
    is_array(b)
}


Use safe_concat in paths or pipelines where inputs may be missing or partially null.

Time Functions (No time.diff)

Time built-ins revolve around:

Getting the current time (time.now_ns)

Parsing timestamps (time.parse_rfc3339_ns)

Formatting (time.format, etc.)

Example of computing a duration:

now   := time.now_ns()
start := time.parse_rfc3339_ns(input.window.start)
end   := time.parse_rfc3339_ns(input.window.end)

duration_ns := end - start

too_long if {
    duration_ns > 5 * 60 * 1e9  # > 5 minutes
}


Important corrections:

There is no standard time.diff builtin in OPA.

Differences are computed with normal arithmetic on integer nanosecond timestamps:

duration_ns := end_ns - start_ns.

This approach works consistently across CLI, server, and WASM runtime.

6.15 HTTP Built-ins

http.send allows policies to call external services. Use with discipline.

resp := http.send({
    "method": "GET",
    "url": "https://example.com/api/v1/status",
    "headers": {"Accept": "application/json"},
    "timeout": "3s"  # optional, string with units
})
# resp = {"status": 200, "body": ..., "headers": {...}}


Characteristics:

Potentially slow and side-effectful.

Memoized: same arguments â†’ single call per evaluation, cached for subsequent uses in the same query.

Patterns:

Prefer to fetch external data ahead of time and feed via data or input.

In CI or admission controllers, avoid http.send altogether if possible.

Testing:

test_http_policy if {
    result := policy.check
        with http.send as mock_http_send
}

6.16 Network & CIDR Built-ins

Networking helpers are invaluable for Kubernetes and cloud policies.

net.cidr_contains(cidr, ip)     # true if ip âˆˆ CIDR
net.cidr_expand(cidr)           # list of IPs in small range
net.cidr_intersects(c1, c2)     # overlap?
net.cidr_merge(cidr_list)       # merge overlapping ranges


Example:

deny[msg] if {
    not net.cidr_contains("10.0.0.0/8", input.source_ip)
    msg := "Source IP outside corporate network"
}

6.17 UUID & ULID Generation

Some deployments expose helpers in the standard library or via plugins. Common patterns:

uuid := uuid.rfc4122(seed)
ulid := ulid.generate()


Semantics:

uuid.rfc4122(seed):

Deterministic for a given string seed.

Ideal for tests where you want stable IDs.

ulid.generate():

Time-based and non-deterministic.

Great for production identifiers, but brittle in tests.

Testing recommendations:

# Stable UUID in tests
test_id := uuid.rfc4122("test-seed-123")

# For ULID, either:
# - mock it with: with ulid.generate as "fixed-ulid"
# - or only check that a ULID exists / matches a regex, not its exact value


6.18 Graph & Structural Walks

graph.* functions operate on graph structures (represented as adjacency lists).

graph.reachable(graph, ["start"])  # list of reachable nodes


walk(x) traverses nested structures and returns [path, value] pairs:

pairs := walk(input)
# pairs is [[["path","to","value"], value], ...]


Patterns:

# Find all values under keys called "id"
ids := {v |
    [p, v] := walk(input)
    p[_] == "id"
}

6.19 Units & Parsing

For human-friendly sizes or durations:

units.parse("10GB")        # parse size with units â†’ numeric bytes
units.parse_bytes("10MB")  # synonym-focused variant


Useful for policies over resource limits:

deny[msg] if {
    limit_bytes := units.parse(input.spec.resources.limits.memory)
    limit_bytes > units.parse("4Gi")
    msg := "Pod memory limit exceeds 4Gi"
}

6.20 Metadata & Annotations

Rego exposes rule metadata at evaluation time:

rule_meta := rego.metadata.rule()   # metadata of current rule
chain_meta := rego.metadata.chain() # stack of rule metadata along evaluation chain


Usage:

Enrich decision logs with rule IDs, owners, severity.

Drive governance features (e.g., map violations back to policy owners).

Example:

deny[msg] if {
    violation_condition
    m := rego.metadata.rule()
    msg := {
        "msg": "Violation detected",
        "rule_id": m.id,
        "owner": m.owner,
    }
}

6.21 Debugging Built-ins: print and trace

print is the primary debugging tool for Rego:

debug_rule if {
    x := input.value
    print("The value of x is:", x)
    x > 10
}


Properties:

print(...) always returns true, so it does not change logical semantics.

Output appears in OPA logs or opa eval --explain trace output depending on environment.

trace may also be available as an alias in some environments; print is the standard.

Best practices:

Use print liberally during development and experiments.

Remove or gate print statements in production policies to avoid log noise and PII leaks (many style guides enforce no print in prod).

6.22 Error Semantics & Strict Mode

By default, built-in errors make expressions undefined:

# If to_number fails, rule body is undefined
is_valid if {
    n := to_number(input.score)
    n >= 0
}


For higher assurance, strict builtin errors convert such errors into hard failures:

CLI:

opa eval --strict-builtin-errors ...


HTTP API: strict-builtin-errors=true query parameter.

Use strict mode:

In CI to catch unexpected type mismatches and invalid data.

In critical policies where silent undefined behavior is unacceptable.

Pattern: Combine strict mode in tests with non-strict mode in production, or vice versa, depending on risk posture.

6.23 Performance Patterns with Built-ins

Guard expensive built-ins with cheap checks

# Good: fast predicate first
deny if {
    input.method == "POST"
    regex.match(`(?i)password`, input.body)
}


Avoid large intermediate arrays via comprehensions if a boolean will do

# Bad
admins := {u | some u in users; "admin" in u.roles}
has_admin if count(admins) > 0

# Good
has_admin if {
    some u in users
    "admin" in u.roles
}


Use sets for membership, arrays for ordered sequences

Memoization awareness

Expensive built-ins with same arguments (e.g., http.send, complex regex.match) will be evaluated once per query and cached.

If inputs differ slightly each time, caching may not help; consider pre-processing.

6.24 Design Patterns & Anti-Patterns

Patterns

Validation helpers: Make dedicated rules using type and conversion built-ins (is_valid_request, normalize_email) and reuse everywhere.

Canonicalization: Always lowercase/trim user-identifiers before comparison.

Safe logging: Use object.remove + json.marshal + trim* to avoid PII leaks.

Anti-Patterns

Regex everywhere:

Overuse of regex in hot loops will tank performance.

Prefer startswith, endswith, contains, or exact matches when sufficient.

Hidden type conversions:

Relying on to_number implicitly instead of checking type leads to brittle policies.

Unbounded http.send usage:

Using HTTP calls per request is rarely acceptable in admission controllers or hot authorization paths.

Non-mocked time in tests:
Using time.now_ns() directly in tests causes flakiness; always with time.now_ns as ...

Chapter 7 â€“ Testing, Debugging & Troubleshooting (From Hello-World to PhD)
Testing is not an afterthought in Rego/OPA; it is the mechanism by which you prove that your policies are correct, stable, and maintainable. This chapter builds from basic _test rules up to full-blown policy test architectures, fuzzing, and debugging strategies.
________________________________________
7.1 Testing Fundamentals
Where tests live
	Tests are Rego modules whose package names end in _test.
	Convention:
	Production package: package authz.api
	Test package: package authz.api_test
Naming rules
	Test rules must start with test_.
	A test passes if its body can be satisfied (i.e., is true); it fails otherwise.
package authz.api_test

import data.authz.api

test_admin_can_read if {
    api.allow with input as {
        "user": {"id": "alice", "roles": ["admin"]},
        "action": "read",
        "resource": {"id": "123"}
    }
}

test_guest_cannot_write if {
    not api.allow with input as {
        "user": {"id": "guest", "roles": ["guest"]},
        "action": "write",
        "resource": {"id": "123"}
    }
}
Running tests
# All tests in current tree
opa test .

# Verbose (see individual test names)
opa test . -v

# Specific path or file
opa test policies/ authz_test.rego

# With coverage reporting
opa test . --coverage --format=json > coverage.json
________________________________________
7.2 The with Keyword for Mocking
with is the cornerstone of Rego testing. It temporarily overrides input, data, or even built-ins for a single evaluation.
Override input
test_non_admin_denied if {
    authz.allow with input as {
        "user": {"id": "bob", "roles": ["user"]},
        "action": "delete",
        "resource": {"id": "123"}
    }
}
Override data
test_role_from_data if {
    authz.allow
        with input as {"user": "alice", "action": "read"}
        with data.roles as {"alice": ["admin"]}
}
Override built-ins (time, http, etc.)
# in policy:
within_business_hours if {
    now := time.now_ns()
    [hour, _, _] := time.clock(now)
    hour >= 9
    hour < 17
}

# in test:
test_within_business_hours_if_daytime if {
    within_business_hours
        with time.now_ns as 1700000000000000000  # some daytime timestamp
}
This makes your policies deterministic and testable, even when they rely on clocks, network calls, or external data.
________________________________________
7.3 Unit Tests vs Integration Tests vs â€œGoldenâ€ Tests
Testing & Tooling

This chapter describes patterns for unit tests, integration tests, and golden tests.

7.3 Golden Tests & File I/O (Corrected)

Golden tests compare the decision against a â€œgoldenâ€ expected result stored in a file. Critically:

Rego itself has no read_file builtin and cannot perform file I/O.
All file reading is handled by the test harness (shell, Go, Python, etc.).

A realistic pattern:

package compliance_test

import data.compliance

test_large_pr_risk_profile if {
    # Harness loads JSON from disk into data.tests.*
    input_case := data.tests["pr_large"].input
    expected   := data.tests["pr_large"].expected

    result := compliance with input as input_case
    result == expected
}


Typical harness responsibilities:

Read tests/inputs/pr_large.json and tests/expected/pr_large.json from disk.

Populate data.tests["pr_large"] before invoking opa test or the OPA SDK.

Optionally parameterize tests via CLI flags or environment.

In other words:

Rego: pure data and rules; no file system.

Harness: performs all file I/O and passes JSON into Rego as input or data.
________________________________________
7.4 Debugging with print and opa eval
print is your printf.
	Signature: print(x1, x2, ...)
	Always returns true, so you can drop it directly inside rule bodies.
debug_threshold if {
    t := input.threshold
    print("Threshold is:", t)
    t > 10
}
Where output appears
	opa eval â†’ printed to stderr / logs.
	Embedded OPA â†’ appears in OPA logs; your host system should capture these.
Key points
	print doesnâ€™t alter semantics (just like adding true).
	Good for:
	Inspecting variable bindings.
	Confirming which rule body is being hit.
	Bad for:
	Production policies with PII.
	Flooding logs; use sparingly or behind a debug flag.
________________________________________
7.5 opa eval Explain & Profile Modes
opa eval is both a REPL and microscope.
Explain modes
opa eval --explain=notes -d policy.rego -i input.json 'data.authz.allow'
opa eval --explain=full  ...
	notes = high-level reasoning (rule success/failure).
	full = full derivation tree; great for debugging, painful for huge queries.
Profile mode
opa eval --profile -d . -i input.json 'data.compliance'
You get:
	Per-rule evaluation counts and cumulative time.
	A ranking of â€œhotâ€ rules (the ones to optimize or refactor).
Typical workflow
	Problem: â€œPolicy is slow for large PRs / big cluster.â€
	Run: opa eval --profile ...
	Identify rules with:
	Many evaluations (thousands or millions).
	High total time.
	Refactor:
	Use sets/objects instead of scanning arrays.
	Add guard conditions (cheap predicates before expensive ones).
	Use partial evaluation (Â§11).
________________________________________
7.6 Common Errors and How to Diagnose Them
	rego_unsafe_var_error â€“ unsafe variables
	# âŒ Unsafe: user appears only under negation
	deny if {
	    not blacklisted[user]
	}
Fix: Bind user outside negation.
deny if {
    user := input.user
    not blacklisted[user]
}
	rego_type_error â€“ type mismatch
	Example: using to_number on an object, or sum over [1, "two"].
	Fix:
	Guard with is_* built-ins (is_number(x), is_array(x)).
	Normalize incoming data.
	Rule conflict errors
	Multiple complete rules with same name produce different values for same input.
	f(1) := 2
	f(1) := 3  # conflict
	For sets/partial objects this is okay (results are merged); for complete rules & functions itâ€™s an error.
	Infinite or pathological recursion
	Patterns that refer back to themselves without a base case.
	OPA has guardrails, but logic errors can still create huge evaluation trees.
Mitigate with:
	Explicit depth counters.
	Clear base rules.
________________________________________
7.7 String Literal Handling in Tests: JSON vs Rego String Semantics

A critical distinction exists between how string literals are interpreted in JSON inputs versus Rego test files. This difference frequently causes test failures that are difficult to diagnose.

7.7.1 The Newline Escape Sequence Problem

When testing policies that operate on multi-line content (e.g., file diffs, code blocks, structured text), developers often encounter a subtle but critical difference:

**JSON Input (via `opa eval --input`):**
```json
{
  "diff": "+ // TODO:\n+ function getUsers() {"
}
```
In JSON, `\n` is interpreted as an actual newline character during JSON parsing. The policy receives a string containing a real line break.

**Rego Test File (inline string literal):**
```rego
test_example if {
    mock_input := {"diff": "+ // TODO:\n+ function getUsers() {"}
    # \n here is literal: backslash + 'n', NOT a newline
}
```
In Rego test files, `\n` within double-quoted strings is treated as a literal two-character sequence: backslash followed by 'n'. It is not decoded to an actual newline.

**Impact on Regex Patterns:**
```rego
# Policy expects actual newline
regex.match("TODO:\\s*\\n", file.diff)  # Fails in tests with \n literal

# Test input with \n literal
"diff": "+ // TODO:\n+ function()"  # Contains literal "\n", not newline
```

The regex pattern `TODO:\\s*\\n` expects an actual newline character, but receives the literal string "\n", causing the match to fail.

7.7.2 Solution: Raw Strings (Backticks) for Multi-Line Test Data

For test inputs containing multi-line content, use raw strings (backticks) which preserve actual newlines:

```rego
# âœ… CORRECT: Raw string preserves actual newlines
test_todo_with_newline if {
    diff_content := `+ // TODO:
+ function getUsers() {`
    
    mock_input := {"changed_files": [{
        "path": "file.ts",
        "diff": diff_content
    }]}
    
    # Policy regex now matches correctly
    warnings := policy.warn with input as mock_input
    count(warnings) >= 1
}
```

**Raw String Properties:**
- Preserve actual newline characters (not `\n` literals)
- Do not interpret escape sequences (`\n`, `\t`, etc.)
- Ideal for multi-line test data (diffs, code blocks, structured text)
- Compatible with regex patterns expecting real newlines

**When to Use Raw Strings vs Double-Quoted:**
- **Raw strings (backticks)**: Multi-line content, actual newlines needed, regex patterns matching line breaks
- **Double-quoted**: Single-line content, escape sequences acceptable, JSON-like strings

7.7.3 Debugging String Literal Issues

**Symptoms:**
- Tests fail with `opa test` but pass with `opa eval --input <json-file>`
- Regex patterns that work with JSON inputs fail in test files
- Multi-line matching fails unexpectedly

**Diagnostic Steps:**
1. Compare test input structure with working JSON input
2. Check if regex patterns expect actual newlines vs `\n` literals
3. Use `print()` to inspect actual string content:
   ```rego
   test_debug if {
       diff := "+ // TODO:\n+ function()"
       print("Length:", count(diff))  # Check if \n is one char or two
       print("Contains newline:", contains(diff, "\n"))  # May fail if literal
   }
   ```
4. Convert test strings to raw strings (backticks) if multi-line content is needed

**Best Practice:** When testing policies that process multi-line content (diffs, code, logs), always use raw strings in test files to match the behavior of JSON inputs.

________________________________________
7.8 Test Evaluation Context and Variable Binding Patterns

The evaluation context of `with` clauses in tests can affect how rule results are accessed. Understanding these patterns prevents subtle test failures.

7.8.1 Direct Evaluation vs Variable Binding

When testing rules that return sets (e.g., `warn`, `deny`), the method of accessing results matters:

**Pattern 1: Direct Evaluation (May Fail)**
```rego
# âŒ PROBLEMATIC: Direct count() with with clause
test_example if {
    mock_input := {"changed_files": [...]}
    count(policy.warn) >= 1 with input as mock_input
}
```

**Pattern 2: Variable Binding (Recommended)**
```rego
# âœ… CORRECT: Bind result to variable first
test_example if {
    mock_input := {"changed_files": [...]}
    warnings := policy.warn with input as mock_input
    count(warnings) >= 1
}
```

**Why Variable Binding is Preferred:**
- Explicit evaluation context: `with input as mock_input` applies to the rule evaluation, not the `count()` call
- Clearer semantics: The rule is evaluated with mocked input, then the result is counted
- More reliable: Avoids potential evaluation order issues in complex test expressions
- Better debugging: Can inspect `warnings` set before counting

7.8.2 Accessing Set Elements in Tests

When a rule returns a set (partial rule with `contains`), accessing elements requires proper iteration:

```rego
# âœ… CORRECT: Iterate set to get first element
test_get_warning_message if {
    mock_input := {"changed_files": [...]}
    warnings := policy.warn with input as mock_input
    count(warnings) >= 1
    
    # Get first warning message
    warning := [msg | msg := warnings[_]][0]
    contains(warning, "expected text")
}

# âŒ WRONG: Sets don't support index access
warning := warnings[0]  # Error: sets don't have indices
```

**Pattern for Multiple Assertions:**
```rego
test_multiple_assertions if {
    warnings := policy.warn with input as mock_input
    count(warnings) >= 1
    
    # Check all warnings
    some warning in warnings
    contains(warning, "pattern1")
    
    # Or check specific warning
    specific_warning := [msg | msg := warnings[_]; contains(msg, "pattern2")][0]
    contains(specific_warning, "pattern2")
}
```

7.8.3 Rule Precedence and Overlapping Conditions

When multiple rules can match the same input, understanding evaluation order is critical for test design.

**Problem: Overlapping Rule Conditions**
```rego
# Policy has two rules that can both match:
# R15-W02: Meaningful TODO not logged (general check)
# R15-W03: TODO added without reference (specific check for +.*TODO:)

# Both rules check:
# - has_meaningful_todo_keywords(file)
# - not has_tech_debt_reference(file)
# R15-W03 also checks: regex.match("\\+.*TODO:", file.diff)
```

**Test Design Strategy:**
```rego
# âœ… CORRECT: Test for either rule, or check for common message pattern
test_meaningful_todo_not_logged if {
    mock_input := {"changed_files": [{
        "diff": "+ // TODO: Fix issue (workaround)"
    }]}
    
    warnings := policy.warn with input as mock_input
    count(warnings) >= 1
    
    # Check for message pattern common to both rules
    some warning in warnings
    contains(warning, "meaningful TODO/FIXME")
    contains(warning, "tech-debt.md")
}

# âŒ FRAGILE: Testing for specific rule ID
test_specific_rule if {
    # This may fail if rule precedence changes
    # or if a more specific rule triggers first
}
```

**Best Practice:** Design tests to verify policy behavior (what warnings are produced) rather than implementation details (which specific rule triggered). This makes tests more resilient to policy refactoring.

________________________________________
7.9 Case Sensitivity and String Matching in Tests

String matching functions in Rego are case-sensitive, which can cause test failures when test inputs don't match policy expectations.

7.9.1 The Case Sensitivity Trap

The `contains()` function performs case-sensitive substring matching:

```rego
# Policy checks for lowercase "temporary"
has_meaningful_todo_keywords(file) if {
    contains(file.diff, "FIXME:")
    contains(file.diff, "temporary")  # Lowercase required
}

# âŒ TEST FAILS: Test uses "Temporary" (capital T)
test_example if {
    mock_input := {"diff": "+ // FIXME: Temporary hack"}
    # Policy doesn't match "Temporary" (capital T)
    # Test expects warning but gets none
}

# âœ… TEST PASSES: Test uses "temporary" (lowercase)
test_example if {
    mock_input := {"diff": "+ // FIXME: temporary hack"}
    # Policy matches "temporary" correctly
}
```

7.9.2 Mitigation Strategies

**Option 1: Normalize Test Inputs**
```rego
# Normalize keywords in test inputs to match policy expectations
test_example if {
    # Use lowercase to match policy checks
    mock_input := {"diff": "+ // FIXME: temporary hack"}
    # ...
}
```

**Option 2: Policy-Level Normalization (Recommended for Production)**
```rego
# Policy normalizes input before checking
has_meaningful_todo_keywords(file) if {
    contains(file.diff, "FIXME:")
    diff_lower := lower(file.diff)
    contains(diff_lower, "temporary")  # Case-insensitive check
}
```

**Option 3: Explicit Case Variants in Policy**
```rego
# Policy checks multiple case variants
has_meaningful_todo_keywords(file) if {
    contains(file.diff, "FIXME:")
    contains(file.diff, "temporary")
}

has_meaningful_todo_keywords(file) if {
    contains(file.diff, "FIXME:")
    contains(file.diff, "Temporary")
}
```

**Best Practice:** For production policies, prefer normalization (Option 2) to handle case variations gracefully. For tests, ensure inputs match policy expectations exactly, or document case sensitivity requirements clearly.

________________________________________
7.7 Advanced Testing: Fuzzing & Mutation
For high-assurance policies (security, compliance):
	Fuzzing:
	Generate random or adversarial JSON inputs.
	Run opa eval or opa test against them.
	Look for panics, regressions, or surprising allow/deny.
	Mutation testing:
	Mutate policies (flip conditions, remove clauses).
	Check that test suite fails appropriately.
	Failing to detect "killed" mutants = missing tests.
This is often orchestrated by external tooling (Python/Go harnesses that call OPA), but the principles are Rego-agnostic.
________________________________________
Chapter 8 â€“ OPA Architecture & Integration Patterns
This chapter is about where and how you run OPA.
________________________________________
8.1 The PDP / PEP Split
	PDP (Policy Decision Point): OPA, evaluating Rego.
	PEP (Policy Enforcement Point): Your app, proxy, or platform component that:
	Collects input (HTTP request, Kubernetes object, Terraform plan, CI metadata).
	Sends it to PDP.
	Enforces the decision (allow/deny/mutate/log).
OPA is only the PDP. The PEP is your responsibility.
________________________________________
8.2 Deployment Topologies
	Sidecar / local daemon
	OPA runs alongside your service, often in the same Pod.
	Low latency, no network hop beyond localhost.
Typical:
	Envoy external authz â†’ OPA.
	Kubernetes admission controller â†’ OPA sidecar in same namespace.
	Central PDP service
	OPA (or OPA-based service) runs as a central API.
	Multiple services call it over the network.
Tradeoffs:
	Pros: Single place to manage policies; simpler distribution.
	Cons: Latency, scalability, SPOF (unless HA), multi-tenant complexity.
	Library / SDK
	Embed OPA:
	Go: github.com/open-policy-agent/opa/rego
	WASM: compile Rego to WASM and embed in any WASM host (Node, Rust, etc.).
	Useful for:
	Client-side enforcement (e.g., in a browser or mobile app).
	Edge scenarios.
________________________________________
8.3 Integration Examples
	Kubernetes (Gatekeeper & friends)
	Admission review â†’ OPA policy.
	Rego receives:
	input.request (raw AdmissionReview).
	data includes ConstraintTemplates, constraints, reference data.
	Typical structure:
	package kubernetes.admission
	
	deny[msg] if {
	    input.request.kind.kind == "Pod"
	    some c in input.request.object.spec.containers
	    c.image == "latest"
	    msg := "Images must not use :latest tag"
	}
	Envoy / API Gateway
	Envoy external authorization filter calls OPA with HTTP headers, method, path, source IP.
	Decision rule: data.envoy.authz.allow.
	Example:
	package envoy.authz
	
	default allow := false
	
	allow if {
	    input.attributes.request.http.method == "GET"
	    input.attributes.request.http.path == "/status"
	}
	CI/CD â€“ GitHub Actions, GitLab CI, etc.
	PR/diff metadata â†’ JSON (opa-input.json).
	OPA evaluates data.compliance.
	CI interprets deny, warn, override arrays and posts PR comments / fails build.
	IaC scanning (Terraform, Kubernetes YAML)
	Terraform plan JSON or Kubernetes manifests as input.
	Policies check:
	Public buckets.
	Unencrypted volumes.
	Exposed security groups.
________________________________________
8.4 Multi-layer Policy Architecture on OPA
	Layers usually look like:
	Global baseline â€“ org-level security/compliance invariants.
	Domain policies â€“ per product or platform (e.g., CRM, billing).
	Team/service policies â€“ localized rules.
	Tenant overlays â€“ per customer/tenant customizations.
	Implement via:
	Multiple bundles merged in OPA.
	Data-driven toggles (e.g., data.tenants[tenant_id].overrides).
	Rego evaluation order (e.g., base allow, then deny overlays).
________________________________________
8.5 OPA as a Policy Mesh
In large environments, you might have:
	Many OPAs running across clusters/namespaces.
	A central bundle server pushing policies.
	Decision logs shipped to SIEM / data lake.
Rego itself doesnâ€™t change; the architecture around it does.
________________________________________
Chapter 9 â€“ Policy Bundling & Distribution
OPA is not just an evaluator; it has a bundle system for shipping policies and data.
________________________________________
9.1 Bundle Basics
A bundle is:
	A .tar.gz containing:
	/policies/*.rego
	/data/*.json (or YAML, etc.)
	.manifest file with metadata.
Example manifest (conceptual):
{
  "revision": "git-sha-1234",
  "roots": ["authz", "compliance"],
  "metadata": {
    "version": "1.2.3",
    "built_at": "2025-11-25T12:00:00Z"
  }
}
OPA config:
services:
  policy:
    url: https://opa-bundles.example.com

bundles:
  main:
    service: policy
    resource: /bundles/crm-main.tar.gz
    polling:
      min_delay_seconds: 10
      max_delay_seconds: 60
OPA periodically pulls bundles, verifies them, and updates its data and policy set.
________________________________________
9.2 Bundle Layering & Tenancy
You can have multiple bundles:
	global-baseline.tar.gz â†’ data.global
	org-security.tar.gz â†’ data.org
	crm-team.tar.gz â†’ data.crm
	tenant-123.tar.gz â†’ data.tenants["123"]
OPA merges them in the data document.
Patterns:
	Tenant-specific overrides are just data:
	package authz
	
	default allow := false
	
	allow if {
	    base_allow
	    not data.tenants[input.tenant_id].deny_all
	}
	Canary rollout:
	Serve new bundle under /bundles/crm-main-canary.tar.gz to subset of OPAs.
	Compare decisions vs stable.
________________________________________
9.3 Release Engineering & Versioning
	Use semantic versioning for bundles: vMAJOR.MINOR.PATCH.
	Track:
	Git commit SHA.
	Build ID.
	CI pipeline run.
	Typical pipeline:
	opa fmt + lint + opa test + opa check --strict.
	opa build / custom bundler to produce bundle.tar.gz.
	Sign bundle (e.g., Sigstore, GPG).
	Upload to bundle server / CDN.
	Tag release in Git.
________________________________________
Chapter 10 â€“ Linting, Style & CI
Even perfect policies are useless if theyâ€™re unreadable or unmaintainable. This chapter merges style guides, linting, and CI patterns into an enforceable system.
________________________________________
10.1 Style Principles (Based on Styra + Enterprise Practice)
	Readability first
	Prefer clear, small rules over clever one-liners.
	Use opa fmt always
	Standardizes indentation, spacing, and layout.
	Enforce via CI.
	Use modern syntax (Rego v1)
	if, contains, every, some ... in ....
	Import rego.v1 or future.keywords when needed.
	Naming conventions
	Packages: domain.service.component
	crm.authz.http, infra.k8s.admission.
	Rules & functions: snake_case.
	Helper rules: prefix with _ (convention).
	package crm.authz.http
	
	_is_admin(user) if "admin" in user.roles
	
	allow if {
	    _is_admin(input.user)
	    input.request.method == "GET"
	}
	Rule organization
	Top of file:
	Package.
	Imports.
	Constants/defaults.
	Then:
	Helper rules (unexported).
	Public rules (allow, deny, violation, etc.).
________________________________________
10.2 Regal (Linter) & Custom Lint Rules
Regal is a dedicated Rego linter.
Example config (.regal/config.yaml):
rules:
  naming-convention:
    snake_case: true
  unused-decls: error
  no-var-shadowing: error
  require-some: error
  no-ambiguous-negation: warn
  max-rule-size:
    severity: warn
    limit: 10
  avoid-inline-comprehensions: warn
  package-path-alignment: error
  no-import-input: error
Typical checks:
	Snake_case for everything.
	No unused variables (except _).
	No variable shadowing.
	Explicit some declarations.
	Package name alignment with file path.
	Metadata required on certain rules (e.g., deny rules).
________________________________________
10.3 CI Pipeline: From Formatting to Enforcement
Lint & format stage â€“ GitHub Actions example
name: Rego Linting
on: [push, pull_request]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install OPA
        run: |
          curl -L -o opa https://openpolicyagent.org/downloads/latest/opa_linux_amd64
          chmod +x opa
          sudo mv opa /usr/local/bin/opa

      - name: Install Regal
        run: |
          curl -sSL https://raw.githubusercontent.com/styrainc/regal/main/install.sh | sh
          sudo mv regal /usr/local/bin/regal

      - name: Check formatting
        run: opa fmt --fail .

      - name: Lint (Regal)
        run: regal lint --format=github .
Test stage
name: Rego Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install OPA
        run: |
          curl -L -o opa https://openpolicyagent.org/downloads/latest/opa_linux_amd64
          chmod +x opa
          sudo mv opa /usr/local/bin/opa
      - name: Run tests
        run: opa test policies/ tests/ --verbose --timeout 30s
Compliance evaluation stage (optional)
	Run opa eval with CI inputs (like PR diffs) to enforce policy gates.
________________________________________
10.4 Editor & Developer Experience
	.editorconfig:
	[*.rego]
	indent_style = tab
	indent_size  = 4
	Editor extensions:
	Syntax highlighting, opa fmt on save.
	Regal integration where possible.
	For Cursor / custom AI agents:
	Auto-run opa fmt in pre-commit hooks.
	Use Rego-specific patterns (no inline comprehensions in allow/deny, etc.) in your rules system.
________________________________________
Chapter 11 â€“ Performance Engineering (From Heuristics to Formal Bounds)
OPA is fast, but bad policies can be slow. This chapter formalizes the performance story.
________________________________________
11.1 Complexity Mental Model
Roughly:
	Lookup in objects/sets: ~O(1)
	Array iteration: O(n)
	Nested iteration: O(nÂ²) or worse
	Graph-like recursion: O(depth Ã— fan-out), potentially exponential without care
Your goal: rewrite policies such that most operations become hash lookups, not brute-force scans.
________________________________________
11.2 Expression Ordering
OPA evaluates rule bodies top to bottom, left to right within that body. Rearranging expressions can dramatically change performance.
# Good: cheap, selective checks first
deny[msg] if {
    input.method == "POST"          # cheap
    size := input.body_size         # cheap
    size > 1e6                      # cheap
    expensive_regex_check()         # expensive
}

# Bad: expensive runs for all inputs
deny[msg] if {
    expensive_regex_check()
    input.method == "POST"
}
________________________________________
11.3 Index-friendly Data Modeling
Given:
# Slow pattern
deny[msg] if {
    some u in data.users
    u.id == input.user_id
    not u.active
    msg := "User is inactive"
}
Instead, structure data.users as a map keyed by ID:
{
  "users": {
    "alice": {"id": "alice", "active": true},
    "bob":   {"id": "bob",   "active": false}
  }
}
Then:
user := data.users[input.user_id]
deny[msg] if {
    user.active == false
    msg := "User is inactive"
}
OPA can automatically index these object lookups, giving near O(1) access.
________________________________________
11.4 Avoiding Redundant Computation
Bad:
inefficient if {
    sum(numbers) > 100
    sum(numbers) < 1000
    result := sum(numbers)
}
Good:
efficient if {
    total := sum(numbers)
    total > 100
    total < 1000
    result := total
}
OPA memoizes built-ins within a query, but you still pay the call overhead and it hurts readability.
________________________________________
11.5 Comprehension Patterns
Prefer existential patterns over building large intermediate sets:
# Good
has_admin if {
    some u in users
    "admin" in u.roles
}

# Bad
admins := {u | some u in users; "admin" in u.roles}
has_admin if count(admins) > 0
________________________________________
11.6 Partial Evaluation & Compilation
Partial evaluation is like compiling away some of your logic for known inputs.
11.6 Partial Evaluation & WASM Build Modes

Partial evaluation lets OPA pre-compute parts of a policy given known inputs (e.g., config, topology) and unknown inputs (e.g., request-time data).

Two important workflows:

11.6.1 WASM Compilation (Edge / Embedded)
# Build a WebAssembly module for a specific entrypoint
opa build -t wasm -e 'data.authz.allow' policies/


-t wasm â†’ produce a WebAssembly binary.

-e 'data.authz.allow' â†’ fix the entrypoint.

Intended for:

Envoy filters

In-process SDKs (Go, Node, etc.)

Edge runtimes or sidecars.

The build process performs internal partial evaluation for the chosen entrypoint and emits an optimized WASM module.

11.6.2 General Partial Evaluation (Bundles / CLI)

For non-WASM optimization:

# Build a bundle for a specific entrypoint without WASM
opa build -e 'data.authz.allow' policies/


This produces:

An optimized bundle (policy + data),

Suitable for the standard OPA runtime, with partial eval already applied for that entrypoint.

Exploratory / ad-hoc partial evaluation:

opa eval --partial \
  -d policies/ \
  'data.authz.allow'


This:

Returns residual policy expressions capturing unknowns,

Lets you inspect how much work can be pre-computed,

Is useful for iterative tuning and performance analysis.

Summary:

opa build -t wasm ... â†’ WASM module for embedded/edge.

opa build ... â†’ optimized bundle for standard OPA.

opa eval --partial ... â†’ interactive partial eval for debugging and design.
________________________________________
Chapter 12 â€“ Formal Semantics (Doctorate-Level View)
Now we go under the hood. You donâ€™t need this to use Rego, but you do need it to design new policy frameworks, reason about correctness, or write academic work.
________________________________________
12.1 Rego as a Datalog Variant
At its core, a Rego program is a set of Horn clauses (rules) over a Herbrand universe of JSON-like terms.
	A rule:
	h(tÌ„) if {
	    bâ‚
	    ...
	    bâ‚™
	}
corresponds to:
b_1âˆ§â‹¯âˆ§b_nâ‡’h(t Ë‰)

	Some syntactic sugar (arrays, objects, comprehensions) desugar to relational forms.
Interpretation:
	An interpretation Iassigns truth values to all ground atoms (e.g., p("alice", "admin")).
	The meaning of a program Pis the least fixed point of the immediate consequence operator T_P, analogous to classical Datalog.
________________________________________
12.2 Immediate Consequence Operator & Fixpoint
Define T_Pover interpretations:
	T_P (I)= set of all heads h(t Ë‰)such that there exists a rule h(t Ë‰)â‡b_1,â€¦,b_nand all b_iare satisfied under I.
Iterative construction:
I_0=âˆ…I_(k+1)=T_P (I_k)"Eval"(P)=â‹ƒ_(k=0)^âˆ I_k

Because:
	Herbrand base is finite for a given finite data and bounded terms.
	T_Pis monotonic for stratified, positive fragments.
â†’ Fixpoint is reached in finite steps.
________________________________________
12.3 Unification & =, :=, ==
	Unification (=): find a most general unifier (MGU) that makes two terms equal.
	If both sides partially unbound, unify them structurally.
Example:
[x, "world"] = ["hello", y]
	MGU: {xâ†¦"hello",yâ†¦"world"}.
	Assignment (:=): one-way binding; fails if variable is already bound to a different value.
	Equality (==): no variable binding; pure comparison.
In implementation, OPA uses a mixture of:
	Unification-like semantics to explore bindings.
	Assignments and comparisons for clarity and performance in v1 syntax.
________________________________________
12.4 Negation-as-Failure & Stratification
Rego uses NAF (Negation-as-Failure):
not p(X)
means: â€œit is not provable that p(X) holdsâ€.
Formally:
"Eval"(P)âŠ¨"not " p(t)" â€Š"âŸº" â€ŠEval"(P)âŠ¨Ì¸p(t)

To avoid paradoxes (like p :- not p), Rego effectively works in the space of stratified programs (or well-founded semantics):
	Build a dependency graph between predicates (rules).
	Require that cycles with negation are disallowed or handled carefully.
This is why variables in negated expressions must be grounded elsewhere; otherwise, the semantics become ill-defined.
________________________________________
12.5 Partial vs Complete Rules: Semantic Interpretation
	Complete rule (one final value):
	max_memory := 4 if ...
	max_memory := 8 if ...
	default max_memory := 1
Interpreted as a function max_memory : Input â†’ Scalar such that:
	If multiple definitions apply and yield same value â†’ OK.
	If they yield different values â†’ conflict (no model).
	Partial rules (sets/objects):
	deny[msg] if ...
	deny[msg] if ...
Interpreted as:
deny={msgâˆ£âˆƒ" body s.t." bodyâ‡’msg}

The semantics is set union of instances.
________________________________________
12.6 Complexity of Evaluation
Let:
	âˆ£Dâˆ£= size of data.
	âˆ£Iâˆ£= size of input.
	âˆ£Pâˆ£= size (number of rules/clauses) of program.
Then:
	Basic evaluation (no recursion) is polynomial in âˆ£Dâˆ£+âˆ£Iâˆ£.
	General Datalog with negation can be EXPTIME-complete in the worst case, but OPA:
	Forbids or discourages patterns that would lead to blow-ups.
	Optimizes with indexing, partial evaluation, grounding.
Rule-of-thumb:
	Flattened, non-recursive Rego with bounded comprehensions behaves like complex SQL queries in terms of complexity.
	Recursive policies (e.g., graph reachability) behave like graph algorithms.
________________________________________
12.7 Partial Evaluation Semantics
Given:
	Program P.
	Known input fragment KâŠ†(data,input).
Define the partial evaluation operator:
PE(P,K)â†’P^'

such that for all remaining inputs U:
"Eval"(P^',U)â‰¡"Eval"(P,KâˆªU)

Key points:
	P^'is smaller and more specialized.
	OPA uses this to generate WASM or pre-compiled forms that execute efficiently for fixed queries.

Chapter 13 â€“ Multi-Layer Policy Architecture
Multi-layer policy architecture is how you scale from one clever Rego file to hundreds of policy owners, bundles, and tenants without descending into chaos.
At scale, you need:
â€¢	Layers: global â†’ domain â†’ team â†’ tenant.
â€¢	Ownership metadata: who owns what, and how severe is it.
â€¢	Override semantics: how do layers combine, and who wins on conflict.
________________________________________
13.1 Layer Model: Global â†’ Domain â†’ Team â†’ Tenant
Think of policies as a stack of overlays:
1.	Global Baseline (Organization Level)
o	Owned by: security/compliance.
o	Guarantees non-negotiable invariants:
ï‚§	â€œNo public S3 bucketsâ€
ï‚§	â€œAll admin actions must be auditedâ€
o	Usually has the highest precedence for denies (security wins).
2.	Domain Policies (Product / Platform Level)
o	Example domains:
ï‚§	crm.*, billing.*, identity.*.
o	Define domain-specific invariants:
ï‚§	â€œAn Opportunity must have an associated Accountâ€
ï‚§	â€œA Subscription must have a plan and billing cycleâ€
3.	Team / Service Policies
o	Local teams add guardrails and UX-level rules:
ï‚§	â€œThis API must include X-Request-Idâ€
ï‚§	â€œThis microservice cannot call that microservice directlyâ€
4.	Tenant Overlays (Customer-Specific)
o	Per-tenant exceptions and configuration:
ï‚§	â€œTenant A enforces stricter password rulesâ€
ï‚§	â€œTenant B has a special approval workflowâ€
OPA sees all of these as data + Rego modules merged into a single virtual data tree.
________________________________________
13.2 Encoding Layers in Data and Packages
One robust pattern:
â€¢	Global policies: package global.*
â€¢	Domains: package domain.<name>.*
â€¢	Teams/services: package svc.<service_name>.*
â€¢	Tenant overlays: data.tenants[tenant_id].*
Example structure:
policies/
  global/
    baseline.rego          # package global.baseline
  crm/
    authz.rego             # package domain.crm.authz
    schema.rego            # package domain.crm.schema
  svc/
    accounts.rego          # package svc.accounts.rules
  tenants/
    123/
      overrides.json       # data.tenants["123"]
    456/
      overrides.json
________________________________________
13.3 Policy Ownership Metadata
Every rule that matters should be self-describing.
You can store metadata as:
â€¢	A dedicated rule (__meta__)
â€¢	Rego annotations (via rego.metadata.rule())
â€¢	Comments (less machine-friendly)
Example:
package crm.policies.account_lifecycle

__meta__ := {
  "rule_id":  "ACCT_001",
  "owner":    "team-crm-platform",
  "service":  "accounts-api",
  "layer":    "domain",
  "severity": "BLOCK",      # BLOCK | OVERRIDE | WARN | INFO
  "version":  "1.0.0",
  "tags": ["lifecycle", "compliance"]
}

deny[msg] if {
  input.account.status == "closed"
  input.action == "reopen"
  msg := {
    "rule_id": __meta__.rule_id,
    "owner":   __meta__.owner,
    "msg":     "Closed accounts cannot be reopened",
  }
}
For global policies:
package global.network

__meta__ := {
  "rule_id":  "NET_001",
  "layer":    "global",
  "severity": "BLOCK",
  "owner":    "sec-net",
}

deny[msg] if {
  resource := input.terraform.resources[_]
  resource.type == "aws_s3_bucket"
  resource.acl == "public-read"
  msg := {"rule_id": __meta__.rule_id, "msg": "Public S3 bucket forbidden"}
}
________________________________________
13.4 Override Precedence and Combining Layers
You need a formal precedence model so people donâ€™t guess.
Think in terms of layer priority and decision semantics.
13.4.1 Priority Model
Assign numeric ranks to layers:
package policy.layers

layer_rank := {
  "global":  100,
  "domain":  80,
  "team":    60,
  "tenant":  40,
}
Now, each decision includes:
â€¢	effect: "allow" | "deny" | "override" | "warn"
â€¢	layer: "global" | "domain" | "team" | "tenant"
________________________________________
13.4.2 Decision Aggregation Pattern
Define a canonical decision document:
package decision

default result := {
  "allow": false,
  "effects": [],   # list of all hits from all layers
}

# Collect all candidate effects from all packages
effects[eff] if {
  eff := data.global.baseline.effects[_]
}

effects[eff] if {
  eff := data.domain.crm.authz.effects[_]
}

effects[eff] if {
  eff := data.svc.accounts.rules.effects[_]
}

effects[eff] if {
  tenant := input.tenant_id
  eff := data.tenants[tenant].overlays.effects[_]
}
Each eff looks like:
{
  "effect": "deny",
  "layer":  "global",
  "rule_id": "NET_001",
  "severity": "BLOCK",
  "msg": "Public S3 bucket forbidden"
}
Now: compute final decision.
result := {
  "allow": allow,
  "effects": all_effects,
} if {
  all_effects := [e | e := effects[_]]

  some deny in all_effects
  deny.effect == "deny"
  deny.severity == "BLOCK"
  allow := false
}

# Fallback: if no BLOCK denies, then allow if explicit allow exists or default rules say so.
result := {
  "allow": allow_flag,
  "effects": all_effects,
} if {
  all_effects := [e | e := effects[_]]
  not some e in all_effects { e.effect == "deny"; e.severity == "BLOCK" }

  allow_flag := some e in all_effects { e.effect == "allow" }
}
You can refine this by:
â€¢	Picking highest-ranked deny by layer rank.
â€¢	Allowing tenant to tighten, but never to weaken global invariants.
________________________________________
13.5 Tenant Overlays and Safe Customization
Tenant-specific rules should be additive and tightening, not weakening:
â€¢	Allowed:
o	Tenant can restrict their own behavior further.
â€¢	Forbidden:
o	Tenant cannot bypass global security invariants.
Pattern:
package authz

default allow := false

base_allow if {
  data.global.authz.allow
}

base_allow if {
  data.domain.crm.authz.allow
}

tenant_extra_deny[msg] if {
  tenant := input.tenant_id
  eff := data.tenants[tenant].overlays.effects[_]
  eff.effect == "deny"
  msg := eff.msg
}

allow if {
  base_allow
  not tenant_extra_deny[_]
}
This gives global â†’ domain final say on allow, and tenant extra ways to say â€œno.â€
________________________________________
Chapter 14 â€“ Observability & Audit
OPA is not only a decision engine; itâ€™s an evidence generator. Observability and audit are how you prove that decisions are:
â€¢	Correct
â€¢	Consistent
â€¢	Explainable
â€¢	Compliant with regulation
________________________________________
14.1 Decision Logs
Every OPA decision should be treatable as a replayable event:
Minimum recommended fields:
â€¢	decision_id (UUID)
â€¢	timestamp
â€¢	path (e.g., data.authz.allow)
â€¢	input_hash or input (with PII scrubbing)
â€¢	result (decision doc: allow/deny/effects)
â€¢	bundle_revision
â€¢	metrics (evaluation time, rule count)
â€¢	correlation_id (to tie into tracing)
Conceptual log:
{
  "decision_id": "3f7b9b1a-0ee2-4e52-9f39-4edb8b6a3a01",
  "timestamp": "2025-11-25T10:02:45Z",
  "path": "data.authz.allow",
  "input_hash": "sha256:abcd...",
  "result": {
    "allow": false,
    "effects": [
      {
        "effect": "deny",
        "rule_id": "ACCT_001",
        "layer": "domain",
        "msg": "Closed accounts cannot be reopened"
      }
    ]
  },
  "bundle_revision": "git:1234abcd",
  "metrics": {
    "eval_time_ns": 45321,
    "num_rules_evaluated": 37
  },
  "correlation_id": "trace-xyz-123"
}
OPA supports decision logs via configuration; your host system should stream them to:
â€¢	Kafka / Kinesis
â€¢	ELK / Loki
â€¢	Datadog / Prometheus / Grafana
________________________________________
14.2 Metrics and SLOs
To treat OPA like a production service, track at least:
â€¢	Latency:
o	p50 / p95 / p99 evaluation time.
â€¢	Throughput:
o	decisions per second.
â€¢	Decision deltas:
o	How often outcomes change after a new bundle.
â€¢	Error rate:
o	Number of evaluation failures (e.g., built-in errors in strict mode).
Define SLOs like:
â€¢	99.9% of policy decisions complete in < 10 ms.
â€¢	< 0.1% of decisions result in evaluation error.
â€¢	Decision delta after bundle rollout < 1% for stable inputs (in shadow mode).
________________________________________
14.3 Correlation IDs and Tracing
Policy evaluations rarely stand alone; theyâ€™re part of a larger request trace:
â€¢	HTTP header:
o	X-Request-Id
o	traceparent (W3C Trace Context)
â€¢	PEP should pass correlation ID in:
o	input.trace_id
o	or embed as part of input.request.headers.
Then decision logs include correlation_id, which lets you:
â€¢	Trace a single userâ€™s journey across services.
â€¢	Root-cause analyze unauthorized/denied requests quickly.
Example pattern:
package authz

default allow := false

trace_id := input.request.headers["x-request-id"]

allow if {
  # ...logic...
}

# decision doc
decision := {
  "allow": allow,
  "trace_id": trace_id,
}
________________________________________
14.4 PII and Redaction in Logs
Golden rule: logs must not become a data breach.
â€¢	Do not log entire input if it contains PII.
â€¢	Instead:
o	Log hashed fields (hash(email))
o	Log ids / foreign keys
o	Redact sensitive values (e.g., use "redacted")
Pattern:
safe_input := {
  "user_id": input.user.id,
  "tenant_id": input.tenant_id,
  "resource_id": input.resource.id,
  "action": input.action,
}
Your decision logger uses safe_input rather than raw input.
________________________________________
14.5 Reproducibility & Auditability
A compliant audit story usually needs:
â€¢	Given:
o	bundle_revision
o	policy_version
o	input (or hash + associated fixture)
â€¢	You can re-evaluate the decision and get the same result.
To achieve this:
â€¢	Store:
o	Bundle artifacts (bundle.tar.gz)
o	Manifest metadata (revision, version)
o	Decision logs + input fixtures (or deterministic reconstruction)
â€¢	Avoid:
o	Non-deterministic calls in Rego (e.g., random, uncontrolled http.send)
When you must use time.now_ns or external data:
â€¢	Either:
o	Snapshot it in the input used to evaluate.
o	Or store enough context to reconstruct.
________________________________________
Chapter 15 â€“ Stateful & Temporal Extensions
OPA itself is stateless: each query sees input and data as immutable snapshots. Yet many policies are stateful or temporal:
â€¢	Rate limits (N requests per unit time)
â€¢	â€œNo more than 5 failed logins in 10 minutesâ€
â€¢	â€œThis migration must be rolled out only after all canaries passâ€
The trick: Move state and time into data + input, not inside Rego.
________________________________________
Stateful & Temporal Extensions

OPA is logically stateless: every evaluation sees a snapshot of policy + data. Stateful or temporal behaviors must be modeled via external systems that write to data or pass state through input.

15.1 External State for Rate-Limiting & Anomaly Detection

Example of externally managed login counts:

# External system populates:
# data.state.login_counts = {
#   "alice": {"last_5m": 12, "last_1h": 42},
#   "bob":   {"last_5m": 2,  "last_1h":  8},
# }

package authz

too_many_logins[user] if {
    counts := data.state.login_counts[user]
    counts.last_5m > 10
}


Key properties:

OPA never mutates data.state.login_counts.

A separate component (stream processor, cron job, gateway) periodically:

reads raw events (e.g., login attempts),

aggregates them (windowed counts),

publishes a new snapshot to:

a bundle,

or an in-memory structure via the OPA Go SDK,

or a shared cache that OPA reads from.

Think of the pattern:

Events â†’ (Kafka / Kinesis / PubSub / Logs)

Aggregator â†’ (Flink / custom job / Lambda)

State Snapshot â†’ (bundle / data.state.*)

OPA Policy â†’ reads data.state.* as a pure input.

OPA remains a pure decision engine; all state transitions happen outside.
________________________________________
15.2 Temporal Logic Using time.*
OPA has:
â€¢	time.now_ns()
â€¢	time.parse_ns(layout, string)
â€¢	time.clock(ns) and time.date(ns)
â€¢	time.weekday(ns)
Patterns:
1.	Business hours
2.	package business
3.	
4.	within_business_hours if {
5.	  now := time.now_ns()
6.	  [hour, _, _] := time.clock(now)
7.	  hour >= 9
8.	  hour < 17
9.	}
10.	Sliding window from event log in input
Suppose input.events contains last 1 hour of events (pre-filtered by upstream system):
package limits

default allow := true

deny[msg] if {
  now := input.now_ns
  cutoff := now - 5 * 60 * 1e9  # last 5 minutes in ns

  # events: [{"ts": ..., "action": "login_failure", "user": "alice"}, ...]
  recent_failures := {e |
    some e in input.events
    e.user == input.user_id
    e.action == "login_failure"
    e.ts >= cutoff
  }

  count(recent_failures) > 5
  msg := "Too many recent login failures"
}
OPA sees only a subset; the window is curated by your stateful event pipeline.
________________________________________
15.3 Event-Driven Architectures with OPA
Typical pattern:
1.	Events flow into Kafka / Kinesis.
2.	A stream processor:
o	Maintains aggregates:
ï‚§	counts, sums, last-seen times, sliding windows.
o	Writes materialized state to:
ï‚§	Redis, DB, or data-bundles for OPA.
3.	OPA uses that state to decide:
o	Allow or deny new events.
o	Trigger downstream actions/alerts.
OPA remains pure â€” no long-lived state, no hidden mutable variables.
________________________________________
15.4 Time-Scoped Exceptions
Sometimes you want:
â€¢	â€œAllow this temporary override until 2025-12-31.â€
Pattern:
package overrides

temporary_allow if {
  o := data.overrides[input.resource_id]
  now := time.now_ns()
  expiry := time.parse_rfc3339_ns(o.expires_at)
  now < expiry
}
You encode exceptions in data.overrides, with explicit expiration timestamps. This keeps temporal logic in data, not code.
________________________________________
Chapter 16 â€“ Data Policy Models (GraphQL, APIs, Data Filtering)
OPA is particularly strong for data access policies because Rego is JSON-native. This chapter focuses on query-shaped inputs like GraphQL and REST.
________________________________________
16.1 GraphQL AST Policies
When a GraphQL query enters your gateway, you can:
1.	Parse it into an AST.
2.	Send AST + user context to OPA.
3.	Enforce:
o	Field-level authorization.
o	Query depth/width limits.
o	Allowed operations.
Example input (simplified):
{
  "user": {"id": "alice", "roles": ["user"]},
  "operation": "query",
  "query": {
    "name": "GetCustomer",
    "fields": [
      {"path": ["customer", "email"]},
      {"path": ["customer", "creditCardNumber"]}
    ]
  }
}
Policy:
package gql.authz

default allow := false
default violations := []

# data.gql.allowed_fields = {
#   "user": {
#     "customer": ["id", "name", "email"]
#   },
#   "admin": {
#     "customer": ["*", "creditCardNumber"]
#   }
# }

role := r if {
  r := input.user.roles[_]
}

# Check each requested field
violations contains v if {
  f := input.query.fields[_]
  path := f.path        # ["customer", "creditCardNumber"]

  resource := path[0]
  field := path[1]

  not field_allowed(role, resource, field)

  v := {
    "path": path,
    "msg": sprintf("Field %v not allowed for role %v", [path, role]),
  }
}

field_allowed(role, resource, field) if {
  allowed := data.gql.allowed_fields[role][resource]
  allowed[_] == "*"  # wildcard
}

field_allowed(role, resource, field) if {
  allowed := data.gql.allowed_fields[role][resource]
  field in allowed
}

allow if {
  count(violations) == 0
}
________________________________________
Data Policy Models & GraphQL Costing

This chapter covers structural data policies and cost-based models, especially for GraphQL.

16.2 Field Cost Calculation (Corrected array.concat)

Suppose you maintain per-field costs in data.gql.field_costs:

# Example:
# data.gql.field_costs = {
#   "Query.users": 1,
#   "Query.users.email": 2,
#   "Query.users.orders": 3,
# }


You want to compute a cost for each field given its path and leaf name.

# field_cost([path, field]) := c
#   path  = ["Query", "users"]
#   field = "email"
#   full  = "Query.users.email"

field_cost([path, field]) := c if {
    full := concat(".", array.concat(path, [field]))
    c := data.gql.field_costs[full]
}


Corrections and nuances:

Use array.concat(path, [field]), not a non-existent append builtin.

array.concat([1, 2], [3]) = [1, 2, 3].

If either argument is null or non-array, OPA throws a type error, so in more defensive code:

safe_field_cost([path, field]) := c if {
    is_array(path)
    is_string(field)
    full := concat(".", array.concat(path, [field]))
    c := data.gql.field_costs[full]
}


This function can be used inside a comprehension that walks a GraphQL AST:

total_cost := sum({ c |
    some i
    field := input.gql.fields[i]
    path  := field.path       # e.g., ["Query", "users"]
    name  := field.name       # e.g., "email"
    c     := field_cost([path, name])
})


Here you get:

A compositional cost model (paths + leaves).

Defensive concatenation.

A clean hook for enforcing query limits:

deny_reason := sprintf("GraphQL query too expensive: cost=%v", [total_cost]) if {
    total_cost > data.gql.max_cost
}

________________________________________
16.3 REST / SQL / Data Filtering
For REST APIs, you can:
1.	Treat the request as input: method, path, query params, body.
2.	Output a filter document:
3.	{
4.	  "where": {
5.	    "tenant_id": "tenant-123",
6.	    "visibility": ["public", "shared_with_user"]
7.	  }
8.	}
9.	The service uses that filter to generate SQL.
Example:
package datafilter

default filter := {}

filter := {
  "tenant_id": input.tenant_id,
  "allowed_status": allowed_statuses,
} if {
  user := input.user
  allowed_statuses := statuses_for(user)
}

statuses_for(user) := {"active", "pending"} if {
  "admin" in user.roles
}

statuses_for(user) := {"active"} if {
  not "admin" in user.roles
}
This pattern:
â€¢	Keeps data access rules central.
â€¢	Allows multiple services to enforce the same logic.
________________________________________
Chapter 17 â€“ LLM & Agentic Integration with OPA
LLMs are good at generating Rego, OPA is good at executing and verifying Rego. Together they form:
â€œAI drafts policy, OPA and tests keep it safe.â€
________________________________________
17.1 The Agentic Workflow
Canonical pipeline:
1.	Requirements in natural language:
o	â€œAPI keys must not be visible in logsâ€
o	â€œAdmin role modifications require approvalâ€
2.	LLM drafts:
o	Rego module.
o	Test suite (_test.rego).
o	Metadata (owner, rule_id).
3.	Static checks:
o	opa fmt
o	Regal lint
o	opa check --strict
4.	Dynamic checks:
o	opa test (unit + integration tests).
o	Fuzz/Golden tests for critical policies.
5.	Human review:
o	Security / Policy engineers review diff, semantics.
6.	Bundle build & rollout:
o	Standard policy SDLC.
OPA becomes the execution and verification back-end for LLM-authored policy.
________________________________________
17.2 Guardrails for LLM-Generated Rego
When you let an LLM write Rego, you must:
â€¢	Enforce style & safety:
o	Modern syntax only (import rego.v1 or future.keywords).
o	No http.send in production rules (unless explicitly allowed).
o	No secrets in code.
o	Type guards for all input.* references.
â€¢	Require tests:
o	At least one positive and one negative case.
o	Use with overrides instead of real network/time.
You can encode this as Rego that reviews Rego:
â€¢	Use rego.metadata.chain() and AST analysis to enforce rules.
â€¢	Or use external tools (Regal) plus your own AST/grep rules.
________________________________________
17.3 â€œPolicy Copilotâ€ Pattern
A typical agentic stack:
1.	Authoring agent:
o	Generates initial Rego module + tests from description and examples.
2.	Critic agent:
o	Reads module, runs static analysis (Regal messages, opa check).
o	Suggests improvements and simplifications.
3.	Tester agent:
o	Proposes additional tests (edge cases, negative paths).
o	Extends _test.rego.
4.	Reviewer agent:
o	Summarizes behavior in human language.
o	Flags risky constructs, ambiguous cases.
5.	Bundle builder:
o	Once human approves, compiles into bundle artifact.
OPA is the deterministic core all these agents orbit around.
________________________________________
17.4 LLM Self-Checking with Rego
LLMs can call OPA during prompt execution:
â€¢	Use examples like:
o	â€œWrite a policy such that opa eval returns allow=true for these inputs and false for others.â€
â€¢	LLM loops:
1.	Generate candidate Rego.
2.	Invoke opa test programmatically.
3.	If tests fail, update policy and try again (up to N iterations).
4.	Present final Rego + test report.
This turns Rego into a ground truth oracle inside an agentic system.
________________________________________
Chapter 18 â€“ Rego Cheat Sheet (Condensed)
This chapter is intentionally tight â€“ itâ€™s the 2-page desk reference.
________________________________________
18.1 Core Rule Types
Type	Syntax	Example
Boolean	name if { ... }	allow if { is_admin }
Complete	name := value if { ... }	max_conns := 10 if is_admin
Partial Set	name contains x if { ... }	deny contains msg if { ... }
Partial Obj	name[key] := value if { ... }	roles[user] := role if { ... }
Function	f(x) := y if { ... }	double(x) := x * 2
Default	default name = value	default allow = false
________________________________________
18.2 Assignments & Comparisons
â€¢	:= â€“ assignment (one-way)
â€¢	== â€“ equality (no binding)
â€¢	= â€“ unification (binds if unbound, else compares)
Examples:
x := 10               # assignment
ok if x == 10         # comparison

[x, "world"] = ["hello", y]
# => x = "hello", y = "world"
________________________________________
18.3 Collections
â€¢	Array: [1, 2, 3]
â€¢	Set: {1, 2, 3} (unordered, unique)
â€¢	Object: {"k": 1, "v": 2}
Special:
â€¢	Empty set: `{}` (not `set()`, which is a type conversion function requiring an argument)
â€¢	Empty object: `{}`

**Important:** `set()` is a type conversion function (e.g., `set([1,2,3])` â†’ `{1,2,3}`) and requires an argument. To create an empty set, use `{}` directly. Using `set()` without arguments will cause a runtime error.
________________________________________
18.4 Iteration
Implicit:
arr[_]               # all values
obj[k]               # binds k to each key
set[v]               # binds v to each member
Explicit with some ... in:
some x in arr        # values
some i, x in arr     # index, value
some k, v in obj     # key, value
some v in set        # members
________________________________________
18.5 Quantifiers
â€¢	Existential: some x in xs { ... }
â€¢	Universal:
o	Using every:
o	all_valid if {
o	  every x in xs {
o	    x.valid == true
o	  }
o	}
o	Or via negation:
o	all_valid if not any_invalid
o	any_invalid if {
o	  some x in xs
o	  not x.valid
o	}
________________________________________
18.6 Negation
not cond = â€œcannot prove cond.â€
Safety: variables in cond must be bound beforehand.
deny if {
  user := input.user
  not blacklisted[user]
}
________________________________________
18.7 Built-in Highlights
â€¢	Aggregates: count, sum, max, min
â€¢	Strings: concat, contains, startswith, endswith, split, replace
â€¢	Regex: regex.match, regex.split
â€¢	JSON: json.marshal, json.unmarshal
â€¢	Time: time.now_ns, time.parse_rfc3339_ns, time.clock
â€¢	Crypto: crypto.sha256, io.jwt.*
________________________________________
18.8 Testing
â€¢	Tests: package ending in _test, rules starting with test_.
â€¢	Use with to override input, data, or built-ins.
test_admin_can_read if {
  authz.allow with input as {"user": "alice", "role": "admin"}
}
Run:
opa test .
________________________________________
18.9 Best Practices (Ultra Condensed)
â€¢	Always opa fmt and lint.
â€¢	Use modern syntax (import rego.v1 or future.keywords).
â€¢	Prefer sets/objects for membership tests.
â€¢	Avoid inline comprehensions in complex allow/deny.
â€¢	Use helper rules with clear names.
â€¢	Always have tests for deny/allow semantics.
________________________________________
Chapter 19 â€“ Glossary (Rigorous)
Alphabetical list of core terms.
________________________________________
ABAC (Attribute-Based Access Control)
Access model where decisions are based on attributes of subject, resource, action, and environment, not just roles.
Allow / Deny (Effects)
Canonical authorization decision outcomes. Frequently modeled via Rego rules like allow and deny or decision documents with effects.
AST (Abstract Syntax Tree)
Tree representation of parsed input (e.g., GraphQL query), often passed to OPA as input for fine-grained policies.
Baseline Policy (Global Baseline)
Organization-wide invariant policy layer that lower layers cannot override or weaken (e.g., â€œNo public S3 bucketsâ€).
Bundle
A versioned tarball containing Rego policies, data, and a .manifest file. Used by OPA to load and update policies in production.
Complete Rule
A Rego rule that defines a single final value (e.g., max_conns := 10 or allow := true). Multiple definitions that produce different values for the same input cause conflicts.
ConstraintTemplate (Gatekeeper)
Kubernetes CRD that defines reusable OPA policies for Gatekeeper. Users instantiate constraints based on templates.
Correlation ID
Identifier used to tie together logs and traces across systems, included in OPA decision logs for observability.
Data (in OPA)
Persistent, relatively static information (loaded from bundles or in-memory), accessed as data.*. May mirror configuration, schemas, user roles, etc.
Decision Document
The JSON result of an OPA query (e.g., data.authz.allow or a more complex document with allow, deny, effects, risk_score).
Decision Log
Structured record of each OPA evaluation: includes path, input (or hash), result, metrics, and bundle revision, used for audit and observability.
Datalog
A subset of Prolog used for declarative logic programming, without complex function symbols. Rego is inspired by Datalog and extends it with JSON-like structures.
Deny Rule
A partial rule (often deny[msg] or deny contains msg) that accumulates violation messages, typically used in compliance and validation policies.
Effect
The semantic outcome of a policy evaluation (e.g., "allow", "deny", "warn", "override"), often encoded in decision documents.
Fixpoint
A stable interpretation of a logic program where applying the immediate consequence operator (deriving new facts) produces no new facts. Regoâ€™s semantics can be described via least fixpoints.
Future Keywords
The future.keywords import (Rego v0.x) that enables newer language constructs like if, in, contains, every. In OPA 1.0+ this is replaced by import rego.v1.
Global Baseline
See Baseline Policy: global layer of policies applied to all services/tenants, usually with highest precedence for security.
GraphQL Policy
Policy that operates on GraphQL queries represented as AST; can enforce field-level auth, query depth, or cost.
HTTP Sidecar
Deployment pattern where OPA runs as a sidecar container next to a service, receiving authorization queries over localhost.
Input (in OPA)
Per-request JSON document provided by the caller to OPA, containing details like user, action, resource, HTTP request, etc. Accessed as input.*.
LLM (Large Language Model)
Neural network model (like ChatGPT) used to generate or refactor Rego; OPA then validates and executes resulting policies.
NAF (Negation-as-Failure)
Logic programming semantics where not p(X) means â€œp(X) cannot be proven.â€ Used in Rego for negation.
OPA (Open Policy Agent)
General-purpose policy decision engine that evaluates Rego policies against JSON inputs and data.
PDP (Policy Decision Point)
Component that computes policy decisions (e.g., OPA).
PEP (Policy Enforcement Point)
Component that enforces decisions (e.g., API gateway, Kubernetes admission controller).
Partial Evaluation (PE)
Technique where OPA specializes policies with respect to known input and data, producing an optimized, often smaller program or WASM artifact.
Partial Rule
A Rego rule that defines members of a virtual set or object incrementally (e.g., deny[msg] or roles[user] := role).
Rego
OPAâ€™s declarative policy language, inspired by Datalog and designed for reasoning over JSON-like documents.
Regal
A dedicated linter for Rego, enforcing style and correctness rules beyond opa fmt.
Rule Conflict
Runtime error when multiple complete rules or function rules with the same name and arguments produce different values.
Schema (JSON Schema)
Formal type definition for JSON documents. OPA can use schemas to perform type checking on input or data.
Sidecar
Deployment pattern where OPA runs alongside an application in the same Pod/host, reducing network latency for policy queries.
Stateful Policy
Policy whose decision depends on past events or accumulated state. Implemented in OPA by passing state snapshots as data or input, not by mutability in Rego.
Stratification
Property of a logic program whereby cycles through negation are avoided, enabling well-defined semantics for negation-as-failure.
Temporal Policy
Policy that involves time (e.g., deadlines, windows, schedules), typically implemented with time.* built-ins and time-stamped state.
Tenant Overlay
Per-tenant policy or configuration that tightens (but does not weaken) global/domain rules, often stored under data.tenants[tenant_id].
Virtual Document
A Rego rule or package that behaves like a JSON document when queried (e.g., data.authz.allow), although it is computed on demand rather than stored.
WASM (WebAssembly)
Portable binary format that can run Rego policies compiled from OPA in multiple environments (browsers, proxies, services).
With (Keyword)
Rego keyword that allows overriding input, data, or built-ins for the scope of an expression; heavily used in testing and mocking.
Zero-Trust Architecture
Security model where no implicit trust is granted to assets or user accounts based solely on network location; OPA policies often implement zero-trust authorization logic.


Chapter 3 â€“ Evaluation Flow (Diagram)
3.X Evaluation Flow: From Request to Decision

The full decision path for a typical OPA evaluation looks like this:

flowchart LR
    A[Client / Service] -->|HTTP/SDK| B[OPA]
    B --> C[Parse & Compile Policies]
    C --> D[Load Data Bundles]
    D --> E[Evaluate Query]
    E --> F[Decision Document]

    subgraph POLICIES & DATA
        C
        D
    end

    subgraph INPUTS
        B
    end

    F -->|JSON Response| A


A more detailed view that includes partial evaluation and decision logging:

flowchart TD
    R[Request: input] --> OPA[OPA Engine]

    subgraph Policy Lifecycle
        P[Parse Rego] --> Q[Compile to IR]
        Q --> PE[Optional: Partial Eval]
    end

    OPA --> P
    PE --> D1[Optimized Policy Set]

    subgraph Data Layer
        B1[Bundles] --> LD[Load Data into data.*]
        DS[Dynamic Data APIs] --> LD
    end

    LD --> EV[Evaluate Query]
    D1 --> EV
    R --> EV

    EV --> RES[Decision Document]
    EV --> LOG[Decision Log Event]

    RES --> SVC[Caller / Service]
    LOG --> COL[Log Collector / Sidecar] --> OBS[SIEM / APM / Data Lake]


Narrative:

Policies are parsed and compiled once; optional partial evaluation moves static work out of the hot path.

Data from bundles and dynamic sources is loaded into data.*.

Each incoming request passes input + compiled policies + current data snapshot into the evaluator.

The evaluator returns a structured decision document and emits decision logs for observability and audits.

Chapter 8 â€“ Deployment Topologies (Sidecar vs Central vs Embedded)
8.X Topology Overview Diagram

OPA can be deployed in three canonical modes: sidecar, central service, and embedded.

flowchart LR
    subgraph Sidecar Mode
        A1[App Pod] --- O1[OPA Sidecar]
    end

    subgraph Central Service
        A2[Apps / Gateways] --> O2[OPA Cluster]
    end

    subgraph Embedded Library
        A3[App Process with OPA SDK]
    end

8.X.1 Sidecar Mode
flowchart LR
    SVC[Service Container] -->|localhost:8181 /v1/data/...| OPA[OPA Sidecar]

    B[BUNDLE Server] --> OPA


Each app pod has its own OPA.

Low latency (localhost).

Good for microservices and per-tenant tuning.

8.X.2 Central Policy Service
flowchart LR
    GW[API Gateway] -->|batched queries| OPA_CLUSTER[Central OPA]
    AUTH[IdP / Token Service] --> GW
    B[BUNDLE Server] --> OPA_CLUSTER


One or a few OPA instances serve many clients.

Great for shared policies and simple clients (like Nginx, legacy apps).

8.X.3 Embedded OPA
flowchart LR
    APP[Application Process] -->|in-process call| LIB[OPA SDK / WASM]
    B[BUNDLE Source] --> APP


OPA compiled to WASM or linked via Go library.

No extra HTTP hop; ideal for edge, FaaS, or latency-critical paths.

Chapter 13 â€“ Multi-Layer Policy Architecture Visualization
13.X Multi-Layer Policy Stack
flowchart TB
    G[Global Layer\n(org-wide baselines)] --> D[Domain Layer\n(product / region)]
    D --> T[Team Layer\nservice / app]
    T --> N[Tenant Layer\ncustomer-specific]

    N --> Q[Final Decision]


Conceptual flow:

Global: Non-negotiable baselines (e.g., MFA required, PII rules, legal holds).

Domain: Variants per product/region (e.g., EU vs US data rules).

Team: Service-specific routes/resources (e.g., /billing/* vs /analytics/*).

Tenant: Overrides and feature flags per customer (e.g., stricter IP allowlists).

13.X.1 Layered Evaluation Example
package authz

default allow := false

# Global: no public write operations
global_deny[reason] if {
    input.method == "POST"
    input.path == [ "public", _ ]
    reason := "Global: public writes forbidden"
}

# Domain: EU requires additional consent
domain_deny[reason] if {
    input.region == "eu"
    not input.user.consented
    reason := "Domain(EU): consent required"
}

# Team: service-specific checks
team_deny[reason] if {
    input.service == "billing"
    not input.user.roles[_] == "billing_admin"
    reason := "Team(Billing): admin role required"
}

# Tenant: per-tenant overrides
tenant_allow[reason] if {
    input.tenant == "tenant-123"
    input.path == ["beta", "feature-x"]
    reason := "Tenant override: feature-x beta allow"
}

deny[reason] := reason if {
    some r
    r := global_deny[r]  # global always first
} or {
    some r
    r := domain_deny[r]
} or {
    some r
    r := team_deny[r]
}

allow := true if {
    count(deny) == 0
    some r
    r := tenant_allow[r]  # tenant can only *widen* within guardrails
}


This pattern makes layer provenance explicit and traceable.

Chapter 14 â€“ Decision Log Flow Diagram
14.X Decision Log Pipeline
flowchart LR
    REQ[Incoming Request] --> OPA[OPA]
    OPA --> DEC[Decision Response]
    OPA --> LOG[Decision Log JSON]

    LOG --> COL[Log Collector / Sidecar]
    COL --> BUS[Message Bus / Stream]
    BUS --> SIEM[SIEM / Security Lake]
    BUS --> APM[APM / Metrics]
    BUS --> DWH[Data Warehouse]


Typical fields in the decision log:

input (possibly redacted)

result (decision document)

path / query

labels (instance, version, tenant)

metrics (eval time, number of rules evaluated)

This pipeline supports:

Real-time alerting (SIEM / SOC).

Dashboards (latency, volume, error rates).

Audit trails (who allowed what, when, and why).

Chapter 5 â€“ Real-World Comprehension Examples
5.X Nested Comprehension with Filtering

Scenario: You have data.resources listing projects and environments, and you want all production services owned by a user.

package resources

# data.resources.projects = [
#   {
#     "name": "proj-a",
#     "services": [
#       {"name": "svc-1", "env": "prod", "owners": ["alice"]},
#       {"name": "svc-2", "env": "dev",  "owners": ["bob"]}
#     ]
#   },
#   {
#     "name": "proj-b",
#     "services": [
#       {"name": "svc-3", "env": "prod", "owners": ["alice", "carol"]}
#     ]
#   }
# ]

prod_services_owned_by(user) := result {
    result := [
        {
            "project": proj.name,
            "service": svc.name,
            "env": svc.env
        }
        |
        proj := data.resources.projects[_]
        svc := proj.services[_]

        svc.env == "prod"
        svc.owners[_] == user
    ]
}


Usage:

alice_prod := prod_services_owned_by("alice")


This returns:

[
  {"project": "proj-a", "service": "svc-1", "env": "prod"},
  {"project": "proj-b", "service": "svc-3", "env": "prod"}
]


Key features:

Two nested comprehensions (projects[_], services[_]).

Inline filtering by environment and ownership.

Structured result objects built inside the comprehension.

Chapter 6 â€“ End-to-End JWT Validation Workflow
6.X Full JWT Validation Example

Complete pattern combining decode, verify, and claim checks.

package authz.jwt

# Configuration in data.jwt:
# data.jwt = {
#   "issuer": "https://issuer.example.com/",
#   "audience": "my-api",
#   "jwks": { ... }  # if using embedded JWKS
# }

default allow := false

allow if {
    token := input.headers.authorization
    startswith(token, "Bearer ")

    raw := substring(token, count("Bearer "), -1)

    # Decode (header, payload, signature)
    [header, payload, signature] := io.jwt.decode(raw)

    verify_signature(raw)
    verify_standard_claims(payload)
    verify_custom_claims(payload)
}

verify_signature(raw) if {
    # For symmetric key:
    # verified := io.jwt.verify_hs256(raw, data.jwt.hmac_secret)
    # verified == true

    # For asymmetric key w/ JWKS:
    valid := io.jwt.verify_rs256(raw, data.jwt.jwks)
    valid == true
}

verify_standard_claims(payload) if {
    # iss
    payload.iss == data.jwt.issuer

    # aud (can be string or array) â€“ normalize to array
    aud := payload.aud
    (
        is_string(aud)  ; aud_array := [aud]
    ) or (
        is_array(aud)   ; aud_array := aud
    )

    some i
    aud_array[i] == data.jwt.audience

    # exp (timestamp in seconds since epoch)
    now := time.now_ns() / 1000000000
    payload.exp > now
}

verify_custom_claims(payload) if {
    # Example: require email_verified
    payload.email_verified == true

    # Scope-based check
    some i
    payload.scope[i] == "read:orders"
}


This example is realistic enough to drop into an API gateway or backend service.

Chapter 9 â€“ Full Bundle Structure with Manifest
9.X Bundle Layout Example

A typical bundle layout on disk:

bundle/
â”œâ”€â”€ .manifest
â”œâ”€â”€ policies/
â”‚   â”œâ”€â”€ authz.rego
â”‚   â”œâ”€â”€ jwt.rego
â”‚   â””â”€â”€ resources.rego
â””â”€â”€ data/
    â”œâ”€â”€ config.json
    â””â”€â”€ tenants/
        â”œâ”€â”€ tenant-1.json
        â””â”€â”€ tenant-2.json

9.X.1 Example .manifest File
{
  "revision": "2025-11-25T10:00:00Z-abc123",
  "roots": [
    "authz",
    "jwt",
    "config",
    "tenants"
  ]
}


Meaning:

revision is an opaque version string for debugging/rollback.

roots tell OPA which prefixes in data this bundle owns:

authz â†’ data.authz.* (from authz.rego)

jwt â†’ data.jwt.* (if any data)

config â†’ data.config.* (from data/config.json)

tenants â†’ data.tenants.* (from data/tenants/*.json)

You can layer bundles by:

Using disjoint roots (e.g., authz/ vs pricing/).

Or orchestrating versioning in the bundle distribution system.

Chapter 13 â€“ Multi-Tenant Decision Aggregation (End-to-End)
13.Y Multi-Tenant Aggregated Decision Document

Goal: build a decision document that exposes per-layer decisions and the final result for a multi-tenant system.

package authz.multi_tenant

default allow := false

# Layer rules return {allow: bool, reasons: [string]}
global_decision := {"allow": allow, "reasons": reasons} {
    deny_reasons := {r |
        some r
        r := global_deny[r]
    }
    reasons := sort(deny_reasons)
    allow := count(deny_reasons) == 0
}

domain_decision := {"allow": allow, "reasons": reasons} {
    deny_reasons := {r |
        some r
        r := domain_deny[r]
    }
    reasons := sort(deny_reasons)
    allow := count(deny_reasons) == 0
}

tenant_decision := {"allow": allow, "reasons": reasons} {
    allow_reasons := {r |
        some r
        r := tenant_allow[r]
    }
    reasons := sort(allow_reasons)
    allow := count(allow_reasons) > 0
}

# Final decision aggregates the layers
decision := {
    "global": global_decision,
    "domain": domain_decision,
    "tenant": tenant_decision,
    "final": {
        "allow": final_allow,
        "source": final_source
    }
} {
    not global_decision.allow
    final_allow := false
    final_source := "global"
} {
    global_decision.allow
    not domain_decision.allow
    final_allow := false
    final_source := "domain"
} {
    global_decision.allow
    domain_decision.allow
    tenant_decision.allow
    final_allow := true
    final_source := "tenant"
} {
    global_decision.allow
    domain_decision.allow
    not tenant_decision.allow
    final_allow := true
    final_source := "domain/global"
}


Clients now get a rich decision document:

{
  "global": {"allow": true, "reasons": []},
  "domain": {"allow": true, "reasons": []},
  "tenant": {"allow": true, "reasons": ["Tenant override: feature-x beta"]},
  "final": {"allow": true, "source": "tenant"}
}

Chapter 16 â€“ Complete GraphQL Authorization System
16.X GraphQL Schema, AST, and Field-Level Auth

Assume:

API gateway parses GraphQL into an AST and passes it in input.gql.

Schema-driven config is in data.gql.

Example config:

{
  "field_costs": {
    "Query.users": 1,
    "Query.users.email": 2,
    "Query.users.orders": 3
  },
  "max_cost": 20,
  "roles": {
    "Query.users": ["admin", "support"],
    "Query.users.email": ["admin"],
    "Query.users.orders": ["admin", "billing"]
  }
}


Rego module:

package gql.authz

import future.keywords.in

default allow := false

# input.gql example:
# {
#   "operations": [
#     {
#       "type": "query",
#       "root": "Query",
#       "fields": [
#         {
#           "path": ["Query", "users"],
#           "name": "users",
#           "subfields": [
#             {"path": ["Query", "users", "email"], "name": "email"},
#             {"path": ["Query", "users", "orders"], "name": "orders"}
#           ]
#         }
#       ]
#     }
#   ],
#   "user": {
#     "id": "alice",
#     "roles": ["support"]
#   }
# }

user_roles := input.gql.user.roles

# Check if user has required role for a field
field_allowed([path, field]) if {
    full := concat(".", array.concat(path, [field]))
    required := data.gql.roles[full]
    some r in user_roles
    r in required
}

field_cost([path, field]) := c if {
    full := concat(".", array.concat(path, [field]))
    c := data.gql.field_costs[full]
}

field_cost([path, field]) := 0 if {
    full := concat(".", array.concat(path, [field]))
    not data.gql.field_costs[full]
}

# Flatten all selected fields (including nested subfields)
all_fields := result {
    result := [
        {"path": f.path, "name": f.name} |
        op := input.gql.operations[_]
        f := op.fields[_]
    ] ++ [
        {"path": sf.path, "name": sf.name} |
        op := input.gql.operations[_]
        f := op.fields[_]
        sf := f.subfields[_]
    ]
}

total_cost := sum({ c |
    f := all_fields[_]
    c := field_cost([f.path, f.name])
})

too_expensive if {
    total_cost > data.gql.max_cost
}

unauthorized_fields[full] if {
    f := all_fields[_]
    not field_allowed([f.path, f.name])
    full := concat(".", array.concat(f.path, [f.name]))
}

allow if {
    not too_expensive
    count(unauthorized_fields) == 0
}

decision := {
    "allow": allow,
    "total_cost": total_cost,
    "unauthorized_fields": unauthorized_fields
}


This gives:

Field-level auth (field_allowed).

Cost-based limiting (total_cost, too_expensive).

A rich decision document for clients.

Chapter 17 â€“ Full LLM â†’ OPA Workflow with Validation
17.X Architecture Diagram
flowchart LR
    REQ[User / Dev Describes Policy] --> LLM[LLM / Copilot]
    LLM --> CAND[Candidate Rego Policy]
    CAND --> PIPE[Validation Pipeline]
    PIPE -->|fail| FEEDBACK[Errors / Suggestions]
    PIPE -->|pass| BUNDLE[Signed Policy Bundle]
    BUNDLE --> OPA[OPA Deployments]

17.X.1 Validation Pipeline Steps

Syntactic checks: opa fmt, opa check.

Unit tests: opa test.

Static analysis: internal style & safety rules.

Staging OPA: run candidate policy against recorded traffic (shadow mode).

Human review for MAD (Major Action/Decision) changes.

17.X.2 Example â€œLLM-Writtenâ€ Policy + Tests

Candidate Rego (generated by LLM):

package authz.orders

default allow := false

# Allow read if user owns order or is admin
allow if {
    input.method == "GET"
    input.path == ["orders", order_id]

    some order
    order := data.orders[order_id]

    (
        order.owner_id == input.user.id
    ) or (
        input.user.roles[_] == "admin"
    )
}


Validation tests:

package authz.orders_test

import data.authz.orders

test_owner_can_read if {
    input := {
        "method": "GET",
        "path": ["orders", "o1"],
        "user": {"id": "alice", "roles": []}
    }
    data.orders["o1"].owner_id == "alice"

    result := orders.allow with input as input
    result == true
}

test_non_owner_cannot_read if {
    input := {
        "method": "GET",
        "path": ["orders", "o1"],
        "user": {"id": "bob", "roles": []}
    }
    data.orders["o1"].owner_id == "alice"

    result := orders.allow with input as input
    result == false
}

test_admin_can_read_any if {
    input := {
        "method": "GET",
        "path": ["orders", "o1"],
        "user": {"id": "random", "roles": ["admin"]}
    }

    result := orders.allow with input as input
    result == true
}


Pipeline actions:

Run opa fmt â†’ ensure style.

Run opa check â†’ catch unknown refs, unsafe vars.

Run opa test â†’ ensure behavior matches expectations.

Run internal checks (e.g., no input.user.is_admin == true shortcuts, no unsafe wildcards in paths).

If all pass, bundle and distribute.

Common Pitfalls: Variable Scoping & Safety
4.X Common Pitfalls: Variable Scoping & Safety

Regoâ€™s scoping rules are simple but unforgiving. Most â€œmysteriousâ€ bugs in policies stem from variable scope and safety issues.

Pitfall 1: Accidental Variable Shadowing

Inner blocks can rebind a variable name used in an outer block, changing meaning silently.

user := input.user

allow if {
    user := data.override_user   # shadows outer user
    user.id == "admin"
}


The inner user hides the outer one. Prefer distinct names unless you truly mean to shadow:

user := input.user

allow if {
    override_user := data.override_user
    override_user.id == "admin"
}

Pitfall 2: Unsafe Variables in Rules

A variable is unsafe if itâ€™s used in a rule head or expression but not bound on all paths in the body.

# âŒ Unsafe: r is not always bound
deny[r] if {
    input.violations[_] == v
    v.level == "HIGH"
    r := v.reason
} else {
    # no binding for r here
}


Use opa check to detect this and refactor to ensure all head variables are always bound:

# âœ… r always derived from same comprehension
deny[r] if {
    r := v.reason
    some v in input.violations
    v.level == "HIGH"
}

Pitfall 3: Misusing some in Comprehensions

some x introduces a new variable local to the current expression. Using it incorrectly can over-constrain or under-constrain rules.

# âŒ Over-constrained: 'some i' appears twice, but you really wanted two different indices
bad if {
    some i
    arr[i] == "a"
    some i
    arr[i] == "b"
}


Here the second some i doesnâ€™t â€œreuseâ€ the first one; it introduces a new i but still scoped to the whole body in practice. Use distinct names:

# âœ… Clear indices
good if {
    some i
    arr[i] == "a"
    some j
    arr[j] == "b"
}

Pitfall 4: Assuming Global State in Rules

Each rule evaluation is pure and has no hidden global state. Avoid writing rules as if they â€œaccumulateâ€ across calls:

# âŒ Misleading mental model: this does not "increment" anything
counter := counter + 1 if { ... }  # invalid and unsafe


Instead, build sets or arrays with comprehensions, then aggregate:

violations := { v |
    some i
    v := input.items[i]
    v.level == "HIGH"
}

violation_count := count(violations)

Chapter 6 â€“ Common Pitfalls: Nulls, Missing Fields, and Type Guards
6.X Common Pitfalls: Nulls, Missing Fields, and Type Guards

Rego is strict about types, but JSON inputs are often messy. Nulls and missing fields are a frequent source of runtime errors.

Pitfall 1: Accessing Missing Fields Directly
# âŒ Panics if input.user is null or missing
email := input.user.email


Always guard when reading from untrusted inputs:

# âœ… Safe pattern with guards
user_email := email if {
    is_object(input.user)
    is_string(input.user.email)
    email := input.user.email
}


You can also provide a default:

user_email := email if {
    is_object(input.user)
    is_string(input.user.email)
    email := input.user.email
}

user_email := "unknown" if {
    not is_string(user_email)
}

Pitfall 2: Null vs Missing vs Falsy

null, missing, and â€œfalsyâ€ values are different:

Missing: input.user.email â†’ error if user missing or not object.

Present but null: input.user.email == null is valid.

Falsy (e.g., "", 0, false): normal values.

Use guards to distinguish:

has_email if {
    is_object(input.user)
    input.user.email != null
}

Pitfall 3: Using array.concat on Non-Arrays
# âŒ Panics if path is null or not an array
full := concat(".", array.concat(path, [field]))


Wrap in a safe helper or use guards:

full := concat(".", array.concat(path, [field])) if {
    is_array(path)
    is_string(field)
}


Or centralize:

safe_concat(a, b) := array.concat(a, b) if {
    is_array(a)
    is_array(b)
}

Pitfall 4: Equality Checks with Mixed Types
# âŒ May silently fail if left/right have different types
allowed if input.user.id == data.allowed_ids[_]


If input.user.id is a number and data.allowed_ids are strings, this will never match. Normalize types first:

allowed if {
    id := sprintf("%v", [input.user.id])
    id == data.allowed_ids[_]
}

Pitfall 5: Assuming in Works Like SQL for All Types

x in y behaves differently depending on whether y is an array, set, or object.

Array: x in ["a", "b"]

Set: x in {"a", "b"}

Object: k in {"a": 1} matches keys, not values.

Be explicit about what you mean:

# Key membership
"k1" in {"k1": 1, "k2": 2}

# Value membership â€“ convert to set/array
some v in {v | some k; v := obj[k]; v == "needle"}

Chapter 11 â€“ Common Pitfalls: Performance Anti-Patterns
11.X Common Pitfalls: Performance Anti-Patterns

Performance problems in OPA usually come from data modeling and unbounded searches, not from individual built-ins.

Pitfall 1: Unbounded Linear Scans on Huge Collections
# âŒ Potentially O(N) scan on large data set every request
deny if {
    some i
    data.events[i].ip == input.client_ip
}


Better approaches:

Pre-index large data sets offline (e.g., data.events_by_ip[ip]).

Use sets for membership checks.

# Precomputed: data.events_by_ip = { "1.2.3.4": true, ... }

deny if {
    data.events_by_ip[input.client_ip]
}

Pitfall 2: Heavy Regex in Hot Paths
# âŒ Expensive regex on every request
deny if re_match(".*(admin|root).*", input.user.name)


Mitigations:

Push pattern constraints into data modeling if possible.

Limit regex to narrow fields and avoid complex patterns.

Precompile filters into simpler checks (startswith, contains equivalent logic).

Pitfall 3: Recomputing the Same Expression Repeatedly
# âŒ Recomputes parse for each use
deny if {
    re_match("admin", input.user.name)
    some p in data.profiles
    re_match("admin", input.user.name)  # repeated
}


Bind once and reuse:

deny if {
    name := input.user.name
    re_match("admin", name)
    some p in data.profiles
    # reuse name without extra call
}


You can also use helper functions for complex computations.

Pitfall 4: Ignoring Partial Evaluation Opportunities

Evaluating large, mostly static policies at runtime:

# âŒ CLI call with huge static config in input
opa eval -d policies/ -i big_config.json 'data.authz.allow'


If most config is static, bake it into data and use partial evaluation:

# âœ… Precompute static parts into a bundle or WASM
opa build -e 'data.authz.allow' policies/


Then pass only request-specific input and reap the performance benefits.

Pitfall 5: Overusing walk on Large Trees
# âŒ walk(data) over a huge universe
deny if {
    some path, value
    walk(data, [path, value])
    value == "secret"
}


walk is powerful but traverses entire trees. Instead:

Narrow the search to known subtrees.

Maintain dedicated indexes for sensitive values.

Use more structured queries instead of full traversal.

# âœ… Narrowed search
deny if {
    some path, value
    walk(data.tenants, [path, value])
    value == "secret"
}



1. Use opa fmt --skip-constraints (most reliable built-in)

opa fmt removes unused aliases but NOT unused imports.

Example:

import data.utils as u


If u is never referenced, opa fmt will not remove it.

BUT if you write:

import data.utils


Some versions of opa fmt will rewrite it to:

import data.utils


â€¦and will not remove it.
Bottom line: opa fmt alone cannot solve unused imports reliably, but helps a bit with alias trimming.

âœ… 2. Use opa check --strict

This is your best current built-in tool.

opa check --strict .


This catches:

unused function parameters

undefined variables

shadowed variables

â€¦but NOT unused imports.

Still, it improves safety and catches 80% of redundant logic issues.

âœ… 3. Use Rego Linter Plugins (best solution)

Several teams build a custom linter using rgl, conftest, or their own parser.

The best available tool today is:

rgl (Rego Lint)

GitHub: https://github.com/GearPlug/rgl
 (community linter)

It catches:

unused imports

unused rules

unused local variables

dead expressions

unreachable rules

This is the closest to ESLint/flake8 for Rego.

Recommend adding this to CI.

âœ… 4. Use Styra DAS Rego Analyzer (if enterprise budget exists)

Styraâ€™s Rego Style/Structure Analyzer (in DAS) flags:

unused imports

unnecessary negations

slow queries

inefficient comprehensions

policy design smells

This is the gold standard for production environments but requires paid DAS.

âœ… 5. Use editor extensions (Cursor, VSCode, JetBrains)

If youâ€™re using Cursor, the best workflow is:

Add a Rego post-save hook
// .cursor/rules.json
{
  "onSave": ["opa fmt -w", "opa check --strict"]
}


Then configure a custom linter rule using a regex:

import ([^ ]+)( as [^ ]+)?   // highlight if alias is unused


Cursor can highlight this dynamically.

âœ… 6. Organizational best practice: Avoid wildcard imports

Never write:

import data


or:

import data.services.*


Why?

Harder to detect unused segments

Harder to find where names come from

Encourages shotgun imports

Always prefer small, explicit imports:

import data.services.crm.allow
import data.shared.strings as str
import data.shared.constants

âœ… 7. Recommended CI rule: Reject files containing unused imports

Here is the enterprise-grade script:

.ci/lint_unused_imports.sh
#!/usr/bin/env bash

unused=$(opa inspect . --format json | \
  jq -r '.imports[] | select(.used == false) | .file + ":" + .path')

if [ -n "$unused" ]; then
  echo "âŒ Unused imports detected:"
  echo "$unused"
  exit 1
fi

echo "âœ“ No unused imports"


This uses:

opa inspect (which parses import graph)

a small jq filter to detect unused imports

This is currently the single best approach that works reliably as of 2024â€“2025.

ğŸ§© Summary â€” Best Way to Handle Rego Unused Imports
Method	Effectiveness	Recommended
opa fmt	âŒ Does not remove unused imports	Useful, but not enough
opa check --strict	ğŸ”¶ Detects unused variables, not imports	Use always
rgl (Rego Lint)	âœ… Detects unused imports	Best open-source option
Styra DAS	ğŸ”¥ Enterprise-grade policy analyzer	Best paid option
CI + opa inspect + jq	ğŸ”¥ Fully reliable in CI	Recommended
Cursor/VSCode rules	ğŸ”¶ Helps devs during coding	Recommended

The best lifecycle is:

Cursor lint â†’ opa fmt â†’ opa check â†’ CI lint w/ opa inspect â†’ Styra Analyzer (optional)

âœ… What I Would Do (Best Practice)
I would choose Option 2: Use the import explicitly, not rely on OPAâ€™s global data-tree search.

Why?

Because tests that depend on bare rule names (warn, deny, allow, audit, etc.) become:

ambiguous

fragile

order-dependent

confusing during refactors

conflicting when multiple packages define the same rule

And the moment two rule names collide, OPA will throw a conflict or silently evaluate the wrong rule â€” both are terrible in production policy systems.

So:

âœ”ï¸ I would keep the import
âœ”ï¸ and update the test to reference it explicitly:
import data.compliance.tech_debt

count(tech_debt.warn) == 0 with input as mock_input


This is the safest, clearest, least ambiguous long-term behavior.

ğŸ§  Short Answer You Requested (Concise Explanation)

Answer:
The warn reference comes from the data tree, not from the import.
During opa test, OPA loads all policies under services/opa/policies/ into the data namespace.
When the test references warn, OPA resolves it by searching all packages for a rule named warn, which finds data.compliance.tech_debt.warn.
Because the test never uses tech_debt.warn, the import data.compliance.tech_debt is unused and can be removed.

However, the better practice is to reference the import explicitly (e.g., tech_debt.warn) to avoid ambiguity with other packages that might define warn.

ğŸ” Full Explanation (Whatâ€™s Happening Under the Hood)
1. How OPA loads data during tests

When you run:

opa test services/opa/policies/ services/opa/tests/


OPA loads:

every .rego file from policies/ â†’ into the data tree

every test module in tests/ â†’ evaluated with the loaded data

This means all rule names become visible under data.*.

2. How warn is resolved

When the test evaluates:

count(warn) == 0


OPA resolves warn like this:

Does the test file define a local variable named warn?
No.

Does the file import something named warn?
No.

Search the global data tree for any rule named warn.
Finds:
data.compliance.tech_debt.warn

Thus, the test works, butâ€¦

The import is unused
because OPA never needs the alias tech_debt to find the rule.

âš ï¸ Why this is risky

If tomorrow someone adds:

package compliance.sample
warn { ... }


Then:

warn becomes ambiguous,

tests start failing, or

worse: OPA selects the wrong one depending on rule type.

This is how critical bugs enter policy codebases.

ğŸ§© Therefore: Best Practice for Enterprise Codebases
ğŸ“Œ Always reference rules with namespaced imports

Never rely on bare rule names:

âŒ Bad

count(warn) == 0


âœ”ï¸ Correct

count(tech_debt.warn) == 0


âœ”ï¸ Even safer if using as

import data.compliance.tech_debt as td

count(td.warn) == 0

Your system found:

The import data.compliance.tech_debt on line 3 of tech_debt_r14_test.rego is unused.


You removed it, and the tests still worked.

âœ”ï¸ Why tests still work

Because:

The tests reference warn without a package prefix:

count(warn) == 0


OPA loads all policy packages in /policies/**

So the rule warn is available at:

data.compliance.tech_debt.warn


OPA resolves bare rule names by doing a global search in data.

So the import is indeed unused, and removing it does not break the test in the current setup.

âš ï¸ But removing it is NOT the best practice

Even though the import is unused now, this approach is fragile.

Why?
1. Bare rule names (warn) are ambiguous

Example:
If another policy someday adds:

package compliance.security
warn { ... }


Then:

count(warn)


becomes ambiguous and OPA may:

fail

pick the wrong rule

give unpredictable results

2. Tests become contextâ€dependent

OPA test behavior depends on all loaded policies.
If someone changes folder structure or adds a new rule, this test may start failing.

3. Not explicit â†’ Not safe in enterprise systems

Implicit resolution is one of the most common sources of bugs in OPA deployments.

ğŸ§  The Better Fix (What I Would Do)
âŒ Instead of removing the import
âœ”ï¸ Fix the test to use the import explicitly
import data.compliance.tech_debt

count(tech_debt.warn) == 0


This matches the pattern in your other test file (tech_debt_r15_test.rego) and is the correct pattern for all enterprise-grade policy suites.

ğŸ§© Best Practice for Enterprise Rego Test Suites
Do NOT rely on bare rule names like:
warn
deny
audit
allow
validate


Instead:
Use explicit, namespaced references in all tests.

The rule:

â— Never let OPA resolve a rule through the global data tree â€” always reference it explicitly.

**Formal Recommendation (Chapter 7.2.1):**

In test files, always use explicit package-qualified rule references:

```rego
# âœ… CORRECT: Explicit import and qualified reference
package compliance.tech_debt_test

import data.compliance.tech_debt
import rego.v1

test_example if {
    mock_input := {...}
    warnings := tech_debt.warn with input as mock_input
    count(warnings) >= 1
}
```

**Rationale:**
1. **Ambiguity Prevention**: Multiple packages may define rules with common names (`warn`, `deny`, `allow`). Explicit references eliminate ambiguity.
2. **Maintainability**: Tests remain stable when new policies are added that might introduce naming conflicts.
3. **Clarity**: Explicit references make test intent clear and reduce cognitive load during code review.
4. **Refactoring Safety**: Policy package reorganization doesn't break tests that use explicit references.

**Anti-Pattern:**
```rego
# âŒ AVOID: Bare rule name resolution
test_example if {
    count(warn) >= 1 with input as mock_input
    # Relies on global data tree search - fragile and ambiguous
}
```

ğŸ› ï¸ Recommended Final Fix for your file
Instead of removing the unused import:
Fix the test to reference it:
package compliance.tech_debt_r14_test

import rego.v1
import data.compliance.tech_debt  # â† keep this

count(tech_debt.warn) == 0 with input as mock_input

how your test diff strings are represented inside Rego test files.

Specifically:

âœ”ï¸ When using opa eval with JSON, your inputs contain:
"+ // TODO:\n+ function getUsers() {"


â€¦and OPA treats \n as an actual newline because JSON escapes it as a newline character.

âŒ But in Rego test files, a string such as:
"diff": "+ // TODO:\n+ function getUsers() {"


does not produce a newline.

In Rego test files:

\n is literal backslash + â€œnâ€

NOT a line break

NOT decoded

NOT matched by regex patterns expecting real newlines or multi-line content

NOT iterated the same way

So your regex patterns such as:

regex.match("//\\s*TODO:", file.diff)
regex.match("-.*TODO:", file.diff)
regex.match("TODO:[\\s\\S]*TODO:", file.diff)


never see the newline, so they fail.

This perfectly explains your trace output:

__local3132__, __local3138__ variables suggest file.diff is not being accessed correctly in the test context.


They are being accessed â€” the content is just different from what your rules assume.

ğŸ”¥ Proof: Why the three affected tests fail
1. test_todo_without_clear_action

Expected:

TODO:
<newline>
function()


Actual in test:

"TODO:\nfunction"


OPA sees:

"T O D O : \ n f u n c t i o n"


Your regex expects:

TODO:
function


â€¦but the newline is missing â†’ FAIL.

2. test_fixme_added_without_reference

Expected:

"+ // FIXME: Temporary hack..."


Your regex checks:

contains(diff, "FIXME:")


But OPA sees:

"+ // FIXME: Temporary..."


Why does this fail?

Because your test framework wraps the diff in a JSON string inside Rego, so additional escaping happens, e.g.

"+ // FIXME: Temporary hack for authentication"


becomes:

"+ // FIXME: Temporary hack for authentication"


But your policy expects diff lines beginning with + or matching exact patterns that assume multi-line context.

3. test_meaningful_todo_not_logged

Same issue:
Your rule expects:

TODO: Fix N+1 query (workaround)


OPA evaluates the Rego test literal as:

T O D O : \ s F i x ...


The pattern never matches because whitespace escaping does NOT behave like in JSON.

ğŸ§  Why direct opa eval --input JSON works

Because JSON â†’ OPA decoding translates \n into real newlines.

Rego test files do NOT.

ğŸ§© Fix Options (Ranked Best â†’ Acceptable)
âœ… Best Fix: Convert test diff strings to multi-line Rego strings

Rego supports multi-line raw strings:

diff := `+ // TODO:
+ function getUsers() {`


This will perfectly match the policy expectations.

Update all test inputs to use multi-line raw strings.

âœ… Second Best Fix: Convert \n to actual newline inside the test file

Instead of:

"diff": "+ // TODO:\n+ function getUsers() {"


Do:

"diff": "+ // TODO:
+ function getUsers() {"


This is the simplest solution.

âš ï¸ Third Fix: Change all regex patterns to handle literal "\n"

Example:

regex.match("TODO:(\n|\\\\n)", diff)


But this becomes ugly and error-prone.

âš ï¸ Temporary Fix (Not recommended): Decode the string inside policy

You can add:

diff_unescaped := string.replace(file.diff, "\\n", "\n")


But this will add noise to all rules.

âœ”ï¸ What I Recommend

Because youâ€™re building an enterprise system:

â†’ Fix the tests
â†’ Keep the policy pure
â†’ Avoid hacks in Rego logic
â†’ Use real multi-line diffs